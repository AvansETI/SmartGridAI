{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n",
    "## Requirements\n",
    "- python 3.7\n",
    "- keras\n",
    "- tensorflow\n",
    "- scikit-learn\n",
    "- matplotlib\n",
    "- seaborn\n",
    "- pandas\n",
    "- numpy\n",
    "- wandb\n",
    "- plaidMl (optional, only required when using AMD GPU) | [https://github.com/plaidml/plaidml](https://github.com/plaidml/plaidml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- IMPORTS --\n",
    "\n",
    "# PlaidML Imports - disable if you make use of cudnn\n",
    "amd = False\n",
    "\n",
    "# -- DATA --\n",
    "\n",
    "datasets = {\n",
    "    0: ('data/sendlab/2019-ETI-EMON-V01-695FA5-1640EF.csv', '695FA5.hdf5'),\n",
    "    1: ('data/sendlab/2019-ETI-EMON-V01-C602ED-1640EF.csv', 'C602ED.hdf5'),\n",
    "    2: ('data/sendlab/2019-ETI-EMON-V01-C6007C-1640EF.csv', 'C6007C.hdf5')\n",
    "}\n",
    "\n",
    "# current_file determines which dataset will be used to train the model with.\n",
    "current_file = datasets[2]\n",
    "\n",
    "data_location = current_file[0]\n",
    "\n",
    "\n",
    "# determines whether we apply data analysis to the dataset.\n",
    "do_analysis = True\n",
    "\n",
    "# -- MODEL BUILDING --\n",
    "\n",
    "# no. hours to forecast\n",
    "n_forecasts = 8\n",
    "\n",
    "# determines how much data is used to forecast\n",
    "n_input = n_forecasts * 3\n",
    "\n",
    "# determines if the data will be scaled\n",
    "use_scaled = False\n",
    "\n",
    "# determines whether we're going to train or evaluate an existing model\n",
    "training = True\n",
    "\n",
    "# determines whether we're going to train a new model or continue training a existing model\n",
    "resume_training = False\n",
    "\n",
    "# sets filepath where model gets saved / loaded from if resume_training = True\n",
    "model_location = current_file[1]\n",
    "\n",
    "\n",
    "# -- HYPERPARAMETERS --\n",
    "\n",
    "epochs = 10000\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "verbose = 1\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "# determines after how many epochs the model gets saved (aka after each n-th epoch)\n",
    "n_checkpoint = 100\n",
    "\n",
    "activation_function = 'relu'\n",
    "\n",
    "\n",
    "\n",
    "# FORECASTING\n",
    "# seaborn chart sizes\n",
    "figure_width, figure_height = 14, 5\n",
    "\n",
    "# how many hours into the past should be displayed in the chart?\n",
    "history_length = 72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "wandb: WARNING Keras version 2.3.1 is not fully supported. Required keras >= 2.4.0\n",
      "wandb: Currently logged in as: insaine (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.12 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.11<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">sparkling-paper-141</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/insaine/smartgrid-lstm-open\" target=\"_blank\">https://wandb.ai/insaine/smartgrid-lstm-open</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/insaine/smartgrid-lstm-open/runs/24pijzu8\" target=\"_blank\">https://wandb.ai/insaine/smartgrid-lstm-open/runs/24pijzu8</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\moham\\JupyterProjects\\SmartGridAI\\Time Serie Prediction\\LSTM\\wandb\\run-20210111_150949-24pijzu8</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "if amd:\n",
    "    import plaidml.keras\n",
    "    plaidml.keras.install_backend()\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "    os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#     os.environ['PLAIDML_USE_STRIPE']='1'\n",
    "#     os.environ['PLAIDML_VERBOSE']='1'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(figure_width, figure_height)})\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Dropout, TimeDistributed, RepeatVector\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "if training:\n",
    "    wandb.init(project=\"smartgrid-lstm-open\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_supervised(train, n_input, n_output=8):\n",
    "    X, y = list(),list()\n",
    "    \n",
    "    X_start = 0\n",
    "    \n",
    "    # iterate over train dataset\n",
    "    for _ in range(len(train)):\n",
    "        \n",
    "        # set the ranges for input + output\n",
    "        X_end = X_start + n_input\n",
    "        y_end = X_end + n_output\n",
    "        \n",
    "        # check if data contains enough samples for sequence\n",
    "        if y_end <= len(train):\n",
    "            X.append(train[X_start:X_end, :])\n",
    "            y.append(train[X_end:y_end, 0])\n",
    "            \n",
    "        X_start += 1\n",
    "    assert len(X) > 0, \"Unable to transform given data into a supervised format. \\n train size: ({}), n_input+n_output: ({})\".format(len(train), n_input+n_output)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def build_model(data, n_input, params):\n",
    "    \n",
    "    # data preperation\n",
    "    train, val = data\n",
    "    X_train, y_train = to_supervised(train, n_input)\n",
    "    X_val, y_val = to_supervised(val, n_input)\n",
    "    \n",
    "    # meta / parameters\n",
    "    epochs, batch_size, verbose, learning_rate, n_checkpoint, model_location, resume_training, activation_function = params\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "\n",
    "    # reshape output\n",
    "    y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], 1))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], 1))\n",
    "    \n",
    "    \n",
    "    if resume_training:\n",
    "        model = load_model(model_location)\n",
    "    else:   \n",
    "        model = Sequential()\n",
    "        model.add(LSTM(48, activation=activation_function, input_shape=(n_timesteps, n_features)))\n",
    "        model.add(Dropout(.5))\n",
    "        model.add(RepeatVector(n_outputs))\n",
    "        model.add(LSTM(48, activation=activation_function, return_sequences=True))\n",
    "        model.add(Dropout(.3))\n",
    "        model.add(LSTM(48, activation=activation_function, return_sequences=True))\n",
    "        model.add(Dropout(.3))\n",
    "        model.add(TimeDistributed(Dense(48, activation=activation_function)))\n",
    "        model.add(TimeDistributed(Dense(48, activation=activation_function)))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        opt = Adam(lr=learning_rate)\n",
    "        model.compile(loss='mse', optimizer=opt)\n",
    "        \n",
    "    checkpoint = ModelCheckpoint(model_location, monitor='loss', verbose=1, save_best_only=True, mode='auto', period=n_checkpoint)\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data=(X_val, y_val), callbacks=[WandbCallback(),checkpoint], shuffle=False)\n",
    "    \n",
    "#     model.save(os.path.join(wandb.run.dir, \"model.h5\"))\n",
    "    \n",
    "    # plot the model\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def forecast(model, history, n_input):\n",
    "    data = np.array(history)\n",
    "    X = data[-n_input:, :]\n",
    "    X = X.reshape((1, X.shape[0], X.shape[1]))\n",
    "    yhat = model.predict(X, verbose=0)\n",
    "    yhat = yhat[0]\n",
    "    return yhat\n",
    "\n",
    "def visualize_forecast(history, validation, future, pred, future_pred, n_input, n_forecasts, history_length=48):\n",
    "    if n_input > history_length:\n",
    "        past = history[-history_length:-n_forecasts+1]\n",
    "    else:   \n",
    "        past = history[-n_input:-n_forecasts+1]\n",
    "    \n",
    "    future = future[-n_forecasts:]\n",
    "    validation = validation[-n_forecasts:]\n",
    "\n",
    "    validation.index = validation.index + pd.Timedelta(n_forecasts, unit='h')\n",
    "    future.index = future.index + pd.Timedelta(n_forecasts, unit='h')\n",
    "\n",
    "    future['Prediction'] = future_pred\n",
    "    validation['Prediction'] = pred\n",
    "    validation['Actual'] = history[-8:]['Actueel verbruik']\n",
    "    \n",
    "    sns.lineplot(data=past, x=past.index, y=\"Actueel verbruik\")\n",
    "    sns.lineplot(data=validation, x=validation.index, y=\"Actual\", color=\"lime\")\n",
    "    sns.lineplot(data=validation, x=validation.index, y=\"Prediction\", color=\"red\")\n",
    "    sns.lineplot(data=future, x=future.index, y=\"Prediction\", color=\"darkred\")\n",
    "    plt.legend(['Actueel verbruik (Past)','Actueel verbruik (Actual)','Actueel verbruik (Prediction)', 'Actueel verbruik (Future Prediction)'])\n",
    "\n",
    "    plt.title('Predictions of Actueel verbruik')\n",
    "    plt.xlabel('Timeline')\n",
    "    plt.ylabel('Actueel verbruik')\n",
    "    plt.grid(which='major', color=\"#ffffff\", alpha=.5)\n",
    "    plt.axvline(x=past.index[-1], color=\"green\", linestyle=\"--\")\n",
    "    plt.axvline(x=validation.index[-1], color=\"green\", linestyle=\"--\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(future)\n",
    "def to_datetime(timestamp):    \n",
    "    return np.datetime64(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\envs\\ztdl-updated\\lib\\site-packages\\ipykernel_launcher.py:111: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_location, index_col='Timestamp')\n",
    "data.index = data.index.map(to_datetime)\n",
    "data['Totaal vermogen ontvangen'] = data['Totaal vermogen ontvangen in tariff 1 in KWH'] + data['Totaal vermogen ontvangen in tariff 2 in KWH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 285 \n",
      "\n",
      "Number of rows (NaN excluded): 285 \n",
      "\n",
      "\n",
      "Days in dataset (after setting index):\n",
      "   2020-12-10 00:00:00\n",
      "   2020-12-11 00:00:00\n",
      "   2020-12-12 00:00:00\n",
      "   2020-12-13 00:00:00\n",
      "   2020-12-14 00:00:00\n",
      "   2020-12-15 00:00:00\n",
      "   2020-12-16 00:00:00\n",
      "   2020-12-17 00:00:00\n",
      "   2020-12-18 00:00:00\n",
      "   2020-12-19 00:00:00\n",
      "   2020-12-20 00:00:00\n",
      "   2020-12-21 00:00:00\n",
      "   2020-12-22 00:00:00\n",
      "\n",
      "Days with NaN's:\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0IAAAE/CAYAAABrfXNCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxTdb7/8XdKaaUCKZQuXAV0HAV/CLiMLJWWxbHIUinIUhdQRNQZsQ56RdSKXkBQ1Ivr9SpXcQNlGRbBGUCpLFLUwYcjoyKyFpGlawIFuqQ5vz8qGYGmSUrPSWhez8eDBz1Jzvl8kibfnk++y7EZhmEIAAAAAMJIRLATAAAAAACrUQgBAAAACDsUQgAAAADCDoUQAAAAgLBDIQQAAAAg7FAIAQAAAAg7FEIAAAAAwk5ksBM4EyUlR+V2cxkkAAAAACeLiLCpRYtzvd5/VhdCbrdBIQQAAAAgYAyNAwAAABB2KIQAAAAAhB0KIQAAAABhh0IIAAAAQNihEAIAAAAQdiiEAAAAAIQdCiEAAAAAYYdCCAAAAEDYOasvqAoAAFAXGzas1bp1Oafd7nQ6JEl2e2yN+/Xq1VcpKb3NTA2ARSiEAAAAfuVw1F4IAWg4bIZhGMFOoq6Kikrldp+16QMAgBAzbdpkSVJ29pQgZwLgTEVE2BQX19T7/RbmAgAAAAAhgUIIAAAAQNihEAIAAAAQdiiEAAAAAIQdCiEAAAAAYYdCCAAAAEDYoRACAAAAEHYohAAAAACEHQohAAAAAGGHQggAAABA2KEQAgAAABB2KIQAAAAAhB0KIQAAAABhh0IIAAAAQNihEAIAAAAQdiiEAAAAAIQdCiEAAAAAYYdCCAAAAEDYoRACAAAAEHYohAAAAACEHQohAAAAAGGHQggAAABA2KEQAgAAABB2KIQAAAAAhB0KIQAAAABhh0IIAAAAQNihEAIAAAAQdkwthEpLSzVo0CDt27fvtPu2bt2qoUOHql+/fnrsscfkcrnMTAUAAAAAPEwrhL799lvddNNN2rNnT433P/TQQ5o8ebJWrVolwzC0YMECs1IBAAAAgJOYVggtWLBATzzxhBISEk6775dfflFZWZkuv/xySdLQoUO1cuVKs1IBAAAAgJNEmnXgp556yut9+fn5io+P92zHx8fr0KFDAceIi2tap9wAAABqEhVVfWoUH98syJkAMJtphVBt3G63bDabZ9swjJO2/VVUVCq326jP1AAAQBirqKies1xQcCTImQA4UxERtlo7ToKyalxSUpIKCgo824WFhTUOoQMAAAAAMwSlEDrvvPMUHR2tr7/+WpK0bNkypaamBiMVAAAAAGHI0kJo3Lhx+te//iVJeu655zRjxgxdf/31OnbsmEaPHm1lKgAAAADCmM0wjLN2kg1zhAAAQH2aNm2yJCk7e0qQMwFwpkJyjhAAAAAABBOFEAAAAICwQyEEAAAAIOxQCAEAAAAIOxRCAAAAAMIOhRAAAACAsEMhBAAAACDsUAgBAAAACDsUQgAAAADCDoUQAAAAgLBDIQQAAAAg7FAIAQAAAAg7FEIAAAAAwg6FEAAAAICwQyEEAAAAIOxQCAEAAAAIO5HBTgAAAAAIhg0b1mrdupzTbnc6HZIkuz22xv169eqrlJTeZqYGC1AIAQAAAL/hcNReCKFhoBACAABAWEpJ6V1jz860aZMlSdnZUyzOCFZijhAAAACAsEMhBAAAACDsUAgBAAAACDsUQgAAAADCDoUQAAAAgLBDIQQAAAAg7FAIAQAAAAg7XguhDz/8UAcPHrQyFwAAAACwhNcLqubk5OjZZ5/Veeedp969e6tXr1664oorFBFBJxIAAAh97703R3l5uwPaJy9vj6R/X1DTX+3aXahRo8YEtA+A4PJaCL3xxhuqqqrSt99+q02bNumFF17Qnj171LVrV/Xu3Vvp6elW5gkAABCQvLzd+mnXbkXHtfF7H1dU8+p9nS6/9ykv+jng3AAEn9dCSJIaNWqkK6+8UldeeaUyMzO1ceNGvfXWW1q9ejWFEAAACHnRcW3UdvBEU2PsXTbT1OMDMEethdB3332nnJwcrVmzRkVFRUpJSdE999yjnj17WpUfAAAAANQ7r4VQr169FBcXp969e2vKlCnq3LmzbDablbkBAAAAgCm8rnyQlJQkh8OhwsJCFRcXq6Kiwsq8AAAAAMA0XnuE5s+fr+LiYq1bt05LlizRY489pk6dOql3797q06ePkpKSrMwTAAAAAOpNrWtht2zZUkOGDNFLL72kdevWKSMjQx9++KH69OljVX4AAAAAUO9qXSzh8OHD+sc//qGvvvpKX331lQoLC5WcnKy77rrLqvwAAAAAoN55LYSGDBmiHTt26LLLLlNKSoqmTp2qyy67LKCDL1++XK+99ppcLpduu+023XLLLSfd//3332vy5MmqrKxU69at9eyzz6p58+Z1eyYAAAAA4CevhdDYsWOVkpIiu91+2n1Hjx7VueeeW+uBDx06pFmzZmnx4sWKiopSZmamunXrpt///veexzz11FPKyspSr1699PTTT+vNN9/UhAkTzuDpAAAAAIBvXucI/fOf/6yxCNq5c6eGDx/u88C5ubnq3r27YmNjFRMTo379+mnlypUnPcbtduvo0aOSpOPHj+ucc84JNH8AAAAACJjXHqFNmzZp9uzZGjdunOe2Tz/9VA8//LAyMjJ8Hjg/P1/x8fGe7YSEBG3ZsuWkx0yaNEl33HGHpk+friZNmmjBggUBJR8X1zSgxwMAgPARFRUpyWVZrPj4ZpbEgvmq3zvid9rAeS2E3nrrLd18881KTEzUDTfcoP/+7//WBx98oKlTp2rAgAE+D+x2u0+6AKthGCdtl5WV6bHHHtPbb7+tzp07a86cOXr44Yf1xhtv+J18UVGp3G7D78cDAIDwUVFhTRF0IlZBwRHL4sFcJ947/E7PbhERtlo7TrwWQomJiXrrrbd02223ad68eSorK9PChQt1wQUX+BU4KSlJmzdv9mwXFBQoISHBs/3TTz8pOjpanTt3liSNHDlSL774ol/HBgAAAIAzUet1hNq1a6f//d//1a5du5Sdne13ESRJycnJ2rRpk4qLi3X8+HGtXr1aqampJx374MGD2rVrlyRpzZo16tSpU92eBQAAAAAEwGuP0OrVqz0/DxkyRFlZWXr00UcVFRUlSUpLS6v1wImJiZowYYJGjx6tyspKDRs2TJ07d9a4ceOUlZWlTp06acaMGfrLX/4iwzAUFxen6dOn19PTAgAAAADvvBZC77333knbF110kebPny9JstlsPgshSUpPT1d6evpJt82ePdvzc69evdSrV6+AEgYAAACAM+V3IQQAAAAADUWtc4QAAAAAoCGiEAIAAAAQdiiEAAAAAIQdr3OEfuuXX36R0+mUYfz74qUdO3Y0LSkAAAAAMJPPQujFF1/UW2+9pbi4OM9tNptNa9asMTUxAAAAADCLz0Jo2bJlWr16tRITE63IBwAAAABM53OOUOvWrSmCAAAAADQoPnuEevTooZkzZ+raa6/VOeec47mdOUIAAAAAzlY+C6HFixdLklauXOm5jTlCAAAAAM5mPguhnJwcK/IAAAAA8KuSkhK9+uosjR8/QbGxLYKdToPktRCaPXu2xo0bp2nTptV4f3Z2tmlJAQAAAOFs6dKF2rZtq5YsWaQxY8YFO50GyetiCc2aNZMkxcbG1vgPAAAAQP0rKSnR+vWfyTAMrV//mRyOkmCn1CB57RHKzMyUJI0fP96yZAAAAIBwt3TpQhmGIUkyDDe9QibxuXw2AAAAAOvk5m6Qy+WSJLlcLuXmrg9yRg0ThRAAAAAQQpKTUxQZWT1wKzIyUsnJqUHOqGGqUyF05MiR+s4DAAAAgKSMjOGy2WySJJstQkOGDAtyRg2Tz+Wzn3/+eT344IOe7Y0bN+qxxx7T2rVrzcwLAAAACEstWrRQamof5eR8otTUPqYun71hw1qtW3f65XKcTockyW6veZG0Xr36KiWlt2l5WcFnIfTNN9/ozTff1KhRozRz5kytXLlSTzzxhBW5AQAA1JnT6VB5UYn2Lptpapzyop/lFNd5Qf3KyBiuX37ZF7TeIIej9kKoIfBZCL3xxhsaO3as5s6dq86dO2v58uVq0YIPOwAAAGCWFi1aKDt7iulxUlJ619izM23aZEmyJIdg8VoIff/9956fs7KyNHHiRHXr1k379+/X/v371bFjR0sSBAAAqAu7PVYONVXbwRNNjbN32UzZ7T6/WwYQYrx+au+7776Tths3bqzZs2dLkmw2m9asWWNuZiYqKSnRq6/O0vjxE0wdcwkAAAAgNHkthHJyTp801VDMn/++fvzxB3344Vzdcw8XjAUAAADCjddCaPbs2Ro3bpymTZtW4/3Z2dmmJWWmkpISbdxYfVGqjRvXKzPzFnqFAAAAgDDj9TpCzZo1kyTFxsbW+O9sNX/++zIMQ5JkGG59+OHcIGcEAAAAwGpee4QyMzMlSePHN6yhY5s2fX7K9gaGxwEAAABhxucSJ+np6TXevnz58npPBgAABA+LCaEheu+9OcrL2x3QPnl5eyT9ewlpf7Vrd6FGjRoT0D4IHp+F0OOPP+75ubKyUh9//LHatGljalJm6tGjpz7/fJ1nOzk5JYjZAAAQOpYuXaht27ZqyZJFGjNmXLDTAepFXt5u5e3YozbN2/q9jz3CLkly57v93ufnw3sDzg3B5bMQ6tq160nbycnJyszM1J/+9CfTkjLTyJG3Kjd3g9xutyIiIjRy5C3BTgkAgKArKSnR+vWfyTAMrV//mYYMGUavEBqMNs3b6sFuj5ga4/kvZ5h6fNQ/r4sleFNSUqL8/HwzcrFEixYtPL1A11yTSiMPAICqe4N+u5jQkiWLgpwRAJgr4DlC+/fv18iRI01LyAojR96qwsICeoMAAPhVbu4GuVwuSZLL5VJu7nqGxwFo0HwWQg8//LCioqIkSTabTS1bttRFF11kemJmatGihbKzpwQ7DQAAQkZycorWrcuRy+VSZGSkkpNTg50SAJjK59C4Z599Vl27dlXXrl119dVXn/VFkFQ9vG/atMlyOEqCnQoAACEhI2O4bDabJMlmi9CQIcOCnBEAmMtnIdSkSRMdPHjQilws89tVcQAAQPVoidTUPrLZbEpN7cMcWgANns+hccePH9e1116rpKQkxcTEeG4/W68jxKo4QGjhuiVA6MjIGK5fftlHbxCAsOCzEHrsscesyMMyNa2Kw2RQIHi4bgkQOphDCyCc+Bwa17VrV8XFxemnn37Srl27lJiYeNq1hbxZvny5BgwYoLS0NM2dO/e0+3ft2qVRo0bphhtu0NixY+V0OgN/BgGqaVUcAMFxag8t8/YAAIBVfBZCf/3rXzV69Ght2bJFmzdv1i233KJVq1b5PPChQ4c0a9YszZs3T0uXLtX8+fO1Y8cOz/2GYehPf/qTxo0bp48++kiXXnqp3njjjTN7Nn5ITk5RZGR1Rxir4gDBxXVLAABAsPgcGvf2229ryZIlSkhIkFR9HaG7775b/fr1q3W/3Nxcde/eXbGxsZKkfv36aeXKlRo/frwk6fvvv1dMTIxSU6sLkXvuuUeHDx8+oyfjj4yM4Vq//jNJrIoDBBvXLQEAAMHisxBq3LixpwiSpP/4j/9Q48aNfR44Pz9f8fHxnu2EhARt2bLFs7137161atVKjz76qLZu3arf/e53evzxxwNKPi6uaUCPl6T4+Gbq16+fPv74Y/Xrl6aLL24b8DEA1I9rr71WK1eu9Fy35Nprr1V8fLNgpwWggYiKipTksiwW7VdoioqKVJkqLIvVUN4H1Z8fNZjnUxOvhdD3338vSWrfvr2mTJmikSNHqlGjRlq8eLGuvPJKnwd2u92e6xFI1UPhfrvtcrn01Vdf6f3331enTp30wgsv6Omnn9bTTz/td/JFRaVyuw2/H39Cv36DtWPHLl1//WAVFBwJeH8A9aNfv8GeobY2WwSfSQD1qqLCmiLoRCzar9DE+6BuTrxuZ/PziYiw1dpx4rUQuu+++07aXrt2rednm82m7OzsWgMnJSVp8+bNnu2CgoKTepbi4+PVrl07derUSZI0aNAgZWVl1XrM+sKqOEBoOHHdkpycT7huCQAAsJTXQignJ0eS9Omnn+qPf/xjwAdOTk7Wyy+/rOLiYjVp0kSrV6/W1KlTPfdfccUVKi4u1o8//qgOHTooJydHHTt2rMNTAHA247olAAAgGHzOEZo1a1adCqHExERNmDBBo0ePVmVlpYYNG6bOnTtr3LhxysrKUqdOnfTqq68qOztbx48fV1JSkmbOnFmnJwHg7EUPLQAACAafhdAll1yi1157TX/4wx8UExPjud2f3pv09HSlp6efdNvs2bM9P3fp0kWLFrFcLgAAAABr+SyEvv32W3377bdauHCh5zabzaY1a9aYmhgAAAAAmMVnIXRirhAAAAAANBQRvh5w9OhRTZkyRbfddpscDocmT56so0ePWpEbAAAAAJjCZyE0bdo0NWvWTEVFRYqOjlZpaakmT55sRW4AAAAAYAqfhdDWrVs1YcIERUZGqkmTJnruuee0detWK3IDAAAAAFP4LIQiIk5+SFVV1Wm3AQAAAMDZxOdiCVdffbWeffZZlZWVacOGDZo7d666detmRW4AAAAAYAqfXTv/+Z//qZiYGDVr1kyzZs1S+/btNXHiRCtyAwAAAABT+OwR+uKLL3Tvvffq3nvvtSIfAAAAADCdzx6hl19+WX379tX//M//6NChQ1bkBAAAAACm8lkILViwQLNnz9bRo0c1YsQI3X333fr000+tyA0AAAAATOHX8m8XXXSRHnroIb388ssqKSnRAw88YHZeAAAAAGAan3OEioqK9NFHH2nJkiWqqqrSsGHD9Prrr1uRGwAAAACYwmchlJaWprS0NE2ePFl/+MMfrMgJAAAAAEzlsxBat26dmjZtakUuAAAAAGAJn3OEKIIAAAAANDR+LZYAAAAAAA0JhRAAAACAsON1jtCcOXNq3XHMmDH1ngwAAACCq6SkRK++Okvjx09QbGyLYKcDmMZrIfTTTz9ZmQcAAABCwNKlC7Vt21YtWbJIY8aMC3Y6gGm8FkIzZsw4afvw4cNq3ry56QkBAAAgOEpKSrR+/WcyDEPr13+mIUOG0SuEBsvnHKHdu3drwIABGjhwoA4dOqT+/ftr586dVuQGAEBYKSkp0bRpk+VwlAQ7FYSppUsXyjAMSZJhuLVkyaIgZwSYx2chNHXqVD322GOKi4tTYmKibr31Vk2ePNmK3AAACCu/HZIEBENu7ga5XC5JksvlUm7u+iBnBJjHZyHkcDh0zTXXeLZvueUWlZaWmpoUAADh5tQhSfQKIRiSk1MUGVk9cyIyMlLJyalBzggwj1/LZ5eXl8tms0mSCgoK5Ha7TU0KAIBww5AkhIKMjOGecz6bLUJDhgwLckaAeXwWQjfffLPGjh2roqIiPf/88xo5cqRuuukmK3IDACBsMCQJoaBFixZKTe0jm82m1NQ+LJSABs3rqnEnDBs2TO3atdPatWvlcrk0derUk4bKAQCAM5ecnKJ163LkcrkYkoSgysgYrl9+2UdvEBo8n4WQJLVp00Zdu3bVNddco/z8fLNzAgAg7GRkDNf69Z9JYkgSgqtFixbKzp4S7DQA0/kcGrd27VplZmbqv/7rv1RcXKyBAwfq008/tSI3AADCBkOSAMBaPguhV199VQsWLFDz5s2VkJCgefPm6aWXXrIiNwAAwkpGxnC1b38pvUEAYAGfQ+OqqqqUkJDg2b700ks9q4kAAID6w5AkALCOzx6hJk2aaP/+/Z7iZ/PmzYqOjjY9MQAAAAAwi88eoQcffFB33HGHCgoKNHLkSO3Zs0cvv/yyFbkBAAAAgCl8FkJXXnmlFixYoG+++UZut1tdunRRy5YtrcgNAICwUlJSoldfnaXx4yewWAIAmMzn0Ljvv/9eP//8s1q1aqWEhAQdOHBA33//vRW5AQAQVpYuXaht27ZqyZJFwU4FABo8nz1C9913n+fnyspKFRQU6LLLLtOiRTTSAADUl5KSEq1f/5kMw9D69Z9pyJBh9AoBgIl89gjl5OR4/m3YsEHvvPOOOnTo4NfBly9frgEDBigtLU1z5871+ri1a9eqb9++/mcNAEADs3TpQhmGIUkyDDe9QgBgMp+F0Km6devm19C4Q4cOadasWZo3b56WLl2q+fPna8eOHac9rrCwUM8880ygaQAA0KDk5m6Qy+WSJLlcLuXmrg9yRgDQsPk1R+jEv++++04ffvihysrKfB44NzdX3bt3V2xsrGJiYtSvXz+tXLnytMdlZ2dr/PjxdcseAIAGIjk5RZGR1SPWIyMjlZycGuSMAKBhC2iOkM1mU1xcnJ588kmfB87Pz1d8fLxnOyEhQVu2bDnpMe+++67+3//7f+rSpUsAKf9bXFzTOu0HAECoGTv2dm3YsFaSFBERoTvvvF0tWzYLZkpnvaioSEkuy2LFx/P7CkVRUZEqU4VlsRrK+6D686MG83xq4rMQmjdvnpKSkk66raYhbqdyu92ei7BKkmEYJ23/9NNPWr16td5++20dPHgwkJw9iopK5XYbddoXABA6WDZakqKUktJbOTmfKCWlj6qqGqug4EiwkzqrVVRYUwSdiMXvKzTxPqibE6/b2fx8IiJstXaceB0a53A45HA4dNddd8npdMrhcMjpdKqwsNCvoWxJSUkqKCjwbBcUFCghIcGzvXLlShUUFOjGG2/UXXfdpfz8fN18883+Pi8AQAPCstHVMjKGq337SzVkyLBgpwIADZ7XHqEHH3xQGzdulFS9QMIJjRo10vXXX+/zwMnJyXr55ZdVXFysJk2aaPXq1Zo6darn/qysLGVlZUmS9u3bp9GjR2vevHl1fiIAgLMTy0b/W4sWLZSdPSXYaQBoYN57b47y8nYHtE9e3h5J0rRpkwPar127CzVq1JiA9gkWr4XQm2++KUl65JFHNGPGjIAPnJiYqAkTJmj06NGqrKzUsGHD1LlzZ40bN05ZWVnq1KlT3bMGADQYNS0bPWbMuCBnBQANR17ebu3dsVNtmyf5fvCvYiOaVP+Qf9TvffYertt0l2DxOUfo/vvv15NPPqknn3xSu3bt0nPPPacpU6aoVatWPg+enp6u9PT0k26bPXv2aY87//zzlZOTE0DaAICGoqZloymEAKB+tW2epEe7m9tTM/2LOaYev775XD570qRJ+t3vfidJOu+889S1a1c98sgjpicGAAgPLBsNAAgGn4VQSUmJRo8eLUmKjo7W7bffftIiCAAAnImMjOGeVUVttggWCgAAWMJnIVRVVaVDhw55tgsLCz1juQEAOFMtWrRQamof2Ww2pab2CduFEgAA1vI5R+j2229XRkaGUlJSJEmbNm3SxIkTTU8MABA+MjKG65df9tEbBACwjM9CaNiwYbrsssv0xRdfqFGjRmrbtq3efffd0xZBAACgrlg2GgBgNZ+FkCS1bt1aFRUVmjt3ro4dO6ZRo0aZnRcAAAAAmKbWQmjXrl1655139NFHH+m8885TWVmZcnJy1KxZM6vyA1APNmxYq3Xral6i3ul0SJLs9tjT7uvVq69SUnqbmRoAAEBQeF0s4a677tKtt96qxo0b691339WKFSt07rnnUgQBDYzD4ZDD4Qh2GgAAAJby2iP0ww8/qGPHjrr44ovVrl07SfIsbwrg7JKS0ttrz860aZMlifkZAAAgrHjtEVq7dq2GDBmiFStWqGfPnsrKylJ5ebmVuQEAgDBTUlKiadMmy+EoCXYqABo4r4VQZGSkBgwYoPfee0+LFy9WQkKCysvLlZaWpg8++MDKHAEAQJhYunShtm3bqiVLFgU7FQANnM8LqkrS73//e2VnZ2v9+vUaO3asFixYYHZeAAAgzJSUlGj9+s9kGIbWr/+MXiEApvKrEDqhSZMmGjlypJYsWWJWPgAAIEwtXbpQhmFIkgzDTa8QAFMFVAgBQEPEnAQgNOTmbpDL5ZIkuVwu5eauD3JGABoyCiEAYY85CUBoSE5OUWRk9YK2kZGRSk5ODXJGABoyCiEAYY05CUDoyMgY7rlUh80WoSFDhgU5IwANGYUQgLDGnAQgdLRo0UKpqX1ks9mUmtpHsbEtgp0SgAaMQghAWGNOAhBaMjKGq337S+kNAmC6yGAnAADBlJyconXrcuRyuZiTAISAFi1aKDt7SrDTMN2GDWu1bl1Ojfc5nQ5Jkt0ee9p9vXr1VUpKbzNTA8IGhRCAsJaRMVzr138miTkJQCgoKSnRq6/O0vjxE+plaFx50c/au2ym3493HTssSYqMaR5QDNkvDDg3bxwO74UQgPpDIQQgrJ2Yk5CT8wlzEoAQ8NtVHMeMGXdGx2rXLvDiJM9RXQi1a93S/53sFwYcKyWlt9eenWnTJktSWPSMAcFEIQQg7GVkDNcvv+yjNwgIslNXcRwyZNgZfTkxatSYgPehCAHCB4slAAh7J+Yk0BsEBBerOAKwEj1CAADLeJsgXtvkcIkJ4uGiplUcz3R4HAB4Q48QACDoHA6HZ4I4wldycooiI6u/o2UVRwBmo0cIAGAZbxPEmZcBiVUcAViLQgiAJRgSBcAXVnEEYCUKIQBBxfUyGp733pujvLzdAe2Tl7dH0r97hvzVrt2FdVoZDKGLVRwBWIVCCIAlGBIVPvLyduvHXdulOLv/O0VVT1n90Znv/z5FzgAzw9ngxCqOAGA2CiEgiOr7CupAyIizKzK9l6khXMvXmXp8AEDDRiEEBFF9XkFdYkgSAACAvyiEgCCp7yuoS9VDknbu/EH2AA7T6NdWoLD4B7/3cZYEmFgI8LZYg1T7gg0s1gAAQMNEIQQESU1XUK+PXiF7Cyk17YwPU6v1q809vtVYsAGAWeipB0IXhRAQJFxB3VreFmuQWLABgHny8nZr5649io1r6/c+kVHVC40UOd1+7+Mo2htwbkC4oxACgiQ5OUXr1uXI5XJxBXUAaMBi49qq9w2PmRpj7UdPmXp8oCGKCHYCQLjKyBgum80miSuoI/hKSko0bdpkORxn4QQwAADqwNRCaPny5RowYHmTN4cAACAASURBVIDS0tI0d+7c0+7/9NNPNXjwYN1www3685//LKeTa0IgfJy4grrNZuMK6gi6365gCABAODBtaNyhQ4c0a9YsLV68WFFRUcrMzFS3bt30+9//XpJUWlqqJ598Un/961+VmJioF198US+//LKys7MDilPbJESn0+GZBB2I2NjYGidNMwkR9Y0rqCMU1PcKhk6nQypymH+dnyKHnIoyNwYA07CaJ4LNtB6h3Nxcde/eXbGxsYqJiVG/fv20cuVKz/2VlZV64oknlJiYKElq3769Dhw4EHCcvLzd2rtju1RQdPq/I6VSZWXg/46UnnasvTu2B7zqC+DLiSuo0xuEYKppBUMACCaHo25fZgOBMK1HKD8/X/Hx8Z7thIQEbdmyxbPdokULXXfddZKksrIyvfHGGxo1alRAMeLimioqKlJt7S2VnWLuesHTNqxWVFSk4uObmRoHOBNRUdatf1Jfn4cTOQfzsxUKOQTTpk2fn7SC4aZNGzRx4gN1Pl58fCsdUIUi03vVV4o1ci1fp/j4VvX2eysqKtKMGTP06KOPqmXLlvVyTJx96rs9qD5eRb0cy59YgeT9ySefaPXq06+HUFxcLElePwdpaWmec7gzMXRouoYOTa/xvoceekiS9Oyzz55xnKioSJWF6O/AKlFRkRa9AqH7GtTEtLMmt9vtmQguSYZhnLR9wpEjR3TvvfeqQ4cOGjJkSEAxiopKVVHhOuNc/VVR4VJBwRHL4gGBOhs/DydyDuZnKxRyCKYePXqetIJhjx4pZ/RanI3vQ0maM+dtfffdd/q//3ubpezDWH23B6H8eThypKzG/IqKqguhpk2be93P7PayPn8Pofw7sEq4vgYRETbFxTX1er9phVBSUpI2b97s2S4oKFBCQsJJj8nPz9fYsWPVvXt3Pfroo2alAoQNp9MhR4n5Fzx1lEiNGzFkoaHIyBiu9es/kxS+KxjW9zwp4Gzg7fpq9X1tNS4qi1BlWiGUnJysl19+WcXFxWrSpIlWr16tqVOneu6vqqrSPffco/79++vPf/6zWWkAAHw4sYJhTs4nYbuCYU3zpBpyr5C3Seq1TVCXGtYkdW+vga8T8LPtNQiFIiQvb7f27NyjpFj/Lyp7bmT1RWXLivy/qOxBx9l3UVkWjAgu0wqhxMRETZgwQaNHj1ZlZaWGDRumzp07a9y4ccrKytLBgwf1ww8/qKqqSqtWrZIkXXbZZXrqKS4IBtSV3R6ryqr9SjV3ypzWr/Z+ooSzU7ivYJibu+GkeVK5uesbdCHkzYnJ6WZ/vkP55C82tmG1bXl5u7Vr1x7Ft2zn9z7nRFUXIUccht/7FBTn1Xp/Umxb3XmtuReV/b81Desc0qrPYzgzdWZ1enq60tNPngQ3e/ZsSVKnTp30448/mhkegMVC4ZtH1M2JFQzDVXJyyknzpJKTU4OdkqmsGhJVF1ad/Hl7DRqi+JbtNHxAYJcnCdTCv00z9fgNVW3vw1D4PDZ01i0xBaDBy8vbre27flDTQBbc+vUyMAccP/i9S2lxYHkBvjBPylqc/AEIBRRCAOpV05ZSlwHmxvj2b+YeH+GHeVIAEH4ohAAA9a/IKdfydf4//lhZ9f8x5wQUQ/YE34/zU7jPk4I5nE6HHEUlWvuRufNXHEV5ihQFfKhi6HhoohACANSrdu0uDHifPMee6n1bB1DY2BPqFMubcJ8nBfO4KsvlKKp9MYHfcldVSZIiGjUKKEaocjodKnaUmL6YwQFHnlpGhmYxmJe3W3t37FbbZuf5vU+s7dfr3xzy/1Koe4/8EmhqYY1CCABQr+ryTSTzQtBQde58hez2uvUEtGt3QUD71fTFgNPpUFGRw/TFDAqK8uS2sbpZbdo2O0+PXH2fqTFm/ONlU4/f0FAIAQAAUzAciC8GpOoVAKNdzS1ZPvsce4SpMdCwUAgBaFA48QJCR17ebv24a5caxbX2ex93VIwkabvzuN/7VBUdCDi3cGG3xyrCsFuyfHYzu83UGHXldDrkOFyi57+cYWqcnw/nKTY6NIfmoWYUQgAalLy83dq26wc1jvN/n6pfl/De5fR/Ce/KogATA8JUo7jWikm/y9QYx5a/YerxATRMFEIAGpzGcVKrweZ+M1m4zP8rrgNAMBUU5wU0R+jY8eqL2sY08X/OT0FxnprFXhBoapaw22PVrLy5Huz2iKlxnv9yhiIYmndWoRACAABooOqysmKx0ylJSmzt/zCvZrEX1Osqjg2N0+mQ40ix6YsZ5B3Zp9hzArmqeXijEAIAi2zYsFbr1uWcdrvTWf3tq91e87evvXr1VUpKb9Pi+8qhvuIj/DidDlUVFZs+dK2q6ICcOrtO/mr7PNY2bzHQz2OoLNZw0LE3oOWzS8uqi7Gm59gDinFB3AWBpoYwRiEEAEHmcNReCIVLDlYIp2KQhUPOXrGxDetzWJeeokN51YVQqzj/e6UuiAvdXim7PVbOgpKA9nGWH67eN7q53/vYZDvr2vG6tsvSmbfNFEIAYJGUlN41NthWLZXrLb6VOYSyhlYMVq/YtlMRcf5fpNaIOkeS9JPziN/7uIvyvd5nt8cqX9GWLJZgtzcxNUZ9q+3zaBVvJ6C+CuL66pWq7QS4NnU5+f358N6AVo07XF5diDWP9r9H6ufDe9Uu4YIa76tLgebIK5Uk2RNb+b1P28QLQ7YYrAuz22UKIQCoR3wLH9rCrRiMiEtQ9KCbTI1RvuIDU48P64VCj1R95lCXwsD5a49UbIL/PVLtErz3SAV7iGL1EuJFmv7FnDM+Vm3yDh9UbHQAy7YquO0yhRAA1KPqb+F/lFqd4/9O0S5J0o+H9/i/T2FZYIkBwCmC3StlVfzaihAre6UQeiiEANQbp9Oh0iLp27+ZG6e0SHLaHOYGOROtzlGjwb8zNUTVsl2mHv9sR88cgDMRCr1i9cluj5W9vLEe7W5uWzX9izmS/VxTY9QnCiEAQINT3TO3XbY4/1cSM6Kq/yRuc/p/tVyjqDjg3MJpwQYg1AW7V8yq1QMlae/hgwENjXOW/zpHKbppQDHaJlwUUF7BRCEEoN7Y7bE6ZuxXlwHmxvn2bw1nQjvMY4trqchB/UyN4Vqxqsbba+uRcjodngnApyovrx7yWNP9H3202OsJE71SQMMT7HlSjrwCSZI9IdHvfdomXOQ1Vij21FMIAQAaHKfTIaOo2GuhUl+MomI51ei026t7pHbIFudltScvJzjGsWOSpLKYmNPuOyjpoPP0AskoKvQ/YQAhJRTmSXlT3wsV5OXt1t4dO9TWHu/3PrGNoqt/KHD6vc9eZ4Hfj6UQAlCvSosDmyNUcbz6/6gAVr4tLZbk5Ysyp9OhyiKpcJnh/wHroLJIcur0k1Kn0yEVlZk/h6ewTE6j5l6FUPzWLRzZ4lqp8aDBpsepXLGsxtudTofcRUWmr+rmLsqXU1WmxgDQMLS1x+ux5OGmxngqd6Hfj6UQAlBv6tL1nufcI0lq3foC/3eKrVuscFHdG/GTFOf/uG5FVf/3o3O///sUlQaWmIXs9lgdVJUlQ+MYpgkAZycKIQD1JhS63u32WBVpv1oNttXL8bwpXGbUeAJst8fqgM1hyapx9ua1nIDHNVXk4D+YmoNr2WZTj382qx6aV+i1t6Y+GUWFqmnQiN0eq0NqZMl1hOz2ZqbGAAAzUAgBFvC2KkxtK0RJdVsVxlkirV/t/+PLfh2adk4AQ9OcJVIr/xfjAhDGqooO6NjyN/x+vPvYEUlSRIz/xVVV0QHJbu6XDwAaHgohE4XCEqlWnoAHEt/KHELZiZWh6mtoTZ2Gpv06N6RVywv83qdVS4amhbLqeUpHzO+xKTpS4zwpnBiaJ8vmCIXq8Lw6tUmOQ9X7tk7wfyf772iTgBDndDrkcBYGNIenLvKcBYqN8m+e8FlfCFW/qMWatiGAr8DrIM9ZrNio01cGkrxPTA7lJVLr+wS8vl8DyfvrEOhrYFVBWpcJ6r6sW5cT0GsQCkPTvPH2e/A1Sb8uBXGgiyVUVS/UpUanL9RVawzZvdxZGOBiCcdc1f/HBNAkF5ZJzf1/eKiw8n0QbHUZGndi1ThbDavG1RZHXtpyd1F+QIslGMeO/hrf/wsiuovyJS9D47y1SbW1y7U5G98HQKgLp3b5VGd9IRQKqpcD/Elt7SdPTLZLssdE1biP89eayh5dw/0Vx6SCY6fdvNdZ88Tkp5+eqp07tweU84ki5MSb/FTvvvuW3n33rdNuv+iiizVp0uOn3b5lyzc6eHC/vNSKNYr49X935enPVZKKC46puODkidsVVSeKl9P/uAa7IM3L261dO39QywBqy1+v3yhH0Q9+71PcwL6Ar++rd9ftG+g91fsGsmCDveZYdYpf8mv8pADiN/cey26P1QEds2SOUH19mWLGVdwDXT7bOFY9TtQW4/84UaOoWLLHnXZ7XXsn8n5ti9q1/g//d7LH1t970VH0a/ykAOI3q9feGDPeCwACV9+fRbs9Vs6CwJb7d5ZXnyPao/3/csgm/7/oP+sLoeoX1f/1wiXJWV79x84e7f8fu9peVKfToTKXS3nOI34fr8pd/W21o6zc733KXVWeHozfKioqUPnxY4oO4LfpqVe8FCE1x6+O5U1UI6l1rLkT1A84vH/Lf6IYaxzA6xDxa7pVrtNfh6LCYyoqPH0FrUpXzcWY0+lQoAs2NzknwB0kGVKN74NQF+xrJVj1DXTI9MoVlQY2NO5YRfX/Xr688RbDa6+YF1a9D7ydmPvzxUh0heu0+2JjY2v+G2CPqzFWXXvu6/O9EDLvxRpY9T4A4NvZ0C47qmo+X66pbW4bb/f7y5mzvhCq7Yl6e2H//aKe/sdO8vai1vzHTpLi4uJrjFNV5ZLLVXMMt9stSYrw9Iv8W2RkpBo1Ov1XE924Otap7PZYOQr2q01z/7tjDpdXx28efXp8b34+XOW1GLTbY1VSQ9FQm9Ky6rKh6Tn+F082W/0N5zODyyUVBVCj/Po2UIT/vwZ5eUvVqrYioLau74bQ7e0Pq76Btmr4wZn1igXSExG6c8XqUhBbNXczFITzUBgAwVHf7bJ05m3SWV8I1faNl1ULBdQ0VKy2+L5yqM+THl/FoNMdXeN+NRWD7RK8xzqTKv9oVc3dIjXlcEEr77E6d76ixtezthxcv+bQOPL0HLx+A6yac/AWv7YcTrwGkTXEry0HhqEELpS/ga7v30Gwe8VCWSi8D0L5i4lwaQ8AhI5gtss2wzDMvfy6iYqKSuV2n7XpW4JV40LjG+Bg/x4AKTQ+C+D3AABWiYiwKa6Wi4tTCAEAAABocHwVQgHMTAAAAACAhoFCCAAAAEDYoRACAAAAEHYohAAAAACEHQohAAAAAGHH1EJo+fLlGjBggNLS0jR37tzT7t+6dauGDh2qfv366bHHHvN68VEAAAAAqE+mFUKHDh3SrFmzNG/ePC1dulTz58/Xjh07TnrMQw89pMmTJ2vVqlUyDEMLFiwwKx0AAAAA8DCtEMrNzVX37t0VGxurmJgY9evXTytXrvTc/8svv6isrEyXX365JGno0KEn3Q8AAAAAZok068D5+fmKj4/3bCckJGjLli1e74+Pj9ehQ4cCilHbBZIAAAAAwBvTCiG32y2bzebZNgzjpG1f9/ujpOSo3G7jzJMFAAAA0KBERNjUosW5Xu83rRBKSkrS5s2bPdsFBQVKSEg46f6CggLPdmFh4Un3+6O2JwYAAAAA3pg2Ryg5OVmbNm1ScXGxjh8/rtWrVys1NdVz/3nnnafo6Gh9/fXXkqRly5addD8AAAAAmMVmGIZpY8uWL1+u119/XZWVlRo2bJjGjRuncePGKSsrS506ddKPP/6o7OxslZaWqmPHjpoxY4aioqLMSgcAAAAAJJlcCAEAAABAKDL1gqoAAAAAEIoohAAAAACEHQohAAAAAGGHQggAAABA2KEQAgAAABB2KIQAAAAAhB0KIQAAAABhJywLoeXLl2vAgAFKS0vT3Llzg5JDaWmpBg0apH379gUl/iuvvKKBAwdq4MCBmjlzpuXxX3zxRQ0YMEADBw7UnDlzLI//W88884wmTZpkedxRo0Zp4MCBGjx4sAYPHqxvv/3W8hxycnI0dOhQ9e/fX9OmTbM8/sKFCz3Pf/Dgwbrqqqs0ZcoUS3NYtmyZ57PwzDPPWBr7hDfeeEP9+vVTenq6XnvtNcvintoO5ebmKj09XWlpaZo1a5bl8SWpsrJSt912m7788kvT49eUw/z58zVo0CClp6frkUceUUVFheU5zJs3TwMHDtSAAQP0zDPPyOzL/Xn7e/T+++9r1KhRpsb2lsMjjzyitLQ0T9vwySefWBr/m2++0YgRIzRw4EA98MADlr8P1q1bd1Lb2L17d919992WxZekzz//XDfccIMGDRqkiRMnBuWzsHjxYg0YMEDp6emaNm2aXC6XqfFrOjeysl30dm5mZbtYUw5Wtos1xTe1TTTCzMGDB40+ffoYJSUlxtGjR4309HRj+/btlubwz3/+0xg0aJDRsWNH4+eff7Y0tmEYxsaNG42RI0ca5eXlRkVFhTF69Ghj9erVlsX/8ssvjczMTKOystI4fvy40adPH2Pnzp2Wxf+t3Nxco1u3bsbDDz9saVy322307NnTqKystDTub+3du9fo2bOnceDAAaOiosK46aabjLVr1wYtn59++sm47rrrjKKiIstiHjt2zLj66quNoqIio7Ky0hg2bJixceNGy+IbRvXncdCgQcaRI0cMl8tl3H333caqVatMj3tqO3T8+HGjV69ext69e43KykrjjjvuMPX9UFM7uHPnTmPkyJFGp06djC+++MK02N5y2LVrl3HdddcZR44cMdxutzFx4kRjzpw5luawd+9e47rrrjOOHj1quFwuY+TIkcaGDRssi3/C9u3bjZSUFOPWW281LXZtOQwaNMg4dOiQ6bFrin/kyBHjmmuuMbZu3WoYhmFMmDDBmDt3rqU5/FZ+fr5x7bXXGrt377Y0fmpqqrFjxw7DMAzjvvvuMxYsWGBa/Jpy2Llzp5GSkuJ5HzzxxBPGW2+9ZVr8ms6Nli9fblm76O3czMp2saYcXn/9dcvaxZriz5kzx9Q2Mex6hHJzc9W9e3fFxsYqJiZG/fr108qVKy3NYcGCBXriiSeUkJBgadwT4uPjNWnSJEVFRalx48a66KKLtH//fsvid+3aVe+++64iIyNVVFSkqqoqxcTEWBb/BIfDoVmzZumee+6xPPauXbskSXfccYduuOEGvf/++5bn8Mknn2jAgAFKSkpS48aNNWvWLHXp0sXyPE548sknNWHCBLVs2dKymFVVVXK73Tp+/LhcLpdcLpeio6Mtiy9JP/zwg3r27KmmTZuqUaNGSklJ0aeffmp63FPboS1btqhdu3Zq06aNIiMjlZ6ebmrbWFM7uGjRIt15552WvQ9PzSEqKkpPPPGEmjZtKpvNpksuucT0tvHUHNq0aaOPP/5YMTExOnz4sEpLS9W8eXPL4ktSRUWFJk+erKysLNPi1pbD8ePHtX//fj366KNKT0/XSy+9JLfbbVn8jRs36vLLL1eHDh0kSdnZ2bruuutMi19TDr81c+ZMZWZm6oILLrA0flVVlUpLS1VVVaXy8nLT28ZTc9i2bZsuv/xyz3afPn1MbRtrOjfas2ePZe2it3MzK9vFmnKoqKiwrF2sKb7NZjO1TYystyOdJfLz8xUfH+/ZTkhI0JYtWyzN4amnnrI03qkuvvhiz8979uzR3//+d33wwQeW5tC4cWO99NJLeuutt3T99dcrMTHR0viSNHnyZE2YMEEHDhywPPbhw4fVo0cPPf7446qsrNTo0aN14YUX6pprrrEsh7y8PDVu3Fj33HOPDhw4oN69e+svf/mLZfF/Kzc3V2VlZerfv7+lcZs2bar7779f/fv3V5MmTXT11VfryiuvtDSHjh07avr06br77rvVpEkT5eTkmD4USjq9HaqpbTx06JBl8SVp4sSJkqR33nnHtLi15XDeeefpvPPOkyQVFxdr7ty5mjFjhqU5SNXt44IFC/TMM8+oc+fOnhNyq+I///zzuvHGG3X++eebFre2HAoLC9W9e3c98cQTatasme6++24tWrRII0aMsCR+Xl6eYmJiNGHCBO3atUtXXnml6cOnvZ0X7NmzR1999ZXp5w01Hf/JJ5/UqFGj1LRpU51//vm6/vrrLc2hQ4cOevrpp3XgwAElJCRo5cqVKiwsNC1+TedGt956q2XtordzsxMFsBXtoq8czG4XvcU3s00Mux4ht9stm83m2TYM46TtcLJ9+3bdcccdmjhxoqnfNHmTlZWlTZs26cCBA1qwYIGlsRcuXKjWrVurR48elsY94YorrtDMmTPVrFkztWzZUsOGDdO6desszaGqqkqbNm3S9OnTNX/+fG3ZskVLliyxNIcTPvzwQ40ZM8byuD/++KP++te/6rPPPtOGDRsUERGhN99809IcevTooaFDh2rUqFG68847ddVVV6lx48aW5iDRNv7WoUOHdNttt+nGG29Ut27dgpLDiBEj9OWXX6pVq1Z65ZVXLIu7ceNGHThwQDfeeKNlMU/Vpk0bvfrqq0pISFCTJk00atQoS9vHqqoqff7553rggQe0ePFiHT9+XG+88YZl8X9r/vz5uvnmmxUVFWVp3IKCAj333HNasWKFPv/8c3Xp0sX0LwVOdeGFF+rBBx/Un/70J91yyy1q3769JW3jb8+N2rRpY3m7GOxzM285WNku1hTfrDYx7AqhpKQkFRQUeLYLCgqCNkQtmL7++mvdfvvtevDBBzVkyBBLY+/cuVNbt26VJDVp0kRpaWnatm2bpTn87W9/08aNGzV48GC99NJLysnJ0fTp0y2Lv3nzZm3atMmzbRiGIiOt7aBt1aqVevTooZYtW+qcc87RH//4R8t7R6XqYTj/+Mc/1LdvX8tjf/755+rRo4fi4uIUFRWloUOH6quvvrI0h9LSUqWlpWn58uV67733FBUVpTZt2liag0TbeMLOnTuVmZmpIUOG6N5777U8/oEDB/T1119LkiIjIzVw4EBL28cVK1Zo+/btGjx4sLKzs/Xdd99Z3lO8bds2rVq1yrNtdfvYqlUrdenSRW3atFGjRo3Uv3//oLSNkrRmzRoNGDDA8ribN2/WJZdcorZt2yoiIkIjRoywvG0sLy9X586dtXTpUn344YdKTEw0vW089dzI6nYxmOdmteVgZbt4anyz28SwK4SSk5O1adMmFRcX6/jx41q9erVSU1ODnZalDhw4oHvvvVfPPfecBg4caHn8ffv2KTs7WxUVFaqoqNCaNWt01VVXWZrDnDlztGLFCi1btkxZWVnq27evHn30UcviHzlyRDNnzlR5eblKS0u1ZMkS08egn6pPnz76/PPPdfjwYVVVVWnDhg3q2LGjpTlI1Sc9F1xwQVDmiXXo0EG5ubk6duyYDMNQTk6OOnXqZGkO+/bt05///Ge5XC4dOXJEixYtsnyIoCR16dJFu3fvVl5enqqqqrRixYqwaxtLS0s1duxY3X///brjjjuCksORI0f00EMP6fDhwzIMQ6tWrbK0fZwxY4b+/ve/a9myZZo2bZouu+wyvfDCC5bFl6oLn+nTp8vpdKqyslLz58+3tH3s2bOnvv/+e8+w6c8++ywobWNxcbHKysqC8sXIJZdcoi1btniGoq1Zs8bytvHYsWO6/fbbVVpaqoqKCr3//vumFoU1nRtZ2S4G+9zMWw5Wtos1xTe7TQy7OUKJiYmaMGGCRo8ercrKSg0bNkydO3cOdlqWevPNN1VeXq6nn37ac1tmZqZuuukmS+L36tVLW7ZsUUZGhho1aqS0tLSgfeiDpU+fPvr222+VkZEht9utm2++WVdccYWlOXTp0kV33nmnbr75ZlVWVuqaa64JynCYn3/+WUlJSZbHlapPeH744QcNHTpUjRs3VqdOnXTXXXdZmkOHDh2UlpamG264QVVVVbr99tst/2JAkqKjo/X000/rvvvuU3l5uXr16mX6nIBQs2jRIhUWFmrOnDmeZf379u2r+++/37IcLrnkEt11113KzMxUo0aN9Ic//CEow0aDqUOHDrrrrrt00003yeVyKS0tTYMGDbIsfuvWrTVlyhTdc889Ki8v16WXXqqHH37Ysvgn7Nu3L2ht40UXXaT7779fo0ePVqNGjdSuXTvLL23QokUL3XvvvRo5cqRcLpdn+WazeDs3sqpdDPa5mbccBgwYYFm76O01MLNNtBlWzMoFAAAAgBASdkPjAAAAAIBCCAAAAEDYoRACAAAAEHYohAAAAACEHQohAAAAAGGHQggAUCfTpk3T4MGDNXjwYF122WXq16+fZ7usrEyDBw/W4cOH6z3uv/71L2VlZQW0z6RJk/Tmm2/Wey4AgLMXy2cDAM5Y37599eKLL1p+0UV/TZo0SRdffLHGjh0b7FQAACEi7C6oCgCwRvv27bVp0yatXbtWq1evltvt1v79+5WYmKgRI0bo/fff1549ezRmzBjPFcsXLlyoDz74QG63W7GxsXr88cd10UUXnXTcL7/8UlOnTtWKFSs0adIkNW3aVNu2bdPBgwfVvn17PfPMMzr33HNPy+ebb75RZmamCgsLdfHFF+v5559XTEyMNm/erJkzZ+r48eNq3Lix/vKXvyg1NVWLFy/WqlWr9Prrr0vSSduTJk2Sw+HQzz//rN69e6tPnz56+umn5Xa7JUl33323+vXrZ/IrDAA4ExRCAADTbd68WcuXL1diYqLS09P18ccf65133tFPP/2kESNG6Pbbb9fmzZu1dOlSzZ07V02aNNHnn3+u8ePH6+9//3utx/7uu+/07rvvymazacSIEVq5cqVuvPHG0x536NAhvfvuu4qKitLw4cO1evVq9erVS1lZWXrttdfUpUsXbd++XbfeeqsWLVrk8zmVlZXp448/liTdv1SyUAAAAjxJREFUdtttGjNmjAYOHKgff/xR8+fPpxACgBBHIQQAMF2nTp3UunVrSdL555+vnj17KiIiQm3atFF5ebmOHz+utWvXKi8vT5mZmZ79Dh8+LIfDodjYWK/HTklJUVRUlCTpkksukdPprPFxf/zjH9WkSRNJ0sUXX6zi4mJt2bJFbdu2VZcuXTy3X3nllfrqq69ks9lqfU5XXXWV5+f+/ftrypQpysnJUXJysh544AE/XhUAQDBRCAEATHeiUDkhMvL0Pz9ut1uDBw/WQw895NnOz8+X3W6v9djnnHOO52ebzSZvU19/G/PE46qqqk4reAzDkMvlUlRU1EnHqqysPOlxMTExnp8zMzPVp08fbdy4URs2bNArr7yilStXKjo6utbcAQDBw6pxAICQ0LNnT3388cfKz8+XJH3wwQe67bbbTI15+eWXa9euXdqyZYskafv27frHP/6hrl27qmXLltq+fbvKy8tVWVmpVatWeT1OZmamtm7dqqFDh2rq1Kk6fPiwCgoKTM0dAHBm6BECAISEnj17aty4cbrjjjtks9nUtGlTvfLKKz6HqJ2Jli1b6sUXX9TUqVNVVlYmm82mGTNm6MILL1SbNm109dVXq3///oqPj1e3bt20bdu2Go/zn//5n5o+fbpeeOEF2Ww2jR8/Xueff75peQMAzhzLZwMAAAAIOwyNAwAAABB2KIQAAAAAhB0KIQAAAABhh0IIAAAAQNihEAIAAAAQdiiEAAAAAIQdCiEAAAAAYef/A2cLXbPAA4u3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if do_analysis:\n",
    "    columns = [x for x in data.columns if x in ['Actueel verbruik in KW', 'Totaal vermogen ontvangen in tariff 1 in KWH', 'Totaal vermogen ontvangen in tariff 2 in KWH', 'Totaal vermogen ontvangen']]\n",
    "    data_resample = pd.DataFrame(columns=columns)\n",
    "    data_resample['Actueel verbruik in KW'] = data['Actueel verbruik in KW'].resample('h').mean()\n",
    "    data_resample['Totaal vermogen ontvangen in tariff 1 in KWH'] = data['Totaal vermogen ontvangen in tariff 1 in KWH'].resample('h').max()\n",
    "    data_resample['Totaal vermogen ontvangen in tariff 2 in KWH'] = data['Totaal vermogen ontvangen in tariff 2 in KWH'].resample('h').max()\n",
    "    data_resample['Totaal vermogen ontvangen'] = data['Totaal vermogen ontvangen'].resample('h').max()\n",
    "\n",
    "    print(\"Number of rows: {} \\n\".format(len(data_resample)))\n",
    "    print(\"Number of rows (NaN excluded): {} \\n\".format(len(data_resample[~np.isnan(data_resample['Totaal vermogen ontvangen'])])))\n",
    "    print(\"\")\n",
    "    print(\"Days in dataset (after setting index):\")\n",
    "    for x in data_resample.resample('d').mean().index:\n",
    "        print(\"  \", x)\n",
    "    print(\"\\nDays with NaN's:\")\n",
    "    for x in data_resample[np.isnan(data_resample['Totaal vermogen ontvangen'])].resample('d').mean().index:\n",
    "        print(\"  \", x)\n",
    "    print(\"\\n\")\n",
    "    sns.boxplot(x=data_resample.index.hour, y=data_resample['Actueel verbruik in KW'])\n",
    "    plt.xlabel('Time in hours')\n",
    "    plt.show()\n",
    "    sns.boxplot(x=data_resample.index.day, y=data_resample['Actueel verbruik in KW'])\n",
    "    plt.xlabel('Time in days')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actueel verbruik</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-10 12:00:00</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10 13:00:00</th>\n",
       "      <td>0.073391</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10 14:00:00</th>\n",
       "      <td>0.113103</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10 15:00:00</th>\n",
       "      <td>0.098613</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10 16:00:00</th>\n",
       "      <td>0.270517</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Actueel verbruik  Month  Week  Day  Hour\n",
       "Timestamp                                                    \n",
       "2020-12-10 12:00:00          0.120000     12    50   10    12\n",
       "2020-12-10 13:00:00          0.073391     12    50   10    13\n",
       "2020-12-10 14:00:00          0.113103     12    50   10    14\n",
       "2020-12-10 15:00:00          0.098613     12    50   10    15\n",
       "2020-12-10 16:00:00          0.270517     12    50   10    16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "# set to mean to get kw/h, sum for kw.\n",
    "df['Actueel verbruik'] = data['Actueel verbruik in KW'].resample('h').mean()\n",
    "\n",
    "# remove NaN's from dataset\n",
    "df = df[~np.isnan(df['Actueel verbruik'])]\n",
    "\n",
    "# add time-related information to dataset\n",
    "df['Month'] = df.index.month\n",
    "df['Week'] = df.index.week\n",
    "df['Day'] = df.index.day\n",
    "df['Hour'] = df.index.hour\n",
    "# df['Totaal vermogen ontvangen'] = data['Totaal vermogen ontvangen'].resample('h').max()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN's with column's mean value\n",
    "for j in range(0,len(df.columns)):        \n",
    "        df.iloc[:,j]=df.iloc[:,j].fillna(df.iloc[:,j].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future = df[-n_input:]\n",
    "df_pred = df[-(n_input+n_forecasts):-n_forecasts]\n",
    "df_resample = df[:-n_forecasts*2]\n",
    "\n",
    "if use_scaled:\n",
    "    scaler = MinMaxScaler()\n",
    "    df_pred_scaled = scaler.fit_transform(df_pred)\n",
    "    df_future_scaled = scaler.fit_transform(df_future)\n",
    "    train, val = train_test_split(scaler.fit_transform(df_resample), test_size=.2, shuffle=False, stratify=None)\n",
    "else:\n",
    "    train, val = train_test_split(df_resample.values, test_size=.2, shuffle=False, stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actueel verbruik</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-10 12:00:00</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10 13:00:00</th>\n",
       "      <td>0.073391</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10 14:00:00</th>\n",
       "      <td>0.113103</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10 15:00:00</th>\n",
       "      <td>0.098613</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10 16:00:00</th>\n",
       "      <td>0.270517</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10 17:00:00</th>\n",
       "      <td>0.160636</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10 18:00:00</th>\n",
       "      <td>0.149023</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10 19:00:00</th>\n",
       "      <td>0.179655</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10 20:00:00</th>\n",
       "      <td>0.141676</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10 21:00:00</th>\n",
       "      <td>0.155230</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10 22:00:00</th>\n",
       "      <td>0.100347</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-10 23:00:00</th>\n",
       "      <td>0.085954</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 00:00:00</th>\n",
       "      <td>0.062529</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 01:00:00</th>\n",
       "      <td>0.059770</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 02:00:00</th>\n",
       "      <td>0.046127</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 03:00:00</th>\n",
       "      <td>0.062644</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 04:00:00</th>\n",
       "      <td>0.045838</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 05:00:00</th>\n",
       "      <td>0.051897</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 06:00:00</th>\n",
       "      <td>0.158563</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 07:00:00</th>\n",
       "      <td>0.085838</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 08:00:00</th>\n",
       "      <td>0.090172</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 09:00:00</th>\n",
       "      <td>0.110116</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 10:00:00</th>\n",
       "      <td>0.084138</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 11:00:00</th>\n",
       "      <td>0.205411</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 12:00:00</th>\n",
       "      <td>0.059480</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 13:00:00</th>\n",
       "      <td>0.043966</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 14:00:00</th>\n",
       "      <td>0.057746</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 15:00:00</th>\n",
       "      <td>0.059943</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 16:00:00</th>\n",
       "      <td>0.878046</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11 17:00:00</th>\n",
       "      <td>0.159942</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-20 11:00:00</th>\n",
       "      <td>0.232471</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-20 12:00:00</th>\n",
       "      <td>0.086474</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-20 13:00:00</th>\n",
       "      <td>0.460862</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-20 14:00:00</th>\n",
       "      <td>0.640230</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-20 15:00:00</th>\n",
       "      <td>0.124971</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-20 16:00:00</th>\n",
       "      <td>0.685057</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-20 17:00:00</th>\n",
       "      <td>0.275575</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-20 18:00:00</th>\n",
       "      <td>0.156705</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-20 19:00:00</th>\n",
       "      <td>0.146897</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-20 20:00:00</th>\n",
       "      <td>0.112414</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-20 21:00:00</th>\n",
       "      <td>0.117803</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-20 22:00:00</th>\n",
       "      <td>0.096343</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-20 23:00:00</th>\n",
       "      <td>0.078092</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 00:00:00</th>\n",
       "      <td>0.051437</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 01:00:00</th>\n",
       "      <td>0.053851</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 02:00:00</th>\n",
       "      <td>0.055029</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 03:00:00</th>\n",
       "      <td>0.047299</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 04:00:00</th>\n",
       "      <td>0.057414</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 05:00:00</th>\n",
       "      <td>0.044971</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 06:00:00</th>\n",
       "      <td>0.057069</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 07:00:00</th>\n",
       "      <td>0.254682</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 08:00:00</th>\n",
       "      <td>0.063966</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 09:00:00</th>\n",
       "      <td>0.114220</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 10:00:00</th>\n",
       "      <td>0.056609</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 11:00:00</th>\n",
       "      <td>0.140115</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 12:00:00</th>\n",
       "      <td>0.086590</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 13:00:00</th>\n",
       "      <td>0.054770</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 14:00:00</th>\n",
       "      <td>0.049885</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 15:00:00</th>\n",
       "      <td>0.062717</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21 16:00:00</th>\n",
       "      <td>1.143218</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>269 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Actueel verbruik  Month  Week  Day  Hour\n",
       "Timestamp                                                    \n",
       "2020-12-10 12:00:00          0.120000     12    50   10    12\n",
       "2020-12-10 13:00:00          0.073391     12    50   10    13\n",
       "2020-12-10 14:00:00          0.113103     12    50   10    14\n",
       "2020-12-10 15:00:00          0.098613     12    50   10    15\n",
       "2020-12-10 16:00:00          0.270517     12    50   10    16\n",
       "2020-12-10 17:00:00          0.160636     12    50   10    17\n",
       "2020-12-10 18:00:00          0.149023     12    50   10    18\n",
       "2020-12-10 19:00:00          0.179655     12    50   10    19\n",
       "2020-12-10 20:00:00          0.141676     12    50   10    20\n",
       "2020-12-10 21:00:00          0.155230     12    50   10    21\n",
       "2020-12-10 22:00:00          0.100347     12    50   10    22\n",
       "2020-12-10 23:00:00          0.085954     12    50   10    23\n",
       "2020-12-11 00:00:00          0.062529     12    50   11     0\n",
       "2020-12-11 01:00:00          0.059770     12    50   11     1\n",
       "2020-12-11 02:00:00          0.046127     12    50   11     2\n",
       "2020-12-11 03:00:00          0.062644     12    50   11     3\n",
       "2020-12-11 04:00:00          0.045838     12    50   11     4\n",
       "2020-12-11 05:00:00          0.051897     12    50   11     5\n",
       "2020-12-11 06:00:00          0.158563     12    50   11     6\n",
       "2020-12-11 07:00:00          0.085838     12    50   11     7\n",
       "2020-12-11 08:00:00          0.090172     12    50   11     8\n",
       "2020-12-11 09:00:00          0.110116     12    50   11     9\n",
       "2020-12-11 10:00:00          0.084138     12    50   11    10\n",
       "2020-12-11 11:00:00          0.205411     12    50   11    11\n",
       "2020-12-11 12:00:00          0.059480     12    50   11    12\n",
       "2020-12-11 13:00:00          0.043966     12    50   11    13\n",
       "2020-12-11 14:00:00          0.057746     12    50   11    14\n",
       "2020-12-11 15:00:00          0.059943     12    50   11    15\n",
       "2020-12-11 16:00:00          0.878046     12    50   11    16\n",
       "2020-12-11 17:00:00          0.159942     12    50   11    17\n",
       "...                               ...    ...   ...  ...   ...\n",
       "2020-12-20 11:00:00          0.232471     12    51   20    11\n",
       "2020-12-20 12:00:00          0.086474     12    51   20    12\n",
       "2020-12-20 13:00:00          0.460862     12    51   20    13\n",
       "2020-12-20 14:00:00          0.640230     12    51   20    14\n",
       "2020-12-20 15:00:00          0.124971     12    51   20    15\n",
       "2020-12-20 16:00:00          0.685057     12    51   20    16\n",
       "2020-12-20 17:00:00          0.275575     12    51   20    17\n",
       "2020-12-20 18:00:00          0.156705     12    51   20    18\n",
       "2020-12-20 19:00:00          0.146897     12    51   20    19\n",
       "2020-12-20 20:00:00          0.112414     12    51   20    20\n",
       "2020-12-20 21:00:00          0.117803     12    51   20    21\n",
       "2020-12-20 22:00:00          0.096343     12    51   20    22\n",
       "2020-12-20 23:00:00          0.078092     12    51   20    23\n",
       "2020-12-21 00:00:00          0.051437     12    52   21     0\n",
       "2020-12-21 01:00:00          0.053851     12    52   21     1\n",
       "2020-12-21 02:00:00          0.055029     12    52   21     2\n",
       "2020-12-21 03:00:00          0.047299     12    52   21     3\n",
       "2020-12-21 04:00:00          0.057414     12    52   21     4\n",
       "2020-12-21 05:00:00          0.044971     12    52   21     5\n",
       "2020-12-21 06:00:00          0.057069     12    52   21     6\n",
       "2020-12-21 07:00:00          0.254682     12    52   21     7\n",
       "2020-12-21 08:00:00          0.063966     12    52   21     8\n",
       "2020-12-21 09:00:00          0.114220     12    52   21     9\n",
       "2020-12-21 10:00:00          0.056609     12    52   21    10\n",
       "2020-12-21 11:00:00          0.140115     12    52   21    11\n",
       "2020-12-21 12:00:00          0.086590     12    52   21    12\n",
       "2020-12-21 13:00:00          0.054770     12    52   21    13\n",
       "2020-12-21 14:00:00          0.049885     12    52   21    14\n",
       "2020-12-21 15:00:00          0.062717     12    52   21    15\n",
       "2020-12-21 16:00:00          1.143218     12    52   21    16\n",
       "\n",
       "[269 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 184 samples, validate on 23 samples\n",
      "Epoch 1/10000\n",
      "184/184 [==============================] - 1s 8ms/step - loss: 1823.9026 - val_loss: 1010.4258\n",
      "Epoch 2/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1478.3302 - val_loss: 1002.2869\n",
      "Epoch 3/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1209.6496 - val_loss: 985.3236\n",
      "Epoch 4/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1514.6012 - val_loss: 988.8127\n",
      "Epoch 5/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 1781.9798 - val_loss: 988.8402\n",
      "Epoch 6/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1443.7186 - val_loss: 987.1061\n",
      "Epoch 7/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 1294.8582 - val_loss: 986.3755\n",
      "Epoch 8/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1687.5847 - val_loss: 983.2203\n",
      "Epoch 9/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 1723.1306 - val_loss: 981.0160\n",
      "Epoch 10/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1710.3420 - val_loss: 979.7619\n",
      "Epoch 11/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1261.9523 - val_loss: 978.6144\n",
      "Epoch 12/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 1628.3814 - val_loss: 977.6320\n",
      "Epoch 13/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1439.3557 - val_loss: 977.7723\n",
      "Epoch 14/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 1755.3845 - val_loss: 977.7307\n",
      "Epoch 15/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1343.8888 - val_loss: 977.6230\n",
      "Epoch 16/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1515.3683 - val_loss: 978.0776\n",
      "Epoch 17/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1567.9153 - val_loss: 980.1401\n",
      "Epoch 18/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1651.2544 - val_loss: 980.9939\n",
      "Epoch 19/10000\n",
      "184/184 [==============================] - 0s 435us/step - loss: 2014.7954 - val_loss: 980.6464\n",
      "Epoch 20/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1583.7914 - val_loss: 981.1068\n",
      "Epoch 21/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1215.6952 - val_loss: 981.2346\n",
      "Epoch 22/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1690.9750 - val_loss: 980.5899\n",
      "Epoch 23/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1931.3587 - val_loss: 979.5464\n",
      "Epoch 24/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1256.0713 - val_loss: 978.1723\n",
      "Epoch 25/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1482.3772 - val_loss: 976.8261\n",
      "Epoch 26/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 2038.8239 - val_loss: 975.5038\n",
      "Epoch 27/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1384.7471 - val_loss: 973.8170\n",
      "Epoch 28/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1688.34 - 0s 440us/step - loss: 1530.3113 - val_loss: 966.5528\n",
      "Epoch 29/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1395.8030 - val_loss: 959.8644\n",
      "Epoch 30/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1476.2321 - val_loss: 957.8762\n",
      "Epoch 31/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 1540.5843 - val_loss: 957.2472\n",
      "Epoch 32/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1340.0399 - val_loss: 955.7147\n",
      "Epoch 33/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 1570.7745 - val_loss: 954.1215\n",
      "Epoch 34/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1655.6664 - val_loss: 953.2061\n",
      "Epoch 35/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 1714.6764 - val_loss: 952.9757\n",
      "Epoch 36/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1716.3524 - val_loss: 952.8485\n",
      "Epoch 37/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1254.9406 - val_loss: 951.4453\n",
      "Epoch 38/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1391.9093 - val_loss: 949.5246\n",
      "Epoch 39/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1429.52 - 0s 478us/step - loss: 1431.6970 - val_loss: 946.8751\n",
      "Epoch 40/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 1257.7152 - val_loss: 945.0522\n",
      "Epoch 41/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1179.7362 - val_loss: 943.6328\n",
      "Epoch 42/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1519.6552 - val_loss: 936.4775\n",
      "Epoch 43/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1125.2432 - val_loss: 925.1425\n",
      "Epoch 44/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1589.8397 - val_loss: 924.3014\n",
      "Epoch 45/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1276.8069 - val_loss: 925.6730\n",
      "Epoch 46/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1423.7778 - val_loss: 925.2220\n",
      "Epoch 47/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 1153.0022 - val_loss: 924.2958\n",
      "Epoch 48/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 1264.1138 - val_loss: 923.9219\n",
      "Epoch 49/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1190.8884 - val_loss: 923.3335\n",
      "Epoch 50/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1403.1859 - val_loss: 921.8345\n",
      "Epoch 51/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1351.1214 - val_loss: 921.7745\n",
      "Epoch 52/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1218.6292 - val_loss: 918.3789\n",
      "Epoch 53/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1452.3631 - val_loss: 918.6795\n",
      "Epoch 54/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1415.57 - 0s 495us/step - loss: 1294.9259 - val_loss: 914.2940\n",
      "Epoch 55/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1257.9288 - val_loss: 913.7038\n",
      "Epoch 56/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1474.4950 - val_loss: 913.0401\n",
      "Epoch 57/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1246.8244 - val_loss: 913.3003\n",
      "Epoch 58/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1129.1890 - val_loss: 915.0336\n",
      "Epoch 59/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1824.5120 - val_loss: 923.0488\n",
      "Epoch 60/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1482.3978 - val_loss: 917.9458\n",
      "Epoch 61/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1563.5702 - val_loss: 913.5217\n",
      "Epoch 62/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1623.5413 - val_loss: 911.6411\n",
      "Epoch 63/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1400.5353 - val_loss: 909.8005\n",
      "Epoch 64/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1433.2697 - val_loss: 911.9648\n",
      "Epoch 65/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 1571.1133 - val_loss: 911.7474\n",
      "Epoch 66/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1273.0293 - val_loss: 910.5106\n",
      "Epoch 67/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1590.3183 - val_loss: 911.2819\n",
      "Epoch 68/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1653.4618 - val_loss: 908.9529\n",
      "Epoch 69/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1444.6906 - val_loss: 912.4355\n",
      "Epoch 70/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1625.4719 - val_loss: 945.1343\n",
      "Epoch 71/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1512.2533 - val_loss: 926.1512\n",
      "Epoch 72/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1458.4747 - val_loss: 924.5217\n",
      "Epoch 73/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1700.9550 - val_loss: 928.2824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 1216.9411 - val_loss: 930.2656\n",
      "Epoch 75/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 1675.2956 - val_loss: 930.9807\n",
      "Epoch 76/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1308.9512 - val_loss: 931.5480\n",
      "Epoch 77/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1565.3333 - val_loss: 932.1158\n",
      "Epoch 78/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 1475.3850 - val_loss: 930.7039\n",
      "Epoch 79/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1554.5857 - val_loss: 929.5683\n",
      "Epoch 80/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1447.0764 - val_loss: 928.7407\n",
      "Epoch 81/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1384.7851 - val_loss: 928.7188\n",
      "Epoch 82/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1479.2928 - val_loss: 928.1346\n",
      "Epoch 83/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1381.7432 - val_loss: 927.4352\n",
      "Epoch 84/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 1280.7691 - val_loss: 926.5080\n",
      "Epoch 85/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1618.5167 - val_loss: 924.3930\n",
      "Epoch 86/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1434.8612 - val_loss: 921.2250\n",
      "Epoch 87/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 1328.1906 - val_loss: 919.6676\n",
      "Epoch 88/10000\n",
      "184/184 [==============================] - 0s 804us/step - loss: 1276.9578 - val_loss: 922.9876\n",
      "Epoch 89/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 1209.1187 - val_loss: 941.9394\n",
      "Epoch 90/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1154.3611 - val_loss: 942.8998\n",
      "Epoch 91/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1719.6928 - val_loss: 927.5958\n",
      "Epoch 92/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1404.9685 - val_loss: 918.7582\n",
      "Epoch 93/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 1426.3422 - val_loss: 908.6009\n",
      "Epoch 94/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 1442.8404 - val_loss: 908.3752\n",
      "Epoch 95/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1694.8205 - val_loss: 910.0173\n",
      "Epoch 96/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1382.0642 - val_loss: 910.9362\n",
      "Epoch 97/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1428.8181 - val_loss: 907.7496\n",
      "Epoch 98/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1515.1811 - val_loss: 903.6262\n",
      "Epoch 99/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1393.7973 - val_loss: 900.9406\n",
      "Epoch 100/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1399.2061 - val_loss: 899.4073\n",
      "\n",
      "Epoch 00100: loss improved from inf to 1399.20607, saving model to C6007C.hdf5\n",
      "Epoch 101/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1361.0788 - val_loss: 900.2278\n",
      "Epoch 102/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1448.9628 - val_loss: 901.8529\n",
      "Epoch 103/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 1405.5563 - val_loss: 901.3093\n",
      "Epoch 104/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 1318.8457 - val_loss: 902.8543\n",
      "Epoch 105/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 1497.9720 - val_loss: 903.4069\n",
      "Epoch 106/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 1341.7101 - val_loss: 902.5951\n",
      "Epoch 107/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 1561.5017 - val_loss: 900.0578\n",
      "Epoch 108/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 1288.4496 - val_loss: 899.1461\n",
      "Epoch 109/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 1148.2971 - val_loss: 899.5178\n",
      "Epoch 110/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 1272.8849 - val_loss: 901.4894\n",
      "Epoch 111/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1258.8618 - val_loss: 898.1819\n",
      "Epoch 112/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 1477.1281 - val_loss: 897.2159\n",
      "Epoch 113/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1389.9077 - val_loss: 897.2424\n",
      "Epoch 114/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1592.19 - 0s 484us/step - loss: 1565.0713 - val_loss: 897.0708\n",
      "Epoch 115/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 1522.2773 - val_loss: 897.4236\n",
      "Epoch 116/10000\n",
      "184/184 [==============================] - 0s 880us/step - loss: 1581.6958 - val_loss: 894.0084\n",
      "Epoch 117/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 1380.2858 - val_loss: 893.7756\n",
      "Epoch 118/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 1828.3641 - val_loss: 894.2263\n",
      "Epoch 119/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 1483.4469 - val_loss: 900.4140\n",
      "Epoch 120/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 1488.0315 - val_loss: 902.7509\n",
      "Epoch 121/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1395.0522 - val_loss: 909.5912\n",
      "Epoch 122/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1559.4280 - val_loss: 911.5143\n",
      "Epoch 123/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1286.9134 - val_loss: 910.0275\n",
      "Epoch 124/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1392.6747 - val_loss: 910.1500\n",
      "Epoch 125/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 1504.6435 - val_loss: 907.5122\n",
      "Epoch 126/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1435.3115 - val_loss: 902.6250\n",
      "Epoch 127/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1257.2215 - val_loss: 898.4008\n",
      "Epoch 128/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1346.7172 - val_loss: 894.7541\n",
      "Epoch 129/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1971.8284 - val_loss: 897.3276\n",
      "Epoch 130/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1461.6581 - val_loss: 896.9169\n",
      "Epoch 131/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1569.5681 - val_loss: 895.4086\n",
      "Epoch 132/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 1290.8019 - val_loss: 889.3214\n",
      "Epoch 133/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 1594.8371 - val_loss: 881.5273\n",
      "Epoch 134/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1395.2678 - val_loss: 884.4473\n",
      "Epoch 135/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1108.1696 - val_loss: 891.3578\n",
      "Epoch 136/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1569.1955 - val_loss: 896.9362\n",
      "Epoch 137/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1362.4704 - val_loss: 900.9709\n",
      "Epoch 138/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1662.7540 - val_loss: 900.2099\n",
      "Epoch 139/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1485.5523 - val_loss: 899.8709\n",
      "Epoch 140/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1547.0301 - val_loss: 897.6656\n",
      "Epoch 141/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 1366.0561 - val_loss: 896.0197\n",
      "Epoch 142/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1180.6229 - val_loss: 895.6501\n",
      "Epoch 143/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1523.5374 - val_loss: 895.4469\n",
      "Epoch 144/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1418.7900 - val_loss: 882.7350\n",
      "Epoch 145/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1672.2509 - val_loss: 889.4988\n",
      "Epoch 146/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 516us/step - loss: 1173.2463 - val_loss: 891.2916\n",
      "Epoch 147/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1214.5031 - val_loss: 899.3624\n",
      "Epoch 148/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1535.1507 - val_loss: 888.0143\n",
      "Epoch 149/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1349.0809 - val_loss: 886.6572\n",
      "Epoch 150/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1375.4372 - val_loss: 884.4910\n",
      "Epoch 151/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1267.3593 - val_loss: 916.2775\n",
      "Epoch 152/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1407.2982 - val_loss: 909.9340\n",
      "Epoch 153/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1360.6015 - val_loss: 899.0723\n",
      "Epoch 154/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1435.4064 - val_loss: 894.4141\n",
      "Epoch 155/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1388.0843 - val_loss: 895.8527\n",
      "Epoch 156/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1313.1495 - val_loss: 896.0297\n",
      "Epoch 157/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1362.9670 - val_loss: 896.1691\n",
      "Epoch 158/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1456.4624 - val_loss: 895.9100\n",
      "Epoch 159/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1198.4817 - val_loss: 894.9674\n",
      "Epoch 160/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1253.2741 - val_loss: 894.0883\n",
      "Epoch 161/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1590.1034 - val_loss: 890.7407\n",
      "Epoch 162/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1268.5628 - val_loss: 896.1420\n",
      "Epoch 163/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1269.0167 - val_loss: 901.2717\n",
      "Epoch 164/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1259.1517 - val_loss: 887.6080\n",
      "Epoch 165/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 1581.5068 - val_loss: 878.2483\n",
      "Epoch 166/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1191.8440 - val_loss: 876.5308\n",
      "Epoch 167/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1414.8921 - val_loss: 875.6957\n",
      "Epoch 168/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1908.6429 - val_loss: 876.7012\n",
      "Epoch 169/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1378.7230 - val_loss: 874.0336\n",
      "Epoch 170/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 1282.6299 - val_loss: 877.9299\n",
      "Epoch 171/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 1394.0117 - val_loss: 877.7366\n",
      "Epoch 172/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 1636.6146 - val_loss: 881.1398\n",
      "Epoch 173/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1268.1456 - val_loss: 894.1868\n",
      "Epoch 174/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1241.9941 - val_loss: 895.2513\n",
      "Epoch 175/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1315.3630 - val_loss: 897.1777\n",
      "Epoch 176/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1087.3403 - val_loss: 900.2067\n",
      "Epoch 177/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1593.7750 - val_loss: 903.0500\n",
      "Epoch 178/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1337.3915 - val_loss: 905.1846\n",
      "Epoch 179/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1156.8324 - val_loss: 906.7788\n",
      "Epoch 180/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1353.8953 - val_loss: 907.8377\n",
      "Epoch 181/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1357.1973 - val_loss: 914.6120\n",
      "Epoch 182/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1194.8623 - val_loss: 919.0822\n",
      "Epoch 183/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1231.2635 - val_loss: 918.7292\n",
      "Epoch 184/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 1206.7747 - val_loss: 919.0853\n",
      "Epoch 185/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 1400.9319 - val_loss: 922.0004\n",
      "Epoch 186/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1428.5772 - val_loss: 924.3364\n",
      "Epoch 187/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 1357.5204 - val_loss: 924.9387\n",
      "Epoch 188/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1429.0709 - val_loss: 925.4695\n",
      "Epoch 189/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1217.6630 - val_loss: 925.7547\n",
      "Epoch 190/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1536.1625 - val_loss: 925.7481\n",
      "Epoch 191/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1063.4229 - val_loss: 926.1281\n",
      "Epoch 192/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1305.2870 - val_loss: 918.4334\n",
      "Epoch 193/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1783.0586 - val_loss: 920.4988\n",
      "Epoch 194/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1137.0908 - val_loss: 922.1736\n",
      "Epoch 195/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1359.8875 - val_loss: 923.0519\n",
      "Epoch 196/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1372.9899 - val_loss: 920.8760\n",
      "Epoch 197/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1185.8479 - val_loss: 914.8608\n",
      "Epoch 198/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 1621.6540 - val_loss: 914.4489\n",
      "Epoch 199/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 1380.6015 - val_loss: 913.9201\n",
      "Epoch 200/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 1431.7696 - val_loss: 913.4453\n",
      "\n",
      "Epoch 00200: loss did not improve from 1399.20607\n",
      "Epoch 201/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1549.2906 - val_loss: 912.1447\n",
      "Epoch 202/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1377.4793 - val_loss: 911.8854\n",
      "Epoch 203/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 1393.1509 - val_loss: 912.7049\n",
      "Epoch 204/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1353.9719 - val_loss: 913.1683\n",
      "Epoch 205/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 1359.7438 - val_loss: 914.5790\n",
      "Epoch 206/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1487.26 - 0s 533us/step - loss: 1408.7099 - val_loss: 916.6651\n",
      "Epoch 207/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1168.5665 - val_loss: 918.8458\n",
      "Epoch 208/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 1438.4299 - val_loss: 920.8674\n",
      "Epoch 209/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1687.32 - 0s 576us/step - loss: 1457.2982 - val_loss: 922.3663\n",
      "Epoch 210/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 1662.2222 - val_loss: 923.1875\n",
      "Epoch 211/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 1607.5220 - val_loss: 923.5888\n",
      "Epoch 212/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 1135.3099 - val_loss: 923.8177\n",
      "Epoch 213/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1314.5520 - val_loss: 923.8608\n",
      "Epoch 214/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 1165.8827 - val_loss: 923.7988\n",
      "Epoch 215/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 1634.7867 - val_loss: 923.5857\n",
      "Epoch 216/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 1189.5804 - val_loss: 923.2526\n",
      "Epoch 217/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1438.9554 - val_loss: 922.8079\n",
      "Epoch 218/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 505us/step - loss: 871.6735 - val_loss: 922.3472\n",
      "Epoch 219/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1123.1016 - val_loss: 922.0681\n",
      "Epoch 220/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1422.2408 - val_loss: 932.7512\n",
      "Epoch 221/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1614.4568 - val_loss: 935.9819\n",
      "Epoch 222/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 1822.7202 - val_loss: 924.9459\n",
      "Epoch 223/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 944.1164 - val_loss: 901.1454\n",
      "Epoch 224/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1050.1140 - val_loss: 865.5005\n",
      "Epoch 225/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1316.8083 - val_loss: 861.2804\n",
      "Epoch 226/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 1204.2671 - val_loss: 860.1500\n",
      "Epoch 227/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1522.4550 - val_loss: 860.8568\n",
      "Epoch 228/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1255.1086 - val_loss: 860.7120\n",
      "Epoch 229/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1587.8435 - val_loss: 858.1129\n",
      "Epoch 230/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 1358.6879 - val_loss: 854.7120\n",
      "Epoch 231/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 1316.3560 - val_loss: 854.7029\n",
      "Epoch 232/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1874.8711 - val_loss: 855.7753\n",
      "Epoch 233/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1308.3511 - val_loss: 859.6697\n",
      "Epoch 234/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1030.5412 - val_loss: 859.1035\n",
      "Epoch 235/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1316.5726 - val_loss: 859.5729\n",
      "Epoch 236/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1592.9289 - val_loss: 859.9517\n",
      "Epoch 237/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1355.4152 - val_loss: 860.2495\n",
      "Epoch 238/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1235.8197 - val_loss: 860.3638\n",
      "Epoch 239/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1288.7666 - val_loss: 859.6429\n",
      "Epoch 240/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1314.6787 - val_loss: 858.4102\n",
      "Epoch 241/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 1183.1365 - val_loss: 857.3104\n",
      "Epoch 242/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 1648.2080 - val_loss: 856.3787\n",
      "Epoch 243/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 1133.5285 - val_loss: 855.6000\n",
      "Epoch 244/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 1292.5719 - val_loss: 854.8557\n",
      "Epoch 245/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1445.4570 - val_loss: 854.1515\n",
      "Epoch 246/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1784.3867 - val_loss: 853.5117\n",
      "Epoch 247/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1505.7656 - val_loss: 853.0104\n",
      "Epoch 248/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 1393.1230 - val_loss: 852.6251\n",
      "Epoch 249/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1310.8702 - val_loss: 852.2467\n",
      "Epoch 250/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1095.2561 - val_loss: 851.8442\n",
      "Epoch 251/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1225.2716 - val_loss: 851.4748\n",
      "Epoch 252/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1353.5028 - val_loss: 850.3247\n",
      "Epoch 253/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 1243.8999 - val_loss: 849.2791\n",
      "Epoch 254/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1267.8900 - val_loss: 848.3957\n",
      "Epoch 255/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1264.8428 - val_loss: 847.6583\n",
      "Epoch 256/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1148.0877 - val_loss: 847.0421\n",
      "Epoch 257/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 1486.0452 - val_loss: 846.6538\n",
      "Epoch 258/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1721.5386 - val_loss: 846.5178\n",
      "Epoch 259/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 1336.6313 - val_loss: 846.4939\n",
      "Epoch 260/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 933.6158 - val_loss: 846.7606\n",
      "Epoch 261/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1386.6179 - val_loss: 846.8248\n",
      "Epoch 262/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1485.4508 - val_loss: 850.2870\n",
      "Epoch 263/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1265.8152 - val_loss: 854.8915\n",
      "Epoch 264/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1295.1033 - val_loss: 862.8618\n",
      "Epoch 265/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1231.8419 - val_loss: 876.1148\n",
      "Epoch 266/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1097.0550 - val_loss: 880.1942\n",
      "Epoch 267/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1499.8418 - val_loss: 920.3187\n",
      "Epoch 268/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1384.6805 - val_loss: 1031.0417\n",
      "Epoch 269/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1309.3449 - val_loss: 998.3991\n",
      "Epoch 270/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1203.9325 - val_loss: 927.0941\n",
      "Epoch 271/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1438.2571 - val_loss: 864.7271\n",
      "Epoch 272/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 1146.3382 - val_loss: 853.0864\n",
      "Epoch 273/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1155.0574 - val_loss: 847.6461\n",
      "Epoch 274/10000\n",
      "184/184 [==============================] - 0s 429us/step - loss: 1310.0628 - val_loss: 846.5688\n",
      "Epoch 275/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1366.3210 - val_loss: 845.5211\n",
      "Epoch 276/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1348.2271 - val_loss: 998.8824\n",
      "Epoch 277/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1332.8460 - val_loss: 859.3477\n",
      "Epoch 278/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1092.4469 - val_loss: 831.1875\n",
      "Epoch 279/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1182.3229 - val_loss: 827.4190\n",
      "Epoch 280/10000\n",
      "184/184 [==============================] - 0s 494us/step - loss: 1641.7184 - val_loss: 827.1395\n",
      "Epoch 281/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1304.0738 - val_loss: 832.0163\n",
      "Epoch 282/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1230.4144 - val_loss: 837.1984\n",
      "Epoch 283/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1327.6784 - val_loss: 839.8984\n",
      "Epoch 284/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1292.5961 - val_loss: 840.3835\n",
      "Epoch 285/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1073.7254 - val_loss: 843.1567\n",
      "Epoch 286/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1278.3902 - val_loss: 863.0323\n",
      "Epoch 287/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1150.73 - 0s 522us/step - loss: 1190.1293 - val_loss: 876.5158\n",
      "Epoch 288/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 977.1656 - val_loss: 878.2271\n",
      "Epoch 289/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1432.3869 - val_loss: 878.2579\n",
      "Epoch 290/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1165.4323 - val_loss: 877.9388\n",
      "Epoch 291/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 516us/step - loss: 1088.2862 - val_loss: 877.7047\n",
      "Epoch 292/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1161.4812 - val_loss: 878.3201\n",
      "Epoch 293/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1048.1208 - val_loss: 878.4487\n",
      "Epoch 294/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1192.4121 - val_loss: 878.6274\n",
      "Epoch 295/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 1298.1771 - val_loss: 878.8755\n",
      "Epoch 296/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 1083.8432 - val_loss: 879.0988\n",
      "Epoch 297/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1470.9033 - val_loss: 878.4225\n",
      "Epoch 298/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 1501.5092 - val_loss: 879.6051\n",
      "Epoch 299/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1525.4403 - val_loss: 879.1021\n",
      "Epoch 300/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1105.5563 - val_loss: 878.8878\n",
      "\n",
      "Epoch 00300: loss improved from 1399.20607 to 1105.55635, saving model to C6007C.hdf5\n",
      "Epoch 301/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1099.8851 - val_loss: 878.9293\n",
      "Epoch 302/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 1137.8952 - val_loss: 878.9874\n",
      "Epoch 303/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 1219.0188 - val_loss: 878.8973\n",
      "Epoch 304/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1205.8118 - val_loss: 879.6577\n",
      "Epoch 305/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1117.0367 - val_loss: 879.1426\n",
      "Epoch 306/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1229.4206 - val_loss: 879.4290\n",
      "Epoch 307/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1202.1992 - val_loss: 878.0009\n",
      "Epoch 308/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 1167.9993 - val_loss: 878.2407\n",
      "Epoch 309/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1230.6050 - val_loss: 878.4266\n",
      "Epoch 310/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 1070.5269 - val_loss: 878.4705\n",
      "Epoch 311/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1281.6730 - val_loss: 878.7192\n",
      "Epoch 312/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1240.5773 - val_loss: 877.3909\n",
      "Epoch 313/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1161.2048 - val_loss: 874.3597\n",
      "Epoch 314/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 950.9120 - val_loss: 871.1778\n",
      "Epoch 315/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1515.8633 - val_loss: 868.8410\n",
      "Epoch 316/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 1190.9371 - val_loss: 867.7710\n",
      "Epoch 317/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1038.7643 - val_loss: 866.4882\n",
      "Epoch 318/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1077.6890 - val_loss: 862.5916\n",
      "Epoch 319/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1163.7656 - val_loss: 858.8306\n",
      "Epoch 320/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1011.8982 - val_loss: 856.4429\n",
      "Epoch 321/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1354.6115 - val_loss: 855.0939\n",
      "Epoch 322/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1255.9695 - val_loss: 853.8820\n",
      "Epoch 323/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1276.0804 - val_loss: 851.1693\n",
      "Epoch 324/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1160.5179 - val_loss: 848.1990\n",
      "Epoch 325/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1256.3779 - val_loss: 844.4623\n",
      "Epoch 326/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 993.2729 - val_loss: 842.4238\n",
      "Epoch 327/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1137.6368 - val_loss: 839.9454\n",
      "Epoch 328/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1377.3506 - val_loss: 838.4305\n",
      "Epoch 329/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1170.7216 - val_loss: 833.6927\n",
      "Epoch 330/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 1445.2492 - val_loss: 828.0632\n",
      "Epoch 331/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1547.2527 - val_loss: 824.6887\n",
      "Epoch 332/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 1071.6367 - val_loss: 822.5966\n",
      "Epoch 333/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1218.3813 - val_loss: 817.7153\n",
      "Epoch 334/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 1144.4571 - val_loss: 816.4709\n",
      "Epoch 335/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 984.6652 - val_loss: 815.1987\n",
      "Epoch 336/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1349.2846 - val_loss: 814.7535\n",
      "Epoch 337/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 1332.5241 - val_loss: 814.5795\n",
      "Epoch 338/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1173.8436 - val_loss: 813.4968\n",
      "Epoch 339/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1172.6646 - val_loss: 812.7296\n",
      "Epoch 340/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1219.4062 - val_loss: 812.0078\n",
      "Epoch 341/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1332.7365 - val_loss: 811.3691\n",
      "Epoch 342/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1468.7020 - val_loss: 811.3038\n",
      "Epoch 343/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1095.9680 - val_loss: 811.3630\n",
      "Epoch 344/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1258.1333 - val_loss: 811.5039\n",
      "Epoch 345/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1298.5138 - val_loss: 811.7218\n",
      "Epoch 346/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 910.4557 - val_loss: 811.8990\n",
      "Epoch 347/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1218.63 - 0s 467us/step - loss: 1191.8359 - val_loss: 814.6496\n",
      "Epoch 348/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1141.8586 - val_loss: 818.1862\n",
      "Epoch 349/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1339.5586 - val_loss: 820.9235\n",
      "Epoch 350/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1025.6999 - val_loss: 841.4972\n",
      "Epoch 351/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1167.8593 - val_loss: 937.2905\n",
      "Epoch 352/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 1493.0481 - val_loss: 943.9090\n",
      "Epoch 353/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1365.0862 - val_loss: 881.3401\n",
      "Epoch 354/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 1325.9815 - val_loss: 802.5775\n",
      "Epoch 355/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1303.3389 - val_loss: 796.0163\n",
      "Epoch 356/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1068.8641 - val_loss: 795.0864\n",
      "Epoch 357/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1253.0790 - val_loss: 794.9759\n",
      "Epoch 358/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1037.2254 - val_loss: 794.6590\n",
      "Epoch 359/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1377.9554 - val_loss: 793.6573\n",
      "Epoch 360/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 1319.8465 - val_loss: 791.8498\n",
      "Epoch 361/10000\n",
      "184/184 [==============================] - 0s 581us/step - loss: 1204.0468 - val_loss: 789.6059\n",
      "Epoch 362/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1057.4608 - val_loss: 787.6207\n",
      "Epoch 363/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 446us/step - loss: 1113.3203 - val_loss: 786.3438\n",
      "Epoch 364/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1300.7666 - val_loss: 785.2007\n",
      "Epoch 365/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 1179.5282 - val_loss: 784.2377\n",
      "Epoch 366/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1065.0500 - val_loss: 783.2430\n",
      "Epoch 367/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1543.5105 - val_loss: 782.5063\n",
      "Epoch 368/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 1051.2515 - val_loss: 781.9599\n",
      "Epoch 369/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 981.3324 - val_loss: 781.0162\n",
      "Epoch 370/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1216.1434 - val_loss: 782.2113\n",
      "Epoch 371/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1310.5214 - val_loss: 780.0342\n",
      "Epoch 372/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1196.1466 - val_loss: 779.7600\n",
      "Epoch 373/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1075.0291 - val_loss: 778.6656\n",
      "Epoch 374/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1028.4309 - val_loss: 778.3898\n",
      "Epoch 375/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1181.8111 - val_loss: 781.0607\n",
      "Epoch 376/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1536.1424 - val_loss: 783.3054\n",
      "Epoch 377/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1169.7552 - val_loss: 785.2610\n",
      "Epoch 378/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1268.0934 - val_loss: 786.5944\n",
      "Epoch 379/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 977.9543 - val_loss: 787.9319\n",
      "Epoch 380/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1340.3867 - val_loss: 789.1429\n",
      "Epoch 381/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1366.9197 - val_loss: 790.2858\n",
      "Epoch 382/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1333.6965 - val_loss: 791.5266\n",
      "Epoch 383/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1228.3149 - val_loss: 792.8311\n",
      "Epoch 384/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1119.8405 - val_loss: 795.3129\n",
      "Epoch 385/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 991.6044 - val_loss: 795.1586\n",
      "Epoch 386/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1582.3051 - val_loss: 795.0898\n",
      "Epoch 387/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 1252.8065 - val_loss: 794.8882\n",
      "Epoch 388/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1403.1772 - val_loss: 794.8639\n",
      "Epoch 389/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 1007.8914 - val_loss: 794.9540\n",
      "Epoch 390/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1422.5434 - val_loss: 796.7787\n",
      "Epoch 391/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 1350.7477 - val_loss: 798.5403\n",
      "Epoch 392/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 1199.3570 - val_loss: 787.7896\n",
      "Epoch 393/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1283.7919 - val_loss: 789.2394\n",
      "Epoch 394/10000\n",
      "184/184 [==============================] - 0s 435us/step - loss: 1109.7091 - val_loss: 790.8133\n",
      "Epoch 395/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1073.1430 - val_loss: 790.9780\n",
      "Epoch 396/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1469.8842 - val_loss: 790.7756\n",
      "Epoch 397/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 941.6184 - val_loss: 790.2068\n",
      "Epoch 398/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1342.0749 - val_loss: 789.5881\n",
      "Epoch 399/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1281.8745 - val_loss: 788.6417\n",
      "Epoch 400/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1227.0588 - val_loss: 787.7778\n",
      "\n",
      "Epoch 00400: loss did not improve from 1105.55635\n",
      "Epoch 401/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1292.9516 - val_loss: 787.0981\n",
      "Epoch 402/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 984.1399 - val_loss: 786.2634\n",
      "Epoch 403/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1149.4604 - val_loss: 785.5242\n",
      "Epoch 404/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1195.8523 - val_loss: 784.9336\n",
      "Epoch 405/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1469.4694 - val_loss: 784.4401\n",
      "Epoch 406/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1353.4409 - val_loss: 783.5636\n",
      "Epoch 407/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1153.2362 - val_loss: 782.3097\n",
      "Epoch 408/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1309.7754 - val_loss: 780.4603\n",
      "Epoch 409/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 1421.4384 - val_loss: 778.9842\n",
      "Epoch 410/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 1110.0452 - val_loss: 778.1972\n",
      "Epoch 411/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 1067.2186 - val_loss: 777.2808\n",
      "Epoch 412/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 1151.7904 - val_loss: 776.4514\n",
      "Epoch 413/10000\n",
      "184/184 [==============================] - 0s 804us/step - loss: 1176.4738 - val_loss: 775.7099\n",
      "Epoch 414/10000\n",
      "184/184 [==============================] - 0s 848us/step - loss: 1321.5336 - val_loss: 775.2071\n",
      "Epoch 415/10000\n",
      "184/184 [==============================] - 0s 853us/step - loss: 1169.2691 - val_loss: 774.5929\n",
      "Epoch 416/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 1048.8458 - val_loss: 777.8641\n",
      "Epoch 417/10000\n",
      "184/184 [==============================] - 0s 970us/step - loss: 1194.6955 - val_loss: 790.3466\n",
      "Epoch 418/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 1225.5604 - val_loss: 794.6806\n",
      "Epoch 419/10000\n",
      "184/184 [==============================] - 0s 837us/step - loss: 1036.0976 - val_loss: 793.7629\n",
      "Epoch 420/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 1021.2654 - val_loss: 793.3206\n",
      "Epoch 421/10000\n",
      "184/184 [==============================] - 0s 826us/step - loss: 951.0458 - val_loss: 793.0134\n",
      "Epoch 422/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 1444.0290 - val_loss: 792.9464\n",
      "Epoch 423/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 1353.8186 - val_loss: 792.8515\n",
      "Epoch 424/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 1221.9742 - val_loss: 790.0015\n",
      "Epoch 425/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 1135.2133 - val_loss: 787.5072\n",
      "Epoch 426/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 1143.7809 - val_loss: 786.9215\n",
      "Epoch 427/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 1137.8706 - val_loss: 788.3071\n",
      "Epoch 428/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 1221.9716 - val_loss: 792.3184\n",
      "Epoch 429/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 1315.3381 - val_loss: 794.7073\n",
      "Epoch 430/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1089.0384 - val_loss: 794.9518\n",
      "Epoch 431/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1035.0963 - val_loss: 792.5798\n",
      "Epoch 432/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1052.3250 - val_loss: 787.8839\n",
      "Epoch 433/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1426.2062 - val_loss: 776.6418\n",
      "Epoch 434/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1101.5141 - val_loss: 778.9954\n",
      "Epoch 435/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1383.2363 - val_loss: 785.1931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 436/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1298.6887 - val_loss: 790.0495\n",
      "Epoch 437/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1152.3111 - val_loss: 791.2642\n",
      "Epoch 438/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1098.6397 - val_loss: 791.4742\n",
      "Epoch 439/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1297.1168 - val_loss: 790.7641\n",
      "Epoch 440/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1039.0528 - val_loss: 791.2421\n",
      "Epoch 441/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1129.8192 - val_loss: 791.0474\n",
      "Epoch 442/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1131.0842 - val_loss: 790.6879\n",
      "Epoch 443/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1199.8891 - val_loss: 789.9409\n",
      "Epoch 444/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1379.0079 - val_loss: 788.4115\n",
      "Epoch 445/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1085.1880 - val_loss: 785.9648\n",
      "Epoch 446/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1101.1879 - val_loss: 783.6708\n",
      "Epoch 447/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 1228.6393 - val_loss: 781.7973\n",
      "Epoch 448/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 1480.3968 - val_loss: 779.2342\n",
      "Epoch 449/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1260.9210 - val_loss: 777.8332\n",
      "Epoch 450/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 1132.4192 - val_loss: 776.1630\n",
      "Epoch 451/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1179.0021 - val_loss: 774.5133\n",
      "Epoch 452/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1214.1972 - val_loss: 773.7856\n",
      "Epoch 453/10000\n",
      "184/184 [==============================] - 0s 682us/step - loss: 903.9807 - val_loss: 773.2862\n",
      "Epoch 454/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 1058.0645 - val_loss: 772.8450\n",
      "Epoch 455/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 1481.6889 - val_loss: 772.4236\n",
      "Epoch 456/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 1342.2530 - val_loss: 772.7057\n",
      "Epoch 457/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 987.3064 - val_loss: 773.3660\n",
      "Epoch 458/10000\n",
      "184/184 [==============================] - 0s 750us/step - loss: 1231.9510 - val_loss: 773.7985\n",
      "Epoch 459/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 1232.3304 - val_loss: 773.9401\n",
      "Epoch 460/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1385.3069 - val_loss: 771.0953\n",
      "Epoch 461/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1290.7844 - val_loss: 764.9277\n",
      "Epoch 462/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1267.8585 - val_loss: 763.3321\n",
      "Epoch 463/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1124.8274 - val_loss: 759.6052\n",
      "Epoch 464/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1026.6277 - val_loss: 766.1157\n",
      "Epoch 465/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 1004.4518 - val_loss: 763.9154\n",
      "Epoch 466/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1031.3579 - val_loss: 762.7558\n",
      "Epoch 467/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 941.2063 - val_loss: 762.0585\n",
      "Epoch 468/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 1196.8696 - val_loss: 761.5645\n",
      "Epoch 469/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 1262.8465 - val_loss: 761.1256\n",
      "Epoch 470/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1460.9320 - val_loss: 760.5746\n",
      "Epoch 471/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 1059.0496 - val_loss: 760.1620\n",
      "Epoch 472/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1138.9154 - val_loss: 759.7626\n",
      "Epoch 473/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 988.3817 - val_loss: 759.3439\n",
      "Epoch 474/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 970.5031 - val_loss: 759.1011\n",
      "Epoch 475/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1140.5537 - val_loss: 758.9206\n",
      "Epoch 476/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1082.09 - 0s 473us/step - loss: 1067.6776 - val_loss: 758.7862\n",
      "Epoch 477/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1134.2203 - val_loss: 758.9676\n",
      "Epoch 478/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 1325.4429 - val_loss: 758.9909\n",
      "Epoch 479/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 1153.4957 - val_loss: 757.8598\n",
      "Epoch 480/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1127.9767 - val_loss: 756.9766\n",
      "Epoch 481/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1255.8995 - val_loss: 756.3477\n",
      "Epoch 482/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1080.2786 - val_loss: 755.9156\n",
      "Epoch 483/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1118.8436 - val_loss: 755.5511\n",
      "Epoch 484/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1154.2422 - val_loss: 755.1995\n",
      "Epoch 485/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1337.9603 - val_loss: 754.7587\n",
      "Epoch 486/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1040.9630 - val_loss: 754.3212\n",
      "Epoch 487/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1103.9864 - val_loss: 753.8935\n",
      "Epoch 488/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 1003.9240 - val_loss: 753.4581\n",
      "Epoch 489/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 1006.8231 - val_loss: 753.0432\n",
      "Epoch 490/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1123.7077 - val_loss: 752.7117\n",
      "Epoch 491/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1022.7462 - val_loss: 752.3235\n",
      "Epoch 492/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1124.6326 - val_loss: 751.8045\n",
      "Epoch 493/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 1165.8580 - val_loss: 751.2480\n",
      "Epoch 494/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1241.5924 - val_loss: 750.8726\n",
      "Epoch 495/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 925.8724 - val_loss: 750.2947\n",
      "Epoch 496/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 1195.5867 - val_loss: 749.6553\n",
      "Epoch 497/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 1215.3267 - val_loss: 748.0554\n",
      "Epoch 498/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1213.0388 - val_loss: 746.4809\n",
      "Epoch 499/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1185.1970 - val_loss: 745.0213\n",
      "Epoch 500/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 1136.7170 - val_loss: 743.9369\n",
      "\n",
      "Epoch 00500: loss did not improve from 1105.55635\n",
      "Epoch 501/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 904.9637 - val_loss: 742.7293\n",
      "Epoch 502/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1393.2799 - val_loss: 739.9515\n",
      "Epoch 503/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1038.1847 - val_loss: 738.1828\n",
      "Epoch 504/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 1059.1855 - val_loss: 736.9512\n",
      "Epoch 505/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 1275.4128 - val_loss: 735.6964\n",
      "Epoch 506/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1059.3191 - val_loss: 733.1683\n",
      "Epoch 507/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1095.8676 - val_loss: 731.6089\n",
      "Epoch 508/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 674us/step - loss: 1188.5116 - val_loss: 730.4409\n",
      "Epoch 509/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1308.4877 - val_loss: 729.3574\n",
      "Epoch 510/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 1275.7332 - val_loss: 728.4821\n",
      "Epoch 511/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 1137.7890 - val_loss: 727.6880\n",
      "Epoch 512/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 991.0021 - val_loss: 726.9234\n",
      "Epoch 513/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 1136.7695 - val_loss: 726.1632\n",
      "Epoch 514/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 1253.4113 - val_loss: 727.1207\n",
      "Epoch 515/10000\n",
      "184/184 [==============================] - 0s 864us/step - loss: 1056.5007 - val_loss: 727.8518\n",
      "Epoch 516/10000\n",
      "184/184 [==============================] - 0s 842us/step - loss: 1027.2615 - val_loss: 728.2115\n",
      "Epoch 517/10000\n",
      "184/184 [==============================] - 0s 750us/step - loss: 1004.0032 - val_loss: 728.4013\n",
      "Epoch 518/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 1052.8696 - val_loss: 728.5356\n",
      "Epoch 519/10000\n",
      "184/184 [==============================] - 0s 793us/step - loss: 1129.9283 - val_loss: 728.5491\n",
      "Epoch 520/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 1232.0382 - val_loss: 728.5876\n",
      "Epoch 521/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 1117.7154 - val_loss: 728.6005\n",
      "Epoch 522/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 1419.1212 - val_loss: 728.5385\n",
      "Epoch 523/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 945.5182 - val_loss: 728.2435\n",
      "Epoch 524/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 1439.3618 - val_loss: 727.9610\n",
      "Epoch 525/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 1083.8382 - val_loss: 727.6623\n",
      "Epoch 526/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 981.3792 - val_loss: 728.6989\n",
      "Epoch 527/10000\n",
      "184/184 [==============================] - 0s 815us/step - loss: 921.7075 - val_loss: 734.4429\n",
      "Epoch 528/10000\n",
      "184/184 [==============================] - 0s 842us/step - loss: 1141.7384 - val_loss: 736.2924\n",
      "Epoch 529/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 974.6393 - val_loss: 736.9188\n",
      "Epoch 530/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 1242.3455 - val_loss: 737.0720\n",
      "Epoch 531/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 981.0631 - val_loss: 735.5345\n",
      "Epoch 532/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1107.7095 - val_loss: 733.7353\n",
      "Epoch 533/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1051.3484 - val_loss: 732.7355\n",
      "Epoch 534/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1128.1204 - val_loss: 732.2910\n",
      "Epoch 535/10000\n",
      "184/184 [==============================] - 0s 429us/step - loss: 854.1116 - val_loss: 732.0762\n",
      "Epoch 536/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1204.3176 - val_loss: 731.9015\n",
      "Epoch 537/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1342.9993 - val_loss: 731.5818\n",
      "Epoch 538/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 772.4691 - val_loss: 731.3071\n",
      "Epoch 539/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 832.6390 - val_loss: 731.0746\n",
      "Epoch 540/10000\n",
      "184/184 [==============================] - 0s 848us/step - loss: 1052.6748 - val_loss: 730.7473\n",
      "Epoch 541/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 1384.9954 - val_loss: 729.2706\n",
      "Epoch 542/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1033.2940 - val_loss: 725.5543\n",
      "Epoch 543/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1065.1268 - val_loss: 723.2958\n",
      "Epoch 544/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 1023.1431 - val_loss: 722.1223\n",
      "Epoch 545/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 982.6469 - val_loss: 721.1493\n",
      "Epoch 546/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1014.1869 - val_loss: 720.3428\n",
      "Epoch 547/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 1151.8131 - val_loss: 719.3969\n",
      "Epoch 548/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 985.5631 - val_loss: 718.8676\n",
      "Epoch 549/10000\n",
      "184/184 [==============================] - 0s 476us/step - loss: 1022.1260 - val_loss: 718.9256\n",
      "Epoch 550/10000\n",
      "184/184 [==============================] - 0s 525us/step - loss: 959.1926 - val_loss: 719.2231\n",
      "Epoch 551/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1356.0452 - val_loss: 719.6470\n",
      "Epoch 552/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1190.6128 - val_loss: 719.9359\n",
      "Epoch 553/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1241.9279 - val_loss: 719.7758\n",
      "Epoch 554/10000\n",
      "184/184 [==============================] - 0s 435us/step - loss: 1147.0953 - val_loss: 719.0710\n",
      "Epoch 555/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1015.0840 - val_loss: 718.7160\n",
      "Epoch 556/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1241.4650 - val_loss: 718.5190\n",
      "Epoch 557/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 985.3723 - val_loss: 718.2320\n",
      "Epoch 558/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 974.9492 - val_loss: 717.1619\n",
      "Epoch 559/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1186.5491 - val_loss: 715.9726\n",
      "Epoch 560/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 830.0160 - val_loss: 714.8159\n",
      "Epoch 561/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 1263.0187 - val_loss: 713.8779\n",
      "Epoch 562/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 994.8158 - val_loss: 722.5696\n",
      "Epoch 563/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 969.7033 - val_loss: 731.6954\n",
      "Epoch 564/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 993.1806 - val_loss: 726.1015\n",
      "Epoch 565/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 817.8633 - val_loss: 719.8903\n",
      "Epoch 566/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 1091.4324 - val_loss: 707.6058\n",
      "Epoch 567/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1049.0828 - val_loss: 709.5074\n",
      "Epoch 568/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1118.5458 - val_loss: 715.7021\n",
      "Epoch 569/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1099.0701 - val_loss: 729.2717\n",
      "Epoch 570/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1154.6973 - val_loss: 733.9402\n",
      "Epoch 571/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1184.5991 - val_loss: 745.5775\n",
      "Epoch 572/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 1070.2095 - val_loss: 759.0679\n",
      "Epoch 573/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1253.6949 - val_loss: 772.7764\n",
      "Epoch 574/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 862.0992 - val_loss: 787.9799\n",
      "Epoch 575/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 1042.2604 - val_loss: 799.8181\n",
      "Epoch 576/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 959.2526 - val_loss: 806.1415\n",
      "Epoch 577/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1136.0676 - val_loss: 808.4598\n",
      "Epoch 578/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1055.7373 - val_loss: 807.3402\n",
      "Epoch 579/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1324.1451 - val_loss: 806.4592\n",
      "Epoch 580/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 854.2507 - val_loss: 805.6910\n",
      "Epoch 581/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 505us/step - loss: 1156.2491 - val_loss: 805.1096\n",
      "Epoch 582/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 983.2924 - val_loss: 804.6358\n",
      "Epoch 583/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1039.1734 - val_loss: 803.8813\n",
      "Epoch 584/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 1245.5087 - val_loss: 805.7637\n",
      "Epoch 585/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 883.6876 - val_loss: 804.9544\n",
      "Epoch 586/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1024.7786 - val_loss: 801.6778\n",
      "Epoch 587/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1151.5131 - val_loss: 800.8457\n",
      "Epoch 588/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1098.2491 - val_loss: 800.0304\n",
      "Epoch 589/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1077.0345 - val_loss: 799.3058\n",
      "Epoch 590/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1041.7499 - val_loss: 800.0875\n",
      "Epoch 591/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1027.5623 - val_loss: 800.5065\n",
      "Epoch 592/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 972.1979 - val_loss: 800.6877\n",
      "Epoch 593/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1340.3382 - val_loss: 800.3915\n",
      "Epoch 594/10000\n",
      "184/184 [==============================] - 0s 435us/step - loss: 1026.6497 - val_loss: 799.7499\n",
      "Epoch 595/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 1053.7190 - val_loss: 798.6008\n",
      "Epoch 596/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 1153.0430 - val_loss: 795.9143\n",
      "Epoch 597/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1235.9531 - val_loss: 791.9443\n",
      "Epoch 598/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1040.9411 - val_loss: 787.4341\n",
      "Epoch 599/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1121.3312 - val_loss: 783.2285\n",
      "Epoch 600/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1035.90 - 0s 543us/step - loss: 992.4606 - val_loss: 780.7257\n",
      "\n",
      "Epoch 00600: loss improved from 1105.55635 to 992.46061, saving model to C6007C.hdf5\n",
      "Epoch 601/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1064.4136 - val_loss: 779.2225\n",
      "Epoch 602/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 1224.9229 - val_loss: 778.0024\n",
      "Epoch 603/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1078.0761 - val_loss: 735.9572\n",
      "Epoch 604/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 928.5235 - val_loss: 717.9379\n",
      "Epoch 605/10000\n",
      "184/184 [==============================] - 0s 506us/step - loss: 1023.7128 - val_loss: 702.1984\n",
      "Epoch 606/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1081.8546 - val_loss: 697.9129\n",
      "Epoch 607/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 1325.5561 - val_loss: 700.0478\n",
      "Epoch 608/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 978.9682 - val_loss: 692.1978\n",
      "Epoch 609/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 922.3663 - val_loss: 693.0013\n",
      "Epoch 610/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 869.2307 - val_loss: 693.8909\n",
      "Epoch 611/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1313.8359 - val_loss: 695.6512\n",
      "Epoch 612/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1028.0056 - val_loss: 697.5123\n",
      "Epoch 613/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1187.0925 - val_loss: 698.9164\n",
      "Epoch 614/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1167.8463 - val_loss: 699.8369\n",
      "Epoch 615/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1072.0474 - val_loss: 700.3053\n",
      "Epoch 616/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 737.5911 - val_loss: 700.4920\n",
      "Epoch 617/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1108.1578 - val_loss: 700.5905\n",
      "Epoch 618/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1127.1318 - val_loss: 700.5905\n",
      "Epoch 619/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1020.8229 - val_loss: 700.5406\n",
      "Epoch 620/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1137.9178 - val_loss: 700.4020\n",
      "Epoch 621/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1144.7291 - val_loss: 700.1551\n",
      "Epoch 622/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 884.4854 - val_loss: 699.7510\n",
      "Epoch 623/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 1313.7012 - val_loss: 699.3500\n",
      "Epoch 624/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 1246.8865 - val_loss: 698.9575\n",
      "Epoch 625/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1109.4603 - val_loss: 698.5414\n",
      "Epoch 626/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 869.6103 - val_loss: 698.1206\n",
      "Epoch 627/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 1158.4157 - val_loss: 697.7392\n",
      "Epoch 628/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1105.9758 - val_loss: 697.4189\n",
      "Epoch 629/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1078.3722 - val_loss: 696.8937\n",
      "Epoch 630/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1085.0940 - val_loss: 696.3865\n",
      "Epoch 631/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1250.0422 - val_loss: 695.8644\n",
      "Epoch 632/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1001.4574 - val_loss: 695.2897\n",
      "Epoch 633/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1008.4554 - val_loss: 694.3461\n",
      "Epoch 634/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1367.7160 - val_loss: 693.5471\n",
      "Epoch 635/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 935.3455 - val_loss: 692.8347\n",
      "Epoch 636/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 969.0602 - val_loss: 691.5924\n",
      "Epoch 637/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 924.5239 - val_loss: 689.9713\n",
      "Epoch 638/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 873.4348 - val_loss: 688.1517\n",
      "Epoch 639/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1080.2482 - val_loss: 686.3657\n",
      "Epoch 640/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 1037.8808 - val_loss: 684.8466\n",
      "Epoch 641/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1020.4048 - val_loss: 683.4976\n",
      "Epoch 642/10000\n",
      "184/184 [==============================] - 0s 880us/step - loss: 993.6479 - val_loss: 682.2233\n",
      "Epoch 643/10000\n",
      "184/184 [==============================] - 0s 867us/step - loss: 1116.1877 - val_loss: 680.9803\n",
      "Epoch 644/10000\n",
      "184/184 [==============================] - 0s 940us/step - loss: 1142.7927 - val_loss: 679.8584\n",
      "Epoch 645/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 1101.0204 - val_loss: 679.1283\n",
      "Epoch 646/10000\n",
      "184/184 [==============================] - 0s 829us/step - loss: 938.3765 - val_loss: 678.5638\n",
      "Epoch 647/10000\n",
      "184/184 [==============================] - 0s 698us/step - loss: 1253.7858 - val_loss: 677.6515\n",
      "Epoch 648/10000\n",
      "184/184 [==============================] - 0s 709us/step - loss: 1073.3984 - val_loss: 677.0787\n",
      "Epoch 649/10000\n",
      "184/184 [==============================] - 0s 557us/step - loss: 961.3868 - val_loss: 676.6124\n",
      "Epoch 650/10000\n",
      "184/184 [==============================] - 0s 552us/step - loss: 1053.4524 - val_loss: 676.2166\n",
      "Epoch 651/10000\n",
      "184/184 [==============================] - 0s 595us/step - loss: 1138.7012 - val_loss: 675.8865\n",
      "Epoch 652/10000\n",
      "184/184 [==============================] - 0s 720us/step - loss: 1048.5019 - val_loss: 675.5840\n",
      "Epoch 653/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 660us/step - loss: 889.0988 - val_loss: 675.2370\n",
      "Epoch 654/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 855.4500 - val_loss: 675.0844\n",
      "Epoch 655/10000\n",
      "184/184 [==============================] - 0s 666us/step - loss: 857.6282 - val_loss: 675.3423\n",
      "Epoch 656/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 1206.1481 - val_loss: 675.9340\n",
      "Epoch 657/10000\n",
      "184/184 [==============================] - 0s 573us/step - loss: 1225.7245 - val_loss: 677.0766\n",
      "Epoch 658/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 1288.6900 - val_loss: 678.6688\n",
      "Epoch 659/10000\n",
      "184/184 [==============================] - 0s 579us/step - loss: 953.0494 - val_loss: 681.2218\n",
      "Epoch 660/10000\n",
      "184/184 [==============================] - 0s 563us/step - loss: 1274.1280 - val_loss: 685.8419\n",
      "Epoch 661/10000\n",
      "184/184 [==============================] - 0s 552us/step - loss: 984.6284 - val_loss: 691.4342\n",
      "Epoch 662/10000\n",
      "184/184 [==============================] - 0s 492us/step - loss: 909.3703 - val_loss: 689.5871\n",
      "Epoch 663/10000\n",
      "184/184 [==============================] - 0s 470us/step - loss: 1022.4317 - val_loss: 681.9886\n",
      "Epoch 664/10000\n",
      "184/184 [==============================] - 0s 465us/step - loss: 949.7438 - val_loss: 677.8183\n",
      "Epoch 665/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 1057.9477 - val_loss: 676.1245\n",
      "Epoch 666/10000\n",
      "184/184 [==============================] - 0s 448us/step - loss: 1060.3076 - val_loss: 675.3863\n",
      "Epoch 667/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1212.6816 - val_loss: 674.8994\n",
      "Epoch 668/10000\n",
      "184/184 [==============================] - 0s 459us/step - loss: 1017.8112 - val_loss: 674.4410\n",
      "Epoch 669/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 1154.6665 - val_loss: 673.8323\n",
      "Epoch 670/10000\n",
      "184/184 [==============================] - 0s 525us/step - loss: 919.9780 - val_loss: 672.8151\n",
      "Epoch 671/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 1134.1034 - val_loss: 672.0097\n",
      "Epoch 672/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1203.8683 - val_loss: 671.4076\n",
      "Epoch 673/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 975.3720 - val_loss: 671.0028\n",
      "Epoch 674/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 922.4607 - val_loss: 670.6315\n",
      "Epoch 675/10000\n",
      "184/184 [==============================] - 0s 476us/step - loss: 1135.8347 - val_loss: 670.4183\n",
      "Epoch 676/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 961.7296 - val_loss: 670.1825\n",
      "Epoch 677/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 967.9840 - val_loss: 669.5696\n",
      "Epoch 678/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1018.9168 - val_loss: 669.2169\n",
      "Epoch 679/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1020.9238 - val_loss: 669.1460\n",
      "Epoch 680/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1061.3079 - val_loss: 669.0145\n",
      "Epoch 681/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1002.8429 - val_loss: 668.7869\n",
      "Epoch 682/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1104.7993 - val_loss: 668.5257\n",
      "Epoch 683/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 903.8689 - val_loss: 668.1738\n",
      "Epoch 684/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 965.8716 - val_loss: 667.8370\n",
      "Epoch 685/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1023.4805 - val_loss: 667.5364\n",
      "Epoch 686/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1145.2951 - val_loss: 667.6934\n",
      "Epoch 687/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1072.7969 - val_loss: 670.1740\n",
      "Epoch 688/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 900.9035 - val_loss: 678.2526\n",
      "Epoch 689/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 946.3844 - val_loss: 684.4722\n",
      "Epoch 690/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 1009.8232 - val_loss: 681.1337\n",
      "Epoch 691/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 1083.5600 - val_loss: 675.4692\n",
      "Epoch 692/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1049.9538 - val_loss: 670.6237\n",
      "Epoch 693/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 939.3369 - val_loss: 667.4553\n",
      "Epoch 694/10000\n",
      "184/184 [==============================] - 0s 456us/step - loss: 969.8048 - val_loss: 666.1430\n",
      "Epoch 695/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1094.9466 - val_loss: 666.5351\n",
      "Epoch 696/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1339.3216 - val_loss: 667.6633\n",
      "Epoch 697/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 997.8422 - val_loss: 672.4251\n",
      "Epoch 698/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1421.4458 - val_loss: 675.2381\n",
      "Epoch 699/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 989.5445 - val_loss: 681.3983\n",
      "Epoch 700/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 852.760 - 0s 489us/step - loss: 873.9956 - val_loss: 683.8667\n",
      "\n",
      "Epoch 00700: loss improved from 992.46061 to 873.99562, saving model to C6007C.hdf5\n",
      "Epoch 701/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 918.7046 - val_loss: 682.3452\n",
      "Epoch 702/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 784.7434 - val_loss: 683.2433\n",
      "Epoch 703/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 996.7818 - val_loss: 686.1583\n",
      "Epoch 704/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 986.1457 - val_loss: 689.5872\n",
      "Epoch 705/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1307.3473 - val_loss: 693.0803\n",
      "Epoch 706/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1007.6056 - val_loss: 696.8328\n",
      "Epoch 707/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1008.4297 - val_loss: 701.1995\n",
      "Epoch 708/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 899.6058 - val_loss: 705.5931\n",
      "Epoch 709/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 1141.4087 - val_loss: 710.9306\n",
      "Epoch 710/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1132.9260 - val_loss: 715.9575\n",
      "Epoch 711/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 815.0906 - val_loss: 723.3535\n",
      "Epoch 712/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1051.0383 - val_loss: 733.1478\n",
      "Epoch 713/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 910.7914 - val_loss: 740.9481\n",
      "Epoch 714/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 999.6408 - val_loss: 745.8496\n",
      "Epoch 715/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 935.3562 - val_loss: 749.4794\n",
      "Epoch 716/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1175.0740 - val_loss: 751.3987\n",
      "Epoch 717/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 994.3590 - val_loss: 751.9258\n",
      "Epoch 718/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 904.6585 - val_loss: 751.5560\n",
      "Epoch 719/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 809.9130 - val_loss: 750.9320\n",
      "Epoch 720/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1011.8664 - val_loss: 750.2552\n",
      "Epoch 721/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1013.1277 - val_loss: 749.6442\n",
      "Epoch 722/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1140.8493 - val_loss: 748.8455\n",
      "Epoch 723/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 921.2920 - val_loss: 739.4023\n",
      "Epoch 724/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1073.5506 - val_loss: 724.5667\n",
      "Epoch 725/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 560us/step - loss: 1160.3151 - val_loss: 711.8419\n",
      "Epoch 726/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 829.6091 - val_loss: 704.3807\n",
      "Epoch 727/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1040.0840 - val_loss: 698.6824\n",
      "Epoch 728/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1210.0879 - val_loss: 695.1124\n",
      "Epoch 729/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1098.7604 - val_loss: 693.3546\n",
      "Epoch 730/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 905.5019 - val_loss: 692.2707\n",
      "Epoch 731/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1074.9402 - val_loss: 692.2029\n",
      "Epoch 732/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1019.3917 - val_loss: 692.8130\n",
      "Epoch 733/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1185.0566 - val_loss: 693.5615\n",
      "Epoch 734/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 894.8425 - val_loss: 693.8090\n",
      "Epoch 735/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 795.7376 - val_loss: 693.4315\n",
      "Epoch 736/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 1105.2030 - val_loss: 691.5259\n",
      "Epoch 737/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1029.1076 - val_loss: 690.1938\n",
      "Epoch 738/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 1138.7470 - val_loss: 688.9962\n",
      "Epoch 739/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 1072.6441 - val_loss: 687.6956\n",
      "Epoch 740/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 963.5323 - val_loss: 685.9951\n",
      "Epoch 741/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 850.9986 - val_loss: 684.4254\n",
      "Epoch 742/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 990.9711 - val_loss: 683.0739\n",
      "Epoch 743/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 992.1490 - val_loss: 681.2178\n",
      "Epoch 744/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1009.3696 - val_loss: 682.7199\n",
      "Epoch 745/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1220.2667 - val_loss: 684.0502\n",
      "Epoch 746/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 859.8771 - val_loss: 684.7256\n",
      "Epoch 747/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1155.2359 - val_loss: 687.8513\n",
      "Epoch 748/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 946.5636 - val_loss: 690.9415\n",
      "Epoch 749/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1085.5173 - val_loss: 693.7571\n",
      "Epoch 750/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 953.0623 - val_loss: 695.9755\n",
      "Epoch 751/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 1245.3728 - val_loss: 697.5579\n",
      "Epoch 752/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1121.0421 - val_loss: 698.6591\n",
      "Epoch 753/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1313.9398 - val_loss: 699.0999\n",
      "Epoch 754/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1069.8246 - val_loss: 699.3893\n",
      "Epoch 755/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 979.9120 - val_loss: 698.6484\n",
      "Epoch 756/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 1147.4799 - val_loss: 697.3954\n",
      "Epoch 757/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1202.2435 - val_loss: 696.3539\n",
      "Epoch 758/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 1057.7871 - val_loss: 694.1545\n",
      "Epoch 759/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 784.7006 - val_loss: 685.1874\n",
      "Epoch 760/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 741.527 - 0s 495us/step - loss: 723.9459 - val_loss: 679.1685\n",
      "Epoch 761/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1040.0361 - val_loss: 674.8031\n",
      "Epoch 762/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 1008.1870 - val_loss: 671.7443\n",
      "Epoch 763/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 974.8041 - val_loss: 669.4370\n",
      "Epoch 764/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 856.4411 - val_loss: 667.7341\n",
      "Epoch 765/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 696.7459 - val_loss: 666.3770\n",
      "Epoch 766/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 924.1659 - val_loss: 665.3371\n",
      "Epoch 767/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 898.2597 - val_loss: 664.4636\n",
      "Epoch 768/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 863.3790 - val_loss: 663.5676\n",
      "Epoch 769/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1007.3576 - val_loss: 662.7940\n",
      "Epoch 770/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 926.9941 - val_loss: 662.1544\n",
      "Epoch 771/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 807.6775 - val_loss: 661.5715\n",
      "Epoch 772/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 1020.1497 - val_loss: 661.0023\n",
      "Epoch 773/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 1208.4180 - val_loss: 661.1484\n",
      "Epoch 774/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1098.8927 - val_loss: 661.2863\n",
      "Epoch 775/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 906.8669 - val_loss: 660.8960\n",
      "Epoch 776/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 965.6117 - val_loss: 661.4398\n",
      "Epoch 777/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 923.7599 - val_loss: 661.1664\n",
      "Epoch 778/10000\n",
      "184/184 [==============================] - 0s 804us/step - loss: 936.8898 - val_loss: 660.9636\n",
      "Epoch 779/10000\n",
      "184/184 [==============================] - 0s 913us/step - loss: 1019.9583 - val_loss: 660.8002\n",
      "Epoch 780/10000\n",
      "184/184 [==============================] - 0s 967us/step - loss: 1009.1101 - val_loss: 660.4319\n",
      "Epoch 781/10000\n",
      "184/184 [==============================] - 0s 848us/step - loss: 973.1461 - val_loss: 659.6832\n",
      "Epoch 782/10000\n",
      "184/184 [==============================] - 0s 848us/step - loss: 697.7218 - val_loss: 658.7047\n",
      "Epoch 783/10000\n",
      "184/184 [==============================] - 0s 930us/step - loss: 918.6695 - val_loss: 657.5788\n",
      "Epoch 784/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 973.0269 - val_loss: 656.5831\n",
      "Epoch 785/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 978.6379 - val_loss: 654.6436\n",
      "Epoch 786/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 762.5651 - val_loss: 653.0111\n",
      "Epoch 787/10000\n",
      "184/184 [==============================] - 0s 873us/step - loss: 1041.5101 - val_loss: 652.0328\n",
      "Epoch 788/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 902.7596 - val_loss: 651.2596\n",
      "Epoch 789/10000\n",
      "184/184 [==============================] - 0s 913us/step - loss: 1142.6055 - val_loss: 650.6090\n",
      "Epoch 790/10000\n",
      "184/184 [==============================] - 0s 924us/step - loss: 1067.5484 - val_loss: 650.0044\n",
      "Epoch 791/10000\n",
      "184/184 [==============================] - 0s 859us/step - loss: 940.8241 - val_loss: 649.6049\n",
      "Epoch 792/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 1049.3512 - val_loss: 649.1934\n",
      "Epoch 793/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 1073.7946 - val_loss: 649.0455\n",
      "Epoch 794/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 734.7033 - val_loss: 648.9994\n",
      "Epoch 795/10000\n",
      "184/184 [==============================] - 0s 843us/step - loss: 876.6802 - val_loss: 648.7491\n",
      "Epoch 796/10000\n",
      "184/184 [==============================] - 0s 946us/step - loss: 927.5692 - val_loss: 648.3527\n",
      "Epoch 797/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 958.7743 - val_loss: 647.4102\n",
      "Epoch 798/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 538us/step - loss: 918.1398 - val_loss: 646.5560\n",
      "Epoch 799/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 897.2746 - val_loss: 646.0624\n",
      "Epoch 800/10000\n",
      "184/184 [==============================] - 0s 715us/step - loss: 974.4477 - val_loss: 646.0123\n",
      "\n",
      "Epoch 00800: loss did not improve from 873.99562\n",
      "Epoch 801/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 762.5988 - val_loss: 647.0313\n",
      "Epoch 802/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 867.8937 - val_loss: 648.9476\n",
      "Epoch 803/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1000.2908 - val_loss: 650.7924\n",
      "Epoch 804/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1069.7423 - val_loss: 652.3051\n",
      "Epoch 805/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 854.9375 - val_loss: 653.0718\n",
      "Epoch 806/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 906.4417 - val_loss: 652.9727\n",
      "Epoch 807/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 1057.7276 - val_loss: 652.6180\n",
      "Epoch 808/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 965.3142 - val_loss: 652.2061\n",
      "Epoch 809/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 793.9072 - val_loss: 651.6843\n",
      "Epoch 810/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 979.2493 - val_loss: 651.2604\n",
      "Epoch 811/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 1026.4850 - val_loss: 650.8539\n",
      "Epoch 812/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 1094.0397 - val_loss: 650.4371\n",
      "Epoch 813/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 972.2856 - val_loss: 650.0697\n",
      "Epoch 814/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1082.8817 - val_loss: 649.7607\n",
      "Epoch 815/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 989.5940 - val_loss: 650.0801\n",
      "Epoch 816/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 1032.2374 - val_loss: 650.9100\n",
      "Epoch 817/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 893.9553 - val_loss: 651.4720\n",
      "Epoch 818/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 1089.6664 - val_loss: 651.2805\n",
      "Epoch 819/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 914.6272 - val_loss: 650.9705\n",
      "Epoch 820/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 949.3137 - val_loss: 652.9302\n",
      "Epoch 821/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 708.0022 - val_loss: 654.8718\n",
      "Epoch 822/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 971.1383 - val_loss: 651.9126\n",
      "Epoch 823/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 922.3269 - val_loss: 650.1703\n",
      "Epoch 824/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 986.5854 - val_loss: 649.2460\n",
      "Epoch 825/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 1089.1704 - val_loss: 648.4970\n",
      "Epoch 826/10000\n",
      "184/184 [==============================] - 0s 601us/step - loss: 898.6362 - val_loss: 647.6230\n",
      "Epoch 827/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 1137.9170 - val_loss: 646.5508\n",
      "Epoch 828/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 965.6804 - val_loss: 645.7662\n",
      "Epoch 829/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1026.3966 - val_loss: 645.1876\n",
      "Epoch 830/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 1026.4888 - val_loss: 644.5863\n",
      "Epoch 831/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 923.1531 - val_loss: 644.0230\n",
      "Epoch 832/10000\n",
      "184/184 [==============================] - 0s 544us/step - loss: 844.4154 - val_loss: 643.5887\n",
      "Epoch 833/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 953.9760 - val_loss: 643.1659\n",
      "Epoch 834/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 1098.9487 - val_loss: 642.7526\n",
      "Epoch 835/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 973.6925 - val_loss: 642.3975\n",
      "Epoch 836/10000\n",
      "184/184 [==============================] - 0s 573us/step - loss: 950.0157 - val_loss: 642.0726\n",
      "Epoch 837/10000\n",
      "184/184 [==============================] - 0s 680us/step - loss: 887.9132 - val_loss: 641.7509\n",
      "Epoch 838/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 1050.8751 - val_loss: 641.5030\n",
      "Epoch 839/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1101.6562 - val_loss: 641.1885\n",
      "Epoch 840/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 966.6425 - val_loss: 640.8506\n",
      "Epoch 841/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 1072.2112 - val_loss: 640.2993\n",
      "Epoch 842/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1274.3094 - val_loss: 639.8207\n",
      "Epoch 843/10000\n",
      "184/184 [==============================] - 0s 810us/step - loss: 882.0015 - val_loss: 639.3750\n",
      "Epoch 844/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 840.1898 - val_loss: 638.7809\n",
      "Epoch 845/10000\n",
      "184/184 [==============================] - 0s 772us/step - loss: 1087.1447 - val_loss: 638.5423\n",
      "Epoch 846/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 817.4194 - val_loss: 638.4494\n",
      "Epoch 847/10000\n",
      "184/184 [==============================] - 0s 486us/step - loss: 1300.4147 - val_loss: 638.2897\n",
      "Epoch 848/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1033.5130 - val_loss: 638.2471\n",
      "Epoch 849/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 1103.5321 - val_loss: 638.1515\n",
      "Epoch 850/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 764.7164 - val_loss: 637.9935\n",
      "Epoch 851/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 862.1692 - val_loss: 637.7661\n",
      "Epoch 852/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 932.1175 - val_loss: 637.4882\n",
      "Epoch 853/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 1028.3049 - val_loss: 637.4758\n",
      "Epoch 854/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1059.3362 - val_loss: 637.6697\n",
      "Epoch 855/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1020.1211 - val_loss: 637.8027\n",
      "Epoch 856/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 833.4098 - val_loss: 637.8887\n",
      "Epoch 857/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 997.5605 - val_loss: 639.6732\n",
      "Epoch 858/10000\n",
      "184/184 [==============================] - 0s 864us/step - loss: 988.9664 - val_loss: 641.2878\n",
      "Epoch 859/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 1000.4630 - val_loss: 640.8978\n",
      "Epoch 860/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 1207.0324 - val_loss: 640.6301\n",
      "Epoch 861/10000\n",
      "184/184 [==============================] - 0s 842us/step - loss: 1069.9922 - val_loss: 640.4829\n",
      "Epoch 862/10000\n",
      "184/184 [==============================] - 0s 864us/step - loss: 1027.4896 - val_loss: 640.2938\n",
      "Epoch 863/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 1245.1171 - val_loss: 639.4496\n",
      "Epoch 864/10000\n",
      "184/184 [==============================] - 0s 821us/step - loss: 894.3625 - val_loss: 638.1181\n",
      "Epoch 865/10000\n",
      "184/184 [==============================] - 0s 788us/step - loss: 818.7519 - val_loss: 637.0994\n",
      "Epoch 866/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 962.1936 - val_loss: 636.2985\n",
      "Epoch 867/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 900.7592 - val_loss: 635.5056\n",
      "Epoch 868/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 980.2103 - val_loss: 634.8025\n",
      "Epoch 869/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 1070.4189 - val_loss: 634.2023\n",
      "Epoch 870/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 990.5073 - val_loss: 633.6707\n",
      "Epoch 871/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 549us/step - loss: 921.5044 - val_loss: 633.2618\n",
      "Epoch 872/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 948.4738 - val_loss: 632.6655\n",
      "Epoch 873/10000\n",
      "184/184 [==============================] - 0s 793us/step - loss: 1001.4002 - val_loss: 632.2999\n",
      "Epoch 874/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 776.9460 - val_loss: 632.4134\n",
      "Epoch 875/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 796.1407 - val_loss: 632.5004\n",
      "Epoch 876/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 873.4392 - val_loss: 631.7089\n",
      "Epoch 877/10000\n",
      "184/184 [==============================] - 0s 793us/step - loss: 1253.5266 - val_loss: 630.1320\n",
      "Epoch 878/10000\n",
      "184/184 [==============================] - 0s 709us/step - loss: 880.6762 - val_loss: 630.0875\n",
      "Epoch 879/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 1127.0748 - val_loss: 629.3055\n",
      "Epoch 880/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 950.6564 - val_loss: 628.4551\n",
      "Epoch 881/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 980.2043 - val_loss: 629.1838\n",
      "Epoch 882/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 850.2300 - val_loss: 629.7580\n",
      "Epoch 883/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 844.6121 - val_loss: 629.5500\n",
      "Epoch 884/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1101.5820 - val_loss: 629.3304\n",
      "Epoch 885/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1019.8773 - val_loss: 628.7173\n",
      "Epoch 886/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 761.8399 - val_loss: 628.1387\n",
      "Epoch 887/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 1126.4391 - val_loss: 627.5736\n",
      "Epoch 888/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 925.6720 - val_loss: 626.7728\n",
      "Epoch 889/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 767.1380 - val_loss: 626.4824\n",
      "Epoch 890/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 966.8000 - val_loss: 625.9489\n",
      "Epoch 891/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 806.8044 - val_loss: 625.4285\n",
      "Epoch 892/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 1015.4555 - val_loss: 625.1395\n",
      "Epoch 893/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 753.9095 - val_loss: 624.6860\n",
      "Epoch 894/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 786.4378 - val_loss: 624.3023\n",
      "Epoch 895/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 917.5500 - val_loss: 623.9455\n",
      "Epoch 896/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 835.3502 - val_loss: 623.5295\n",
      "Epoch 897/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 873.0407 - val_loss: 623.1940\n",
      "Epoch 898/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 869.1670 - val_loss: 623.0239\n",
      "Epoch 899/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 870.1052 - val_loss: 622.7967\n",
      "Epoch 900/10000\n",
      "184/184 [==============================] - 0s 546us/step - loss: 1106.2430 - val_loss: 622.2771\n",
      "\n",
      "Epoch 00900: loss did not improve from 873.99562\n",
      "Epoch 901/10000\n",
      "184/184 [==============================] - 0s 541us/step - loss: 883.6335 - val_loss: 621.7865\n",
      "Epoch 902/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 1025.3389 - val_loss: 621.2787\n",
      "Epoch 903/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1044.6353 - val_loss: 620.4980\n",
      "Epoch 904/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 755.9089 - val_loss: 620.3506\n",
      "Epoch 905/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 880.2955 - val_loss: 620.4261\n",
      "Epoch 906/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 773.8302 - val_loss: 620.3748\n",
      "Epoch 907/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 1085.1055 - val_loss: 620.1562\n",
      "Epoch 908/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 1052.1209 - val_loss: 619.7350\n",
      "Epoch 909/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 1012.4080 - val_loss: 619.0739\n",
      "Epoch 910/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 836.2599 - val_loss: 618.4162\n",
      "Epoch 911/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 983.8075 - val_loss: 617.3019\n",
      "Epoch 912/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 682.8728 - val_loss: 616.1206\n",
      "Epoch 913/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 905.6354 - val_loss: 615.2396\n",
      "Epoch 914/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 830.7453 - val_loss: 614.4336\n",
      "Epoch 915/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 954.5285 - val_loss: 613.6714\n",
      "Epoch 916/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 901.6792 - val_loss: 609.8451\n",
      "Epoch 917/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 836.6004 - val_loss: 608.1172\n",
      "Epoch 918/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 852.3757 - val_loss: 607.6375\n",
      "Epoch 919/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1010.1439 - val_loss: 608.0389\n",
      "Epoch 920/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 904.9695 - val_loss: 609.3925\n",
      "Epoch 921/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 795.2503 - val_loss: 611.3961\n",
      "Epoch 922/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 855.9560 - val_loss: 614.2126\n",
      "Epoch 923/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 856.5780 - val_loss: 616.5605\n",
      "Epoch 924/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 970.8724 - val_loss: 617.6797\n",
      "Epoch 925/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 855.6925 - val_loss: 617.6138\n",
      "Epoch 926/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 801.4712 - val_loss: 616.6960\n",
      "Epoch 927/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 981.3265 - val_loss: 613.3364\n",
      "Epoch 928/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 905.6085 - val_loss: 610.8765\n",
      "Epoch 929/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 1110.0784 - val_loss: 609.5908\n",
      "Epoch 930/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 834.3436 - val_loss: 608.2680\n",
      "Epoch 931/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 920.6003 - val_loss: 607.5884\n",
      "Epoch 932/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 764.5789 - val_loss: 606.6686\n",
      "Epoch 933/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 969.2060 - val_loss: 605.8659\n",
      "Epoch 934/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 723.9592 - val_loss: 605.2123\n",
      "Epoch 935/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 991.2884 - val_loss: 613.6981\n",
      "Epoch 936/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 793.1938 - val_loss: 609.3312\n",
      "Epoch 937/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 1044.9900 - val_loss: 619.2767\n",
      "Epoch 938/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 877.7073 - val_loss: 626.5630\n",
      "Epoch 939/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 886.3319 - val_loss: 627.4467\n",
      "Epoch 940/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 1153.2496 - val_loss: 619.2634\n",
      "Epoch 941/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 919.7038 - val_loss: 623.8267\n",
      "Epoch 942/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 1011.8345 - val_loss: 623.9850\n",
      "Epoch 943/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 850.2245 - val_loss: 622.6934\n",
      "Epoch 944/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 549us/step - loss: 830.3666 - val_loss: 616.0804\n",
      "Epoch 945/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 769.0373 - val_loss: 615.2346\n",
      "Epoch 946/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1212.0366 - val_loss: 617.2142\n",
      "Epoch 947/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 937.7974 - val_loss: 626.6411\n",
      "Epoch 948/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 891.8026 - val_loss: 628.6927\n",
      "Epoch 949/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 825.2479 - val_loss: 631.2586\n",
      "Epoch 950/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 957.1431 - val_loss: 636.4445\n",
      "Epoch 951/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 933.5949 - val_loss: 647.3336\n",
      "Epoch 952/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 870.3177 - val_loss: 708.7191\n",
      "Epoch 953/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 995.0535 - val_loss: 735.2918\n",
      "Epoch 954/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 881.2833 - val_loss: 737.7272\n",
      "Epoch 955/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 985.0377 - val_loss: 738.6877\n",
      "Epoch 956/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 722.6849 - val_loss: 739.1002\n",
      "Epoch 957/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 976.7769 - val_loss: 737.8527\n",
      "Epoch 958/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 834.0960 - val_loss: 735.6958\n",
      "Epoch 959/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 799.0011 - val_loss: 727.6779\n",
      "Epoch 960/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 852.7198 - val_loss: 722.4963\n",
      "Epoch 961/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 1322.9679 - val_loss: 732.1969\n",
      "Epoch 962/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 935.8267 - val_loss: 732.0228\n",
      "Epoch 963/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 857.8832 - val_loss: 731.6799\n",
      "Epoch 964/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1002.2178 - val_loss: 751.3512\n",
      "Epoch 965/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 961.9894 - val_loss: 702.6547\n",
      "Epoch 966/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 839.8303 - val_loss: 673.7996\n",
      "Epoch 967/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 813.9636 - val_loss: 663.2128\n",
      "Epoch 968/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1013.8576 - val_loss: 645.4241\n",
      "Epoch 969/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 951.7241 - val_loss: 641.2979\n",
      "Epoch 970/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 814.7906 - val_loss: 640.1310\n",
      "Epoch 971/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 833.4804 - val_loss: 642.0163\n",
      "Epoch 972/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 951.5237 - val_loss: 640.6107\n",
      "Epoch 973/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 890.1517 - val_loss: 639.1833\n",
      "Epoch 974/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 811.5749 - val_loss: 638.5067\n",
      "Epoch 975/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 821.9828 - val_loss: 638.0927\n",
      "Epoch 976/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 765.5762 - val_loss: 637.8091\n",
      "Epoch 977/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 935.9146 - val_loss: 637.5984\n",
      "Epoch 978/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 1000.8567 - val_loss: 637.7502\n",
      "Epoch 979/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 836.8809 - val_loss: 638.0859\n",
      "Epoch 980/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 950.9074 - val_loss: 638.5562\n",
      "Epoch 981/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 797.9035 - val_loss: 638.9869\n",
      "Epoch 982/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 980.6568 - val_loss: 639.6940\n",
      "Epoch 983/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 1003.8232 - val_loss: 640.2674\n",
      "Epoch 984/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 828.4991 - val_loss: 640.6645\n",
      "Epoch 985/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 883.1418 - val_loss: 641.4088\n",
      "Epoch 986/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 844.7590 - val_loss: 642.2017\n",
      "Epoch 987/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 807.2088 - val_loss: 643.1192\n",
      "Epoch 988/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 926.7228 - val_loss: 644.4592\n",
      "Epoch 989/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 905.1534 - val_loss: 642.5818\n",
      "Epoch 990/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 872.0857 - val_loss: 644.8047\n",
      "Epoch 991/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 821.9915 - val_loss: 646.6311\n",
      "Epoch 992/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 1028.2532 - val_loss: 650.9351\n",
      "Epoch 993/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 785.0738 - val_loss: 660.2383\n",
      "Epoch 994/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 1119.3894 - val_loss: 664.0916\n",
      "Epoch 995/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 1020.2157 - val_loss: 667.2812\n",
      "Epoch 996/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 892.9782 - val_loss: 674.1835\n",
      "Epoch 997/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 995.2488 - val_loss: 695.8336\n",
      "Epoch 998/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 966.5056 - val_loss: 699.3906\n",
      "Epoch 999/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 807.351 - 0s 505us/step - loss: 785.9620 - val_loss: 697.7529\n",
      "Epoch 1000/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 1028.1162 - val_loss: 702.9848\n",
      "\n",
      "Epoch 01000: loss did not improve from 873.99562\n",
      "Epoch 1001/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 829.4240 - val_loss: 706.3680\n",
      "Epoch 1002/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 809.2612 - val_loss: 709.2018\n",
      "Epoch 1003/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 868.2503 - val_loss: 715.4230\n",
      "Epoch 1004/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 837.6068 - val_loss: 727.3537\n",
      "Epoch 1005/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 753.5239 - val_loss: 737.0035\n",
      "Epoch 1006/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 795.3116 - val_loss: 740.5453\n",
      "Epoch 1007/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 805.4893 - val_loss: 739.3805\n",
      "Epoch 1008/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 933.1403 - val_loss: 738.1194\n",
      "Epoch 1009/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 818.9501 - val_loss: 738.2977\n",
      "Epoch 1010/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 875.4669 - val_loss: 738.4616\n",
      "Epoch 1011/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 796.7184 - val_loss: 738.5523\n",
      "Epoch 1012/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 881.3884 - val_loss: 734.0167\n",
      "Epoch 1013/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 836.1761 - val_loss: 729.4178\n",
      "Epoch 1014/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 798.7973 - val_loss: 716.7307\n",
      "Epoch 1015/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 690.2746 - val_loss: 706.2560\n",
      "Epoch 1016/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 908.4123 - val_loss: 699.1783\n",
      "Epoch 1017/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 571us/step - loss: 867.8598 - val_loss: 687.8146\n",
      "Epoch 1018/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 860.7065 - val_loss: 674.2608\n",
      "Epoch 1019/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 778.2811 - val_loss: 672.4965\n",
      "Epoch 1020/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 803.6057 - val_loss: 686.4984\n",
      "Epoch 1021/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 839.3393 - val_loss: 691.2263\n",
      "Epoch 1022/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 840.304 - 0s 587us/step - loss: 924.7775 - val_loss: 695.4395\n",
      "Epoch 1023/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 985.9433 - val_loss: 700.1716\n",
      "Epoch 1024/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 913.5925 - val_loss: 698.0199\n",
      "Epoch 1025/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 780.9040 - val_loss: 690.5986\n",
      "Epoch 1026/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 798.8487 - val_loss: 664.1182\n",
      "Epoch 1027/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 892.8779 - val_loss: 659.2250\n",
      "Epoch 1028/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 810.7412 - val_loss: 655.2725\n",
      "Epoch 1029/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 983.1977 - val_loss: 647.7329\n",
      "Epoch 1030/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 1044.9153 - val_loss: 636.1760\n",
      "Epoch 1031/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 852.8047 - val_loss: 631.0449\n",
      "Epoch 1032/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 738.1989 - val_loss: 628.6717\n",
      "Epoch 1033/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 914.6676 - val_loss: 627.1201\n",
      "Epoch 1034/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 709.0239 - val_loss: 625.5684\n",
      "Epoch 1035/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 961.2111 - val_loss: 624.9281\n",
      "Epoch 1036/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 788.2949 - val_loss: 624.1192\n",
      "Epoch 1037/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 854.3586 - val_loss: 623.5206\n",
      "Epoch 1038/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 791.4651 - val_loss: 622.8568\n",
      "Epoch 1039/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 1010.9623 - val_loss: 622.2780\n",
      "Epoch 1040/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 889.5246 - val_loss: 622.0237\n",
      "Epoch 1041/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 909.4240 - val_loss: 622.3655\n",
      "Epoch 1042/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 990.6202 - val_loss: 623.3007\n",
      "Epoch 1043/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1194.0954 - val_loss: 643.8586\n",
      "Epoch 1044/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 696.3260 - val_loss: 701.1962\n",
      "Epoch 1045/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 904.0198 - val_loss: 717.4966\n",
      "Epoch 1046/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 885.7144 - val_loss: 673.2227\n",
      "Epoch 1047/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 1009.8022 - val_loss: 607.8447\n",
      "Epoch 1048/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 579.0443 - val_loss: 600.6573\n",
      "Epoch 1049/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 895.5657 - val_loss: 597.6892\n",
      "Epoch 1050/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 832.1636 - val_loss: 596.4809\n",
      "Epoch 1051/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 835.4382 - val_loss: 595.5274\n",
      "Epoch 1052/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 823.8189 - val_loss: 594.8110\n",
      "Epoch 1053/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 797.6881 - val_loss: 594.1230\n",
      "Epoch 1054/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 1104.8792 - val_loss: 593.2910\n",
      "Epoch 1055/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 705.6207 - val_loss: 593.6254\n",
      "Epoch 1056/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 664.2583 - val_loss: 593.5822\n",
      "Epoch 1057/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 944.3156 - val_loss: 593.3865\n",
      "Epoch 1058/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 995.6682 - val_loss: 595.2371\n",
      "Epoch 1059/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 809.0807 - val_loss: 599.0779\n",
      "Epoch 1060/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 827.0456 - val_loss: 603.9927\n",
      "Epoch 1061/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 807.5331 - val_loss: 601.5355\n",
      "Epoch 1062/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 1082.3675 - val_loss: 621.4790\n",
      "Epoch 1063/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 985.6316 - val_loss: 667.5573\n",
      "Epoch 1064/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 928.9019 - val_loss: 682.4084\n",
      "Epoch 1065/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 823.5619 - val_loss: 703.8663\n",
      "Epoch 1066/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 865.8557 - val_loss: 706.9019\n",
      "Epoch 1067/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 777.6734 - val_loss: 710.2244\n",
      "Epoch 1068/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 832.9949 - val_loss: 710.0845\n",
      "Epoch 1069/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 1067.1774 - val_loss: 711.5337\n",
      "Epoch 1070/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 849.0926 - val_loss: 712.7470\n",
      "Epoch 1071/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 747.2773 - val_loss: 714.4387\n",
      "Epoch 1072/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 801.2092 - val_loss: 715.8074\n",
      "Epoch 1073/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 906.5730 - val_loss: 717.2789\n",
      "Epoch 1074/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 694.5712 - val_loss: 718.7430\n",
      "Epoch 1075/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 1046.4473 - val_loss: 719.3279\n",
      "Epoch 1076/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 769.5335 - val_loss: 719.5821\n",
      "Epoch 1077/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 858.0602 - val_loss: 719.0648\n",
      "Epoch 1078/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 883.4296 - val_loss: 709.4084\n",
      "Epoch 1079/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 738.0271 - val_loss: 702.0378\n",
      "Epoch 1080/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 825.0104 - val_loss: 680.5768\n",
      "Epoch 1081/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 979.5021 - val_loss: 661.7479\n",
      "Epoch 1082/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 942.5066 - val_loss: 604.7164\n",
      "Epoch 1083/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 937.9590 - val_loss: 601.5742\n",
      "Epoch 1084/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 884.3697 - val_loss: 598.0660\n",
      "Epoch 1085/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 894.1771 - val_loss: 595.0031\n",
      "Epoch 1086/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 883.7439 - val_loss: 593.1625\n",
      "Epoch 1087/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 699.2033 - val_loss: 590.7471\n",
      "Epoch 1088/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 650.2359 - val_loss: 589.7259\n",
      "Epoch 1089/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 801.6025 - val_loss: 588.2776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1090/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 884.7556 - val_loss: 587.2373\n",
      "Epoch 1091/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 1067.0719 - val_loss: 586.4807\n",
      "Epoch 1092/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 880.1459 - val_loss: 585.6304\n",
      "Epoch 1093/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 919.8611 - val_loss: 586.9326\n",
      "Epoch 1094/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 765.6370 - val_loss: 583.6685\n",
      "Epoch 1095/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 961.1833 - val_loss: 573.9433\n",
      "Epoch 1096/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 680.0126 - val_loss: 573.8205\n",
      "Epoch 1097/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 731.4278 - val_loss: 574.3326\n",
      "Epoch 1098/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 758.9327 - val_loss: 578.8999\n",
      "Epoch 1099/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 849.0288 - val_loss: 579.9076\n",
      "Epoch 1100/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 852.0492 - val_loss: 579.5205\n",
      "\n",
      "Epoch 01100: loss improved from 873.99562 to 852.04917, saving model to C6007C.hdf5\n",
      "Epoch 1101/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 938.9186 - val_loss: 579.5190\n",
      "Epoch 1102/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 762.6529 - val_loss: 579.5503\n",
      "Epoch 1103/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 990.6127 - val_loss: 579.1528\n",
      "Epoch 1104/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 843.7790 - val_loss: 578.5543\n",
      "Epoch 1105/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 727.3925 - val_loss: 577.9576\n",
      "Epoch 1106/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 763.7196 - val_loss: 577.3728\n",
      "Epoch 1107/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 740.2486 - val_loss: 576.8383\n",
      "Epoch 1108/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 863.3674 - val_loss: 576.3801\n",
      "Epoch 1109/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 747.0052 - val_loss: 575.9697\n",
      "Epoch 1110/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 737.2296 - val_loss: 575.5727\n",
      "Epoch 1111/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 834.7149 - val_loss: 571.6683\n",
      "Epoch 1112/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 829.6097 - val_loss: 568.0405\n",
      "Epoch 1113/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 926.9764 - val_loss: 567.1041\n",
      "Epoch 1114/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 832.8043 - val_loss: 573.8488\n",
      "Epoch 1115/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 886.4425 - val_loss: 573.3515\n",
      "Epoch 1116/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 1070.8539 - val_loss: 572.4709\n",
      "Epoch 1117/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 745.6834 - val_loss: 571.8032\n",
      "Epoch 1118/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 807.5968 - val_loss: 571.2651\n",
      "Epoch 1119/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 756.5878 - val_loss: 570.8258\n",
      "Epoch 1120/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 790.3921 - val_loss: 570.4252\n",
      "Epoch 1121/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 845.2511 - val_loss: 570.0193\n",
      "Epoch 1122/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 924.1902 - val_loss: 569.4703\n",
      "Epoch 1123/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 735.0253 - val_loss: 568.5963\n",
      "Epoch 1124/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 917.2117 - val_loss: 567.4633\n",
      "Epoch 1125/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 673.5381 - val_loss: 565.8459\n",
      "Epoch 1126/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 861.8583 - val_loss: 564.2869\n",
      "Epoch 1127/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 863.3342 - val_loss: 563.2430\n",
      "Epoch 1128/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 982.8983 - val_loss: 562.8555\n",
      "Epoch 1129/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 713.4976 - val_loss: 562.6855\n",
      "Epoch 1130/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 734.7172 - val_loss: 565.6729\n",
      "Epoch 1131/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 721.6693 - val_loss: 567.2423\n",
      "Epoch 1132/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 703.4437 - val_loss: 566.7178\n",
      "Epoch 1133/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 804.0829 - val_loss: 565.7060\n",
      "Epoch 1134/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 698.5963 - val_loss: 564.7385\n",
      "Epoch 1135/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 829.4684 - val_loss: 564.2148\n",
      "Epoch 1136/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 771.0486 - val_loss: 563.8306\n",
      "Epoch 1137/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 792.4696 - val_loss: 563.1614\n",
      "Epoch 1138/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 760.4047 - val_loss: 562.7181\n",
      "Epoch 1139/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 791.7313 - val_loss: 562.1555\n",
      "Epoch 1140/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 826.5836 - val_loss: 561.4807\n",
      "Epoch 1141/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 793.0517 - val_loss: 560.6033\n",
      "Epoch 1142/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 792.5339 - val_loss: 559.9023\n",
      "Epoch 1143/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 895.5850 - val_loss: 557.9916\n",
      "Epoch 1144/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 847.969 - 0s 505us/step - loss: 843.7204 - val_loss: 558.0125\n",
      "Epoch 1145/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 903.3064 - val_loss: 557.6584\n",
      "Epoch 1146/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 829.4357 - val_loss: 557.5123\n",
      "Epoch 1147/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 842.4400 - val_loss: 557.4512\n",
      "Epoch 1148/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 715.7258 - val_loss: 557.5208\n",
      "Epoch 1149/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 752.4829 - val_loss: 557.5122\n",
      "Epoch 1150/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 957.3415 - val_loss: 556.8990\n",
      "Epoch 1151/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 790.3791 - val_loss: 554.7756\n",
      "Epoch 1152/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 863.2355 - val_loss: 553.0792\n",
      "Epoch 1153/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 862.5742 - val_loss: 552.1739\n",
      "Epoch 1154/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 857.0644 - val_loss: 551.5343\n",
      "Epoch 1155/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 753.3097 - val_loss: 550.6758\n",
      "Epoch 1156/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 713.2611 - val_loss: 550.0369\n",
      "Epoch 1157/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 755.2168 - val_loss: 548.7115\n",
      "Epoch 1158/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 698.7059 - val_loss: 561.0193\n",
      "Epoch 1159/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 821.2274 - val_loss: 670.0755\n",
      "Epoch 1160/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 598.2354 - val_loss: 604.3994\n",
      "Epoch 1161/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 631.7446 - val_loss: 577.7484\n",
      "Epoch 1162/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 462us/step - loss: 822.4171 - val_loss: 577.3000\n",
      "Epoch 1163/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 777.5225 - val_loss: 574.8126\n",
      "Epoch 1164/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 970.3664 - val_loss: 571.1465\n",
      "Epoch 1165/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 917.2815 - val_loss: 568.8709\n",
      "Epoch 1166/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 874.1543 - val_loss: 568.1598\n",
      "Epoch 1167/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 940.9528 - val_loss: 566.8363\n",
      "Epoch 1168/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 852.2633 - val_loss: 565.4953\n",
      "Epoch 1169/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 746.9697 - val_loss: 563.0512\n",
      "Epoch 1170/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 837.1067 - val_loss: 562.6345\n",
      "Epoch 1171/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 1061.9660 - val_loss: 562.1412\n",
      "Epoch 1172/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 935.3908 - val_loss: 561.6622\n",
      "Epoch 1173/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 915.7536 - val_loss: 560.9633\n",
      "Epoch 1174/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 943.7275 - val_loss: 560.3099\n",
      "Epoch 1175/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 863.9121 - val_loss: 559.7174\n",
      "Epoch 1176/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 686.0622 - val_loss: 559.1854\n",
      "Epoch 1177/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 990.9629 - val_loss: 558.7099\n",
      "Epoch 1178/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 833.0627 - val_loss: 558.2901\n",
      "Epoch 1179/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 786.0514 - val_loss: 557.8862\n",
      "Epoch 1180/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 903.9917 - val_loss: 557.4097\n",
      "Epoch 1181/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 720.8536 - val_loss: 556.9870\n",
      "Epoch 1182/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 736.8227 - val_loss: 556.6439\n",
      "Epoch 1183/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 991.2225 - val_loss: 556.5195\n",
      "Epoch 1184/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 845.1232 - val_loss: 556.3951\n",
      "Epoch 1185/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 913.4409 - val_loss: 556.2657\n",
      "Epoch 1186/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 783.8461 - val_loss: 556.1436\n",
      "Epoch 1187/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 832.9768 - val_loss: 556.0409\n",
      "Epoch 1188/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 782.8529 - val_loss: 555.9236\n",
      "Epoch 1189/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 853.2404 - val_loss: 555.7935\n",
      "Epoch 1190/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 679.4004 - val_loss: 555.6273\n",
      "Epoch 1191/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 723.0609 - val_loss: 555.5164\n",
      "Epoch 1192/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 801.9067 - val_loss: 555.4457\n",
      "Epoch 1193/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 858.4954 - val_loss: 554.2476\n",
      "Epoch 1194/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 778.0326 - val_loss: 553.3167\n",
      "Epoch 1195/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 728.6197 - val_loss: 552.7028\n",
      "Epoch 1196/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 1138.0351 - val_loss: 552.6855\n",
      "Epoch 1197/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 703.8200 - val_loss: 552.4850\n",
      "Epoch 1198/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 884.3950 - val_loss: 552.2734\n",
      "Epoch 1199/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 927.2447 - val_loss: 552.0432\n",
      "Epoch 1200/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 745.5780 - val_loss: 553.3192\n",
      "\n",
      "Epoch 01200: loss improved from 852.04917 to 745.57800, saving model to C6007C.hdf5\n",
      "Epoch 1201/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 848.6296 - val_loss: 550.1660\n",
      "Epoch 1202/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 661.6015 - val_loss: 549.9991\n",
      "Epoch 1203/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 888.7968 - val_loss: 549.9020\n",
      "Epoch 1204/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 835.5439 - val_loss: 549.7051\n",
      "Epoch 1205/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 792.3653 - val_loss: 548.9280\n",
      "Epoch 1206/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 871.8695 - val_loss: 548.7474\n",
      "Epoch 1207/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 720.8903 - val_loss: 548.6495\n",
      "Epoch 1208/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 807.1809 - val_loss: 548.5931\n",
      "Epoch 1209/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 649.2878 - val_loss: 548.7114\n",
      "Epoch 1210/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 668.7650 - val_loss: 548.8571\n",
      "Epoch 1211/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 618.2039 - val_loss: 549.2612\n",
      "Epoch 1212/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 728.8384 - val_loss: 549.7127\n",
      "Epoch 1213/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 606.8613 - val_loss: 550.1888\n",
      "Epoch 1214/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 836.0617 - val_loss: 550.2844\n",
      "Epoch 1215/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 952.8944 - val_loss: 550.3781\n",
      "Epoch 1216/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 884.4723 - val_loss: 550.2894\n",
      "Epoch 1217/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 684.6106 - val_loss: 550.3483\n",
      "Epoch 1218/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 681.7739 - val_loss: 552.4598\n",
      "Epoch 1219/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 764.3051 - val_loss: 553.6646\n",
      "Epoch 1220/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 1082.1478 - val_loss: 554.6606\n",
      "Epoch 1221/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 810.2779 - val_loss: 554.8242\n",
      "Epoch 1222/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 687.5992 - val_loss: 554.8671\n",
      "Epoch 1223/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 777.6245 - val_loss: 554.7040\n",
      "Epoch 1224/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 672.9851 - val_loss: 554.3720\n",
      "Epoch 1225/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 922.4221 - val_loss: 554.0834\n",
      "Epoch 1226/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 1322.6341 - val_loss: 553.3544\n",
      "Epoch 1227/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 712.0802 - val_loss: 552.3217\n",
      "Epoch 1228/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 907.7338 - val_loss: 551.1842\n",
      "Epoch 1229/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 809.5852 - val_loss: 549.3262\n",
      "Epoch 1230/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 792.0767 - val_loss: 548.2493\n",
      "Epoch 1231/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 699.4506 - val_loss: 547.8046\n",
      "Epoch 1232/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 793.6211 - val_loss: 547.0094\n",
      "Epoch 1233/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 806.6312 - val_loss: 546.1436\n",
      "Epoch 1234/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 527us/step - loss: 806.1712 - val_loss: 545.5451\n",
      "Epoch 1235/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 744.0228 - val_loss: 545.0759\n",
      "Epoch 1236/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 777.4551 - val_loss: 544.6191\n",
      "Epoch 1237/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 887.2598 - val_loss: 544.2840\n",
      "Epoch 1238/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 791.1074 - val_loss: 543.9963\n",
      "Epoch 1239/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 678.8338 - val_loss: 544.0215\n",
      "Epoch 1240/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 698.2885 - val_loss: 543.9089\n",
      "Epoch 1241/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 884.7807 - val_loss: 543.8457\n",
      "Epoch 1242/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 809.0779 - val_loss: 544.3278\n",
      "Epoch 1243/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 761.9772 - val_loss: 544.9575\n",
      "Epoch 1244/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 727.9099 - val_loss: 544.6641\n",
      "Epoch 1245/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 636.6357 - val_loss: 545.6581\n",
      "Epoch 1246/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 774.2579 - val_loss: 545.6102\n",
      "Epoch 1247/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 700.7123 - val_loss: 545.3055\n",
      "Epoch 1248/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 862.8515 - val_loss: 545.0029\n",
      "Epoch 1249/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 612.1421 - val_loss: 544.9051\n",
      "Epoch 1250/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 909.581 - 0s 538us/step - loss: 918.4166 - val_loss: 544.9012\n",
      "Epoch 1251/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 760.8656 - val_loss: 544.7177\n",
      "Epoch 1252/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 683.6149 - val_loss: 544.5284\n",
      "Epoch 1253/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 841.6322 - val_loss: 544.2946\n",
      "Epoch 1254/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 545.034 - 0s 500us/step - loss: 584.2804 - val_loss: 544.0208\n",
      "Epoch 1255/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 645.6671 - val_loss: 543.7916\n",
      "Epoch 1256/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 688.1187 - val_loss: 543.6555\n",
      "Epoch 1257/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 645.7028 - val_loss: 543.5023\n",
      "Epoch 1258/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 952.4221 - val_loss: 543.3399\n",
      "Epoch 1259/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 709.7377 - val_loss: 543.1552\n",
      "Epoch 1260/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 1007.4058 - val_loss: 542.8879\n",
      "Epoch 1261/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 770.8119 - val_loss: 542.5795\n",
      "Epoch 1262/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 833.4663 - val_loss: 542.2017\n",
      "Epoch 1263/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 789.2324 - val_loss: 541.9357\n",
      "Epoch 1264/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 938.8362 - val_loss: 541.5717\n",
      "Epoch 1265/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 870.1703 - val_loss: 541.2359\n",
      "Epoch 1266/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 755.7098 - val_loss: 540.8894\n",
      "Epoch 1267/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 681.2578 - val_loss: 540.5819\n",
      "Epoch 1268/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 888.9848 - val_loss: 540.1115\n",
      "Epoch 1269/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 778.9784 - val_loss: 539.7410\n",
      "Epoch 1270/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 767.1610 - val_loss: 539.1804\n",
      "Epoch 1271/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 833.4959 - val_loss: 538.1608\n",
      "Epoch 1272/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 660.1163 - val_loss: 537.2595\n",
      "Epoch 1273/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 801.4345 - val_loss: 540.0085\n",
      "Epoch 1274/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 719.5702 - val_loss: 539.3568\n",
      "Epoch 1275/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 644.9908 - val_loss: 539.1950\n",
      "Epoch 1276/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 659.7159 - val_loss: 539.1691\n",
      "Epoch 1277/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 642.5668 - val_loss: 536.7304\n",
      "Epoch 1278/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 796.6859 - val_loss: 535.9668\n",
      "Epoch 1279/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 853.3465 - val_loss: 535.3586\n",
      "Epoch 1280/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 970.8595 - val_loss: 534.7651\n",
      "Epoch 1281/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 775.9978 - val_loss: 534.2336\n",
      "Epoch 1282/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 792.5770 - val_loss: 533.7372\n",
      "Epoch 1283/10000\n",
      "184/184 [==============================] - 0s 544us/step - loss: 631.8477 - val_loss: 533.2661\n",
      "Epoch 1284/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 572.0818 - val_loss: 532.8358\n",
      "Epoch 1285/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 692.6997 - val_loss: 532.4409\n",
      "Epoch 1286/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 774.0960 - val_loss: 531.8836\n",
      "Epoch 1287/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 734.1732 - val_loss: 531.3498\n",
      "Epoch 1288/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 785.5954 - val_loss: 530.8458\n",
      "Epoch 1289/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 773.2634 - val_loss: 530.3015\n",
      "Epoch 1290/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 735.7894 - val_loss: 529.8242\n",
      "Epoch 1291/10000\n",
      "184/184 [==============================] - 0s 715us/step - loss: 678.8401 - val_loss: 529.2213\n",
      "Epoch 1292/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 743.0493 - val_loss: 528.4863\n",
      "Epoch 1293/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 856.8644 - val_loss: 527.7667\n",
      "Epoch 1294/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 882.7271 - val_loss: 526.7785\n",
      "Epoch 1295/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 708.8546 - val_loss: 525.4836\n",
      "Epoch 1296/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 879.6620 - val_loss: 522.5001\n",
      "Epoch 1297/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 741.8111 - val_loss: 519.8835\n",
      "Epoch 1298/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 786.5605 - val_loss: 518.8000\n",
      "Epoch 1299/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 709.7001 - val_loss: 517.8907\n",
      "Epoch 1300/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 809.1285 - val_loss: 516.9218\n",
      "\n",
      "Epoch 01300: loss did not improve from 745.57800\n",
      "Epoch 1301/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 826.8075 - val_loss: 515.9472\n",
      "Epoch 1302/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 618.9465 - val_loss: 515.3081\n",
      "Epoch 1303/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 703.5983 - val_loss: 514.9303\n",
      "Epoch 1304/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 695.5355 - val_loss: 514.2001\n",
      "Epoch 1305/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 827.9509 - val_loss: 513.6376\n",
      "Epoch 1306/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 555us/step - loss: 877.3527 - val_loss: 513.1104\n",
      "Epoch 1307/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 806.5469 - val_loss: 512.5731\n",
      "Epoch 1308/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 815.8121 - val_loss: 512.0167\n",
      "Epoch 1309/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 762.8014 - val_loss: 511.0638\n",
      "Epoch 1310/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 708.6459 - val_loss: 510.2028\n",
      "Epoch 1311/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 647.2764 - val_loss: 509.3303\n",
      "Epoch 1312/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 654.2212 - val_loss: 508.5802\n",
      "Epoch 1313/10000\n",
      "184/184 [==============================] - 0s 492us/step - loss: 812.0444 - val_loss: 507.8924\n",
      "Epoch 1314/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 669.5563 - val_loss: 507.2938\n",
      "Epoch 1315/10000\n",
      "184/184 [==============================] - 0s 541us/step - loss: 734.7078 - val_loss: 506.7299\n",
      "Epoch 1316/10000\n",
      "184/184 [==============================] - 0s 601us/step - loss: 599.7436 - val_loss: 506.2320\n",
      "Epoch 1317/10000\n",
      "184/184 [==============================] - 0s 486us/step - loss: 765.1314 - val_loss: 505.8174\n",
      "Epoch 1318/10000\n",
      "184/184 [==============================] - 0s 557us/step - loss: 723.4682 - val_loss: 505.3479\n",
      "Epoch 1319/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 773.4081 - val_loss: 504.9909\n",
      "Epoch 1320/10000\n",
      "184/184 [==============================] - 0s 633us/step - loss: 823.6695 - val_loss: 504.7633\n",
      "Epoch 1321/10000\n",
      "184/184 [==============================] - 0s 525us/step - loss: 643.0674 - val_loss: 504.5756\n",
      "Epoch 1322/10000\n",
      "184/184 [==============================] - 0s 552us/step - loss: 789.3294 - val_loss: 504.7365\n",
      "Epoch 1323/10000\n",
      "184/184 [==============================] - 0s 481us/step - loss: 770.3766 - val_loss: 505.7332\n",
      "Epoch 1324/10000\n",
      "184/184 [==============================] - 0s 476us/step - loss: 827.9411 - val_loss: 506.3449\n",
      "Epoch 1325/10000\n",
      "184/184 [==============================] - 0s 497us/step - loss: 690.0689 - val_loss: 506.0324\n",
      "Epoch 1326/10000\n",
      "184/184 [==============================] - 0s 476us/step - loss: 725.0026 - val_loss: 505.3940\n",
      "Epoch 1327/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 591.0202 - val_loss: 504.8377\n",
      "Epoch 1328/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 697.8932 - val_loss: 504.5322\n",
      "Epoch 1329/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 523.8425 - val_loss: 504.4068\n",
      "Epoch 1330/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 771.2997 - val_loss: 504.2905\n",
      "Epoch 1331/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 751.7258 - val_loss: 503.7921\n",
      "Epoch 1332/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 787.5556 - val_loss: 503.8475\n",
      "Epoch 1333/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 753.1445 - val_loss: 503.6971\n",
      "Epoch 1334/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 707.0299 - val_loss: 503.4851\n",
      "Epoch 1335/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 675.3352 - val_loss: 503.3980\n",
      "Epoch 1336/10000\n",
      "184/184 [==============================] - 0s 595us/step - loss: 597.8087 - val_loss: 503.3344\n",
      "Epoch 1337/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 640.2804 - val_loss: 503.0134\n",
      "Epoch 1338/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 783.7825 - val_loss: 502.4983\n",
      "Epoch 1339/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 728.7373 - val_loss: 502.2132\n",
      "Epoch 1340/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 532.1670 - val_loss: 501.5010\n",
      "Epoch 1341/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 831.3304 - val_loss: 500.8790\n",
      "Epoch 1342/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 800.3409 - val_loss: 498.5917\n",
      "Epoch 1343/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 857.6678 - val_loss: 495.3345\n",
      "Epoch 1344/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 708.7866 - val_loss: 491.9245\n",
      "Epoch 1345/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 916.4056 - val_loss: 488.7074\n",
      "Epoch 1346/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 688.6196 - val_loss: 486.7419\n",
      "Epoch 1347/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 747.2923 - val_loss: 484.5851\n",
      "Epoch 1348/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 700.5323 - val_loss: 482.7115\n",
      "Epoch 1349/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 716.7180 - val_loss: 481.5448\n",
      "Epoch 1350/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 739.9739 - val_loss: 480.5988\n",
      "Epoch 1351/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 611.2283 - val_loss: 479.8968\n",
      "Epoch 1352/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 655.3655 - val_loss: 479.2790\n",
      "Epoch 1353/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 766.3736 - val_loss: 478.6967\n",
      "Epoch 1354/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 622.2537 - val_loss: 478.3370\n",
      "Epoch 1355/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 662.7358 - val_loss: 478.0481\n",
      "Epoch 1356/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 842.1345 - val_loss: 477.7288\n",
      "Epoch 1357/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 711.7935 - val_loss: 477.3883\n",
      "Epoch 1358/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 734.5409 - val_loss: 477.0522\n",
      "Epoch 1359/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 658.2686 - val_loss: 476.7134\n",
      "Epoch 1360/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 792.4477 - val_loss: 476.3384\n",
      "Epoch 1361/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 702.5866 - val_loss: 476.3048\n",
      "Epoch 1362/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 822.0947 - val_loss: 476.6228\n",
      "Epoch 1363/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 604.0131 - val_loss: 477.0926\n",
      "Epoch 1364/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 852.5158 - val_loss: 477.8522\n",
      "Epoch 1365/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 687.7084 - val_loss: 478.4441\n",
      "Epoch 1366/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 849.7791 - val_loss: 478.7945\n",
      "Epoch 1367/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 721.5918 - val_loss: 478.9394\n",
      "Epoch 1368/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 810.5383 - val_loss: 479.0224\n",
      "Epoch 1369/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 789.0448 - val_loss: 479.1777\n",
      "Epoch 1370/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 796.8926 - val_loss: 479.3009\n",
      "Epoch 1371/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 507.1154 - val_loss: 479.3921\n",
      "Epoch 1372/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 730.0641 - val_loss: 479.3489\n",
      "Epoch 1373/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 652.4622 - val_loss: 479.2621\n",
      "Epoch 1374/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 535.5897 - val_loss: 478.7619\n",
      "Epoch 1375/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 653.6217 - val_loss: 478.4292\n",
      "Epoch 1376/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 716.7833 - val_loss: 477.7463\n",
      "Epoch 1377/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 680.4370 - val_loss: 476.7285\n",
      "Epoch 1378/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 587.3710 - val_loss: 475.7818\n",
      "Epoch 1379/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 538us/step - loss: 801.0942 - val_loss: 475.0651\n",
      "Epoch 1380/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 892.5816 - val_loss: 474.4836\n",
      "Epoch 1381/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 716.7409 - val_loss: 473.9299\n",
      "Epoch 1382/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 770.4282 - val_loss: 473.4411\n",
      "Epoch 1383/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 810.1822 - val_loss: 473.0109\n",
      "Epoch 1384/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 767.5804 - val_loss: 472.6336\n",
      "Epoch 1385/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 737.2096 - val_loss: 472.0201\n",
      "Epoch 1386/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 688.9976 - val_loss: 471.4850\n",
      "Epoch 1387/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 741.0202 - val_loss: 471.0419\n",
      "Epoch 1388/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 775.2517 - val_loss: 470.6176\n",
      "Epoch 1389/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 776.0339 - val_loss: 470.7182\n",
      "Epoch 1390/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 688.4186 - val_loss: 471.3446\n",
      "Epoch 1391/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 725.8761 - val_loss: 472.2078\n",
      "Epoch 1392/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 668.1019 - val_loss: 472.9087\n",
      "Epoch 1393/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 858.1674 - val_loss: 473.2612\n",
      "Epoch 1394/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 775.9556 - val_loss: 475.0623\n",
      "Epoch 1395/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 639.1437 - val_loss: 475.7776\n",
      "Epoch 1396/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 705.6281 - val_loss: 476.7325\n",
      "Epoch 1397/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 730.4505 - val_loss: 477.1366\n",
      "Epoch 1398/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 864.8516 - val_loss: 478.6367\n",
      "Epoch 1399/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 710.5673 - val_loss: 478.8744\n",
      "Epoch 1400/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 789.6323 - val_loss: 480.9219\n",
      "\n",
      "Epoch 01400: loss did not improve from 745.57800\n",
      "Epoch 1401/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 691.5748 - val_loss: 484.1694\n",
      "Epoch 1402/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 697.3341 - val_loss: 484.1157\n",
      "Epoch 1403/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 705.0034 - val_loss: 482.8668\n",
      "Epoch 1404/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 558.0943 - val_loss: 482.2780\n",
      "Epoch 1405/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 775.3610 - val_loss: 480.8225\n",
      "Epoch 1406/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 925.3889 - val_loss: 480.5714\n",
      "Epoch 1407/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 610.1277 - val_loss: 480.2270\n",
      "Epoch 1408/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 575.3121 - val_loss: 479.2843\n",
      "Epoch 1409/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 839.0665 - val_loss: 478.2747\n",
      "Epoch 1410/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 869.1990 - val_loss: 477.2432\n",
      "Epoch 1411/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 590.7950 - val_loss: 476.1860\n",
      "Epoch 1412/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 612.3858 - val_loss: 475.0957\n",
      "Epoch 1413/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 754.184 - 0s 467us/step - loss: 741.2413 - val_loss: 474.1554\n",
      "Epoch 1414/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 755.9066 - val_loss: 473.3782\n",
      "Epoch 1415/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 922.5253 - val_loss: 472.6440\n",
      "Epoch 1416/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 632.7626 - val_loss: 472.0764\n",
      "Epoch 1417/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 579.5836 - val_loss: 471.5679\n",
      "Epoch 1418/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 673.3396 - val_loss: 471.1762\n",
      "Epoch 1419/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 645.4351 - val_loss: 470.8575\n",
      "Epoch 1420/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 911.7451 - val_loss: 470.6098\n",
      "Epoch 1421/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 700.8982 - val_loss: 470.3593\n",
      "Epoch 1422/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 593.9523 - val_loss: 470.0585\n",
      "Epoch 1423/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 685.2982 - val_loss: 469.7467\n",
      "Epoch 1424/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 833.8226 - val_loss: 469.4113\n",
      "Epoch 1425/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 550.9119 - val_loss: 469.1094\n",
      "Epoch 1426/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 777.4500 - val_loss: 468.7863\n",
      "Epoch 1427/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 670.1826 - val_loss: 468.4609\n",
      "Epoch 1428/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 702.3151 - val_loss: 468.1200\n",
      "Epoch 1429/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 669.5227 - val_loss: 467.1248\n",
      "Epoch 1430/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 727.4522 - val_loss: 465.9454\n",
      "Epoch 1431/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 689.2491 - val_loss: 465.4286\n",
      "Epoch 1432/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 634.4229 - val_loss: 465.0214\n",
      "Epoch 1433/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 656.0357 - val_loss: 464.7269\n",
      "Epoch 1434/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 530.8106 - val_loss: 464.6123\n",
      "Epoch 1435/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 716.8982 - val_loss: 464.4753\n",
      "Epoch 1436/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 637.2821 - val_loss: 464.3191\n",
      "Epoch 1437/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 579.2910 - val_loss: 464.0354\n",
      "Epoch 1438/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 808.1977 - val_loss: 463.6628\n",
      "Epoch 1439/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 640.9451 - val_loss: 463.3082\n",
      "Epoch 1440/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 768.9079 - val_loss: 462.9882\n",
      "Epoch 1441/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 636.9117 - val_loss: 462.6791\n",
      "Epoch 1442/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 665.9863 - val_loss: 462.3372\n",
      "Epoch 1443/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 750.9591 - val_loss: 461.9672\n",
      "Epoch 1444/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 690.4981 - val_loss: 461.6062\n",
      "Epoch 1445/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 599.2979 - val_loss: 461.2672\n",
      "Epoch 1446/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 670.6017 - val_loss: 460.9638\n",
      "Epoch 1447/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 699.9200 - val_loss: 460.6873\n",
      "Epoch 1448/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 662.7247 - val_loss: 460.4172\n",
      "Epoch 1449/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 697.3256 - val_loss: 460.1700\n",
      "Epoch 1450/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 648.0868 - val_loss: 459.7847\n",
      "Epoch 1451/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 543us/step - loss: 701.3300 - val_loss: 459.4002\n",
      "Epoch 1452/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 589.8877 - val_loss: 459.0463\n",
      "Epoch 1453/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 640.9861 - val_loss: 458.7567\n",
      "Epoch 1454/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 767.2944 - val_loss: 458.5133\n",
      "Epoch 1455/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 766.0047 - val_loss: 458.4663\n",
      "Epoch 1456/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 828.0950 - val_loss: 458.5240\n",
      "Epoch 1457/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 688.8803 - val_loss: 458.3969\n",
      "Epoch 1458/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 749.2545 - val_loss: 458.2359\n",
      "Epoch 1459/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 720.6762 - val_loss: 458.0527\n",
      "Epoch 1460/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 761.1567 - val_loss: 457.8577\n",
      "Epoch 1461/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 848.8303 - val_loss: 457.6565\n",
      "Epoch 1462/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 771.8892 - val_loss: 457.4887\n",
      "Epoch 1463/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 654.6013 - val_loss: 457.2918\n",
      "Epoch 1464/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 654.2726 - val_loss: 457.0744\n",
      "Epoch 1465/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 578.1744 - val_loss: 456.8648\n",
      "Epoch 1466/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 774.7646 - val_loss: 456.6142\n",
      "Epoch 1467/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 706.6842 - val_loss: 456.3680\n",
      "Epoch 1468/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 631.5366 - val_loss: 456.1168\n",
      "Epoch 1469/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 837.5453 - val_loss: 455.8788\n",
      "Epoch 1470/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 603.9418 - val_loss: 455.6307\n",
      "Epoch 1471/10000\n",
      "184/184 [==============================] - 0s 544us/step - loss: 697.8058 - val_loss: 455.3735\n",
      "Epoch 1472/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 603.1129 - val_loss: 455.1211\n",
      "Epoch 1473/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 844.0258 - val_loss: 455.8844\n",
      "Epoch 1474/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 628.1667 - val_loss: 456.4330\n",
      "Epoch 1475/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 561.8785 - val_loss: 456.8205\n",
      "Epoch 1476/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 593.3519 - val_loss: 457.0692\n",
      "Epoch 1477/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 611.8598 - val_loss: 457.2366\n",
      "Epoch 1478/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 642.5310 - val_loss: 457.3317\n",
      "Epoch 1479/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 701.7406 - val_loss: 457.3523\n",
      "Epoch 1480/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 646.6852 - val_loss: 457.3618\n",
      "Epoch 1481/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 702.0808 - val_loss: 457.4078\n",
      "Epoch 1482/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 602.8410 - val_loss: 457.4239\n",
      "Epoch 1483/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 854.2924 - val_loss: 457.2887\n",
      "Epoch 1484/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 589.6012 - val_loss: 457.1465\n",
      "Epoch 1485/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 788.7149 - val_loss: 456.8234\n",
      "Epoch 1486/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 736.6935 - val_loss: 456.4242\n",
      "Epoch 1487/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 763.8927 - val_loss: 455.9406\n",
      "Epoch 1488/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 688.5458 - val_loss: 455.4903\n",
      "Epoch 1489/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 708.3365 - val_loss: 455.0863\n",
      "Epoch 1490/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 586.0747 - val_loss: 454.7250\n",
      "Epoch 1491/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 550.5773 - val_loss: 454.3906\n",
      "Epoch 1492/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 812.8761 - val_loss: 454.0622\n",
      "Epoch 1493/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 709.7566 - val_loss: 453.7318\n",
      "Epoch 1494/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 633.3357 - val_loss: 453.4268\n",
      "Epoch 1495/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 685.8865 - val_loss: 453.6032\n",
      "Epoch 1496/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 612.5642 - val_loss: 453.6872\n",
      "Epoch 1497/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 446.2533 - val_loss: 453.7886\n",
      "Epoch 1498/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 759.2394 - val_loss: 453.8651\n",
      "Epoch 1499/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 693.5451 - val_loss: 453.8445\n",
      "Epoch 1500/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 652.9026 - val_loss: 453.7690\n",
      "\n",
      "Epoch 01500: loss improved from 745.57800 to 652.90255, saving model to C6007C.hdf5\n",
      "Epoch 1501/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 634.4672 - val_loss: 453.6444\n",
      "Epoch 1502/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 542.5150 - val_loss: 453.4955\n",
      "Epoch 1503/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 647.3450 - val_loss: 453.3127\n",
      "Epoch 1504/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 652.9232 - val_loss: 453.1338\n",
      "Epoch 1505/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 584.2941 - val_loss: 452.9502\n",
      "Epoch 1506/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 619.5675 - val_loss: 452.7501\n",
      "Epoch 1507/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 666.6059 - val_loss: 452.5656\n",
      "Epoch 1508/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 637.2019 - val_loss: 452.3716\n",
      "Epoch 1509/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 603.7187 - val_loss: 451.9875\n",
      "Epoch 1510/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 576.3819 - val_loss: 451.6224\n",
      "Epoch 1511/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 797.2537 - val_loss: 451.3021\n",
      "Epoch 1512/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 623.8490 - val_loss: 450.9099\n",
      "Epoch 1513/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 575.7996 - val_loss: 450.5144\n",
      "Epoch 1514/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 666.1960 - val_loss: 450.1369\n",
      "Epoch 1515/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 627.8631 - val_loss: 449.7402\n",
      "Epoch 1516/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 728.0668 - val_loss: 449.3275\n",
      "Epoch 1517/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 710.0951 - val_loss: 448.9328\n",
      "Epoch 1518/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 642.0048 - val_loss: 448.6142\n",
      "Epoch 1519/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 654.9618 - val_loss: 448.4142\n",
      "Epoch 1520/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 724.9606 - val_loss: 448.2116\n",
      "Epoch 1521/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 665.8358 - val_loss: 447.8995\n",
      "Epoch 1522/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 678.9192 - val_loss: 447.2977\n",
      "Epoch 1523/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 565us/step - loss: 710.3155 - val_loss: 446.4808\n",
      "Epoch 1524/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 579.2040 - val_loss: 445.7577\n",
      "Epoch 1525/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 726.8818 - val_loss: 445.1277\n",
      "Epoch 1526/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 544.8282 - val_loss: 444.5308\n",
      "Epoch 1527/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 597.9415 - val_loss: 444.0510\n",
      "Epoch 1528/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 512.6983 - val_loss: 443.5347\n",
      "Epoch 1529/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 708.4238 - val_loss: 443.0362\n",
      "Epoch 1530/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 549.2358 - val_loss: 442.5823\n",
      "Epoch 1531/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 653.5776 - val_loss: 442.1921\n",
      "Epoch 1532/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 536.3006 - val_loss: 441.8419\n",
      "Epoch 1533/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 615.2716 - val_loss: 441.5268\n",
      "Epoch 1534/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 683.9869 - val_loss: 441.2626\n",
      "Epoch 1535/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 760.7640 - val_loss: 441.0151\n",
      "Epoch 1536/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 572.5978 - val_loss: 440.7681\n",
      "Epoch 1537/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 597.8547 - val_loss: 440.4763\n",
      "Epoch 1538/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 569.3199 - val_loss: 440.2137\n",
      "Epoch 1539/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 632.4532 - val_loss: 439.9595\n",
      "Epoch 1540/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 541.2272 - val_loss: 439.7001\n",
      "Epoch 1541/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 601.6580 - val_loss: 439.4359\n",
      "Epoch 1542/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 657.6320 - val_loss: 439.1566\n",
      "Epoch 1543/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 788.2962 - val_loss: 438.8798\n",
      "Epoch 1544/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 690.5350 - val_loss: 438.6085\n",
      "Epoch 1545/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 781.2359 - val_loss: 438.3089\n",
      "Epoch 1546/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 695.4208 - val_loss: 438.0087\n",
      "Epoch 1547/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 668.5361 - val_loss: 437.6820\n",
      "Epoch 1548/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 779.1605 - val_loss: 437.4238\n",
      "Epoch 1549/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 704.9530 - val_loss: 437.2524\n",
      "Epoch 1550/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 691.9066 - val_loss: 437.0512\n",
      "Epoch 1551/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 684.2502 - val_loss: 436.7921\n",
      "Epoch 1552/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 615.4904 - val_loss: 436.5950\n",
      "Epoch 1553/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 637.3899 - val_loss: 436.5041\n",
      "Epoch 1554/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 967.2013 - val_loss: 436.5247\n",
      "Epoch 1555/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 748.7618 - val_loss: 436.5422\n",
      "Epoch 1556/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 838.7776 - val_loss: 436.5086\n",
      "Epoch 1557/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 773.5978 - val_loss: 436.3909\n",
      "Epoch 1558/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 734.5851 - val_loss: 438.8217\n",
      "Epoch 1559/10000\n",
      "184/184 [==============================] - 0s 611us/step - loss: 771.0968 - val_loss: 441.0334\n",
      "Epoch 1560/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 771.1879 - val_loss: 444.5734\n",
      "Epoch 1561/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 734.7393 - val_loss: 448.6617\n",
      "Epoch 1562/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 672.9460 - val_loss: 450.2918\n",
      "Epoch 1563/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 651.1400 - val_loss: 454.0678\n",
      "Epoch 1564/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 704.6830 - val_loss: 455.9497\n",
      "Epoch 1565/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 649.7620 - val_loss: 456.7598\n",
      "Epoch 1566/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 675.3208 - val_loss: 457.2496\n",
      "Epoch 1567/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 770.7196 - val_loss: 456.1045\n",
      "Epoch 1568/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 624.8672 - val_loss: 455.1534\n",
      "Epoch 1569/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 547.5924 - val_loss: 455.8770\n",
      "Epoch 1570/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 691.7348 - val_loss: 457.4811\n",
      "Epoch 1571/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 825.9014 - val_loss: 459.1954\n",
      "Epoch 1572/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 689.6496 - val_loss: 460.9631\n",
      "Epoch 1573/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 656.7629 - val_loss: 463.1059\n",
      "Epoch 1574/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 601.7454 - val_loss: 466.7246\n",
      "Epoch 1575/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 644.9189 - val_loss: 468.4064\n",
      "Epoch 1576/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 632.0751 - val_loss: 468.8012\n",
      "Epoch 1577/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 620.7562 - val_loss: 468.8055\n",
      "Epoch 1578/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 604.2428 - val_loss: 468.6487\n",
      "Epoch 1579/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 558.0254 - val_loss: 468.1732\n",
      "Epoch 1580/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 649.0203 - val_loss: 467.5038\n",
      "Epoch 1581/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 732.6709 - val_loss: 466.6428\n",
      "Epoch 1582/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 457.511 - 0s 467us/step - loss: 530.4900 - val_loss: 465.9289\n",
      "Epoch 1583/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 741.3940 - val_loss: 465.1616\n",
      "Epoch 1584/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 618.7012 - val_loss: 464.2512\n",
      "Epoch 1585/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 578.6204 - val_loss: 464.8848\n",
      "Epoch 1586/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 922.8578 - val_loss: 465.3374\n",
      "Epoch 1587/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 619.0822 - val_loss: 464.5943\n",
      "Epoch 1588/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 586.6611 - val_loss: 463.7849\n",
      "Epoch 1589/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 645.3773 - val_loss: 461.9511\n",
      "Epoch 1590/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 584.0024 - val_loss: 456.2488\n",
      "Epoch 1591/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 698.8502 - val_loss: 453.8489\n",
      "Epoch 1592/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 746.0495 - val_loss: 452.2005\n",
      "Epoch 1593/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 651.2706 - val_loss: 450.9662\n",
      "Epoch 1594/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 713.1016 - val_loss: 450.2027\n",
      "Epoch 1595/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 586.1078 - val_loss: 449.8471\n",
      "Epoch 1596/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 516us/step - loss: 631.8674 - val_loss: 449.8080\n",
      "Epoch 1597/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 582.2223 - val_loss: 449.4086\n",
      "Epoch 1598/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 584.3250 - val_loss: 448.9555\n",
      "Epoch 1599/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 664.6264 - val_loss: 448.8149\n",
      "Epoch 1600/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 719.9297 - val_loss: 449.4849\n",
      "\n",
      "Epoch 01600: loss did not improve from 652.90255\n",
      "Epoch 1601/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 487.7245 - val_loss: 451.8913\n",
      "Epoch 1602/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 673.0154 - val_loss: 457.8560\n",
      "Epoch 1603/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 811.7202 - val_loss: 461.2892\n",
      "Epoch 1604/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 711.7559 - val_loss: 456.2157\n",
      "Epoch 1605/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 593.7432 - val_loss: 456.4464\n",
      "Epoch 1606/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 679.9139 - val_loss: 455.5577\n",
      "Epoch 1607/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 812.7601 - val_loss: 455.2664\n",
      "Epoch 1608/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 693.4360 - val_loss: 455.0404\n",
      "Epoch 1609/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 681.3432 - val_loss: 500.6672\n",
      "Epoch 1610/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 572.9834 - val_loss: 518.7676\n",
      "Epoch 1611/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 522.6615 - val_loss: 458.9525\n",
      "Epoch 1612/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 678.2962 - val_loss: 434.7026\n",
      "Epoch 1613/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 727.4421 - val_loss: 435.8721\n",
      "Epoch 1614/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 595.3892 - val_loss: 434.4467\n",
      "Epoch 1615/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 571.6115 - val_loss: 432.6371\n",
      "Epoch 1616/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 552.6575 - val_loss: 428.0789\n",
      "Epoch 1617/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 721.0422 - val_loss: 425.1921\n",
      "Epoch 1618/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 586.9145 - val_loss: 423.3555\n",
      "Epoch 1619/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 587.4654 - val_loss: 422.1988\n",
      "Epoch 1620/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 651.1288 - val_loss: 421.3241\n",
      "Epoch 1621/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 592.5129 - val_loss: 420.6742\n",
      "Epoch 1622/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 584.5550 - val_loss: 420.1441\n",
      "Epoch 1623/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 665.3838 - val_loss: 419.6954\n",
      "Epoch 1624/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 605.1990 - val_loss: 419.3948\n",
      "Epoch 1625/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 634.3607 - val_loss: 419.1322\n",
      "Epoch 1626/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 634.6446 - val_loss: 418.8885\n",
      "Epoch 1627/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 525.6177 - val_loss: 418.6430\n",
      "Epoch 1628/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 618.6248 - val_loss: 417.9612\n",
      "Epoch 1629/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 493.8210 - val_loss: 417.3777\n",
      "Epoch 1630/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 783.4725 - val_loss: 416.8552\n",
      "Epoch 1631/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 655.0044 - val_loss: 416.3787\n",
      "Epoch 1632/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 634.9518 - val_loss: 415.8893\n",
      "Epoch 1633/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 646.4758 - val_loss: 415.4547\n",
      "Epoch 1634/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 689.6242 - val_loss: 415.0510\n",
      "Epoch 1635/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 776.4650 - val_loss: 414.6825\n",
      "Epoch 1636/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 708.5152 - val_loss: 414.3421\n",
      "Epoch 1637/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 725.5942 - val_loss: 413.9956\n",
      "Epoch 1638/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 562.6938 - val_loss: 413.6504\n",
      "Epoch 1639/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 644.2103 - val_loss: 413.3307\n",
      "Epoch 1640/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 704.1630 - val_loss: 413.0522\n",
      "Epoch 1641/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 750.2831 - val_loss: 412.8018\n",
      "Epoch 1642/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 666.3266 - val_loss: 412.5455\n",
      "Epoch 1643/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 550.3002 - val_loss: 412.3385\n",
      "Epoch 1644/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 564.0444 - val_loss: 412.1862\n",
      "Epoch 1645/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 633.3907 - val_loss: 412.0173\n",
      "Epoch 1646/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 529.0088 - val_loss: 411.8482\n",
      "Epoch 1647/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 584.4250 - val_loss: 411.4152\n",
      "Epoch 1648/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 686.7546 - val_loss: 413.2415\n",
      "Epoch 1649/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 803.7401 - val_loss: 418.5272\n",
      "Epoch 1650/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 600.8916 - val_loss: 423.6768\n",
      "Epoch 1651/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 569.8280 - val_loss: 425.6635\n",
      "Epoch 1652/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 850.4278 - val_loss: 424.1160\n",
      "Epoch 1653/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 556.0800 - val_loss: 470.0285\n",
      "Epoch 1654/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 491.8825 - val_loss: 499.5037\n",
      "Epoch 1655/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 639.3737 - val_loss: 504.4892\n",
      "Epoch 1656/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 832.9901 - val_loss: 506.8581\n",
      "Epoch 1657/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 741.6912 - val_loss: 500.4565\n",
      "Epoch 1658/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 592.4032 - val_loss: 483.4488\n",
      "Epoch 1659/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 625.2910 - val_loss: 452.3782\n",
      "Epoch 1660/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 718.6422 - val_loss: 440.5754\n",
      "Epoch 1661/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 646.4130 - val_loss: 438.7181\n",
      "Epoch 1662/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 604.2931 - val_loss: 440.8840\n",
      "Epoch 1663/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 557.7819 - val_loss: 441.0418\n",
      "Epoch 1664/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 661.1309 - val_loss: 441.7998\n",
      "Epoch 1665/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 676.6522 - val_loss: 441.5182\n",
      "Epoch 1666/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 826.5099 - val_loss: 439.6225\n",
      "Epoch 1667/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 531.4905 - val_loss: 436.3931\n",
      "Epoch 1668/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 615.3821 - val_loss: 433.5801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1669/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 712.3639 - val_loss: 432.1443\n",
      "Epoch 1670/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 576.9601 - val_loss: 431.0069\n",
      "Epoch 1671/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 642.3080 - val_loss: 431.2351\n",
      "Epoch 1672/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 494.8932 - val_loss: 431.4034\n",
      "Epoch 1673/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 642.9692 - val_loss: 430.4868\n",
      "Epoch 1674/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 587.1251 - val_loss: 428.9315\n",
      "Epoch 1675/10000\n",
      "184/184 [==============================] - 0s 581us/step - loss: 635.8761 - val_loss: 427.6917\n",
      "Epoch 1676/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 636.4948 - val_loss: 427.0270\n",
      "Epoch 1677/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 572.0978 - val_loss: 426.5420\n",
      "Epoch 1678/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 626.9616 - val_loss: 425.8338\n",
      "Epoch 1679/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 688.1564 - val_loss: 424.9001\n",
      "Epoch 1680/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 632.7377 - val_loss: 424.5354\n",
      "Epoch 1681/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 690.8921 - val_loss: 424.3437\n",
      "Epoch 1682/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 703.9130 - val_loss: 424.1586\n",
      "Epoch 1683/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 590.2105 - val_loss: 423.9811\n",
      "Epoch 1684/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 609.1454 - val_loss: 423.8316\n",
      "Epoch 1685/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 741.2789 - val_loss: 423.6393\n",
      "Epoch 1686/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 609.5876 - val_loss: 423.2769\n",
      "Epoch 1687/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 627.1419 - val_loss: 422.9597\n",
      "Epoch 1688/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 552.6884 - val_loss: 422.6680\n",
      "Epoch 1689/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 644.8947 - val_loss: 423.6438\n",
      "Epoch 1690/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 735.5286 - val_loss: 423.1134\n",
      "Epoch 1691/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 672.5475 - val_loss: 422.6348\n",
      "Epoch 1692/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 785.4412 - val_loss: 421.6558\n",
      "Epoch 1693/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 483.2713 - val_loss: 419.1086\n",
      "Epoch 1694/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 530.2356 - val_loss: 418.5219\n",
      "Epoch 1695/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 675.1690 - val_loss: 418.2806\n",
      "Epoch 1696/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 681.0438 - val_loss: 418.2570\n",
      "Epoch 1697/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 700.9027 - val_loss: 418.0862\n",
      "Epoch 1698/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 629.4039 - val_loss: 417.8487\n",
      "Epoch 1699/10000\n",
      "184/184 [==============================] - 0s 908us/step - loss: 522.0293 - val_loss: 417.4557\n",
      "Epoch 1700/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 516.6481 - val_loss: 416.7240\n",
      "\n",
      "Epoch 01700: loss improved from 652.90255 to 516.64813, saving model to C6007C.hdf5\n",
      "Epoch 1701/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 753.0561 - val_loss: 415.9414\n",
      "Epoch 1702/10000\n",
      "184/184 [==============================] - 0s 853us/step - loss: 553.2667 - val_loss: 415.4281\n",
      "Epoch 1703/10000\n",
      "184/184 [==============================] - 0s 750us/step - loss: 569.6691 - val_loss: 415.2286\n",
      "Epoch 1704/10000\n",
      "184/184 [==============================] - 0s 835us/step - loss: 780.9442 - val_loss: 415.0776\n",
      "Epoch 1705/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 754.4234 - val_loss: 414.9814\n",
      "Epoch 1706/10000\n",
      "184/184 [==============================] - 0s 761us/step - loss: 592.1515 - val_loss: 414.9369\n",
      "Epoch 1707/10000\n",
      "184/184 [==============================] - 0s 880us/step - loss: 516.8849 - val_loss: 414.8337\n",
      "Epoch 1708/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 540.6072 - val_loss: 414.6744\n",
      "Epoch 1709/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 666.7081 - val_loss: 414.4587\n",
      "Epoch 1710/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 703.0277 - val_loss: 413.4910\n",
      "Epoch 1711/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 667.7575 - val_loss: 413.4293\n",
      "Epoch 1712/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 648.5255 - val_loss: 413.2292\n",
      "Epoch 1713/10000\n",
      "184/184 [==============================] - 0s 870us/step - loss: 538.1180 - val_loss: 413.1346\n",
      "Epoch 1714/10000\n",
      "184/184 [==============================] - 0s 902us/step - loss: 822.4035 - val_loss: 413.0538\n",
      "Epoch 1715/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 644.2777 - val_loss: 412.7898\n",
      "Epoch 1716/10000\n",
      "184/184 [==============================] - 0s 793us/step - loss: 747.7128 - val_loss: 412.5624\n",
      "Epoch 1717/10000\n",
      "184/184 [==============================] - 0s 772us/step - loss: 548.0099 - val_loss: 412.2911\n",
      "Epoch 1718/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 752.4349 - val_loss: 411.7928\n",
      "Epoch 1719/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 643.8170 - val_loss: 411.2214\n",
      "Epoch 1720/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 678.1623 - val_loss: 410.7484\n",
      "Epoch 1721/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 563.3853 - val_loss: 410.3371\n",
      "Epoch 1722/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 564.5570 - val_loss: 409.9820\n",
      "Epoch 1723/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 595.4373 - val_loss: 409.6729\n",
      "Epoch 1724/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 685.9322 - val_loss: 409.4319\n",
      "Epoch 1725/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 698.5353 - val_loss: 408.9612\n",
      "Epoch 1726/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 539.4077 - val_loss: 408.2231\n",
      "Epoch 1727/10000\n",
      "184/184 [==============================] - 0s 783us/step - loss: 760.5728 - val_loss: 407.5312\n",
      "Epoch 1728/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 525.0496 - val_loss: 407.0297\n",
      "Epoch 1729/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 865.8828 - val_loss: 406.1526\n",
      "Epoch 1730/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 699.4688 - val_loss: 405.3892\n",
      "Epoch 1731/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 653.6029 - val_loss: 404.7475\n",
      "Epoch 1732/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 678.3500 - val_loss: 404.1886\n",
      "Epoch 1733/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 477.1711 - val_loss: 403.6859\n",
      "Epoch 1734/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 743.7389 - val_loss: 403.2289\n",
      "Epoch 1735/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 606.1557 - val_loss: 402.8477\n",
      "Epoch 1736/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 772.8989 - val_loss: 402.5262\n",
      "Epoch 1737/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 570.6030 - val_loss: 402.1006\n",
      "Epoch 1738/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 579.8043 - val_loss: 401.5678\n",
      "Epoch 1739/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 760.3466 - val_loss: 400.9100\n",
      "Epoch 1740/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 466.6197 - val_loss: 400.5745\n",
      "Epoch 1741/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 587us/step - loss: 625.3347 - val_loss: 400.2757\n",
      "Epoch 1742/10000\n",
      "184/184 [==============================] - 0s 783us/step - loss: 549.6675 - val_loss: 399.7640\n",
      "Epoch 1743/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 658.3287 - val_loss: 399.3889\n",
      "Epoch 1744/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 541.7687 - val_loss: 398.8667\n",
      "Epoch 1745/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 508.1256 - val_loss: 399.4395\n",
      "Epoch 1746/10000\n",
      "184/184 [==============================] - 0s 837us/step - loss: 608.1158 - val_loss: 399.2274\n",
      "Epoch 1747/10000\n",
      "184/184 [==============================] - 0s 940us/step - loss: 493.0297 - val_loss: 402.8564\n",
      "Epoch 1748/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 579.4240 - val_loss: 436.6799\n",
      "Epoch 1749/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 528.6401 - val_loss: 416.0150\n",
      "Epoch 1750/10000\n",
      "184/184 [==============================] - 0s 973us/step - loss: 507.5911 - val_loss: 416.8548\n",
      "Epoch 1751/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 559.7505 - val_loss: 419.8705\n",
      "Epoch 1752/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 851.5161 - val_loss: 423.9598\n",
      "Epoch 1753/10000\n",
      "184/184 [==============================] - 0s 995us/step - loss: 574.9454 - val_loss: 419.3831\n",
      "Epoch 1754/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 435.0018 - val_loss: 420.3346\n",
      "Epoch 1755/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 542.5802 - val_loss: 417.9771\n",
      "Epoch 1756/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 425.9884 - val_loss: 418.9078\n",
      "Epoch 1757/10000\n",
      "184/184 [==============================] - 0s 935us/step - loss: 488.7973 - val_loss: 418.3260\n",
      "Epoch 1758/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 518.914 - 0s 951us/step - loss: 515.9435 - val_loss: 416.7154\n",
      "Epoch 1759/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 601.9924 - val_loss: 415.0027\n",
      "Epoch 1760/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 548.1582 - val_loss: 413.3905\n",
      "Epoch 1761/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 423.5970 - val_loss: 411.9876\n",
      "Epoch 1762/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 662.5816 - val_loss: 412.2391\n",
      "Epoch 1763/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 497.7022 - val_loss: 411.7859\n",
      "Epoch 1764/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 591.6657 - val_loss: 410.8834\n",
      "Epoch 1765/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 569.9163 - val_loss: 410.4651\n",
      "Epoch 1766/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 515.9065 - val_loss: 410.0707\n",
      "Epoch 1767/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 597.1677 - val_loss: 409.7383\n",
      "Epoch 1768/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 532.3206 - val_loss: 409.4227\n",
      "Epoch 1769/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 602.9550 - val_loss: 409.1410\n",
      "Epoch 1770/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 566.1987 - val_loss: 408.9744\n",
      "Epoch 1771/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 573.4331 - val_loss: 408.8158\n",
      "Epoch 1772/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 459.7695 - val_loss: 408.6523\n",
      "Epoch 1773/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 504.2136 - val_loss: 408.4856\n",
      "Epoch 1774/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 513.8807 - val_loss: 408.2985\n",
      "Epoch 1775/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 568.3115 - val_loss: 408.0903\n",
      "Epoch 1776/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 523.1965 - val_loss: 407.8801\n",
      "Epoch 1777/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 450.2204 - val_loss: 407.6770\n",
      "Epoch 1778/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 518.5825 - val_loss: 407.4893\n",
      "Epoch 1779/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 548.5852 - val_loss: 407.3319\n",
      "Epoch 1780/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 505.3842 - val_loss: 407.1642\n",
      "Epoch 1781/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 473.9473 - val_loss: 406.9106\n",
      "Epoch 1782/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 507.9041 - val_loss: 406.6799\n",
      "Epoch 1783/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 493.8767 - val_loss: 406.4743\n",
      "Epoch 1784/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 539.8573 - val_loss: 406.2825\n",
      "Epoch 1785/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 573.5483 - val_loss: 406.1191\n",
      "Epoch 1786/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 564.0462 - val_loss: 405.9543\n",
      "Epoch 1787/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 463.3389 - val_loss: 405.7872\n",
      "Epoch 1788/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 606.7570 - val_loss: 405.6034\n",
      "Epoch 1789/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 485.7582 - val_loss: 405.4071\n",
      "Epoch 1790/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 556.2747 - val_loss: 404.8495\n",
      "Epoch 1791/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 669.0608 - val_loss: 404.2759\n",
      "Epoch 1792/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 472.9671 - val_loss: 404.3709\n",
      "Epoch 1793/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 490.5456 - val_loss: 404.3840\n",
      "Epoch 1794/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 577.8240 - val_loss: 402.8204\n",
      "Epoch 1795/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 719.1982 - val_loss: 402.6236\n",
      "Epoch 1796/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 573.1594 - val_loss: 402.3908\n",
      "Epoch 1797/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 672.6419 - val_loss: 402.6124\n",
      "Epoch 1798/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 638.1852 - val_loss: 402.7741\n",
      "Epoch 1799/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 517.1564 - val_loss: 402.4069\n",
      "Epoch 1800/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 487.1971 - val_loss: 401.8932\n",
      "\n",
      "Epoch 01800: loss improved from 516.64813 to 487.19710, saving model to C6007C.hdf5\n",
      "Epoch 1801/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 549.0386 - val_loss: 401.6402\n",
      "Epoch 1802/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 746.0312 - val_loss: 401.2993\n",
      "Epoch 1803/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 605.4253 - val_loss: 400.9929\n",
      "Epoch 1804/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 635.5573 - val_loss: 400.7207\n",
      "Epoch 1805/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 592.3466 - val_loss: 400.4343\n",
      "Epoch 1806/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 484.7956 - val_loss: 400.2011\n",
      "Epoch 1807/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 653.7138 - val_loss: 399.9831\n",
      "Epoch 1808/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 587.3521 - val_loss: 399.7616\n",
      "Epoch 1809/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 655.4873 - val_loss: 399.4958\n",
      "Epoch 1810/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 564.7855 - val_loss: 399.6085\n",
      "Epoch 1811/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 460.4429 - val_loss: 399.9117\n",
      "Epoch 1812/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 638.8711 - val_loss: 399.8459\n",
      "Epoch 1813/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 495us/step - loss: 729.4348 - val_loss: 399.7894\n",
      "Epoch 1814/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 531.7484 - val_loss: 399.6006\n",
      "Epoch 1815/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 698.6140 - val_loss: 399.3636\n",
      "Epoch 1816/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 643.2844 - val_loss: 399.0875\n",
      "Epoch 1817/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 569.6004 - val_loss: 398.9455\n",
      "Epoch 1818/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 569.7726 - val_loss: 398.9529\n",
      "Epoch 1819/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 512.1375 - val_loss: 398.8718\n",
      "Epoch 1820/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 618.1682 - val_loss: 398.8150\n",
      "Epoch 1821/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 589.1415 - val_loss: 398.6563\n",
      "Epoch 1822/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 601.1824 - val_loss: 398.4843\n",
      "Epoch 1823/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 537.4927 - val_loss: 398.3126\n",
      "Epoch 1824/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 621.3590 - val_loss: 398.0061\n",
      "Epoch 1825/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 668.7068 - val_loss: 397.5952\n",
      "Epoch 1826/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 681.0335 - val_loss: 397.2003\n",
      "Epoch 1827/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 502.8723 - val_loss: 396.9001\n",
      "Epoch 1828/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 455.2061 - val_loss: 396.6432\n",
      "Epoch 1829/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 824.0396 - val_loss: 396.3985\n",
      "Epoch 1830/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 676.2008 - val_loss: 396.0963\n",
      "Epoch 1831/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 712.2095 - val_loss: 395.8039\n",
      "Epoch 1832/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 656.1184 - val_loss: 395.4829\n",
      "Epoch 1833/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 494.6100 - val_loss: 395.2055\n",
      "Epoch 1834/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 604.1495 - val_loss: 395.9528\n",
      "Epoch 1835/10000\n",
      "184/184 [==============================] - 0s 544us/step - loss: 529.7331 - val_loss: 396.2917\n",
      "Epoch 1836/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 618.7878 - val_loss: 395.6687\n",
      "Epoch 1837/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 508.3861 - val_loss: 395.3599\n",
      "Epoch 1838/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 509.9773 - val_loss: 395.3337\n",
      "Epoch 1839/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 557.4850 - val_loss: 395.2736\n",
      "Epoch 1840/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 551.5155 - val_loss: 393.8469\n",
      "Epoch 1841/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 539.5432 - val_loss: 394.0625\n",
      "Epoch 1842/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 440.5088 - val_loss: 393.0685\n",
      "Epoch 1843/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 576.1274 - val_loss: 391.9977\n",
      "Epoch 1844/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 639.0555 - val_loss: 391.8483\n",
      "Epoch 1845/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 546.1215 - val_loss: 391.4731\n",
      "Epoch 1846/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 552.3916 - val_loss: 390.9509\n",
      "Epoch 1847/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 574.9602 - val_loss: 390.6335\n",
      "Epoch 1848/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 629.8826 - val_loss: 390.4716\n",
      "Epoch 1849/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 585.7993 - val_loss: 390.8246\n",
      "Epoch 1850/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 540.2862 - val_loss: 391.0299\n",
      "Epoch 1851/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 548.0877 - val_loss: 390.9622\n",
      "Epoch 1852/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 397.2340 - val_loss: 390.8393\n",
      "Epoch 1853/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 569.5324 - val_loss: 390.7386\n",
      "Epoch 1854/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 496.4041 - val_loss: 390.5724\n",
      "Epoch 1855/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 689.1651 - val_loss: 390.4041\n",
      "Epoch 1856/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 640.3288 - val_loss: 390.2231\n",
      "Epoch 1857/10000\n",
      "184/184 [==============================] - 0s 606us/step - loss: 505.8589 - val_loss: 390.0548\n",
      "Epoch 1858/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 616.546 - 0s 647us/step - loss: 575.0964 - val_loss: 390.0514\n",
      "Epoch 1859/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 611.6308 - val_loss: 390.0120\n",
      "Epoch 1860/10000\n",
      "184/184 [==============================] - 0s 671us/step - loss: 451.6863 - val_loss: 389.8640\n",
      "Epoch 1861/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 607.5213 - val_loss: 389.6276\n",
      "Epoch 1862/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 501.0383 - val_loss: 389.3922\n",
      "Epoch 1863/10000\n",
      "184/184 [==============================] - 0s 709us/step - loss: 639.5627 - val_loss: 388.4351\n",
      "Epoch 1864/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 519.6897 - val_loss: 385.6219\n",
      "Epoch 1865/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 506.6340 - val_loss: 379.5586\n",
      "Epoch 1866/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 611.5290 - val_loss: 379.1592\n",
      "Epoch 1867/10000\n",
      "184/184 [==============================] - 0s 669us/step - loss: 610.4994 - val_loss: 378.8092\n",
      "Epoch 1868/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 481.4752 - val_loss: 378.3446\n",
      "Epoch 1869/10000\n",
      "184/184 [==============================] - 0s 563us/step - loss: 610.0784 - val_loss: 377.4200\n",
      "Epoch 1870/10000\n",
      "184/184 [==============================] - 0s 666us/step - loss: 580.3844 - val_loss: 377.2093\n",
      "Epoch 1871/10000\n",
      "184/184 [==============================] - 0s 557us/step - loss: 444.6387 - val_loss: 377.1862\n",
      "Epoch 1872/10000\n",
      "184/184 [==============================] - 0s 584us/step - loss: 661.9825 - val_loss: 377.2261\n",
      "Epoch 1873/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 623.2315 - val_loss: 377.1396\n",
      "Epoch 1874/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 654.7153 - val_loss: 376.4894\n",
      "Epoch 1875/10000\n",
      "184/184 [==============================] - 0s 568us/step - loss: 471.6319 - val_loss: 375.8667\n",
      "Epoch 1876/10000\n",
      "184/184 [==============================] - 0s 563us/step - loss: 507.1328 - val_loss: 374.7340\n",
      "Epoch 1877/10000\n",
      "184/184 [==============================] - 0s 492us/step - loss: 532.3553 - val_loss: 374.1201\n",
      "Epoch 1878/10000\n",
      "184/184 [==============================] - 0s 557us/step - loss: 528.3486 - val_loss: 375.1617\n",
      "Epoch 1879/10000\n",
      "184/184 [==============================] - 0s 715us/step - loss: 587.1866 - val_loss: 374.9260\n",
      "Epoch 1880/10000\n",
      "184/184 [==============================] - 0s 595us/step - loss: 571.7414 - val_loss: 374.7660\n",
      "Epoch 1881/10000\n",
      "184/184 [==============================] - 0s 557us/step - loss: 479.7628 - val_loss: 374.5841\n",
      "Epoch 1882/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 551.1974 - val_loss: 374.3534\n",
      "Epoch 1883/10000\n",
      "184/184 [==============================] - 0s 693us/step - loss: 477.0170 - val_loss: 374.1301\n",
      "Epoch 1884/10000\n",
      "184/184 [==============================] - 0s 650us/step - loss: 541.3484 - val_loss: 373.8475\n",
      "Epoch 1885/10000\n",
      "184/184 [==============================] - 0s 720us/step - loss: 691.1039 - val_loss: 373.5850\n",
      "Epoch 1886/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 546us/step - loss: 575.8156 - val_loss: 373.3416\n",
      "Epoch 1887/10000\n",
      "184/184 [==============================] - 0s 552us/step - loss: 607.8909 - val_loss: 373.1124\n",
      "Epoch 1888/10000\n",
      "184/184 [==============================] - 0s 660us/step - loss: 640.3729 - val_loss: 372.9211\n",
      "Epoch 1889/10000\n",
      "184/184 [==============================] - 0s 563us/step - loss: 571.6776 - val_loss: 372.7600\n",
      "Epoch 1890/10000\n",
      "184/184 [==============================] - 0s 628us/step - loss: 533.8661 - val_loss: 372.5883\n",
      "Epoch 1891/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 432.2369 - val_loss: 372.3752\n",
      "Epoch 1892/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 518.6330 - val_loss: 372.1540\n",
      "Epoch 1893/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 597.1452 - val_loss: 371.9215\n",
      "Epoch 1894/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 635.0798 - val_loss: 371.6786\n",
      "Epoch 1895/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 475.8551 - val_loss: 371.5046\n",
      "Epoch 1896/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 477.3882 - val_loss: 371.3296\n",
      "Epoch 1897/10000\n",
      "184/184 [==============================] - 0s 546us/step - loss: 692.0586 - val_loss: 371.3132\n",
      "Epoch 1898/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 661.1599 - val_loss: 371.2585\n",
      "Epoch 1899/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 590.0546 - val_loss: 371.1955\n",
      "Epoch 1900/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 593.2193 - val_loss: 371.0868\n",
      "\n",
      "Epoch 01900: loss did not improve from 487.19710\n",
      "Epoch 1901/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 432.3352 - val_loss: 370.9333\n",
      "Epoch 1902/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 561.2800 - val_loss: 370.7791\n",
      "Epoch 1903/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 542.6246 - val_loss: 370.6125\n",
      "Epoch 1904/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 521.0196 - val_loss: 370.4486\n",
      "Epoch 1905/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 533.7583 - val_loss: 370.2697\n",
      "Epoch 1906/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 512.8089 - val_loss: 370.0836\n",
      "Epoch 1907/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 408.0433 - val_loss: 369.9064\n",
      "Epoch 1908/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 569.9831 - val_loss: 369.7323\n",
      "Epoch 1909/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 521.4599 - val_loss: 369.5649\n",
      "Epoch 1910/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 496.6989 - val_loss: 369.3879\n",
      "Epoch 1911/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 592.7887 - val_loss: 369.2271\n",
      "Epoch 1912/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 492.9606 - val_loss: 369.0816\n",
      "Epoch 1913/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 570.6072 - val_loss: 368.9096\n",
      "Epoch 1914/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 466.0790 - val_loss: 368.7420\n",
      "Epoch 1915/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 508.1199 - val_loss: 368.5668\n",
      "Epoch 1916/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 550.3113 - val_loss: 368.3837\n",
      "Epoch 1917/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 509.3988 - val_loss: 368.1860\n",
      "Epoch 1918/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 579.6392 - val_loss: 367.9930\n",
      "Epoch 1919/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 527.0731 - val_loss: 367.7846\n",
      "Epoch 1920/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 534.3963 - val_loss: 367.5540\n",
      "Epoch 1921/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 547.7268 - val_loss: 367.3779\n",
      "Epoch 1922/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 514.2648 - val_loss: 367.2221\n",
      "Epoch 1923/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 558.0195 - val_loss: 367.0648\n",
      "Epoch 1924/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 503.4517 - val_loss: 366.9047\n",
      "Epoch 1925/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 542.0803 - val_loss: 366.7431\n",
      "Epoch 1926/10000\n",
      "184/184 [==============================] - 0s 579us/step - loss: 510.3976 - val_loss: 366.5752\n",
      "Epoch 1927/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 595.4421 - val_loss: 366.3285\n",
      "Epoch 1928/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 454.6898 - val_loss: 366.0537\n",
      "Epoch 1929/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 607.8091 - val_loss: 365.8088\n",
      "Epoch 1930/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 485.4529 - val_loss: 365.5790\n",
      "Epoch 1931/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 607.9926 - val_loss: 365.3471\n",
      "Epoch 1932/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 464.8739 - val_loss: 365.1672\n",
      "Epoch 1933/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 468.8597 - val_loss: 364.9917\n",
      "Epoch 1934/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 547.5361 - val_loss: 364.8113\n",
      "Epoch 1935/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 647.2051 - val_loss: 364.6174\n",
      "Epoch 1936/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 584.9226 - val_loss: 364.4146\n",
      "Epoch 1937/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 602.7599 - val_loss: 364.2203\n",
      "Epoch 1938/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 549.0857 - val_loss: 364.0148\n",
      "Epoch 1939/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 617.2047 - val_loss: 363.8055\n",
      "Epoch 1940/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 425.7742 - val_loss: 363.6010\n",
      "Epoch 1941/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 498.1944 - val_loss: 363.4220\n",
      "Epoch 1942/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 430.8746 - val_loss: 363.2689\n",
      "Epoch 1943/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 575.0803 - val_loss: 363.1052\n",
      "Epoch 1944/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 614.6698 - val_loss: 362.9300\n",
      "Epoch 1945/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 477.9230 - val_loss: 362.7568\n",
      "Epoch 1946/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 621.6894 - val_loss: 362.5770\n",
      "Epoch 1947/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 502.5927 - val_loss: 362.3773\n",
      "Epoch 1948/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 537.9410 - val_loss: 362.1715\n",
      "Epoch 1949/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 502.4879 - val_loss: 361.9560\n",
      "Epoch 1950/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 667.3876 - val_loss: 361.7701\n",
      "Epoch 1951/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 430.7564 - val_loss: 361.5925\n",
      "Epoch 1952/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 449.8914 - val_loss: 361.4145\n",
      "Epoch 1953/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 594.8964 - val_loss: 361.1671\n",
      "Epoch 1954/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 502.1894 - val_loss: 360.9461\n",
      "Epoch 1955/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 552.6382 - val_loss: 360.7197\n",
      "Epoch 1956/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 561.4914 - val_loss: 360.5410\n",
      "Epoch 1957/10000\n",
      "184/184 [==============================] - 0s 541us/step - loss: 527.2532 - val_loss: 360.3629\n",
      "Epoch 1958/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 497.6867 - val_loss: 360.1711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1959/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 508.2114 - val_loss: 359.9721\n",
      "Epoch 1960/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 514.9170 - val_loss: 359.7713\n",
      "Epoch 1961/10000\n",
      "184/184 [==============================] - 0s 581us/step - loss: 699.6603 - val_loss: 359.5696\n",
      "Epoch 1962/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 486.6178 - val_loss: 359.3669\n",
      "Epoch 1963/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 507.0461 - val_loss: 359.1445\n",
      "Epoch 1964/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 639.6036 - val_loss: 358.9074\n",
      "Epoch 1965/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 499.0718 - val_loss: 358.6670\n",
      "Epoch 1966/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 530.4871 - val_loss: 358.4321\n",
      "Epoch 1967/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 559.6940 - val_loss: 358.1929\n",
      "Epoch 1968/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 517.3686 - val_loss: 357.9734\n",
      "Epoch 1969/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 490.8394 - val_loss: 357.7613\n",
      "Epoch 1970/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 597.6002 - val_loss: 357.5475\n",
      "Epoch 1971/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 475.4932 - val_loss: 357.3314\n",
      "Epoch 1972/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 516.9985 - val_loss: 357.1064\n",
      "Epoch 1973/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 542.0257 - val_loss: 356.8813\n",
      "Epoch 1974/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 679.3672 - val_loss: 356.6380\n",
      "Epoch 1975/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 400.6743 - val_loss: 356.4092\n",
      "Epoch 1976/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 468.3750 - val_loss: 356.1551\n",
      "Epoch 1977/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 658.0948 - val_loss: 355.7468\n",
      "Epoch 1978/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 623.7361 - val_loss: 355.5679\n",
      "Epoch 1979/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 650.9322 - val_loss: 356.0287\n",
      "Epoch 1980/10000\n",
      "184/184 [==============================] - 0s 606us/step - loss: 470.4489 - val_loss: 355.9392\n",
      "Epoch 1981/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 529.3732 - val_loss: 355.5658\n",
      "Epoch 1982/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 471.6661 - val_loss: 355.1472\n",
      "Epoch 1983/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 453.4455 - val_loss: 352.3184\n",
      "Epoch 1984/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 699.7468 - val_loss: 350.5838\n",
      "Epoch 1985/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 562.9020 - val_loss: 349.3568\n",
      "Epoch 1986/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 615.8669 - val_loss: 348.4415\n",
      "Epoch 1987/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 685.1972 - val_loss: 347.7369\n",
      "Epoch 1988/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 505.0494 - val_loss: 347.1446\n",
      "Epoch 1989/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 550.6597 - val_loss: 346.6301\n",
      "Epoch 1990/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 564.5925 - val_loss: 346.4622\n",
      "Epoch 1991/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 392.1817 - val_loss: 346.2856\n",
      "Epoch 1992/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 489.7623 - val_loss: 346.1071\n",
      "Epoch 1993/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 613.4285 - val_loss: 346.1068\n",
      "Epoch 1994/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 462.3181 - val_loss: 346.0594\n",
      "Epoch 1995/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 434.8628 - val_loss: 345.9810\n",
      "Epoch 1996/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 485.7090 - val_loss: 345.8897\n",
      "Epoch 1997/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 457.3336 - val_loss: 345.7759\n",
      "Epoch 1998/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 526.7295 - val_loss: 345.6447\n",
      "Epoch 1999/10000\n",
      "184/184 [==============================] - 0s 525us/step - loss: 504.7602 - val_loss: 345.5014\n",
      "Epoch 2000/10000\n",
      "184/184 [==============================] - 0s 595us/step - loss: 603.6897 - val_loss: 345.3462\n",
      "\n",
      "Epoch 02000: loss did not improve from 487.19710\n",
      "Epoch 2001/10000\n",
      "184/184 [==============================] - 0s 563us/step - loss: 570.3955 - val_loss: 345.1865\n",
      "Epoch 2002/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 496.8878 - val_loss: 345.0258\n",
      "Epoch 2003/10000\n",
      "184/184 [==============================] - 0s 535us/step - loss: 551.3556 - val_loss: 344.8232\n",
      "Epoch 2004/10000\n",
      "184/184 [==============================] - 0s 552us/step - loss: 547.6407 - val_loss: 344.5962\n",
      "Epoch 2005/10000\n",
      "184/184 [==============================] - 0s 544us/step - loss: 439.2272 - val_loss: 344.3751\n",
      "Epoch 2006/10000\n",
      "184/184 [==============================] - 0s 552us/step - loss: 478.5953 - val_loss: 344.1693\n",
      "Epoch 2007/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 536.4916 - val_loss: 343.9733\n",
      "Epoch 2008/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 499.1926 - val_loss: 343.7823\n",
      "Epoch 2009/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 491.6033 - val_loss: 343.5927\n",
      "Epoch 2010/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 539.4652 - val_loss: 343.4024\n",
      "Epoch 2011/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 515.1196 - val_loss: 343.2952\n",
      "Epoch 2012/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 456.0253 - val_loss: 343.1731\n",
      "Epoch 2013/10000\n",
      "184/184 [==============================] - 0s 573us/step - loss: 524.5515 - val_loss: 343.0388\n",
      "Epoch 2014/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 686.5500 - val_loss: 342.8920\n",
      "Epoch 2015/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 413.8787 - val_loss: 342.7546\n",
      "Epoch 2016/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 526.9772 - val_loss: 342.6378\n",
      "Epoch 2017/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 563.6955 - val_loss: 342.5021\n",
      "Epoch 2018/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 698.9571 - val_loss: 342.3598\n",
      "Epoch 2019/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 442.2159 - val_loss: 342.1970\n",
      "Epoch 2020/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 653.2588 - val_loss: 342.0175\n",
      "Epoch 2021/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 406.9841 - val_loss: 341.9419\n",
      "Epoch 2022/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 524.9255 - val_loss: 341.8348\n",
      "Epoch 2023/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 441.6362 - val_loss: 341.7125\n",
      "Epoch 2024/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 642.2344 - val_loss: 341.5792\n",
      "Epoch 2025/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 507.7871 - val_loss: 341.4992\n",
      "Epoch 2026/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 545.7284 - val_loss: 341.4419\n",
      "Epoch 2027/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 571.4573 - val_loss: 341.3473\n",
      "Epoch 2028/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 547.8211 - val_loss: 341.2302\n",
      "Epoch 2029/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 487.5506 - val_loss: 341.1023\n",
      "Epoch 2030/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 488.7237 - val_loss: 340.9579\n",
      "Epoch 2031/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 549us/step - loss: 491.3196 - val_loss: 340.7786\n",
      "Epoch 2032/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 648.7775 - val_loss: 340.5773\n",
      "Epoch 2033/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 525.9949 - val_loss: 340.3736\n",
      "Epoch 2034/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 484.0863 - val_loss: 340.1770\n",
      "Epoch 2035/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 580.0119 - val_loss: 339.9712\n",
      "Epoch 2036/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 431.3930 - val_loss: 339.7561\n",
      "Epoch 2037/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 571.8592 - val_loss: 339.5435\n",
      "Epoch 2038/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 434.5097 - val_loss: 339.4029\n",
      "Epoch 2039/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 483.1958 - val_loss: 339.2490\n",
      "Epoch 2040/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 449.0977 - val_loss: 339.0917\n",
      "Epoch 2041/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 475.5489 - val_loss: 338.9249\n",
      "Epoch 2042/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 518.7943 - val_loss: 338.7508\n",
      "Epoch 2043/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 539.0095 - val_loss: 338.5769\n",
      "Epoch 2044/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 445.3477 - val_loss: 338.5542\n",
      "Epoch 2045/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 648.4066 - val_loss: 338.4402\n",
      "Epoch 2046/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 427.7754 - val_loss: 338.2301\n",
      "Epoch 2047/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 527.1583 - val_loss: 337.9861\n",
      "Epoch 2048/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 455.6715 - val_loss: 337.5950\n",
      "Epoch 2049/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 438.4507 - val_loss: 337.2091\n",
      "Epoch 2050/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 667.2548 - val_loss: 336.5965\n",
      "Epoch 2051/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 423.1521 - val_loss: 336.2089\n",
      "Epoch 2052/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 438.1925 - val_loss: 335.9376\n",
      "Epoch 2053/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 574.5766 - val_loss: 335.8329\n",
      "Epoch 2054/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 431.1190 - val_loss: 335.7209\n",
      "Epoch 2055/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 527.2277 - val_loss: 335.6443\n",
      "Epoch 2056/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 496.5592 - val_loss: 335.5887\n",
      "Epoch 2057/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 486.6519 - val_loss: 335.5223\n",
      "Epoch 2058/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 401.9256 - val_loss: 335.4723\n",
      "Epoch 2059/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 481.2361 - val_loss: 335.4345\n",
      "Epoch 2060/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 483.3461 - val_loss: 335.3315\n",
      "Epoch 2061/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 444.4560 - val_loss: 335.1871\n",
      "Epoch 2062/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 455.7249 - val_loss: 335.0349\n",
      "Epoch 2063/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 582.4239 - val_loss: 334.8584\n",
      "Epoch 2064/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 616.5646 - val_loss: 334.7002\n",
      "Epoch 2065/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 578.4160 - val_loss: 334.5401\n",
      "Epoch 2066/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 417.3442 - val_loss: 334.4008\n",
      "Epoch 2067/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 452.7084 - val_loss: 334.2597\n",
      "Epoch 2068/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 488.4789 - val_loss: 334.0991\n",
      "Epoch 2069/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 485.6242 - val_loss: 333.9870\n",
      "Epoch 2070/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 455.7525 - val_loss: 333.8365\n",
      "Epoch 2071/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 522.0476 - val_loss: 333.6566\n",
      "Epoch 2072/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 542.9643 - val_loss: 333.4617\n",
      "Epoch 2073/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 419.1674 - val_loss: 333.2574\n",
      "Epoch 2074/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 562.8398 - val_loss: 333.0584\n",
      "Epoch 2075/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 507.8334 - val_loss: 332.8579\n",
      "Epoch 2076/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 743.8934 - val_loss: 332.6673\n",
      "Epoch 2077/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 473.6335 - val_loss: 332.4765\n",
      "Epoch 2078/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 520.3698 - val_loss: 332.3062\n",
      "Epoch 2079/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 602.5668 - val_loss: 332.1898\n",
      "Epoch 2080/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 520.7943 - val_loss: 332.3144\n",
      "Epoch 2081/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 401.7722 - val_loss: 331.5242\n",
      "Epoch 2082/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 625.7540 - val_loss: 333.8842\n",
      "Epoch 2083/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 513.5613 - val_loss: 336.3799\n",
      "Epoch 2084/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 509.3093 - val_loss: 332.9730\n",
      "Epoch 2085/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 448.1048 - val_loss: 331.0378\n",
      "Epoch 2086/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 479.0784 - val_loss: 331.0810\n",
      "Epoch 2087/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 515.5294 - val_loss: 331.4331\n",
      "Epoch 2088/10000\n",
      "184/184 [==============================] - 0s 535us/step - loss: 383.2461 - val_loss: 331.2938\n",
      "Epoch 2089/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 443.6055 - val_loss: 330.2756\n",
      "Epoch 2090/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 458.3713 - val_loss: 328.8355\n",
      "Epoch 2091/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 497.8779 - val_loss: 328.9505\n",
      "Epoch 2092/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 496.1449 - val_loss: 329.0816\n",
      "Epoch 2093/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 480.1982 - val_loss: 329.5350\n",
      "Epoch 2094/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 563.3794 - val_loss: 329.3291\n",
      "Epoch 2095/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 549.2917 - val_loss: 329.1619\n",
      "Epoch 2096/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 471.5471 - val_loss: 328.9985\n",
      "Epoch 2097/10000\n",
      "184/184 [==============================] - 0s 581us/step - loss: 458.5590 - val_loss: 328.8219\n",
      "Epoch 2098/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 436.6442 - val_loss: 327.9592\n",
      "Epoch 2099/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 533.4971 - val_loss: 327.6035\n",
      "Epoch 2100/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 555.4268 - val_loss: 327.3851\n",
      "\n",
      "Epoch 02100: loss did not improve from 487.19710\n",
      "Epoch 2101/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 446.1099 - val_loss: 327.1682\n",
      "Epoch 2102/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 541.6234 - val_loss: 326.9873\n",
      "Epoch 2103/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 549.3444 - val_loss: 326.8086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2104/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 512.7357 - val_loss: 326.6465\n",
      "Epoch 2105/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 495.8646 - val_loss: 326.4518\n",
      "Epoch 2106/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 554.9355 - val_loss: 326.1567\n",
      "Epoch 2107/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 484.8940 - val_loss: 328.4131\n",
      "Epoch 2108/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 449.8123 - val_loss: 330.6009\n",
      "Epoch 2109/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 431.8525 - val_loss: 327.7962\n",
      "Epoch 2110/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 478.2004 - val_loss: 325.6079\n",
      "Epoch 2111/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 432.2957 - val_loss: 333.9565\n",
      "Epoch 2112/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 449.7926 - val_loss: 335.2784\n",
      "Epoch 2113/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 410.8195 - val_loss: 335.2024\n",
      "Epoch 2114/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 568.9916 - val_loss: 336.1176\n",
      "Epoch 2115/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 468.7455 - val_loss: 337.6178\n",
      "Epoch 2116/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 522.7264 - val_loss: 336.9745\n",
      "Epoch 2117/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 504.6563 - val_loss: 333.6029\n",
      "Epoch 2118/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 528.0551 - val_loss: 330.3241\n",
      "Epoch 2119/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 427.4115 - val_loss: 327.9974\n",
      "Epoch 2120/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 433.2409 - val_loss: 327.0473\n",
      "Epoch 2121/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 532.8827 - val_loss: 326.3920\n",
      "Epoch 2122/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 490.2992 - val_loss: 325.9916\n",
      "Epoch 2123/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 518.2031 - val_loss: 325.7683\n",
      "Epoch 2124/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 375.9777 - val_loss: 325.5930\n",
      "Epoch 2125/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 561.8075 - val_loss: 325.1189\n",
      "Epoch 2126/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 406.0316 - val_loss: 324.6112\n",
      "Epoch 2127/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 574.6091 - val_loss: 324.4496\n",
      "Epoch 2128/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 515.5023 - val_loss: 324.4234\n",
      "Epoch 2129/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 491.7684 - val_loss: 324.0917\n",
      "Epoch 2130/10000\n",
      "184/184 [==============================] - 0s 568us/step - loss: 448.1178 - val_loss: 323.8984\n",
      "Epoch 2131/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 505.7474 - val_loss: 323.7884\n",
      "Epoch 2132/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 549.6718 - val_loss: 323.6868\n",
      "Epoch 2133/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 400.5781 - val_loss: 323.5994\n",
      "Epoch 2134/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 620.7831 - val_loss: 323.4945\n",
      "Epoch 2135/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 373.4105 - val_loss: 323.3927\n",
      "Epoch 2136/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 423.9545 - val_loss: 323.2457\n",
      "Epoch 2137/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 578.6540 - val_loss: 323.0616\n",
      "Epoch 2138/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 567.9921 - val_loss: 322.6400\n",
      "Epoch 2139/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 535.2611 - val_loss: 322.1770\n",
      "Epoch 2140/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 565.3359 - val_loss: 321.8312\n",
      "Epoch 2141/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 600.6770 - val_loss: 321.6060\n",
      "Epoch 2142/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 672.8851 - val_loss: 321.3685\n",
      "Epoch 2143/10000\n",
      "184/184 [==============================] - 0s 639us/step - loss: 444.2032 - val_loss: 321.1244\n",
      "Epoch 2144/10000\n",
      "184/184 [==============================] - 0s 535us/step - loss: 415.8483 - val_loss: 320.9314\n",
      "Epoch 2145/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 441.4167 - val_loss: 320.6987\n",
      "Epoch 2146/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 484.5266 - val_loss: 320.4501\n",
      "Epoch 2147/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 457.6665 - val_loss: 320.2176\n",
      "Epoch 2148/10000\n",
      "184/184 [==============================] - 0s 552us/step - loss: 365.3615 - val_loss: 320.0020\n",
      "Epoch 2149/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 353.9937 - val_loss: 319.8010\n",
      "Epoch 2150/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 431.1782 - val_loss: 319.6192\n",
      "Epoch 2151/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 504.4065 - val_loss: 319.4198\n",
      "Epoch 2152/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 401.7198 - val_loss: 319.1494\n",
      "Epoch 2153/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 430.8222 - val_loss: 318.9624\n",
      "Epoch 2154/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 523.0428 - val_loss: 318.8482\n",
      "Epoch 2155/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 490.9991 - val_loss: 318.7792\n",
      "Epoch 2156/10000\n",
      "184/184 [==============================] - 0s 783us/step - loss: 637.6956 - val_loss: 318.7101\n",
      "Epoch 2157/10000\n",
      "184/184 [==============================] - 0s 875us/step - loss: 704.1445 - val_loss: 318.1382\n",
      "Epoch 2158/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 549.6390 - val_loss: 317.7907\n",
      "Epoch 2159/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 514.6597 - val_loss: 317.6528\n",
      "Epoch 2160/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 442.4400 - val_loss: 317.7168\n",
      "Epoch 2161/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 432.2352 - val_loss: 317.8364\n",
      "Epoch 2162/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 351.5338 - val_loss: 318.1731\n",
      "Epoch 2163/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 383.4417 - val_loss: 318.6330\n",
      "Epoch 2164/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 445.7951 - val_loss: 317.5309\n",
      "Epoch 2165/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 558.9364 - val_loss: 317.4079\n",
      "Epoch 2166/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 492.8624 - val_loss: 317.5208\n",
      "Epoch 2167/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 523.7937 - val_loss: 317.9202\n",
      "Epoch 2168/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 566.2643 - val_loss: 317.7554\n",
      "Epoch 2169/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 417.8387 - val_loss: 317.4252\n",
      "Epoch 2170/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 472.1136 - val_loss: 316.8794\n",
      "Epoch 2171/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 597.2417 - val_loss: 316.3997\n",
      "Epoch 2172/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 539.9983 - val_loss: 315.9740\n",
      "Epoch 2173/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 449.4007 - val_loss: 315.5652\n",
      "Epoch 2174/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 407.9929 - val_loss: 314.9644\n",
      "Epoch 2175/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 506.7116 - val_loss: 314.8136\n",
      "Epoch 2176/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 400.2903 - val_loss: 314.7713\n",
      "Epoch 2177/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 609us/step - loss: 390.1862 - val_loss: 315.5285\n",
      "Epoch 2178/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 455.3621 - val_loss: 316.8490\n",
      "Epoch 2179/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 476.3804 - val_loss: 316.5253\n",
      "Epoch 2180/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 456.4003 - val_loss: 316.2613\n",
      "Epoch 2181/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 642.2643 - val_loss: 315.8237\n",
      "Epoch 2182/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 471.9320 - val_loss: 315.0419\n",
      "Epoch 2183/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 456.4032 - val_loss: 314.5114\n",
      "Epoch 2184/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 448.4543 - val_loss: 315.7168\n",
      "Epoch 2185/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 359.7941 - val_loss: 315.6340\n",
      "Epoch 2186/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 437.6260 - val_loss: 315.0661\n",
      "Epoch 2187/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 510.9500 - val_loss: 313.0169\n",
      "Epoch 2188/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 408.4959 - val_loss: 312.6689\n",
      "Epoch 2189/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 447.6826 - val_loss: 313.0602\n",
      "Epoch 2190/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 494.4841 - val_loss: 313.0544\n",
      "Epoch 2191/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 446.7085 - val_loss: 313.1428\n",
      "Epoch 2192/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 438.6096 - val_loss: 313.1583\n",
      "Epoch 2193/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 484.5306 - val_loss: 313.1944\n",
      "Epoch 2194/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 467.8162 - val_loss: 313.1597\n",
      "Epoch 2195/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 406.3297 - val_loss: 313.0221\n",
      "Epoch 2196/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 467.0708 - val_loss: 312.8577\n",
      "Epoch 2197/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 524.1078 - val_loss: 312.7148\n",
      "Epoch 2198/10000\n",
      "184/184 [==============================] - 0s 517us/step - loss: 475.1261 - val_loss: 312.5708\n",
      "Epoch 2199/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 459.0718 - val_loss: 312.4195\n",
      "Epoch 2200/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 689.0028 - val_loss: 312.3508\n",
      "\n",
      "Epoch 02200: loss did not improve from 487.19710\n",
      "Epoch 2201/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 344.0845 - val_loss: 312.1230\n",
      "Epoch 2202/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 525.2665 - val_loss: 311.7871\n",
      "Epoch 2203/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 450.4016 - val_loss: 311.4646\n",
      "Epoch 2204/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 382.2898 - val_loss: 311.0934\n",
      "Epoch 2205/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 534.5977 - val_loss: 310.7599\n",
      "Epoch 2206/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 537.4912 - val_loss: 310.4845\n",
      "Epoch 2207/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 363.2561 - val_loss: 310.2502\n",
      "Epoch 2208/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 473.8121 - val_loss: 311.0606\n",
      "Epoch 2209/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 436.6027 - val_loss: 315.2719\n",
      "Epoch 2210/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 496.3359 - val_loss: 318.7045\n",
      "Epoch 2211/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 417.6131 - val_loss: 319.7284\n",
      "Epoch 2212/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 441.4800 - val_loss: 319.8150\n",
      "Epoch 2213/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 557.4374 - val_loss: 318.2278\n",
      "Epoch 2214/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 538.8516 - val_loss: 315.7112\n",
      "Epoch 2215/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 491.0843 - val_loss: 312.4296\n",
      "Epoch 2216/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 447.3453 - val_loss: 311.1957\n",
      "Epoch 2217/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 434.7863 - val_loss: 309.7799\n",
      "Epoch 2218/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 504.2443 - val_loss: 313.5082\n",
      "Epoch 2219/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 485.4268 - val_loss: 316.8328\n",
      "Epoch 2220/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 497.3146 - val_loss: 318.8029\n",
      "Epoch 2221/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 467.9926 - val_loss: 319.6076\n",
      "Epoch 2222/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 491.0953 - val_loss: 319.1917\n",
      "Epoch 2223/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 504.6123 - val_loss: 319.0166\n",
      "Epoch 2224/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 461.4698 - val_loss: 318.8375\n",
      "Epoch 2225/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 602.0545 - val_loss: 318.6360\n",
      "Epoch 2226/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 548.5384 - val_loss: 318.3738\n",
      "Epoch 2227/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 439.7116 - val_loss: 318.0931\n",
      "Epoch 2228/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 444.2247 - val_loss: 317.9109\n",
      "Epoch 2229/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 458.0776 - val_loss: 317.8004\n",
      "Epoch 2230/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 438.3818 - val_loss: 317.7537\n",
      "Epoch 2231/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 404.9340 - val_loss: 317.6666\n",
      "Epoch 2232/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 417.6639 - val_loss: 316.7813\n",
      "Epoch 2233/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 434.2562 - val_loss: 312.7234\n",
      "Epoch 2234/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 522.7301 - val_loss: 309.8340\n",
      "Epoch 2235/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 411.4338 - val_loss: 307.3459\n",
      "Epoch 2236/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 442.0019 - val_loss: 305.7968\n",
      "Epoch 2237/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 395.6545 - val_loss: 305.4576\n",
      "Epoch 2238/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 470.2605 - val_loss: 305.2926\n",
      "Epoch 2239/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 452.8774 - val_loss: 305.1508\n",
      "Epoch 2240/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 495.3713 - val_loss: 304.9041\n",
      "Epoch 2241/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 447.2229 - val_loss: 304.7209\n",
      "Epoch 2242/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 364.3044 - val_loss: 304.5576\n",
      "Epoch 2243/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 553.5607 - val_loss: 304.3576\n",
      "Epoch 2244/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 503.0952 - val_loss: 304.4234\n",
      "Epoch 2245/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 413.4998 - val_loss: 303.6173\n",
      "Epoch 2246/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 422.8677 - val_loss: 305.5072\n",
      "Epoch 2247/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 459.4799 - val_loss: 309.6712\n",
      "Epoch 2248/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 389.4877 - val_loss: 302.8799\n",
      "Epoch 2249/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 425.8752 - val_loss: 303.5901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2250/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 546.1812 - val_loss: 302.1277\n",
      "Epoch 2251/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 362.4801 - val_loss: 302.0012\n",
      "Epoch 2252/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 545.1728 - val_loss: 305.4678\n",
      "Epoch 2253/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 464.4492 - val_loss: 304.0068\n",
      "Epoch 2254/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 432.5055 - val_loss: 304.1953\n",
      "Epoch 2255/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 452.1634 - val_loss: 304.2664\n",
      "Epoch 2256/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 441.4278 - val_loss: 304.0406\n",
      "Epoch 2257/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 534.3846 - val_loss: 306.3388\n",
      "Epoch 2258/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 416.1520 - val_loss: 306.3714\n",
      "Epoch 2259/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 384.8294 - val_loss: 305.6973\n",
      "Epoch 2260/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 384.9439 - val_loss: 306.4185\n",
      "Epoch 2261/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 472.2557 - val_loss: 306.7558\n",
      "Epoch 2262/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 444.2558 - val_loss: 307.7974\n",
      "Epoch 2263/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 516.0584 - val_loss: 307.1372\n",
      "Epoch 2264/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 511.4218 - val_loss: 307.3841\n",
      "Epoch 2265/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 412.9466 - val_loss: 306.2817\n",
      "Epoch 2266/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 368.4067 - val_loss: 306.1426\n",
      "Epoch 2267/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 522.0327 - val_loss: 305.8570\n",
      "Epoch 2268/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 538.4721 - val_loss: 305.3294\n",
      "Epoch 2269/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 391.5182 - val_loss: 305.3224\n",
      "Epoch 2270/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 525.0513 - val_loss: 305.2427\n",
      "Epoch 2271/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 387.4830 - val_loss: 305.0352\n",
      "Epoch 2272/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 465.8023 - val_loss: 304.6593\n",
      "Epoch 2273/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 281.9275 - val_loss: 305.5962\n",
      "Epoch 2274/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 469.8319 - val_loss: 305.0884\n",
      "Epoch 2275/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 389.2882 - val_loss: 304.3164\n",
      "Epoch 2276/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 386.5953 - val_loss: 303.8379\n",
      "Epoch 2277/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 363.3868 - val_loss: 303.5275\n",
      "Epoch 2278/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 420.8484 - val_loss: 303.2344\n",
      "Epoch 2279/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 388.4637 - val_loss: 302.4969\n",
      "Epoch 2280/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 415.5968 - val_loss: 302.4916\n",
      "Epoch 2281/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 499.0565 - val_loss: 302.7303\n",
      "Epoch 2282/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 468.7446 - val_loss: 303.2457\n",
      "Epoch 2283/10000\n",
      "184/184 [==============================] - 0s 593us/step - loss: 458.7115 - val_loss: 303.6816\n",
      "Epoch 2284/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 365.6334 - val_loss: 303.6469\n",
      "Epoch 2285/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 464.0126 - val_loss: 303.4776\n",
      "Epoch 2286/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 428.9386 - val_loss: 296.8469\n",
      "Epoch 2287/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 379.6712 - val_loss: 292.5494\n",
      "Epoch 2288/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 532.7838 - val_loss: 291.6418\n",
      "Epoch 2289/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 430.9047 - val_loss: 291.7937\n",
      "Epoch 2290/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 524.9027 - val_loss: 290.2604\n",
      "Epoch 2291/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 406.1343 - val_loss: 290.1538\n",
      "Epoch 2292/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 452.8732 - val_loss: 289.8766\n",
      "Epoch 2293/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 648.8911 - val_loss: 290.0223\n",
      "Epoch 2294/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 459.9241 - val_loss: 289.4637\n",
      "Epoch 2295/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 390.2073 - val_loss: 287.6266\n",
      "Epoch 2296/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 399.1338 - val_loss: 287.5100\n",
      "Epoch 2297/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 494.2357 - val_loss: 287.4821\n",
      "Epoch 2298/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 407.1397 - val_loss: 287.6132\n",
      "Epoch 2299/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 375.6692 - val_loss: 287.8196\n",
      "Epoch 2300/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 404.2645 - val_loss: 287.9445\n",
      "\n",
      "Epoch 02300: loss improved from 487.19710 to 404.26445, saving model to C6007C.hdf5\n",
      "Epoch 2301/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 544.6807 - val_loss: 288.0365\n",
      "Epoch 2302/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 477.9087 - val_loss: 288.0881\n",
      "Epoch 2303/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 428.0225 - val_loss: 288.0636\n",
      "Epoch 2304/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 431.5481 - val_loss: 288.1141\n",
      "Epoch 2305/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 484.2358 - val_loss: 288.1656\n",
      "Epoch 2306/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 398.6005 - val_loss: 288.1764\n",
      "Epoch 2307/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 457.7066 - val_loss: 288.1353\n",
      "Epoch 2308/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 447.3280 - val_loss: 288.0664\n",
      "Epoch 2309/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 437.6777 - val_loss: 287.9770\n",
      "Epoch 2310/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 334.3509 - val_loss: 287.8261\n",
      "Epoch 2311/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 435.0004 - val_loss: 287.6657\n",
      "Epoch 2312/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 463.6143 - val_loss: 287.6269\n",
      "Epoch 2313/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 479.1821 - val_loss: 287.6682\n",
      "Epoch 2314/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 433.3589 - val_loss: 287.6695\n",
      "Epoch 2315/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 386.0563 - val_loss: 288.0159\n",
      "Epoch 2316/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 564.8558 - val_loss: 288.8976\n",
      "Epoch 2317/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 454.1142 - val_loss: 289.6186\n",
      "Epoch 2318/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 453.9384 - val_loss: 290.0774\n",
      "Epoch 2319/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 590.8364 - val_loss: 290.3162\n",
      "Epoch 2320/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 537.8275 - val_loss: 290.5080\n",
      "Epoch 2321/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 445.8662 - val_loss: 290.7978\n",
      "Epoch 2322/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 560us/step - loss: 469.8346 - val_loss: 291.1219\n",
      "Epoch 2323/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 455.7287 - val_loss: 291.3299\n",
      "Epoch 2324/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 500.9815 - val_loss: 291.4359\n",
      "Epoch 2325/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 505.7289 - val_loss: 291.4927\n",
      "Epoch 2326/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 416.9137 - val_loss: 291.5236\n",
      "Epoch 2327/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 472.2053 - val_loss: 291.4997\n",
      "Epoch 2328/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 473.4864 - val_loss: 291.4460\n",
      "Epoch 2329/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 484.9611 - val_loss: 291.3523\n",
      "Epoch 2330/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 440.8788 - val_loss: 291.2438\n",
      "Epoch 2331/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 412.7687 - val_loss: 291.1276\n",
      "Epoch 2332/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 436.9790 - val_loss: 291.0100\n",
      "Epoch 2333/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 451.0207 - val_loss: 290.8936\n",
      "Epoch 2334/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 420.5022 - val_loss: 290.7780\n",
      "Epoch 2335/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 315.5685 - val_loss: 290.6498\n",
      "Epoch 2336/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 436.0183 - val_loss: 290.5074\n",
      "Epoch 2337/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 462.8564 - val_loss: 290.3528\n",
      "Epoch 2338/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 500.7754 - val_loss: 290.2047\n",
      "Epoch 2339/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 426.0804 - val_loss: 290.0330\n",
      "Epoch 2340/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 411.9665 - val_loss: 289.8531\n",
      "Epoch 2341/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 438.0598 - val_loss: 289.6854\n",
      "Epoch 2342/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 469.9220 - val_loss: 289.5438\n",
      "Epoch 2343/10000\n",
      "184/184 [==============================] - 0s 497us/step - loss: 429.9189 - val_loss: 289.4011\n",
      "Epoch 2344/10000\n",
      "184/184 [==============================] - 0s 584us/step - loss: 460.5555 - val_loss: 289.2625\n",
      "Epoch 2345/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 406.0017 - val_loss: 289.1155\n",
      "Epoch 2346/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 363.2646 - val_loss: 288.9604\n",
      "Epoch 2347/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 455.4436 - val_loss: 288.8095\n",
      "Epoch 2348/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 420.1651 - val_loss: 288.6568\n",
      "Epoch 2349/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 431.6748 - val_loss: 288.5058\n",
      "Epoch 2350/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 313.9128 - val_loss: 288.3814\n",
      "Epoch 2351/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 322.5571 - val_loss: 288.2634\n",
      "Epoch 2352/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 342.9666 - val_loss: 288.1452\n",
      "Epoch 2353/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 489.2723 - val_loss: 288.0231\n",
      "Epoch 2354/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 366.0877 - val_loss: 287.8990\n",
      "Epoch 2355/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 408.3684 - val_loss: 287.7806\n",
      "Epoch 2356/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 402.7674 - val_loss: 287.6450\n",
      "Epoch 2357/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 411.2892 - val_loss: 287.5041\n",
      "Epoch 2358/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 433.4714 - val_loss: 287.3582\n",
      "Epoch 2359/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 377.0272 - val_loss: 287.2109\n",
      "Epoch 2360/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 417.4075 - val_loss: 287.0623\n",
      "Epoch 2361/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 440.0213 - val_loss: 286.9079\n",
      "Epoch 2362/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 323.3669 - val_loss: 286.7560\n",
      "Epoch 2363/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 530.7786 - val_loss: 286.5764\n",
      "Epoch 2364/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 371.9702 - val_loss: 286.3813\n",
      "Epoch 2365/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 665.0497 - val_loss: 286.1752\n",
      "Epoch 2366/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 589.7572 - val_loss: 285.9742\n",
      "Epoch 2367/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 375.5964 - val_loss: 285.7294\n",
      "Epoch 2368/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 484.0903 - val_loss: 285.5002\n",
      "Epoch 2369/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 504.6929 - val_loss: 285.3232\n",
      "Epoch 2370/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 348.9144 - val_loss: 285.1455\n",
      "Epoch 2371/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 345.3450 - val_loss: 284.9761\n",
      "Epoch 2372/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 373.2713 - val_loss: 284.8326\n",
      "Epoch 2373/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 498.2161 - val_loss: 284.7071\n",
      "Epoch 2374/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 424.9429 - val_loss: 284.5835\n",
      "Epoch 2375/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 401.0170 - val_loss: 284.4567\n",
      "Epoch 2376/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 377.5547 - val_loss: 284.3347\n",
      "Epoch 2377/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 439.6405 - val_loss: 284.2059\n",
      "Epoch 2378/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 519.4164 - val_loss: 283.9488\n",
      "Epoch 2379/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 483.7817 - val_loss: 283.1517\n",
      "Epoch 2380/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 370.9269 - val_loss: 282.3328\n",
      "Epoch 2381/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 400.9375 - val_loss: 282.7849\n",
      "Epoch 2382/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 509.2168 - val_loss: 282.6990\n",
      "Epoch 2383/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 318.5046 - val_loss: 283.0324\n",
      "Epoch 2384/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 360.7140 - val_loss: 283.1075\n",
      "Epoch 2385/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 510.5183 - val_loss: 283.0859\n",
      "Epoch 2386/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 440.8246 - val_loss: 283.0032\n",
      "Epoch 2387/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 439.6371 - val_loss: 282.8855\n",
      "Epoch 2388/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 370.5542 - val_loss: 282.7631\n",
      "Epoch 2389/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 391.6529 - val_loss: 282.6285\n",
      "Epoch 2390/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 375.9591 - val_loss: 282.4839\n",
      "Epoch 2391/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 460.3959 - val_loss: 282.3286\n",
      "Epoch 2392/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 424.7280 - val_loss: 282.1679\n",
      "Epoch 2393/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 489.2537 - val_loss: 282.0060\n",
      "Epoch 2394/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 428.4553 - val_loss: 281.8310\n",
      "Epoch 2395/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 554us/step - loss: 372.8897 - val_loss: 281.6534\n",
      "Epoch 2396/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 392.2964 - val_loss: 281.4812\n",
      "Epoch 2397/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 479.9789 - val_loss: 281.3082\n",
      "Epoch 2398/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 391.6333 - val_loss: 281.1472\n",
      "Epoch 2399/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 405.7781 - val_loss: 280.9857\n",
      "Epoch 2400/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 408.3220 - val_loss: 280.8229\n",
      "\n",
      "Epoch 02400: loss did not improve from 404.26445\n",
      "Epoch 2401/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 450.4337 - val_loss: 280.6579\n",
      "Epoch 2402/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 522.0169 - val_loss: 280.5127\n",
      "Epoch 2403/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 462.6392 - val_loss: 280.3670\n",
      "Epoch 2404/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 387.5592 - val_loss: 280.2160\n",
      "Epoch 2405/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 459.2955 - val_loss: 280.0387\n",
      "Epoch 2406/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 425.6220 - val_loss: 279.8521\n",
      "Epoch 2407/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 487.9723 - val_loss: 279.6743\n",
      "Epoch 2408/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 343.1660 - val_loss: 279.5052\n",
      "Epoch 2409/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 383.3009 - val_loss: 279.3419\n",
      "Epoch 2410/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 473.2733 - val_loss: 279.1814\n",
      "Epoch 2411/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 399.1982 - val_loss: 279.0273\n",
      "Epoch 2412/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 442.4085 - val_loss: 278.8734\n",
      "Epoch 2413/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 463.4715 - val_loss: 278.7177\n",
      "Epoch 2414/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 414.2025 - val_loss: 278.5649\n",
      "Epoch 2415/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 454.9622 - val_loss: 278.4113\n",
      "Epoch 2416/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 374.6592 - val_loss: 278.2658\n",
      "Epoch 2417/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 434.1646 - val_loss: 278.1256\n",
      "Epoch 2418/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 458.9442 - val_loss: 277.9784\n",
      "Epoch 2419/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 425.4336 - val_loss: 277.8233\n",
      "Epoch 2420/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 464.9268 - val_loss: 277.6604\n",
      "Epoch 2421/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 396.7641 - val_loss: 277.4988\n",
      "Epoch 2422/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 324.5626 - val_loss: 277.3492\n",
      "Epoch 2423/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 342.8528 - val_loss: 277.2032\n",
      "Epoch 2424/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 333.4763 - val_loss: 277.0803\n",
      "Epoch 2425/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 396.7476 - val_loss: 276.9825\n",
      "Epoch 2426/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 457.5068 - val_loss: 276.8798\n",
      "Epoch 2427/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 397.8216 - val_loss: 276.7570\n",
      "Epoch 2428/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 427.1759 - val_loss: 276.6113\n",
      "Epoch 2429/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 396.5671 - val_loss: 276.4566\n",
      "Epoch 2430/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 397.9413 - val_loss: 276.2965\n",
      "Epoch 2431/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 419.7523 - val_loss: 276.1360\n",
      "Epoch 2432/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 409.5914 - val_loss: 275.9763\n",
      "Epoch 2433/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 345.9791 - val_loss: 275.8234\n",
      "Epoch 2434/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 479.5069 - val_loss: 275.6778\n",
      "Epoch 2435/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 387.4612 - val_loss: 275.5318\n",
      "Epoch 2436/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 446.0105 - val_loss: 275.3875\n",
      "Epoch 2437/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 406.9877 - val_loss: 275.2402\n",
      "Epoch 2438/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 448.2478 - val_loss: 275.0815\n",
      "Epoch 2439/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 393.7279 - val_loss: 274.9207\n",
      "Epoch 2440/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 461.1704 - val_loss: 274.7617\n",
      "Epoch 2441/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 343.2035 - val_loss: 274.6101\n",
      "Epoch 2442/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 360.2540 - val_loss: 274.3260\n",
      "Epoch 2443/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 421.8138 - val_loss: 273.8246\n",
      "Epoch 2444/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 456.8494 - val_loss: 273.3600\n",
      "Epoch 2445/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 416.2050 - val_loss: 272.8752\n",
      "Epoch 2446/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 417.3561 - val_loss: 272.4145\n",
      "Epoch 2447/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 337.8190 - val_loss: 272.0426\n",
      "Epoch 2448/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 367.0819 - val_loss: 271.7488\n",
      "Epoch 2449/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 455.2338 - val_loss: 271.5089\n",
      "Epoch 2450/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 518.5847 - val_loss: 271.2920\n",
      "Epoch 2451/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 354.0590 - val_loss: 271.1020\n",
      "Epoch 2452/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 371.1676 - val_loss: 270.9541\n",
      "Epoch 2453/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 465.9508 - val_loss: 270.8446\n",
      "Epoch 2454/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 390.7356 - val_loss: 270.7413\n",
      "Epoch 2455/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 501.4711 - val_loss: 270.6480\n",
      "Epoch 2456/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 454.6520 - val_loss: 270.5467\n",
      "Epoch 2457/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 438.4757 - val_loss: 270.4038\n",
      "Epoch 2458/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 450.8605 - val_loss: 270.2247\n",
      "Epoch 2459/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 413.1773 - val_loss: 270.0980\n",
      "Epoch 2460/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 441.5537 - val_loss: 269.9552\n",
      "Epoch 2461/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 523.2812 - val_loss: 269.7547\n",
      "Epoch 2462/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 387.6481 - val_loss: 269.6008\n",
      "Epoch 2463/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 403.7469 - val_loss: 269.4376\n",
      "Epoch 2464/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 410.8054 - val_loss: 269.2688\n",
      "Epoch 2465/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 393.8412 - val_loss: 269.1059\n",
      "Epoch 2466/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 391.3457 - val_loss: 268.9529\n",
      "Epoch 2467/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 352.7771 - val_loss: 268.7994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2468/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 308.5282 - val_loss: 268.8471\n",
      "Epoch 2469/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 406.4969 - val_loss: 268.8393\n",
      "Epoch 2470/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 414.0140 - val_loss: 268.7696\n",
      "Epoch 2471/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 406.9548 - val_loss: 268.5811\n",
      "Epoch 2472/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 416.4009 - val_loss: 268.3122\n",
      "Epoch 2473/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 405.0971 - val_loss: 268.0183\n",
      "Epoch 2474/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 436.4653 - val_loss: 267.7137\n",
      "Epoch 2475/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 461.4317 - val_loss: 267.4240\n",
      "Epoch 2476/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 395.2299 - val_loss: 267.1600\n",
      "Epoch 2477/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 384.1676 - val_loss: 266.9168\n",
      "Epoch 2478/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 378.9945 - val_loss: 266.6896\n",
      "Epoch 2479/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 371.8337 - val_loss: 266.4754\n",
      "Epoch 2480/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 477.0869 - val_loss: 266.4845\n",
      "Epoch 2481/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 494.1070 - val_loss: 266.6430\n",
      "Epoch 2482/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 361.5476 - val_loss: 266.7400\n",
      "Epoch 2483/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 343.4313 - val_loss: 266.7966\n",
      "Epoch 2484/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 391.0749 - val_loss: 266.7936\n",
      "Epoch 2485/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 422.1607 - val_loss: 266.7450\n",
      "Epoch 2486/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 381.5534 - val_loss: 266.6780\n",
      "Epoch 2487/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 483.5302 - val_loss: 266.5897\n",
      "Epoch 2488/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 367.7860 - val_loss: 266.5135\n",
      "Epoch 2489/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 495.1405 - val_loss: 266.4409\n",
      "Epoch 2490/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 476.8015 - val_loss: 266.3463\n",
      "Epoch 2491/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 383.0928 - val_loss: 266.2363\n",
      "Epoch 2492/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 341.2174 - val_loss: 266.1096\n",
      "Epoch 2493/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 416.4329 - val_loss: 265.9826\n",
      "Epoch 2494/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 391.5028 - val_loss: 265.8466\n",
      "Epoch 2495/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 504.8136 - val_loss: 265.6982\n",
      "Epoch 2496/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 477.2167 - val_loss: 265.5540\n",
      "Epoch 2497/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 517.4814 - val_loss: 265.3921\n",
      "Epoch 2498/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 344.9436 - val_loss: 265.2401\n",
      "Epoch 2499/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 463.7284 - val_loss: 265.0730\n",
      "Epoch 2500/10000\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 430.9130 - val_loss: 264.9669\n",
      "\n",
      "Epoch 02500: loss did not improve from 404.26445\n",
      "Epoch 2501/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 379.5872 - val_loss: 264.8579\n",
      "Epoch 2502/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 404.3416 - val_loss: 264.7257\n",
      "Epoch 2503/10000\n",
      "184/184 [==============================] - 0s 783us/step - loss: 426.7494 - val_loss: 264.5948\n",
      "Epoch 2504/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 428.2925 - val_loss: 264.4717\n",
      "Epoch 2505/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 400.8221 - val_loss: 264.3157\n",
      "Epoch 2506/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 457.2837 - val_loss: 264.1327\n",
      "Epoch 2507/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 669.5435 - val_loss: 263.9157\n",
      "Epoch 2508/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 334.4445 - val_loss: 263.7127\n",
      "Epoch 2509/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 374.2509 - val_loss: 263.5276\n",
      "Epoch 2510/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 376.0689 - val_loss: 263.3898\n",
      "Epoch 2511/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 402.2392 - val_loss: 263.3213\n",
      "Epoch 2512/10000\n",
      "184/184 [==============================] - 0s 577us/step - loss: 417.2042 - val_loss: 263.2322\n",
      "Epoch 2513/10000\n",
      "184/184 [==============================] - 0s 799us/step - loss: 464.9354 - val_loss: 263.1292\n",
      "Epoch 2514/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 376.3146 - val_loss: 264.0800\n",
      "Epoch 2515/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 433.5467 - val_loss: 263.7667\n",
      "Epoch 2516/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 379.3218 - val_loss: 263.4942\n",
      "Epoch 2517/10000\n",
      "184/184 [==============================] - 0s 929us/step - loss: 410.1765 - val_loss: 262.9779\n",
      "Epoch 2518/10000\n",
      "184/184 [==============================] - 0s 783us/step - loss: 301.2488 - val_loss: 263.9759\n",
      "Epoch 2519/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 362.6999 - val_loss: 264.2899\n",
      "Epoch 2520/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 339.8483 - val_loss: 263.1123\n",
      "Epoch 2521/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 346.2094 - val_loss: 262.9474\n",
      "Epoch 2522/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 366.1825 - val_loss: 262.9664\n",
      "Epoch 2523/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 380.1086 - val_loss: 263.1487\n",
      "Epoch 2524/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 378.1805 - val_loss: 263.2447\n",
      "Epoch 2525/10000\n",
      "184/184 [==============================] - 0s 864us/step - loss: 392.8908 - val_loss: 263.2796\n",
      "Epoch 2526/10000\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 414.5568 - val_loss: 263.2318\n",
      "Epoch 2527/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 462.3510 - val_loss: 263.1223\n",
      "Epoch 2528/10000\n",
      "184/184 [==============================] - 0s 929us/step - loss: 383.0948 - val_loss: 262.9969\n",
      "Epoch 2529/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 442.8870 - val_loss: 262.8628\n",
      "Epoch 2530/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 412.7954 - val_loss: 262.7122\n",
      "Epoch 2531/10000\n",
      "184/184 [==============================] - 0s 854us/step - loss: 420.7576 - val_loss: 262.5600\n",
      "Epoch 2532/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 369.6517 - val_loss: 262.4062\n",
      "Epoch 2533/10000\n",
      "184/184 [==============================] - 0s 935us/step - loss: 365.8432 - val_loss: 262.2573\n",
      "Epoch 2534/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 433.2655 - val_loss: 262.1124\n",
      "Epoch 2535/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 347.6263 - val_loss: 261.9698\n",
      "Epoch 2536/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 442.7389 - val_loss: 261.8232\n",
      "Epoch 2537/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 413.7883 - val_loss: 261.6713\n",
      "Epoch 2538/10000\n",
      "184/184 [==============================] - 0s 848us/step - loss: 464.7459 - val_loss: 261.5112\n",
      "Epoch 2539/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 354.7514 - val_loss: 261.3547\n",
      "Epoch 2540/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 322.6564 - val_loss: 261.2077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2541/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 408.5924 - val_loss: 261.0652\n",
      "Epoch 2542/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 328.3402 - val_loss: 260.9245\n",
      "Epoch 2543/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 451.3716 - val_loss: 260.7838\n",
      "Epoch 2544/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 293.0844 - val_loss: 260.6306\n",
      "Epoch 2545/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 418.9830 - val_loss: 260.4656\n",
      "Epoch 2546/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 366.6725 - val_loss: 260.3145\n",
      "Epoch 2547/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 383.3724 - val_loss: 260.1664\n",
      "Epoch 2548/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 448.0237 - val_loss: 260.0214\n",
      "Epoch 2549/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 421.1682 - val_loss: 259.8841\n",
      "Epoch 2550/10000\n",
      "184/184 [==============================] - 0s 492us/step - loss: 361.9251 - val_loss: 259.7527\n",
      "Epoch 2551/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 384.1863 - val_loss: 259.6216\n",
      "Epoch 2552/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 433.0502 - val_loss: 259.4926\n",
      "Epoch 2553/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 416.7025 - val_loss: 259.3553\n",
      "Epoch 2554/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 462.6873 - val_loss: 259.2023\n",
      "Epoch 2555/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 459.2885 - val_loss: 259.0357\n",
      "Epoch 2556/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 356.5037 - val_loss: 258.8680\n",
      "Epoch 2557/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 341.6040 - val_loss: 258.7090\n",
      "Epoch 2558/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 337.1447 - val_loss: 258.5569\n",
      "Epoch 2559/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 357.7460 - val_loss: 258.4078\n",
      "Epoch 2560/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 384.0130 - val_loss: 258.2634\n",
      "Epoch 2561/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 395.4477 - val_loss: 258.1162\n",
      "Epoch 2562/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 595.0523 - val_loss: 257.9636\n",
      "Epoch 2563/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 413.5679 - val_loss: 257.8119\n",
      "Epoch 2564/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 365.5281 - val_loss: 257.6544\n",
      "Epoch 2565/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 399.4720 - val_loss: 257.4871\n",
      "Epoch 2566/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 440.3159 - val_loss: 257.3170\n",
      "Epoch 2567/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 301.2567 - val_loss: 257.1594\n",
      "Epoch 2568/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 283.0779 - val_loss: 257.0121\n",
      "Epoch 2569/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 415.4011 - val_loss: 256.8658\n",
      "Epoch 2570/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 453.3159 - val_loss: 256.7178\n",
      "Epoch 2571/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 468.2053 - val_loss: 256.5632\n",
      "Epoch 2572/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 284.1865 - val_loss: 256.4185\n",
      "Epoch 2573/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 392.0389 - val_loss: 256.2794\n",
      "Epoch 2574/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 386.3638 - val_loss: 255.7685\n",
      "Epoch 2575/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 364.4178 - val_loss: 254.9184\n",
      "Epoch 2576/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 391.1970 - val_loss: 255.0647\n",
      "Epoch 2577/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 348.8786 - val_loss: 253.7170\n",
      "Epoch 2578/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 570.7870 - val_loss: 252.7466\n",
      "Epoch 2579/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 306.8605 - val_loss: 252.2581\n",
      "Epoch 2580/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 357.4759 - val_loss: 251.9341\n",
      "Epoch 2581/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 329.6363 - val_loss: 251.6290\n",
      "Epoch 2582/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 313.4816 - val_loss: 251.3703\n",
      "Epoch 2583/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 423.6165 - val_loss: 251.1469\n",
      "Epoch 2584/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 382.7783 - val_loss: 250.9534\n",
      "Epoch 2585/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 401.1067 - val_loss: 250.7912\n",
      "Epoch 2586/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 475.3240 - val_loss: 250.6391\n",
      "Epoch 2587/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 361.7473 - val_loss: 250.4938\n",
      "Epoch 2588/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 441.3687 - val_loss: 250.3531\n",
      "Epoch 2589/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 515.1688 - val_loss: 250.2160\n",
      "Epoch 2590/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 431.1462 - val_loss: 250.0607\n",
      "Epoch 2591/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 381.0230 - val_loss: 249.9215\n",
      "Epoch 2592/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 420.8115 - val_loss: 249.7861\n",
      "Epoch 2593/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 306.0203 - val_loss: 249.6571\n",
      "Epoch 2594/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 279.4573 - val_loss: 249.5084\n",
      "Epoch 2595/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 382.5283 - val_loss: 249.3603\n",
      "Epoch 2596/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 423.2518 - val_loss: 249.2142\n",
      "Epoch 2597/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 305.2213 - val_loss: 249.0690\n",
      "Epoch 2598/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 459.3312 - val_loss: 248.9218\n",
      "Epoch 2599/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 354.2666 - val_loss: 248.7718\n",
      "Epoch 2600/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 408.1335 - val_loss: 248.6220\n",
      "\n",
      "Epoch 02600: loss did not improve from 404.26445\n",
      "Epoch 2601/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 341.3454 - val_loss: 248.4726\n",
      "Epoch 2602/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 403.4597 - val_loss: 248.3091\n",
      "Epoch 2603/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 442.4491 - val_loss: 248.1478\n",
      "Epoch 2604/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 311.4158 - val_loss: 247.9897\n",
      "Epoch 2605/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 353.7577 - val_loss: 247.8397\n",
      "Epoch 2606/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 349.2314 - val_loss: 247.6899\n",
      "Epoch 2607/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 391.5771 - val_loss: 247.2072\n",
      "Epoch 2608/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 341.4537 - val_loss: 246.8257\n",
      "Epoch 2609/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 395.6689 - val_loss: 246.7445\n",
      "Epoch 2610/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 389.6851 - val_loss: 246.0406\n",
      "Epoch 2611/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 396.6812 - val_loss: 245.7519\n",
      "Epoch 2612/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 293.1398 - val_loss: 245.7018\n",
      "Epoch 2613/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 527us/step - loss: 338.5234 - val_loss: 245.6463\n",
      "Epoch 2614/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 325.0506 - val_loss: 245.5756\n",
      "Epoch 2615/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 298.7901 - val_loss: 245.0411\n",
      "Epoch 2616/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 319.0894 - val_loss: 244.4796\n",
      "Epoch 2617/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 319.8686 - val_loss: 244.5503\n",
      "Epoch 2618/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 351.3978 - val_loss: 244.3541\n",
      "Epoch 2619/10000\n",
      "184/184 [==============================] - 0s 581us/step - loss: 347.4756 - val_loss: 243.9557\n",
      "Epoch 2620/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 379.8036 - val_loss: 243.8571\n",
      "Epoch 2621/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 327.7254 - val_loss: 243.6886\n",
      "Epoch 2622/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 334.8638 - val_loss: 243.5059\n",
      "Epoch 2623/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 337.2944 - val_loss: 243.3324\n",
      "Epoch 2624/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 364.3857 - val_loss: 243.1561\n",
      "Epoch 2625/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 383.0238 - val_loss: 242.9836\n",
      "Epoch 2626/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 347.0061 - val_loss: 242.8127\n",
      "Epoch 2627/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 338.1189 - val_loss: 242.6460\n",
      "Epoch 2628/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 424.7196 - val_loss: 242.4346\n",
      "Epoch 2629/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 371.7712 - val_loss: 242.2388\n",
      "Epoch 2630/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 376.3077 - val_loss: 241.4410\n",
      "Epoch 2631/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 392.2623 - val_loss: 240.3716\n",
      "Epoch 2632/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 323.8764 - val_loss: 240.3292\n",
      "Epoch 2633/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 379.3885 - val_loss: 240.1167\n",
      "Epoch 2634/10000\n",
      "184/184 [==============================] - 0s 517us/step - loss: 307.4172 - val_loss: 239.6613\n",
      "Epoch 2635/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 398.2721 - val_loss: 239.4040\n",
      "Epoch 2636/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 245.6639 - val_loss: 239.1203\n",
      "Epoch 2637/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 281.5341 - val_loss: 238.8199\n",
      "Epoch 2638/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 271.8041 - val_loss: 238.5333\n",
      "Epoch 2639/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 474.0056 - val_loss: 238.2543\n",
      "Epoch 2640/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 300.3793 - val_loss: 238.0073\n",
      "Epoch 2641/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 335.5881 - val_loss: 237.7932\n",
      "Epoch 2642/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 342.1405 - val_loss: 237.5982\n",
      "Epoch 2643/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 391.6060 - val_loss: 237.4214\n",
      "Epoch 2644/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 326.0324 - val_loss: 237.2540\n",
      "Epoch 2645/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 375.6802 - val_loss: 237.0998\n",
      "Epoch 2646/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 269.2627 - val_loss: 236.9479\n",
      "Epoch 2647/10000\n",
      "184/184 [==============================] - 0s 595us/step - loss: 448.3754 - val_loss: 236.7994\n",
      "Epoch 2648/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 342.9311 - val_loss: 236.6353\n",
      "Epoch 2649/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 449.8048 - val_loss: 236.4736\n",
      "Epoch 2650/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 408.2413 - val_loss: 236.3189\n",
      "Epoch 2651/10000\n",
      "184/184 [==============================] - 0s 492us/step - loss: 358.4118 - val_loss: 236.1644\n",
      "Epoch 2652/10000\n",
      "184/184 [==============================] - 0s 628us/step - loss: 378.3689 - val_loss: 236.0169\n",
      "Epoch 2653/10000\n",
      "184/184 [==============================] - 0s 573us/step - loss: 379.2836 - val_loss: 235.8698\n",
      "Epoch 2654/10000\n",
      "184/184 [==============================] - 0s 660us/step - loss: 364.9640 - val_loss: 235.7291\n",
      "Epoch 2655/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 424.7582 - val_loss: 235.5902\n",
      "Epoch 2656/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 310.6089 - val_loss: 235.4525\n",
      "Epoch 2657/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 377.6509 - val_loss: 235.3396\n",
      "Epoch 2658/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 406.6784 - val_loss: 235.2165\n",
      "Epoch 2659/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 342.6013 - val_loss: 235.0655\n",
      "Epoch 2660/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 338.3290 - val_loss: 234.9207\n",
      "Epoch 2661/10000\n",
      "184/184 [==============================] - 0s 864us/step - loss: 357.7682 - val_loss: 234.7631\n",
      "Epoch 2662/10000\n",
      "184/184 [==============================] - 0s 951us/step - loss: 434.4160 - val_loss: 234.6103\n",
      "Epoch 2663/10000\n",
      "184/184 [==============================] - 0s 995us/step - loss: 301.3143 - val_loss: 234.4646\n",
      "Epoch 2664/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 441.5344 - val_loss: 234.3243\n",
      "Epoch 2665/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 352.1431 - val_loss: 234.1890\n",
      "Epoch 2666/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 350.0853 - val_loss: 234.0574\n",
      "Epoch 2667/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 344.6794 - val_loss: 233.9266\n",
      "Epoch 2668/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 362.5321 - val_loss: 233.7981\n",
      "Epoch 2669/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 391.2075 - val_loss: 233.6767\n",
      "Epoch 2670/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 374.9608 - val_loss: 233.5525\n",
      "Epoch 2671/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 406.8615 - val_loss: 233.4000\n",
      "Epoch 2672/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 358.5843 - val_loss: 233.2532\n",
      "Epoch 2673/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 343.8739 - val_loss: 233.0929\n",
      "Epoch 2674/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 351.1432 - val_loss: 232.9290\n",
      "Epoch 2675/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 337.1087 - val_loss: 232.7775\n",
      "Epoch 2676/10000\n",
      "184/184 [==============================] - 0s 870us/step - loss: 434.7165 - val_loss: 232.6032\n",
      "Epoch 2677/10000\n",
      "184/184 [==============================] - 0s 848us/step - loss: 332.1318 - val_loss: 232.4333\n",
      "Epoch 2678/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 341.7664 - val_loss: 232.2745\n",
      "Epoch 2679/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 283.1973 - val_loss: 232.1088\n",
      "Epoch 2680/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 396.4825 - val_loss: 231.9345\n",
      "Epoch 2681/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 303.4953 - val_loss: 231.7671\n",
      "Epoch 2682/10000\n",
      "184/184 [==============================] - 0s 940us/step - loss: 319.5489 - val_loss: 231.6152\n",
      "Epoch 2683/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 326.6178 - val_loss: 231.4681\n",
      "Epoch 2684/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 402.6928 - val_loss: 231.3248\n",
      "Epoch 2685/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 342.9398 - val_loss: 231.1847\n",
      "Epoch 2686/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 473us/step - loss: 348.8884 - val_loss: 231.0479\n",
      "Epoch 2687/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 338.1182 - val_loss: 230.9280\n",
      "Epoch 2688/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 354.3013 - val_loss: 230.8201\n",
      "Epoch 2689/10000\n",
      "184/184 [==============================] - 0s 946us/step - loss: 302.2409 - val_loss: 230.7083\n",
      "Epoch 2690/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 419.9786 - val_loss: 230.4374\n",
      "Epoch 2691/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 384.8536 - val_loss: 230.0568\n",
      "Epoch 2692/10000\n",
      "184/184 [==============================] - 0s 783us/step - loss: 299.1817 - val_loss: 229.7190\n",
      "Epoch 2693/10000\n",
      "184/184 [==============================] - 0s 750us/step - loss: 426.8499 - val_loss: 229.3805\n",
      "Epoch 2694/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 374.9004 - val_loss: 229.0473\n",
      "Epoch 2695/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 407.4833 - val_loss: 228.7155\n",
      "Epoch 2696/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 307.6873 - val_loss: 228.4288\n",
      "Epoch 2697/10000\n",
      "184/184 [==============================] - 0s 799us/step - loss: 352.8049 - val_loss: 228.1815\n",
      "Epoch 2698/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 271.7492 - val_loss: 227.9654\n",
      "Epoch 2699/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 463.2662 - val_loss: 227.7300\n",
      "Epoch 2700/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 319.4746 - val_loss: 227.4955\n",
      "\n",
      "Epoch 02700: loss improved from 404.26445 to 319.47460, saving model to C6007C.hdf5\n",
      "Epoch 2701/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 378.3421 - val_loss: 227.2746\n",
      "Epoch 2702/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 324.4339 - val_loss: 227.0759\n",
      "Epoch 2703/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 323.0448 - val_loss: 226.8861\n",
      "Epoch 2704/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 414.4884 - val_loss: 226.7128\n",
      "Epoch 2705/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 320.3419 - val_loss: 226.5543\n",
      "Epoch 2706/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 406.4639 - val_loss: 226.4008\n",
      "Epoch 2707/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 343.5635 - val_loss: 226.2467\n",
      "Epoch 2708/10000\n",
      "184/184 [==============================] - 0s 761us/step - loss: 341.6054 - val_loss: 226.1041\n",
      "Epoch 2709/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 451.6332 - val_loss: 225.9567\n",
      "Epoch 2710/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 289.2801 - val_loss: 225.8071\n",
      "Epoch 2711/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 426.6110 - val_loss: 225.6385\n",
      "Epoch 2712/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 295.0039 - val_loss: 225.4821\n",
      "Epoch 2713/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 335.6692 - val_loss: 225.3269\n",
      "Epoch 2714/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 461.8839 - val_loss: 225.1759\n",
      "Epoch 2715/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 434.3900 - val_loss: 225.0162\n",
      "Epoch 2716/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 335.2557 - val_loss: 224.8676\n",
      "Epoch 2717/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 382.2946 - val_loss: 224.7312\n",
      "Epoch 2718/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 298.1707 - val_loss: 224.6000\n",
      "Epoch 2719/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 415.4619 - val_loss: 224.4728\n",
      "Epoch 2720/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 348.4432 - val_loss: 224.3607\n",
      "Epoch 2721/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 414.2394 - val_loss: 224.2415\n",
      "Epoch 2722/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 473.9356 - val_loss: 224.1194\n",
      "Epoch 2723/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 438.6533 - val_loss: 223.9922\n",
      "Epoch 2724/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 417.0199 - val_loss: 223.8495\n",
      "Epoch 2725/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 322.4166 - val_loss: 223.7014\n",
      "Epoch 2726/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 328.5295 - val_loss: 223.5515\n",
      "Epoch 2727/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 419.1451 - val_loss: 223.3504\n",
      "Epoch 2728/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 402.2385 - val_loss: 223.1602\n",
      "Epoch 2729/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 384.5036 - val_loss: 222.9677\n",
      "Epoch 2730/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 344.8555 - val_loss: 222.7821\n",
      "Epoch 2731/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 293.2636 - val_loss: 222.5871\n",
      "Epoch 2732/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 301.8653 - val_loss: 222.3888\n",
      "Epoch 2733/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 349.3097 - val_loss: 222.1966\n",
      "Epoch 2734/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 356.3642 - val_loss: 221.9158\n",
      "Epoch 2735/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 563.4024 - val_loss: 221.5803\n",
      "Epoch 2736/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 363.4372 - val_loss: 221.2962\n",
      "Epoch 2737/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 317.2160 - val_loss: 221.0452\n",
      "Epoch 2738/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 256.5779 - val_loss: 220.8167\n",
      "Epoch 2739/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 269.7449 - val_loss: 220.6134\n",
      "Epoch 2740/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 442.5363 - val_loss: 220.4215\n",
      "Epoch 2741/10000\n",
      "184/184 [==============================] - 0s 772us/step - loss: 300.1714 - val_loss: 220.2414\n",
      "Epoch 2742/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 385.0461 - val_loss: 220.0742\n",
      "Epoch 2743/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 383.5954 - val_loss: 219.8960\n",
      "Epoch 2744/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 319.7811 - val_loss: 219.7425\n",
      "Epoch 2745/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 320.1815 - val_loss: 219.5993\n",
      "Epoch 2746/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 415.2445 - val_loss: 219.4506\n",
      "Epoch 2747/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 376.8522 - val_loss: 219.2296\n",
      "Epoch 2748/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 342.0256 - val_loss: 218.9874\n",
      "Epoch 2749/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 356.5664 - val_loss: 218.7901\n",
      "Epoch 2750/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 385.0457 - val_loss: 218.6194\n",
      "Epoch 2751/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 323.6933 - val_loss: 218.4718\n",
      "Epoch 2752/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 380.0040 - val_loss: 218.3191\n",
      "Epoch 2753/10000\n",
      "184/184 [==============================] - 0s 514us/step - loss: 358.6391 - val_loss: 218.1665\n",
      "Epoch 2754/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 312.9426 - val_loss: 218.0196\n",
      "Epoch 2755/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 318.2556 - val_loss: 217.8806\n",
      "Epoch 2756/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 406.3389 - val_loss: 217.7462\n",
      "Epoch 2757/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 389.0297 - val_loss: 217.6091\n",
      "Epoch 2758/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 511us/step - loss: 314.6888 - val_loss: 217.4817\n",
      "Epoch 2759/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 309.9485 - val_loss: 217.3543\n",
      "Epoch 2760/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 370.9096 - val_loss: 217.2206\n",
      "Epoch 2761/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 372.8115 - val_loss: 217.0910\n",
      "Epoch 2762/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 348.8021 - val_loss: 216.9602\n",
      "Epoch 2763/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 352.5239 - val_loss: 216.8308\n",
      "Epoch 2764/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 448.9119 - val_loss: 216.6921\n",
      "Epoch 2765/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 298.0053 - val_loss: 216.5546\n",
      "Epoch 2766/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 336.7987 - val_loss: 216.4305\n",
      "Epoch 2767/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 266.0753 - val_loss: 216.2984\n",
      "Epoch 2768/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 267.5112 - val_loss: 216.1755\n",
      "Epoch 2769/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 321.0338 - val_loss: 216.0530\n",
      "Epoch 2770/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 336.3817 - val_loss: 215.9285\n",
      "Epoch 2771/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 412.8552 - val_loss: 215.7944\n",
      "Epoch 2772/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 377.8062 - val_loss: 215.6565\n",
      "Epoch 2773/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 365.9531 - val_loss: 215.5182\n",
      "Epoch 2774/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 366.6057 - val_loss: 215.3841\n",
      "Epoch 2775/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 368.4027 - val_loss: 215.2015\n",
      "Epoch 2776/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 448.2672 - val_loss: 214.9941\n",
      "Epoch 2777/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 480.7043 - val_loss: 214.7952\n",
      "Epoch 2778/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 487.1840 - val_loss: 214.6039\n",
      "Epoch 2779/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 353.5467 - val_loss: 214.4263\n",
      "Epoch 2780/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 277.7988 - val_loss: 214.2622\n",
      "Epoch 2781/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 350.0467 - val_loss: 214.1032\n",
      "Epoch 2782/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 445.2821 - val_loss: 213.9468\n",
      "Epoch 2783/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 336.5244 - val_loss: 213.7974\n",
      "Epoch 2784/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 432.3899 - val_loss: 213.6512\n",
      "Epoch 2785/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 329.8450 - val_loss: 213.5111\n",
      "Epoch 2786/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 491.5417 - val_loss: 213.3780\n",
      "Epoch 2787/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 357.3594 - val_loss: 213.2475\n",
      "Epoch 2788/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 341.9997 - val_loss: 213.1182\n",
      "Epoch 2789/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 309.1822 - val_loss: 212.9916\n",
      "Epoch 2790/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 442.8873 - val_loss: 212.8592\n",
      "Epoch 2791/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 270.2602 - val_loss: 212.7340\n",
      "Epoch 2792/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 352.0848 - val_loss: 212.6126\n",
      "Epoch 2793/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 381.9138 - val_loss: 212.5076\n",
      "Epoch 2794/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 384.2508 - val_loss: 212.4261\n",
      "Epoch 2795/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 291.1003 - val_loss: 212.3421\n",
      "Epoch 2796/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 392.0218 - val_loss: 212.2713\n",
      "Epoch 2797/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 380.6379 - val_loss: 212.1964\n",
      "Epoch 2798/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 372.8136 - val_loss: 212.1137\n",
      "Epoch 2799/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 284.8020 - val_loss: 212.0257\n",
      "Epoch 2800/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 360.0110 - val_loss: 211.9334\n",
      "\n",
      "Epoch 02800: loss did not improve from 319.47460\n",
      "Epoch 2801/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 381.8249 - val_loss: 211.9356\n",
      "Epoch 2802/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 312.3953 - val_loss: 211.7511\n",
      "Epoch 2803/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 390.4280 - val_loss: 211.5256\n",
      "Epoch 2804/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 369.2856 - val_loss: 211.3692\n",
      "Epoch 2805/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 391.2237 - val_loss: 211.2908\n",
      "Epoch 2806/10000\n",
      "184/184 [==============================] - 0s 842us/step - loss: 361.3296 - val_loss: 211.3663\n",
      "Epoch 2807/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 303.9960 - val_loss: 211.4456\n",
      "Epoch 2808/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 357.2609 - val_loss: 211.4619\n",
      "Epoch 2809/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 282.0436 - val_loss: 211.4335\n",
      "Epoch 2810/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 297.3561 - val_loss: 211.3945\n",
      "Epoch 2811/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 356.1337 - val_loss: 211.3101\n",
      "Epoch 2812/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 337.0598 - val_loss: 211.2063\n",
      "Epoch 2813/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 334.2340 - val_loss: 211.1005\n",
      "Epoch 2814/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 341.4701 - val_loss: 210.9917\n",
      "Epoch 2815/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 352.9110 - val_loss: 210.8737\n",
      "Epoch 2816/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 303.1378 - val_loss: 210.7480\n",
      "Epoch 2817/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 277.3211 - val_loss: 210.6286\n",
      "Epoch 2818/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 311.6782 - val_loss: 210.5085\n",
      "Epoch 2819/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 444.2285 - val_loss: 210.3904\n",
      "Epoch 2820/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 336.0628 - val_loss: 210.2504\n",
      "Epoch 2821/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 310.9875 - val_loss: 210.1340\n",
      "Epoch 2822/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 365.2678 - val_loss: 210.0118\n",
      "Epoch 2823/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 444.0610 - val_loss: 209.8807\n",
      "Epoch 2824/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 381.4834 - val_loss: 209.7620\n",
      "Epoch 2825/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 345.1674 - val_loss: 209.6295\n",
      "Epoch 2826/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 390.2812 - val_loss: 209.5035\n",
      "Epoch 2827/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 315.8189 - val_loss: 209.3654\n",
      "Epoch 2828/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 341.8283 - val_loss: 209.2220\n",
      "Epoch 2829/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 340.1284 - val_loss: 209.0733\n",
      "Epoch 2830/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 297.3473 - val_loss: 208.9310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2831/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 331.8348 - val_loss: 208.7844\n",
      "Epoch 2832/10000\n",
      "184/184 [==============================] - 0s 755us/step - loss: 302.0088 - val_loss: 208.6258\n",
      "Epoch 2833/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 287.1467 - val_loss: 208.4882\n",
      "Epoch 2834/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 310.7104 - val_loss: 208.3526\n",
      "Epoch 2835/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 321.9314 - val_loss: 208.2746\n",
      "Epoch 2836/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 319.2756 - val_loss: 207.8848\n",
      "Epoch 2837/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 312.1434 - val_loss: 207.5470\n",
      "Epoch 2838/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 371.2943 - val_loss: 207.2567\n",
      "Epoch 2839/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 337.4662 - val_loss: 206.9991\n",
      "Epoch 2840/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 317.1688 - val_loss: 206.7891\n",
      "Epoch 2841/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 365.4201 - val_loss: 206.6140\n",
      "Epoch 2842/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 346.5457 - val_loss: 206.4457\n",
      "Epoch 2843/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 332.6236 - val_loss: 206.2894\n",
      "Epoch 2844/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 353.0695 - val_loss: 206.1394\n",
      "Epoch 2845/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 295.4761 - val_loss: 205.9953\n",
      "Epoch 2846/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 419.3346 - val_loss: 205.8524\n",
      "Epoch 2847/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 344.1326 - val_loss: 205.7091\n",
      "Epoch 2848/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 346.1177 - val_loss: 205.6110\n",
      "Epoch 2849/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 319.8650 - val_loss: 205.5067\n",
      "Epoch 2850/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 406.8106 - val_loss: 205.3995\n",
      "Epoch 2851/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 331.2435 - val_loss: 205.2394\n",
      "Epoch 2852/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 330.7916 - val_loss: 205.0773\n",
      "Epoch 2853/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 337.3906 - val_loss: 204.9201\n",
      "Epoch 2854/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 371.3781 - val_loss: 204.7688\n",
      "Epoch 2855/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 320.9717 - val_loss: 204.6391\n",
      "Epoch 2856/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 343.0726 - val_loss: 204.5202\n",
      "Epoch 2857/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 292.1546 - val_loss: 204.4026\n",
      "Epoch 2858/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 342.4597 - val_loss: 203.8998\n",
      "Epoch 2859/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 401.7722 - val_loss: 203.5131\n",
      "Epoch 2860/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 327.1645 - val_loss: 203.1675\n",
      "Epoch 2861/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 309.8123 - val_loss: 202.9154\n",
      "Epoch 2862/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 331.7742 - val_loss: 202.7261\n",
      "Epoch 2863/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 287.8215 - val_loss: 202.6664\n",
      "Epoch 2864/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 315.5470 - val_loss: 202.6416\n",
      "Epoch 2865/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 314.8351 - val_loss: 202.6090\n",
      "Epoch 2866/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 344.7126 - val_loss: 202.5578\n",
      "Epoch 2867/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 433.8740 - val_loss: 202.5034\n",
      "Epoch 2868/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 378.0640 - val_loss: 202.4408\n",
      "Epoch 2869/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 387.5335 - val_loss: 202.3648\n",
      "Epoch 2870/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 350.5403 - val_loss: 202.2752\n",
      "Epoch 2871/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 290.3757 - val_loss: 202.3221\n",
      "Epoch 2872/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 360.0213 - val_loss: 202.3712\n",
      "Epoch 2873/10000\n",
      "184/184 [==============================] - 0s 633us/step - loss: 319.6536 - val_loss: 202.3386\n",
      "Epoch 2874/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 289.3262 - val_loss: 202.2875\n",
      "Epoch 2875/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 366.4417 - val_loss: 202.2333\n",
      "Epoch 2876/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 293.5987 - val_loss: 202.1872\n",
      "Epoch 2877/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 334.8965 - val_loss: 202.1293\n",
      "Epoch 2878/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 415.3191 - val_loss: 202.0580\n",
      "Epoch 2879/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 342.8756 - val_loss: 201.9735\n",
      "Epoch 2880/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 386.1056 - val_loss: 201.8665\n",
      "Epoch 2881/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 374.1679 - val_loss: 201.7392\n",
      "Epoch 2882/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 340.6741 - val_loss: 201.6132\n",
      "Epoch 2883/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 437.0264 - val_loss: 201.4879\n",
      "Epoch 2884/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 324.5721 - val_loss: 201.3636\n",
      "Epoch 2885/10000\n",
      "184/184 [==============================] - 0s 595us/step - loss: 308.8856 - val_loss: 201.2412\n",
      "Epoch 2886/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 366.4653 - val_loss: 201.1159\n",
      "Epoch 2887/10000\n",
      "184/184 [==============================] - 0s 579us/step - loss: 305.9211 - val_loss: 200.9813\n",
      "Epoch 2888/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 393.5242 - val_loss: 200.8681\n",
      "Epoch 2889/10000\n",
      "184/184 [==============================] - 0s 805us/step - loss: 309.6776 - val_loss: 200.7764\n",
      "Epoch 2890/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 351.2765 - val_loss: 200.6841\n",
      "Epoch 2891/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 412.8337 - val_loss: 200.5774\n",
      "Epoch 2892/10000\n",
      "184/184 [==============================] - 0s 959us/step - loss: 322.4986 - val_loss: 200.4554\n",
      "Epoch 2893/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 342.9939 - val_loss: 200.3316\n",
      "Epoch 2894/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 331.4770 - val_loss: 200.2235\n",
      "Epoch 2895/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 267.1911 - val_loss: 200.1059\n",
      "Epoch 2896/10000\n",
      "184/184 [==============================] - 0s 978us/step - loss: 283.8367 - val_loss: 200.0030\n",
      "Epoch 2897/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 321.2409 - val_loss: 199.9078\n",
      "Epoch 2898/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 467.4268 - val_loss: 199.8081\n",
      "Epoch 2899/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 272.1723 - val_loss: 199.7260\n",
      "Epoch 2900/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 334.4439 - val_loss: 199.6568\n",
      "\n",
      "Epoch 02900: loss did not improve from 319.47460\n",
      "Epoch 2901/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 285.7428 - val_loss: 199.5929\n",
      "Epoch 2902/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 287.0367 - val_loss: 199.5283\n",
      "Epoch 2903/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 332.6828 - val_loss: 199.4518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2904/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 313.4833 - val_loss: 199.3669\n",
      "Epoch 2905/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 350.9922 - val_loss: 199.2708\n",
      "Epoch 2906/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 340.8950 - val_loss: 199.1623\n",
      "Epoch 2907/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 296.9456 - val_loss: 199.0362\n",
      "Epoch 2908/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 307.0522 - val_loss: 198.9161\n",
      "Epoch 2909/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 312.4669 - val_loss: 198.7998\n",
      "Epoch 2910/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 333.0111 - val_loss: 198.6808\n",
      "Epoch 2911/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 380.5598 - val_loss: 198.5612\n",
      "Epoch 2912/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 277.5862 - val_loss: 198.4231\n",
      "Epoch 2913/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 285.9526 - val_loss: 198.3015\n",
      "Epoch 2914/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 332.6634 - val_loss: 198.1913\n",
      "Epoch 2915/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 435.4170 - val_loss: 198.0846\n",
      "Epoch 2916/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 411.4973 - val_loss: 197.9856\n",
      "Epoch 2917/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 398.6946 - val_loss: 197.8491\n",
      "Epoch 2918/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 318.1941 - val_loss: 197.6546\n",
      "Epoch 2919/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 274.4026 - val_loss: 197.4575\n",
      "Epoch 2920/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 322.4072 - val_loss: 197.2989\n",
      "Epoch 2921/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 274.9883 - val_loss: 197.1467\n",
      "Epoch 2922/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 339.7871 - val_loss: 196.9929\n",
      "Epoch 2923/10000\n",
      "184/184 [==============================] - 0s 940us/step - loss: 438.4384 - val_loss: 196.8436\n",
      "Epoch 2924/10000\n",
      "184/184 [==============================] - 0s 880us/step - loss: 329.3827 - val_loss: 196.7016\n",
      "Epoch 2925/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 297.1949 - val_loss: 196.5665\n",
      "Epoch 2926/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 332.7578 - val_loss: 196.4313\n",
      "Epoch 2927/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 312.4577 - val_loss: 196.4804\n",
      "Epoch 2928/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 291.8901 - val_loss: 196.4652\n",
      "Epoch 2929/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 333.6234 - val_loss: 196.5317\n",
      "Epoch 2930/10000\n",
      "184/184 [==============================] - 0s 750us/step - loss: 261.5782 - val_loss: 196.6171\n",
      "Epoch 2931/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 319.3552 - val_loss: 196.7330\n",
      "Epoch 2932/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 324.5225 - val_loss: 196.8514\n",
      "Epoch 2933/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 303.2894 - val_loss: 196.8341\n",
      "Epoch 2934/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 404.0981 - val_loss: 196.6880\n",
      "Epoch 2935/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 367.3206 - val_loss: 196.4429\n",
      "Epoch 2936/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 308.3190 - val_loss: 196.1842\n",
      "Epoch 2937/10000\n",
      "184/184 [==============================] - 0s 815us/step - loss: 272.2911 - val_loss: 195.9915\n",
      "Epoch 2938/10000\n",
      "184/184 [==============================] - 0s 886us/step - loss: 372.0537 - val_loss: 195.8308\n",
      "Epoch 2939/10000\n",
      "184/184 [==============================] - 0s 783us/step - loss: 309.9117 - val_loss: 195.6864\n",
      "Epoch 2940/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 259.7493 - val_loss: 195.5515\n",
      "Epoch 2941/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 303.4358 - val_loss: 195.4151\n",
      "Epoch 2942/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 346.6916 - val_loss: 195.2872\n",
      "Epoch 2943/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 332.1849 - val_loss: 195.1608\n",
      "Epoch 2944/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 371.0839 - val_loss: 195.0496\n",
      "Epoch 2945/10000\n",
      "184/184 [==============================] - 0s 815us/step - loss: 395.7728 - val_loss: 194.9395\n",
      "Epoch 2946/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 268.9395 - val_loss: 194.8319\n",
      "Epoch 2947/10000\n",
      "184/184 [==============================] - 0s 984us/step - loss: 331.0546 - val_loss: 194.7171\n",
      "Epoch 2948/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 394.3213 - val_loss: 194.5757\n",
      "Epoch 2949/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 327.4762 - val_loss: 194.4523\n",
      "Epoch 2950/10000\n",
      "184/184 [==============================] - 0s 842us/step - loss: 339.7895 - val_loss: 194.3633\n",
      "Epoch 2951/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 275.6853 - val_loss: 194.2891\n",
      "Epoch 2952/10000\n",
      "184/184 [==============================] - 0s 783us/step - loss: 307.7524 - val_loss: 194.4243\n",
      "Epoch 2953/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 444.7716 - val_loss: 194.5740\n",
      "Epoch 2954/10000\n",
      "184/184 [==============================] - 0s 755us/step - loss: 264.9558 - val_loss: 194.7013\n",
      "Epoch 2955/10000\n",
      "184/184 [==============================] - 0s 755us/step - loss: 314.2042 - val_loss: 194.5824\n",
      "Epoch 2956/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 336.9808 - val_loss: 194.5028\n",
      "Epoch 2957/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 280.6570 - val_loss: 194.4963\n",
      "Epoch 2958/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 311.3852 - val_loss: 194.5836\n",
      "Epoch 2959/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 330.2360 - val_loss: 194.6043\n",
      "Epoch 2960/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 243.6044 - val_loss: 194.5660\n",
      "Epoch 2961/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 320.5543 - val_loss: 194.4812\n",
      "Epoch 2962/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 320.3034 - val_loss: 194.4036\n",
      "Epoch 2963/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 367.7220 - val_loss: 194.3263\n",
      "Epoch 2964/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 382.7146 - val_loss: 194.2343\n",
      "Epoch 2965/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 306.4451 - val_loss: 194.1183\n",
      "Epoch 2966/10000\n",
      "184/184 [==============================] - 0s 619us/step - loss: 406.6379 - val_loss: 193.9973\n",
      "Epoch 2967/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 300.0108 - val_loss: 193.8811\n",
      "Epoch 2968/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 315.8278 - val_loss: 193.7696\n",
      "Epoch 2969/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 333.0876 - val_loss: 193.6556\n",
      "Epoch 2970/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 325.2712 - val_loss: 193.5420\n",
      "Epoch 2971/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 385.0699 - val_loss: 193.4266\n",
      "Epoch 2972/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 255.0461 - val_loss: 193.3109\n",
      "Epoch 2973/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 296.1419 - val_loss: 193.2129\n",
      "Epoch 2974/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 239.7743 - val_loss: 193.1126\n",
      "Epoch 2975/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 340.0501 - val_loss: 193.0068\n",
      "Epoch 2976/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 293.1306 - val_loss: 192.8950\n",
      "Epoch 2977/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 620us/step - loss: 301.7246 - val_loss: 192.7900\n",
      "Epoch 2978/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 345.8505 - val_loss: 192.6838\n",
      "Epoch 2979/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 278.4564 - val_loss: 192.5759\n",
      "Epoch 2980/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 337.9942 - val_loss: 192.4636\n",
      "Epoch 2981/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 332.2894 - val_loss: 192.3456\n",
      "Epoch 2982/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 252.8627 - val_loss: 192.2344\n",
      "Epoch 2983/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 245.9359 - val_loss: 192.1315\n",
      "Epoch 2984/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 321.8049 - val_loss: 192.0279\n",
      "Epoch 2985/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 475.5593 - val_loss: 191.9172\n",
      "Epoch 2986/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 368.4403 - val_loss: 191.7990\n",
      "Epoch 2987/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 301.8900 - val_loss: 191.6816\n",
      "Epoch 2988/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 264.5867 - val_loss: 191.5644\n",
      "Epoch 2989/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 353.2777 - val_loss: 191.4462\n",
      "Epoch 2990/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 311.2561 - val_loss: 191.3338\n",
      "Epoch 2991/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 288.5728 - val_loss: 191.2214\n",
      "Epoch 2992/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 334.7850 - val_loss: 191.1052\n",
      "Epoch 2993/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 305.8483 - val_loss: 190.9893\n",
      "Epoch 2994/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 290.9202 - val_loss: 190.8741\n",
      "Epoch 2995/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 315.4427 - val_loss: 190.2788\n",
      "Epoch 2996/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 445.3887 - val_loss: 189.9790\n",
      "Epoch 2997/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 268.5245 - val_loss: 190.9723\n",
      "Epoch 2998/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 327.6081 - val_loss: 192.3125\n",
      "Epoch 2999/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 306.9199 - val_loss: 191.7863\n",
      "Epoch 3000/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 297.1292 - val_loss: 192.1708\n",
      "\n",
      "Epoch 03000: loss improved from 319.47460 to 297.12922, saving model to C6007C.hdf5\n",
      "Epoch 3001/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 342.8525 - val_loss: 192.3726\n",
      "Epoch 3002/10000\n",
      "184/184 [==============================] - 0s 962us/step - loss: 308.8974 - val_loss: 192.4743\n",
      "Epoch 3003/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 285.0326 - val_loss: 192.5358\n",
      "Epoch 3004/10000\n",
      "184/184 [==============================] - 0s 810us/step - loss: 408.9276 - val_loss: 192.5460\n",
      "Epoch 3005/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 351.9524 - val_loss: 193.4804\n",
      "Epoch 3006/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 335.6189 - val_loss: 195.3613\n",
      "Epoch 3007/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 326.9448 - val_loss: 195.8461\n",
      "Epoch 3008/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 347.7961 - val_loss: 194.6381\n",
      "Epoch 3009/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 270.0171 - val_loss: 193.6952\n",
      "Epoch 3010/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 313.6350 - val_loss: 193.6276\n",
      "Epoch 3011/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 310.4471 - val_loss: 193.5138\n",
      "Epoch 3012/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 323.3462 - val_loss: 193.4785\n",
      "Epoch 3013/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 308.6916 - val_loss: 193.4728\n",
      "Epoch 3014/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 281.9814 - val_loss: 193.5204\n",
      "Epoch 3015/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 343.5426 - val_loss: 193.5528\n",
      "Epoch 3016/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 351.0020 - val_loss: 193.5577\n",
      "Epoch 3017/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 352.8366 - val_loss: 193.5286\n",
      "Epoch 3018/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 283.7926 - val_loss: 193.4800\n",
      "Epoch 3019/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 331.0745 - val_loss: 193.4014\n",
      "Epoch 3020/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 325.5596 - val_loss: 193.3088\n",
      "Epoch 3021/10000\n",
      "184/184 [==============================] - 0s 815us/step - loss: 349.9758 - val_loss: 193.2115\n",
      "Epoch 3022/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 272.7104 - val_loss: 193.1062\n",
      "Epoch 3023/10000\n",
      "184/184 [==============================] - 0s 755us/step - loss: 365.2728 - val_loss: 192.9998\n",
      "Epoch 3024/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 342.9692 - val_loss: 192.8923\n",
      "Epoch 3025/10000\n",
      "184/184 [==============================] - 0s 783us/step - loss: 300.3231 - val_loss: 192.7806\n",
      "Epoch 3026/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 349.5438 - val_loss: 192.6603\n",
      "Epoch 3027/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 316.1453 - val_loss: 192.5383\n",
      "Epoch 3028/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 332.5480 - val_loss: 192.4094\n",
      "Epoch 3029/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 238.5127 - val_loss: 192.2949\n",
      "Epoch 3030/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 310.1159 - val_loss: 192.1871\n",
      "Epoch 3031/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 321.9074 - val_loss: 192.0714\n",
      "Epoch 3032/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 343.2360 - val_loss: 191.9516\n",
      "Epoch 3033/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 421.2480 - val_loss: 191.8224\n",
      "Epoch 3034/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 298.5680 - val_loss: 191.6890\n",
      "Epoch 3035/10000\n",
      "184/184 [==============================] - 0s 978us/step - loss: 323.1318 - val_loss: 191.5575\n",
      "Epoch 3036/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 291.9137 - val_loss: 191.4389\n",
      "Epoch 3037/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 267.7437 - val_loss: 191.3191\n",
      "Epoch 3038/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 358.6071 - val_loss: 191.2045\n",
      "Epoch 3039/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 282.6922 - val_loss: 191.0985\n",
      "Epoch 3040/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 363.0777 - val_loss: 190.9922\n",
      "Epoch 3041/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 336.1665 - val_loss: 190.8793\n",
      "Epoch 3042/10000\n",
      "184/184 [==============================] - 0s 889us/step - loss: 391.6661 - val_loss: 190.7572\n",
      "Epoch 3043/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 316.6711 - val_loss: 190.6361\n",
      "Epoch 3044/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 289.0847 - val_loss: 190.5159\n",
      "Epoch 3045/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 347.1531 - val_loss: 190.3892\n",
      "Epoch 3046/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 313.6844 - val_loss: 190.2661\n",
      "Epoch 3047/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 272.4928 - val_loss: 190.1455\n",
      "Epoch 3048/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 343.5839 - val_loss: 190.0443\n",
      "Epoch 3049/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 620us/step - loss: 261.5589 - val_loss: 189.9793\n",
      "Epoch 3050/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 309.6290 - val_loss: 189.9268\n",
      "Epoch 3051/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 323.4832 - val_loss: 189.8558\n",
      "Epoch 3052/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 433.2543 - val_loss: 189.7716\n",
      "Epoch 3053/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 268.9566 - val_loss: 189.6636\n",
      "Epoch 3054/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 340.7872 - val_loss: 189.4647\n",
      "Epoch 3055/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 242.7886 - val_loss: 189.2074\n",
      "Epoch 3056/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 304.0306 - val_loss: 188.9755\n",
      "Epoch 3057/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 253.5214 - val_loss: 188.7703\n",
      "Epoch 3058/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 262.5547 - val_loss: 188.5832\n",
      "Epoch 3059/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 289.0544 - val_loss: 188.4080\n",
      "Epoch 3060/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 281.0928 - val_loss: 188.2459\n",
      "Epoch 3061/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 229.5674 - val_loss: 188.0984\n",
      "Epoch 3062/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 252.6368 - val_loss: 187.9651\n",
      "Epoch 3063/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 256.4432 - val_loss: 187.8215\n",
      "Epoch 3064/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 305.6335 - val_loss: 187.6711\n",
      "Epoch 3065/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 252.2688 - val_loss: 187.5264\n",
      "Epoch 3066/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 285.7843 - val_loss: 187.3837\n",
      "Epoch 3067/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 315.9550 - val_loss: 187.2498\n",
      "Epoch 3068/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 296.1432 - val_loss: 187.1171\n",
      "Epoch 3069/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 281.8824 - val_loss: 187.0532\n",
      "Epoch 3070/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 310.0709 - val_loss: 188.8122\n",
      "Epoch 3071/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 380.2052 - val_loss: 188.9187\n",
      "Epoch 3072/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 273.1494 - val_loss: 188.9183\n",
      "Epoch 3073/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 272.2642 - val_loss: 188.9086\n",
      "Epoch 3074/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 341.3747 - val_loss: 188.8944\n",
      "Epoch 3075/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 376.6826 - val_loss: 188.8515\n",
      "Epoch 3076/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 311.1267 - val_loss: 188.7810\n",
      "Epoch 3077/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 349.7056 - val_loss: 188.7071\n",
      "Epoch 3078/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 289.0393 - val_loss: 188.6460\n",
      "Epoch 3079/10000\n",
      "184/184 [==============================] - 0s 601us/step - loss: 319.5062 - val_loss: 188.5778\n",
      "Epoch 3080/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 386.4024 - val_loss: 188.4781\n",
      "Epoch 3081/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 304.1018 - val_loss: 188.3712\n",
      "Epoch 3082/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 325.0155 - val_loss: 188.2885\n",
      "Epoch 3083/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 290.3166 - val_loss: 188.1793\n",
      "Epoch 3084/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 283.4370 - val_loss: 188.0678\n",
      "Epoch 3085/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 315.9904 - val_loss: 187.9545\n",
      "Epoch 3086/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 375.4397 - val_loss: 187.8373\n",
      "Epoch 3087/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 283.5948 - val_loss: 187.7239\n",
      "Epoch 3088/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 328.3420 - val_loss: 187.6084\n",
      "Epoch 3089/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 314.9002 - val_loss: 187.5306\n",
      "Epoch 3090/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 334.0153 - val_loss: 187.4850\n",
      "Epoch 3091/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 382.6422 - val_loss: 187.4351\n",
      "Epoch 3092/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 325.8538 - val_loss: 187.3838\n",
      "Epoch 3093/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 357.6163 - val_loss: 187.3391\n",
      "Epoch 3094/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 268.5525 - val_loss: 187.2777\n",
      "Epoch 3095/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 287.9577 - val_loss: 187.2078\n",
      "Epoch 3096/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 297.0314 - val_loss: 187.1432\n",
      "Epoch 3097/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 267.8119 - val_loss: 187.0849\n",
      "Epoch 3098/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 333.3308 - val_loss: 187.0149\n",
      "Epoch 3099/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 312.4037 - val_loss: 186.9160\n",
      "Epoch 3100/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 331.7942 - val_loss: 186.8137\n",
      "\n",
      "Epoch 03100: loss did not improve from 297.12922\n",
      "Epoch 3101/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 359.4743 - val_loss: 186.6600\n",
      "Epoch 3102/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 287.1884 - val_loss: 186.5235\n",
      "Epoch 3103/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 323.1948 - val_loss: 186.3630\n",
      "Epoch 3104/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 385.1243 - val_loss: 186.2206\n",
      "Epoch 3105/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 252.1990 - val_loss: 186.0851\n",
      "Epoch 3106/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 279.5903 - val_loss: 185.9942\n",
      "Epoch 3107/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 338.5359 - val_loss: 185.9191\n",
      "Epoch 3108/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 357.4260 - val_loss: 185.8220\n",
      "Epoch 3109/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 287.8766 - val_loss: 185.7188\n",
      "Epoch 3110/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 315.0765 - val_loss: 185.6174\n",
      "Epoch 3111/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 346.1086 - val_loss: 185.5175\n",
      "Epoch 3112/10000\n",
      "184/184 [==============================] - 0s 581us/step - loss: 341.5968 - val_loss: 185.4169\n",
      "Epoch 3113/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 272.6392 - val_loss: 185.3348\n",
      "Epoch 3114/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 300.6929 - val_loss: 185.2500\n",
      "Epoch 3115/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 301.2848 - val_loss: 185.1222\n",
      "Epoch 3116/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 326.7730 - val_loss: 184.9729\n",
      "Epoch 3117/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 345.7311 - val_loss: 184.8304\n",
      "Epoch 3118/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 290.0295 - val_loss: 184.6959\n",
      "Epoch 3119/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 378.3395 - val_loss: 184.5577\n",
      "Epoch 3120/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 323.3987 - val_loss: 184.4112\n",
      "Epoch 3121/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 293.4244 - val_loss: 184.2697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3122/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 273.8048 - val_loss: 184.1324\n",
      "Epoch 3123/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 238.0516 - val_loss: 184.0018\n",
      "Epoch 3124/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 260.7422 - val_loss: 183.8859\n",
      "Epoch 3125/10000\n",
      "184/184 [==============================] - 0s 756us/step - loss: 334.2836 - val_loss: 183.7761\n",
      "Epoch 3126/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 315.6223 - val_loss: 183.6743\n",
      "Epoch 3127/10000\n",
      "184/184 [==============================] - 0s 633us/step - loss: 323.0434 - val_loss: 183.5787\n",
      "Epoch 3128/10000\n",
      "184/184 [==============================] - 0s 826us/step - loss: 283.3703 - val_loss: 183.4804\n",
      "Epoch 3129/10000\n",
      "184/184 [==============================] - 0s 772us/step - loss: 322.7167 - val_loss: 183.3818\n",
      "Epoch 3130/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 245.5799 - val_loss: 183.2867\n",
      "Epoch 3131/10000\n",
      "184/184 [==============================] - 0s 688us/step - loss: 316.0331 - val_loss: 183.1938\n",
      "Epoch 3132/10000\n",
      "184/184 [==============================] - 0s 698us/step - loss: 299.2962 - val_loss: 183.0951\n",
      "Epoch 3133/10000\n",
      "184/184 [==============================] - 0s 731us/step - loss: 237.1390 - val_loss: 182.9827\n",
      "Epoch 3134/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 331.6716 - val_loss: 182.8603\n",
      "Epoch 3135/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 269.7652 - val_loss: 182.7438\n",
      "Epoch 3136/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 347.4161 - val_loss: 182.6459\n",
      "Epoch 3137/10000\n",
      "184/184 [==============================] - 0s 644us/step - loss: 275.3291 - val_loss: 182.5554\n",
      "Epoch 3138/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 300.0909 - val_loss: 182.4615\n",
      "Epoch 3139/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 339.4615 - val_loss: 182.3626\n",
      "Epoch 3140/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 219.6864 - val_loss: 182.2568\n",
      "Epoch 3141/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 265.5835 - val_loss: 182.1465\n",
      "Epoch 3142/10000\n",
      "184/184 [==============================] - 0s 693us/step - loss: 252.0674 - val_loss: 182.0228\n",
      "Epoch 3143/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 297.4510 - val_loss: 181.8623\n",
      "Epoch 3144/10000\n",
      "184/184 [==============================] - 0s 897us/step - loss: 309.1112 - val_loss: 181.7198\n",
      "Epoch 3145/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 326.8167 - val_loss: 181.5947\n",
      "Epoch 3146/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 324.6763 - val_loss: 181.4763\n",
      "Epoch 3147/10000\n",
      "184/184 [==============================] - 0s 837us/step - loss: 302.9036 - val_loss: 181.3265\n",
      "Epoch 3148/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 281.6308 - val_loss: 181.1554\n",
      "Epoch 3149/10000\n",
      "184/184 [==============================] - 0s 799us/step - loss: 299.9588 - val_loss: 181.0074\n",
      "Epoch 3150/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 332.8386 - val_loss: 180.8517\n",
      "Epoch 3151/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 277.3829 - val_loss: 180.7080\n",
      "Epoch 3152/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 297.0824 - val_loss: 180.5722\n",
      "Epoch 3153/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 325.5925 - val_loss: 180.4342\n",
      "Epoch 3154/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 300.9246 - val_loss: 180.2926\n",
      "Epoch 3155/10000\n",
      "184/184 [==============================] - 0s 962us/step - loss: 277.0503 - val_loss: 180.1598\n",
      "Epoch 3156/10000\n",
      "184/184 [==============================] - 0s 870us/step - loss: 269.6888 - val_loss: 180.0334\n",
      "Epoch 3157/10000\n",
      "184/184 [==============================] - 0s 799us/step - loss: 310.2081 - val_loss: 179.9159\n",
      "Epoch 3158/10000\n",
      "184/184 [==============================] - 0s 848us/step - loss: 384.9605 - val_loss: 179.8011\n",
      "Epoch 3159/10000\n",
      "184/184 [==============================] - 0s 821us/step - loss: 386.0044 - val_loss: 179.6936\n",
      "Epoch 3160/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 298.0318 - val_loss: 179.5958\n",
      "Epoch 3161/10000\n",
      "184/184 [==============================] - 0s 940us/step - loss: 264.4814 - val_loss: 179.4971\n",
      "Epoch 3162/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 338.8029 - val_loss: 179.3710\n",
      "Epoch 3163/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 308.4017 - val_loss: 179.2287\n",
      "Epoch 3164/10000\n",
      "184/184 [==============================] - 0s 650us/step - loss: 276.7519 - val_loss: 179.0961\n",
      "Epoch 3165/10000\n",
      "184/184 [==============================] - 0s 978us/step - loss: 302.2870 - val_loss: 178.9712\n",
      "Epoch 3166/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 298.1744 - val_loss: 178.8480\n",
      "Epoch 3167/10000\n",
      "184/184 [==============================] - 0s 655us/step - loss: 272.0565 - val_loss: 178.7386\n",
      "Epoch 3168/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 212.316 - 0s 668us/step - loss: 268.8247 - val_loss: 178.6332\n",
      "Epoch 3169/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 268.2940 - val_loss: 178.5326\n",
      "Epoch 3170/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 230.4184 - val_loss: 178.4408\n",
      "Epoch 3171/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 307.5847 - val_loss: 178.3456\n",
      "Epoch 3172/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 349.8498 - val_loss: 178.2481\n",
      "Epoch 3173/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 304.3089 - val_loss: 178.1447\n",
      "Epoch 3174/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 270.8237 - val_loss: 178.0418\n",
      "Epoch 3175/10000\n",
      "184/184 [==============================] - 0s 772us/step - loss: 247.1466 - val_loss: 177.9402\n",
      "Epoch 3176/10000\n",
      "184/184 [==============================] - 0s 821us/step - loss: 298.3370 - val_loss: 177.8381\n",
      "Epoch 3177/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 283.7739 - val_loss: 177.7333\n",
      "Epoch 3178/10000\n",
      "184/184 [==============================] - 0s 755us/step - loss: 248.3761 - val_loss: 177.6372\n",
      "Epoch 3179/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 331.3756 - val_loss: 177.5778\n",
      "Epoch 3180/10000\n",
      "184/184 [==============================] - 0s 989us/step - loss: 293.4561 - val_loss: 177.5925\n",
      "Epoch 3181/10000\n",
      "184/184 [==============================] - 0s 900us/step - loss: 342.8284 - val_loss: 177.4550\n",
      "Epoch 3182/10000\n",
      "184/184 [==============================] - 0s 821us/step - loss: 295.3786 - val_loss: 177.2528\n",
      "Epoch 3183/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 272.8422 - val_loss: 177.0749\n",
      "Epoch 3184/10000\n",
      "184/184 [==============================] - 0s 815us/step - loss: 299.0675 - val_loss: 176.9206\n",
      "Epoch 3185/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 290.3938 - val_loss: 176.7539\n",
      "Epoch 3186/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 237.4127 - val_loss: 176.5749\n",
      "Epoch 3187/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 265.6939 - val_loss: 176.4160\n",
      "Epoch 3188/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 303.8361 - val_loss: 176.2604\n",
      "Epoch 3189/10000\n",
      "184/184 [==============================] - 0s 973us/step - loss: 354.2536 - val_loss: 176.1111\n",
      "Epoch 3190/10000\n",
      "184/184 [==============================] - 0s 935us/step - loss: 360.4419 - val_loss: 175.9526\n",
      "Epoch 3191/10000\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 275.2186 - val_loss: 175.7664\n",
      "Epoch 3192/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 291.5763 - val_loss: 175.5759\n",
      "Epoch 3193/10000\n",
      "184/184 [==============================] - 0s 842us/step - loss: 340.9888 - val_loss: 175.4098\n",
      "Epoch 3194/10000\n",
      "184/184 [==============================] - 0s 761us/step - loss: 257.2832 - val_loss: 175.2581\n",
      "Epoch 3195/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 717us/step - loss: 251.9593 - val_loss: 175.1249\n",
      "Epoch 3196/10000\n",
      "184/184 [==============================] - 0s 886us/step - loss: 327.1590 - val_loss: 175.0023\n",
      "Epoch 3197/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 407.3164 - val_loss: 174.8836\n",
      "Epoch 3198/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 299.3573 - val_loss: 174.7691\n",
      "Epoch 3199/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 295.5739 - val_loss: 174.6446\n",
      "Epoch 3200/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 247.5706 - val_loss: 174.5249\n",
      "\n",
      "Epoch 03200: loss improved from 297.12922 to 247.57060, saving model to C6007C.hdf5\n",
      "Epoch 3201/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 238.8982 - val_loss: 174.4162\n",
      "Epoch 3202/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 259.4921 - val_loss: 174.3105\n",
      "Epoch 3203/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 254.9522 - val_loss: 174.2049\n",
      "Epoch 3204/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 262.2870 - val_loss: 174.0781\n",
      "Epoch 3205/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 257.5513 - val_loss: 173.9353\n",
      "Epoch 3206/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 275.6417 - val_loss: 173.8002\n",
      "Epoch 3207/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 206.8401 - val_loss: 173.6593\n",
      "Epoch 3208/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 246.6029 - val_loss: 173.4919\n",
      "Epoch 3209/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 317.2909 - val_loss: 173.2994\n",
      "Epoch 3210/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 344.6730 - val_loss: 173.0980\n",
      "Epoch 3211/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 308.5990 - val_loss: 172.8731\n",
      "Epoch 3212/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 290.8000 - val_loss: 172.6423\n",
      "Epoch 3213/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 279.8787 - val_loss: 172.4430\n",
      "Epoch 3214/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 219.3206 - val_loss: 172.2672\n",
      "Epoch 3215/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 294.9289 - val_loss: 172.1072\n",
      "Epoch 3216/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 262.3925 - val_loss: 171.9599\n",
      "Epoch 3217/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 221.9763 - val_loss: 171.8294\n",
      "Epoch 3218/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 263.7268 - val_loss: 171.7123\n",
      "Epoch 3219/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 319.3609 - val_loss: 171.6032\n",
      "Epoch 3220/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 282.1138 - val_loss: 171.4989\n",
      "Epoch 3221/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 293.4915 - val_loss: 171.3994\n",
      "Epoch 3222/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 239.8398 - val_loss: 171.2828\n",
      "Epoch 3223/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 292.6831 - val_loss: 171.1651\n",
      "Epoch 3224/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 244.7055 - val_loss: 171.0492\n",
      "Epoch 3225/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 230.0894 - val_loss: 170.9337\n",
      "Epoch 3226/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 347.6755 - val_loss: 170.8163\n",
      "Epoch 3227/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 290.0672 - val_loss: 170.6570\n",
      "Epoch 3228/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 313.1812 - val_loss: 170.4624\n",
      "Epoch 3229/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 361.1482 - val_loss: 170.1592\n",
      "Epoch 3230/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 296.4214 - val_loss: 169.9397\n",
      "Epoch 3231/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 390.2674 - val_loss: 169.4023\n",
      "Epoch 3232/10000\n",
      "184/184 [==============================] - 0s 555us/step - loss: 311.0178 - val_loss: 168.9840\n",
      "Epoch 3233/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 248.1172 - val_loss: 168.6870\n",
      "Epoch 3234/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 301.2657 - val_loss: 168.4592\n",
      "Epoch 3235/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 336.7384 - val_loss: 168.2794\n",
      "Epoch 3236/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 365.3432 - val_loss: 168.1348\n",
      "Epoch 3237/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 249.0799 - val_loss: 167.9370\n",
      "Epoch 3238/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 251.6940 - val_loss: 167.7886\n",
      "Epoch 3239/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 274.4285 - val_loss: 167.6679\n",
      "Epoch 3240/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 291.1015 - val_loss: 167.5559\n",
      "Epoch 3241/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 258.4724 - val_loss: 167.4552\n",
      "Epoch 3242/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 247.8746 - val_loss: 167.3554\n",
      "Epoch 3243/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 352.6183 - val_loss: 167.2592\n",
      "Epoch 3244/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 262.9487 - val_loss: 167.1573\n",
      "Epoch 3245/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 277.1606 - val_loss: 167.0542\n",
      "Epoch 3246/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 291.0601 - val_loss: 166.9535\n",
      "Epoch 3247/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 274.9293 - val_loss: 166.8618\n",
      "Epoch 3248/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 313.2630 - val_loss: 166.7794\n",
      "Epoch 3249/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 246.9103 - val_loss: 166.6935\n",
      "Epoch 3250/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 277.8528 - val_loss: 166.6083\n",
      "Epoch 3251/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 282.2119 - val_loss: 166.5239\n",
      "Epoch 3252/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 284.8381 - val_loss: 166.4337\n",
      "Epoch 3253/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 229.8623 - val_loss: 166.3476\n",
      "Epoch 3254/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 221.4364 - val_loss: 166.2658\n",
      "Epoch 3255/10000\n",
      "184/184 [==============================] - 0s 595us/step - loss: 262.5011 - val_loss: 166.1837\n",
      "Epoch 3256/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 267.7855 - val_loss: 166.0978\n",
      "Epoch 3257/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 339.6757 - val_loss: 166.0071\n",
      "Epoch 3258/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 268.8106 - val_loss: 165.8900\n",
      "Epoch 3259/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 317.1953 - val_loss: 165.7562\n",
      "Epoch 3260/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 270.4572 - val_loss: 165.6426\n",
      "Epoch 3261/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 251.4316 - val_loss: 165.5454\n",
      "Epoch 3262/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 294.8562 - val_loss: 165.4159\n",
      "Epoch 3263/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 350.5248 - val_loss: 165.2547\n",
      "Epoch 3264/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 334.3077 - val_loss: 166.7668\n",
      "Epoch 3265/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 273.7657 - val_loss: 166.7486\n",
      "Epoch 3266/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 276.9484 - val_loss: 166.6511\n",
      "Epoch 3267/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 495us/step - loss: 316.3168 - val_loss: 166.5617\n",
      "Epoch 3268/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 280.9402 - val_loss: 166.4826\n",
      "Epoch 3269/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 279.3826 - val_loss: 166.4428\n",
      "Epoch 3270/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 279.1193 - val_loss: 166.3629\n",
      "Epoch 3271/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 230.3092 - val_loss: 166.3044\n",
      "Epoch 3272/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 309.0378 - val_loss: 166.2132\n",
      "Epoch 3273/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 294.8093 - val_loss: 166.2507\n",
      "Epoch 3274/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 280.6173 - val_loss: 166.2394\n",
      "Epoch 3275/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 276.8440 - val_loss: 166.1903\n",
      "Epoch 3276/10000\n",
      "184/184 [==============================] - 0s 810us/step - loss: 266.8289 - val_loss: 166.1084\n",
      "Epoch 3277/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 262.8548 - val_loss: 166.0051\n",
      "Epoch 3278/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 319.1332 - val_loss: 165.8970\n",
      "Epoch 3279/10000\n",
      "184/184 [==============================] - 0s 989us/step - loss: 354.0589 - val_loss: 165.7960\n",
      "Epoch 3280/10000\n",
      "184/184 [==============================] - 0s 783us/step - loss: 353.4744 - val_loss: 165.6917\n",
      "Epoch 3281/10000\n",
      "184/184 [==============================] - 0s 804us/step - loss: 312.1577 - val_loss: 165.5968\n",
      "Epoch 3282/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 346.8204 - val_loss: 165.5110\n",
      "Epoch 3283/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 272.1091 - val_loss: 165.4147\n",
      "Epoch 3284/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 278.1143 - val_loss: 165.3164\n",
      "Epoch 3285/10000\n",
      "184/184 [==============================] - 0s 832us/step - loss: 263.6072 - val_loss: 165.2132\n",
      "Epoch 3286/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 222.2042 - val_loss: 165.1144\n",
      "Epoch 3287/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 300.2044 - val_loss: 165.0117\n",
      "Epoch 3288/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 268.5185 - val_loss: 164.9223\n",
      "Epoch 3289/10000\n",
      "184/184 [==============================] - 0s 756us/step - loss: 258.8767 - val_loss: 164.8242\n",
      "Epoch 3290/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 289.4637 - val_loss: 164.7247\n",
      "Epoch 3291/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 310.9130 - val_loss: 164.6177\n",
      "Epoch 3292/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 226.4987 - val_loss: 164.5135\n",
      "Epoch 3293/10000\n",
      "184/184 [==============================] - 0s 889us/step - loss: 173.2330 - val_loss: 164.4124\n",
      "Epoch 3294/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 318.3460 - val_loss: 164.3121\n",
      "Epoch 3295/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 215.7263 - val_loss: 164.2081\n",
      "Epoch 3296/10000\n",
      "184/184 [==============================] - 0s 929us/step - loss: 273.3577 - val_loss: 164.1066\n",
      "Epoch 3297/10000\n",
      "184/184 [==============================] - 0s 804us/step - loss: 258.3664 - val_loss: 164.0087\n",
      "Epoch 3298/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 281.4209 - val_loss: 163.9130\n",
      "Epoch 3299/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 237.9559 - val_loss: 163.8187\n",
      "Epoch 3300/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 339.3405 - val_loss: 163.7164\n",
      "\n",
      "Epoch 03300: loss did not improve from 247.57060\n",
      "Epoch 3301/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 286.5129 - val_loss: 163.6093\n",
      "Epoch 3302/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 305.9305 - val_loss: 163.4997\n",
      "Epoch 3303/10000\n",
      "184/184 [==============================] - 0s 821us/step - loss: 251.9818 - val_loss: 163.3926\n",
      "Epoch 3304/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 307.4260 - val_loss: 163.2880\n",
      "Epoch 3305/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 282.0360 - val_loss: 164.0469\n",
      "Epoch 3306/10000\n",
      "184/184 [==============================] - 0s 750us/step - loss: 261.6260 - val_loss: 163.7527\n",
      "Epoch 3307/10000\n",
      "184/184 [==============================] - 0s 601us/step - loss: 349.3518 - val_loss: 164.2171\n",
      "Epoch 3308/10000\n",
      "184/184 [==============================] - 0s 546us/step - loss: 299.4200 - val_loss: 167.0410\n",
      "Epoch 3309/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 297.0549 - val_loss: 164.3462\n",
      "Epoch 3310/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 242.8259 - val_loss: 165.0031\n",
      "Epoch 3311/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 275.0811 - val_loss: 165.3893\n",
      "Epoch 3312/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 253.1469 - val_loss: 165.3264\n",
      "Epoch 3313/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 337.4230 - val_loss: 165.2516\n",
      "Epoch 3314/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 389.8825 - val_loss: 165.1916\n",
      "Epoch 3315/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 300.6170 - val_loss: 165.3015\n",
      "Epoch 3316/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 384.3705 - val_loss: 164.9299\n",
      "Epoch 3317/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 248.4987 - val_loss: 164.8772\n",
      "Epoch 3318/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 220.0131 - val_loss: 164.7526\n",
      "Epoch 3319/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 294.9547 - val_loss: 164.5364\n",
      "Epoch 3320/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 303.3928 - val_loss: 164.4170\n",
      "Epoch 3321/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 296.4186 - val_loss: 164.1953\n",
      "Epoch 3322/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 285.7692 - val_loss: 164.0647\n",
      "Epoch 3323/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 230.9091 - val_loss: 163.9142\n",
      "Epoch 3324/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 235.3301 - val_loss: 163.7070\n",
      "Epoch 3325/10000\n",
      "184/184 [==============================] - 0s 581us/step - loss: 242.7766 - val_loss: 163.5330\n",
      "Epoch 3326/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 243.2766 - val_loss: 163.3994\n",
      "Epoch 3327/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 281.5842 - val_loss: 163.3072\n",
      "Epoch 3328/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 181.6532 - val_loss: 163.0495\n",
      "Epoch 3329/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 320.1380 - val_loss: 162.8392\n",
      "Epoch 3330/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 280.0356 - val_loss: 162.7935\n",
      "Epoch 3331/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 303.1729 - val_loss: 162.6948\n",
      "Epoch 3332/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 222.0540 - val_loss: 162.6539\n",
      "Epoch 3333/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 247.7533 - val_loss: 162.6843\n",
      "Epoch 3334/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 262.1648 - val_loss: 162.6918\n",
      "Epoch 3335/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 263.3211 - val_loss: 162.6216\n",
      "Epoch 3336/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 221.7609 - val_loss: 162.5506\n",
      "Epoch 3337/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 247.2432 - val_loss: 162.4779\n",
      "Epoch 3338/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 300.3818 - val_loss: 162.3789\n",
      "Epoch 3339/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 250.4314 - val_loss: 162.2782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3340/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 268.0222 - val_loss: 162.1798\n",
      "Epoch 3341/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 284.1434 - val_loss: 162.0856\n",
      "Epoch 3342/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 234.2886 - val_loss: 161.9956\n",
      "Epoch 3343/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 280.7585 - val_loss: 161.9034\n",
      "Epoch 3344/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 299.0363 - val_loss: 161.8047\n",
      "Epoch 3345/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 271.3222 - val_loss: 161.7019\n",
      "Epoch 3346/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 221.5888 - val_loss: 161.5963\n",
      "Epoch 3347/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 225.9296 - val_loss: 161.4927\n",
      "Epoch 3348/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 338.3454 - val_loss: 161.3913\n",
      "Epoch 3349/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 260.9658 - val_loss: 161.2846\n",
      "Epoch 3350/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 277.2028 - val_loss: 161.1486\n",
      "Epoch 3351/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 280.7805 - val_loss: 160.9634\n",
      "Epoch 3352/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 226.0173 - val_loss: 160.7757\n",
      "Epoch 3353/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 191.0051 - val_loss: 160.6490\n",
      "Epoch 3354/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 298.6754 - val_loss: 160.5639\n",
      "Epoch 3355/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 252.3753 - val_loss: 160.4783\n",
      "Epoch 3356/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 282.9879 - val_loss: 160.3894\n",
      "Epoch 3357/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 224.8157 - val_loss: 160.3120\n",
      "Epoch 3358/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 355.3393 - val_loss: 160.2141\n",
      "Epoch 3359/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 238.6097 - val_loss: 160.0909\n",
      "Epoch 3360/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 253.1143 - val_loss: 159.9758\n",
      "Epoch 3361/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 221.5815 - val_loss: 159.8816\n",
      "Epoch 3362/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 198.0547 - val_loss: 159.8040\n",
      "Epoch 3363/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 202.6608 - val_loss: 159.7332\n",
      "Epoch 3364/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 329.9396 - val_loss: 159.6371\n",
      "Epoch 3365/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 253.4334 - val_loss: 159.5408\n",
      "Epoch 3366/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 250.0874 - val_loss: 159.4328\n",
      "Epoch 3367/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 299.3490 - val_loss: 159.3066\n",
      "Epoch 3368/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 288.7892 - val_loss: 159.1506\n",
      "Epoch 3369/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 313.6262 - val_loss: 159.0627\n",
      "Epoch 3370/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 186.0288 - val_loss: 158.9769\n",
      "Epoch 3371/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 239.6086 - val_loss: 158.8571\n",
      "Epoch 3372/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 203.5001 - val_loss: 158.7372\n",
      "Epoch 3373/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 235.9035 - val_loss: 158.6204\n",
      "Epoch 3374/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 251.2512 - val_loss: 158.5176\n",
      "Epoch 3375/10000\n",
      "184/184 [==============================] - 0s 946us/step - loss: 327.5847 - val_loss: 158.4376\n",
      "Epoch 3376/10000\n",
      "184/184 [==============================] - 0s 965us/step - loss: 304.9906 - val_loss: 158.3529\n",
      "Epoch 3377/10000\n",
      "184/184 [==============================] - 0s 593us/step - loss: 198.6909 - val_loss: 158.2686\n",
      "Epoch 3378/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 249.1119 - val_loss: 158.2021\n",
      "Epoch 3379/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 250.8291 - val_loss: 158.1247\n",
      "Epoch 3380/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 251.9887 - val_loss: 158.0496\n",
      "Epoch 3381/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 274.1768 - val_loss: 157.9576\n",
      "Epoch 3382/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 242.0096 - val_loss: 157.8573\n",
      "Epoch 3383/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 290.1462 - val_loss: 157.7653\n",
      "Epoch 3384/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 401.9382 - val_loss: 157.6731\n",
      "Epoch 3385/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 218.7789 - val_loss: 157.6009\n",
      "Epoch 3386/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 248.1677 - val_loss: 157.5269\n",
      "Epoch 3387/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 200.9208 - val_loss: 157.4560\n",
      "Epoch 3388/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 204.8833 - val_loss: 157.3879\n",
      "Epoch 3389/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 237.5662 - val_loss: 157.3303\n",
      "Epoch 3390/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 269.1325 - val_loss: 157.2893\n",
      "Epoch 3391/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 220.3413 - val_loss: 157.2314\n",
      "Epoch 3392/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 234.9367 - val_loss: 157.1631\n",
      "Epoch 3393/10000\n",
      "184/184 [==============================] - 0s 584us/step - loss: 280.3884 - val_loss: 157.0914\n",
      "Epoch 3394/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 283.8029 - val_loss: 157.0143\n",
      "Epoch 3395/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 320.2074 - val_loss: 156.9335\n",
      "Epoch 3396/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 250.1891 - val_loss: 156.8420\n",
      "Epoch 3397/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 246.5669 - val_loss: 156.7253\n",
      "Epoch 3398/10000\n",
      "184/184 [==============================] - 0s 848us/step - loss: 271.2288 - val_loss: 156.5860\n",
      "Epoch 3399/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 243.0042 - val_loss: 156.4276\n",
      "Epoch 3400/10000\n",
      "184/184 [==============================] - 0s 788us/step - loss: 272.5390 - val_loss: 156.2723\n",
      "\n",
      "Epoch 03400: loss did not improve from 247.57060\n",
      "Epoch 3401/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 242.3219 - val_loss: 156.1351\n",
      "Epoch 3402/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 251.3219 - val_loss: 156.0067\n",
      "Epoch 3403/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 244.0722 - val_loss: 155.8887\n",
      "Epoch 3404/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 265.4444 - val_loss: 155.7624\n",
      "Epoch 3405/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 249.8391 - val_loss: 155.6324\n",
      "Epoch 3406/10000\n",
      "184/184 [==============================] - 0s 842us/step - loss: 232.8424 - val_loss: 155.7872\n",
      "Epoch 3407/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 221.7359 - val_loss: 155.8846\n",
      "Epoch 3408/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 332.3544 - val_loss: 155.9061\n",
      "Epoch 3409/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 286.8079 - val_loss: 155.8662\n",
      "Epoch 3410/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 217.8261 - val_loss: 155.8018\n",
      "Epoch 3411/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 226.7646 - val_loss: 155.7533\n",
      "Epoch 3412/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 701us/step - loss: 195.4030 - val_loss: 155.7031\n",
      "Epoch 3413/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 226.1519 - val_loss: 155.6215\n",
      "Epoch 3414/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 200.5197 - val_loss: 155.5584\n",
      "Epoch 3415/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 307.4374 - val_loss: 155.4776\n",
      "Epoch 3416/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 257.2466 - val_loss: 155.4212\n",
      "Epoch 3417/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 252.0480 - val_loss: 155.6461\n",
      "Epoch 3418/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 217.3767 - val_loss: 155.8170\n",
      "Epoch 3419/10000\n",
      "184/184 [==============================] - 0s 788us/step - loss: 276.1478 - val_loss: 155.8946\n",
      "Epoch 3420/10000\n",
      "184/184 [==============================] - 0s 805us/step - loss: 242.9788 - val_loss: 155.8593\n",
      "Epoch 3421/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 274.9280 - val_loss: 155.8292\n",
      "Epoch 3422/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 231.7505 - val_loss: 155.7677\n",
      "Epoch 3423/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 242.5990 - val_loss: 155.7143\n",
      "Epoch 3424/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 227.9580 - val_loss: 155.6585\n",
      "Epoch 3425/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 285.8200 - val_loss: 155.6035\n",
      "Epoch 3426/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 302.0851 - val_loss: 155.5499\n",
      "Epoch 3427/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 259.2854 - val_loss: 155.4806\n",
      "Epoch 3428/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 341.6757 - val_loss: 155.4106\n",
      "Epoch 3429/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 248.9757 - val_loss: 155.3430\n",
      "Epoch 3430/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 246.4552 - val_loss: 155.2746\n",
      "Epoch 3431/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 213.4991 - val_loss: 155.2051\n",
      "Epoch 3432/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 272.5567 - val_loss: 155.1312\n",
      "Epoch 3433/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 285.9406 - val_loss: 155.0512\n",
      "Epoch 3434/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 277.8950 - val_loss: 154.9507\n",
      "Epoch 3435/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 276.3417 - val_loss: 154.8517\n",
      "Epoch 3436/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 257.2650 - val_loss: 154.7522\n",
      "Epoch 3437/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 307.1492 - val_loss: 154.6514\n",
      "Epoch 3438/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 211.9725 - val_loss: 154.5516\n",
      "Epoch 3439/10000\n",
      "184/184 [==============================] - 0s 788us/step - loss: 275.7837 - val_loss: 154.4500\n",
      "Epoch 3440/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 320.3659 - val_loss: 154.3446\n",
      "Epoch 3441/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 275.7173 - val_loss: 154.2380\n",
      "Epoch 3442/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 268.5093 - val_loss: 154.1290\n",
      "Epoch 3443/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 194.1676 - val_loss: 154.0203\n",
      "Epoch 3444/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 265.6118 - val_loss: 153.9190\n",
      "Epoch 3445/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 257.2927 - val_loss: 153.8176\n",
      "Epoch 3446/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 293.5093 - val_loss: 153.7100\n",
      "Epoch 3447/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 235.3346 - val_loss: 153.5759\n",
      "Epoch 3448/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 232.2913 - val_loss: 153.4546\n",
      "Epoch 3449/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 189.2085 - val_loss: 153.3534\n",
      "Epoch 3450/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 285.9112 - val_loss: 153.2151\n",
      "Epoch 3451/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 290.8622 - val_loss: 153.0773\n",
      "Epoch 3452/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 207.8710 - val_loss: 152.9592\n",
      "Epoch 3453/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 248.3637 - val_loss: 152.8461\n",
      "Epoch 3454/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 203.5283 - val_loss: 152.7461\n",
      "Epoch 3455/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 266.2881 - val_loss: 152.6593\n",
      "Epoch 3456/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 302.0030 - val_loss: 152.5662\n",
      "Epoch 3457/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 260.2616 - val_loss: 152.4704\n",
      "Epoch 3458/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 285.6978 - val_loss: 152.3697\n",
      "Epoch 3459/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 306.4517 - val_loss: 152.2677\n",
      "Epoch 3460/10000\n",
      "184/184 [==============================] - 0s 951us/step - loss: 258.1370 - val_loss: 152.1664\n",
      "Epoch 3461/10000\n",
      "184/184 [==============================] - 0s 902us/step - loss: 284.5190 - val_loss: 152.0621\n",
      "Epoch 3462/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 245.7549 - val_loss: 151.9551\n",
      "Epoch 3463/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 259.6468 - val_loss: 151.8591\n",
      "Epoch 3464/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 257.2033 - val_loss: 151.7581\n",
      "Epoch 3465/10000\n",
      "184/184 [==============================] - 0s 799us/step - loss: 285.4404 - val_loss: 151.6566\n",
      "Epoch 3466/10000\n",
      "184/184 [==============================] - 0s 736us/step - loss: 264.2524 - val_loss: 151.5480\n",
      "Epoch 3467/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 261.9281 - val_loss: 151.4293\n",
      "Epoch 3468/10000\n",
      "184/184 [==============================] - 0s 965us/step - loss: 210.9136 - val_loss: 151.3056\n",
      "Epoch 3469/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 268.7703 - val_loss: 151.1793\n",
      "Epoch 3470/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 280.6322 - val_loss: 150.9721\n",
      "Epoch 3471/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 292.4142 - val_loss: 150.6734\n",
      "Epoch 3472/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 307.5454 - val_loss: 150.5693\n",
      "Epoch 3473/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 211.2418 - val_loss: 150.4670\n",
      "Epoch 3474/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 235.3307 - val_loss: 150.3484\n",
      "Epoch 3475/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 330.4458 - val_loss: 150.2332\n",
      "Epoch 3476/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 287.2049 - val_loss: 150.1201\n",
      "Epoch 3477/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 253.6921 - val_loss: 150.0085\n",
      "Epoch 3478/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 252.5233 - val_loss: 149.7141\n",
      "Epoch 3479/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 197.6764 - val_loss: 149.4391\n",
      "Epoch 3480/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 232.4332 - val_loss: 149.3371\n",
      "Epoch 3481/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 295.9394 - val_loss: 149.2140\n",
      "Epoch 3482/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 244.2283 - val_loss: 149.2197\n",
      "Epoch 3483/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 256.4078 - val_loss: 149.1328\n",
      "Epoch 3484/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 296.7459 - val_loss: 149.0043\n",
      "Epoch 3485/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 457us/step - loss: 260.5796 - val_loss: 148.8989\n",
      "Epoch 3486/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 293.8497 - val_loss: 148.7721\n",
      "Epoch 3487/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 238.5255 - val_loss: 148.6284\n",
      "Epoch 3488/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 313.5049 - val_loss: 148.5150\n",
      "Epoch 3489/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 220.8462 - val_loss: 148.4348\n",
      "Epoch 3490/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 267.6409 - val_loss: 148.3691\n",
      "Epoch 3491/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 219.0197 - val_loss: 148.3015\n",
      "Epoch 3492/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 241.0763 - val_loss: 148.2386\n",
      "Epoch 3493/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 232.7169 - val_loss: 148.1893\n",
      "Epoch 3494/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 332.3046 - val_loss: 148.1268\n",
      "Epoch 3495/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 258.1189 - val_loss: 148.0590\n",
      "Epoch 3496/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 287.5985 - val_loss: 147.9859\n",
      "Epoch 3497/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 339.1574 - val_loss: 147.9039\n",
      "Epoch 3498/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 234.2259 - val_loss: 147.8203\n",
      "Epoch 3499/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 309.5041 - val_loss: 147.7379\n",
      "Epoch 3500/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 217.3080 - val_loss: 147.6581\n",
      "\n",
      "Epoch 03500: loss improved from 247.57060 to 217.30795, saving model to C6007C.hdf5\n",
      "Epoch 3501/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 284.5536 - val_loss: 147.5701\n",
      "Epoch 3502/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 308.5270 - val_loss: 147.4704\n",
      "Epoch 3503/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 207.1532 - val_loss: 147.3641\n",
      "Epoch 3504/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 255.0133 - val_loss: 147.2638\n",
      "Epoch 3505/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 278.3349 - val_loss: 147.1530\n",
      "Epoch 3506/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 187.6468 - val_loss: 147.0623\n",
      "Epoch 3507/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 233.7662 - val_loss: 147.1922\n",
      "Epoch 3508/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 233.9176 - val_loss: 147.1748\n",
      "Epoch 3509/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 263.0519 - val_loss: 147.3410\n",
      "Epoch 3510/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 251.5216 - val_loss: 147.3327\n",
      "Epoch 3511/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 284.8523 - val_loss: 147.4897\n",
      "Epoch 3512/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 259.5468 - val_loss: 147.4689\n",
      "Epoch 3513/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 258.9717 - val_loss: 147.4411\n",
      "Epoch 3514/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 315.0182 - val_loss: 147.3618\n",
      "Epoch 3515/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 223.9423 - val_loss: 147.2714\n",
      "Epoch 3516/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 287.2271 - val_loss: 147.1907\n",
      "Epoch 3517/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 302.5211 - val_loss: 147.1159\n",
      "Epoch 3518/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 247.7112 - val_loss: 147.0379\n",
      "Epoch 3519/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 306.6467 - val_loss: 146.9551\n",
      "Epoch 3520/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 310.7159 - val_loss: 146.8673\n",
      "Epoch 3521/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 243.6197 - val_loss: 146.7940\n",
      "Epoch 3522/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 212.4975 - val_loss: 146.7177\n",
      "Epoch 3523/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 277.9885 - val_loss: 146.6353\n",
      "Epoch 3524/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 216.7689 - val_loss: 146.5487\n",
      "Epoch 3525/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 228.3129 - val_loss: 146.4589\n",
      "Epoch 3526/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 311.8888 - val_loss: 146.3723\n",
      "Epoch 3527/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 275.7813 - val_loss: 146.2814\n",
      "Epoch 3528/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 292.4621 - val_loss: 146.1864\n",
      "Epoch 3529/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 223.4170 - val_loss: 146.0861\n",
      "Epoch 3530/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 257.3374 - val_loss: 145.9889\n",
      "Epoch 3531/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 194.8291 - val_loss: 145.8997\n",
      "Epoch 3532/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 258.8912 - val_loss: 145.8140\n",
      "Epoch 3533/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 196.6397 - val_loss: 145.7281\n",
      "Epoch 3534/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 223.6159 - val_loss: 145.6472\n",
      "Epoch 3535/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 252.7046 - val_loss: 145.5680\n",
      "Epoch 3536/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 282.7393 - val_loss: 145.4879\n",
      "Epoch 3537/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 241.8708 - val_loss: 145.4078\n",
      "Epoch 3538/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 232.3564 - val_loss: 145.3284\n",
      "Epoch 3539/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 313.0709 - val_loss: 145.2468\n",
      "Epoch 3540/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 258.4088 - val_loss: 145.1658\n",
      "Epoch 3541/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 214.5267 - val_loss: 145.0949\n",
      "Epoch 3542/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 262.8436 - val_loss: 145.0191\n",
      "Epoch 3543/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 280.0724 - val_loss: 144.9402\n",
      "Epoch 3544/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 327.8774 - val_loss: 144.8546\n",
      "Epoch 3545/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 267.6666 - val_loss: 144.7614\n",
      "Epoch 3546/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 183.7038 - val_loss: 144.6709\n",
      "Epoch 3547/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 197.3550 - val_loss: 144.5841\n",
      "Epoch 3548/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 234.0210 - val_loss: 144.4991\n",
      "Epoch 3549/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 254.6863 - val_loss: 144.4119\n",
      "Epoch 3550/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 259.6661 - val_loss: 144.3183\n",
      "Epoch 3551/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 237.3689 - val_loss: 144.2244\n",
      "Epoch 3552/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 207.9268 - val_loss: 144.1320\n",
      "Epoch 3553/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 279.5299 - val_loss: 144.0376\n",
      "Epoch 3554/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 297.2108 - val_loss: 143.9440\n",
      "Epoch 3555/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 231.8761 - val_loss: 143.8551\n",
      "Epoch 3556/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 201.3762 - val_loss: 143.7707\n",
      "Epoch 3557/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 538us/step - loss: 226.1869 - val_loss: 143.6795\n",
      "Epoch 3558/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 219.2529 - val_loss: 143.5827\n",
      "Epoch 3559/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 220.6567 - val_loss: 143.4901\n",
      "Epoch 3560/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 219.1296 - val_loss: 143.4006\n",
      "Epoch 3561/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 213.9844 - val_loss: 143.3149\n",
      "Epoch 3562/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 192.1733 - val_loss: 143.2349\n",
      "Epoch 3563/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 225.7186 - val_loss: 143.1579\n",
      "Epoch 3564/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 217.8231 - val_loss: 143.0765\n",
      "Epoch 3565/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 266.4416 - val_loss: 142.9942\n",
      "Epoch 3566/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 237.7933 - val_loss: 142.9118\n",
      "Epoch 3567/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 234.6794 - val_loss: 142.8311\n",
      "Epoch 3568/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 260.2551 - val_loss: 142.7489\n",
      "Epoch 3569/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 243.3928 - val_loss: 142.6658\n",
      "Epoch 3570/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 237.1254 - val_loss: 142.5852\n",
      "Epoch 3571/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 253.8018 - val_loss: 142.5089\n",
      "Epoch 3572/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 274.8167 - val_loss: 142.4221\n",
      "Epoch 3573/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 175.9554 - val_loss: 142.3393\n",
      "Epoch 3574/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 258.8307 - val_loss: 142.2558\n",
      "Epoch 3575/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 206.5210 - val_loss: 142.1707\n",
      "Epoch 3576/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 248.7101 - val_loss: 142.0845\n",
      "Epoch 3577/10000\n",
      "184/184 [==============================] - 0s 544us/step - loss: 263.2765 - val_loss: 142.0163\n",
      "Epoch 3578/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 225.2614 - val_loss: 141.9628\n",
      "Epoch 3579/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 201.0668 - val_loss: 141.9061\n",
      "Epoch 3580/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 222.7095 - val_loss: 141.8502\n",
      "Epoch 3581/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 215.0119 - val_loss: 141.7818\n",
      "Epoch 3582/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 263.1197 - val_loss: 141.7016\n",
      "Epoch 3583/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 276.6494 - val_loss: 141.6232\n",
      "Epoch 3584/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 204.7487 - val_loss: 141.5447\n",
      "Epoch 3585/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 265.6102 - val_loss: 141.4653\n",
      "Epoch 3586/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 224.1306 - val_loss: 141.3726\n",
      "Epoch 3587/10000\n",
      "184/184 [==============================] - 0s 525us/step - loss: 223.5157 - val_loss: 141.2679\n",
      "Epoch 3588/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 254.9758 - val_loss: 141.1643\n",
      "Epoch 3589/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 281.3153 - val_loss: 141.0678\n",
      "Epoch 3590/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 212.2287 - val_loss: 140.9753\n",
      "Epoch 3591/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 304.9892 - val_loss: 140.8768\n",
      "Epoch 3592/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 295.8038 - val_loss: 140.7802\n",
      "Epoch 3593/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 262.6244 - val_loss: 140.6822\n",
      "Epoch 3594/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 226.3047 - val_loss: 140.5871\n",
      "Epoch 3595/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 254.3137 - val_loss: 140.4971\n",
      "Epoch 3596/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 260.1572 - val_loss: 140.4127\n",
      "Epoch 3597/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 244.5924 - val_loss: 140.3287\n",
      "Epoch 3598/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 249.3401 - val_loss: 140.2473\n",
      "Epoch 3599/10000\n",
      "184/184 [==============================] - 0s 628us/step - loss: 258.0713 - val_loss: 140.1763\n",
      "Epoch 3600/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 262.4559 - val_loss: 140.0809\n",
      "\n",
      "Epoch 03600: loss did not improve from 217.30795\n",
      "Epoch 3601/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 224.9243 - val_loss: 139.9707\n",
      "Epoch 3602/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 241.7123 - val_loss: 139.8743\n",
      "Epoch 3603/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 205.3986 - val_loss: 139.7931\n",
      "Epoch 3604/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 237.7088 - val_loss: 139.7207\n",
      "Epoch 3605/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 297.2961 - val_loss: 139.6385\n",
      "Epoch 3606/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 251.6994 - val_loss: 139.5693\n",
      "Epoch 3607/10000\n",
      "184/184 [==============================] - 0s 881us/step - loss: 210.8771 - val_loss: 139.5074\n",
      "Epoch 3608/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 258.6595 - val_loss: 139.4474\n",
      "Epoch 3609/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 285.1984 - val_loss: 139.3654\n",
      "Epoch 3610/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 191.2885 - val_loss: 139.2851\n",
      "Epoch 3611/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 230.3933 - val_loss: 139.2068\n",
      "Epoch 3612/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 216.5619 - val_loss: 139.2110\n",
      "Epoch 3613/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 209.4924 - val_loss: 139.2189\n",
      "Epoch 3614/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 207.9761 - val_loss: 139.3111\n",
      "Epoch 3615/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 202.9530 - val_loss: 139.2556\n",
      "Epoch 3616/10000\n",
      "184/184 [==============================] - 0s 804us/step - loss: 248.4322 - val_loss: 139.0812\n",
      "Epoch 3617/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 214.7544 - val_loss: 139.0285\n",
      "Epoch 3618/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 209.4432 - val_loss: 138.9733\n",
      "Epoch 3619/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 258.3825 - val_loss: 138.9132\n",
      "Epoch 3620/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 221.3934 - val_loss: 138.8465\n",
      "Epoch 3621/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 211.3713 - val_loss: 138.7757\n",
      "Epoch 3622/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 272.7820 - val_loss: 138.6996\n",
      "Epoch 3623/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 198.7683 - val_loss: 138.6202\n",
      "Epoch 3624/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 237.2303 - val_loss: 138.5410\n",
      "Epoch 3625/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 215.1746 - val_loss: 138.4545\n",
      "Epoch 3626/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 199.2445 - val_loss: 138.3684\n",
      "Epoch 3627/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 261.6008 - val_loss: 138.3018\n",
      "Epoch 3628/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 201.6201 - val_loss: 138.2357\n",
      "Epoch 3629/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 253.7150 - val_loss: 138.1644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3630/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 241.0889 - val_loss: 138.0885\n",
      "Epoch 3631/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 283.1434 - val_loss: 138.0096\n",
      "Epoch 3632/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 266.6048 - val_loss: 137.9406\n",
      "Epoch 3633/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 208.6160 - val_loss: 137.8681\n",
      "Epoch 3634/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 192.9283 - val_loss: 137.7926\n",
      "Epoch 3635/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 198.7764 - val_loss: 137.7175\n",
      "Epoch 3636/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 255.7460 - val_loss: 137.5584\n",
      "Epoch 3637/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 280.4079 - val_loss: 137.3251\n",
      "Epoch 3638/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 233.8516 - val_loss: 137.1354\n",
      "Epoch 3639/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 200.3647 - val_loss: 137.0501\n",
      "Epoch 3640/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 288.3488 - val_loss: 137.1763\n",
      "Epoch 3641/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 301.2841 - val_loss: 137.1276\n",
      "Epoch 3642/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 246.2766 - val_loss: 136.9563\n",
      "Epoch 3643/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 284.4540 - val_loss: 136.7919\n",
      "Epoch 3644/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 257.6890 - val_loss: 136.7340\n",
      "Epoch 3645/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 271.1273 - val_loss: 136.7257\n",
      "Epoch 3646/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 232.3350 - val_loss: 136.7118\n",
      "Epoch 3647/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 244.8410 - val_loss: 136.6973\n",
      "Epoch 3648/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 225.1496 - val_loss: 136.6569\n",
      "Epoch 3649/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 255.0944 - val_loss: 136.5773\n",
      "Epoch 3650/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 194.0405 - val_loss: 136.4953\n",
      "Epoch 3651/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 194.4627 - val_loss: 136.4173\n",
      "Epoch 3652/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 220.0657 - val_loss: 136.3402\n",
      "Epoch 3653/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 218.1925 - val_loss: 136.2644\n",
      "Epoch 3654/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 239.8097 - val_loss: 136.1917\n",
      "Epoch 3655/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 264.8849 - val_loss: 136.1206\n",
      "Epoch 3656/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 265.6652 - val_loss: 136.0432\n",
      "Epoch 3657/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 238.6337 - val_loss: 135.9769\n",
      "Epoch 3658/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 189.2958 - val_loss: 135.9064\n",
      "Epoch 3659/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 311.2785 - val_loss: 135.8265\n",
      "Epoch 3660/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 298.9244 - val_loss: 135.6548\n",
      "Epoch 3661/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 179.7891 - val_loss: 135.4508\n",
      "Epoch 3662/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 218.2548 - val_loss: 134.9144\n",
      "Epoch 3663/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 242.8278 - val_loss: 134.7275\n",
      "Epoch 3664/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 195.8485 - val_loss: 134.7599\n",
      "Epoch 3665/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 232.8740 - val_loss: 134.2605\n",
      "Epoch 3666/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 203.8085 - val_loss: 133.9946\n",
      "Epoch 3667/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 245.2481 - val_loss: 133.6072\n",
      "Epoch 3668/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 221.6990 - val_loss: 133.4589\n",
      "Epoch 3669/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 256.2455 - val_loss: 132.9981\n",
      "Epoch 3670/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 230.7039 - val_loss: 132.5064\n",
      "Epoch 3671/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 230.5956 - val_loss: 133.6819\n",
      "Epoch 3672/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 295.1478 - val_loss: 132.8983\n",
      "Epoch 3673/10000\n",
      "184/184 [==============================] - 0s 621us/step - loss: 222.7379 - val_loss: 132.4417\n",
      "Epoch 3674/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 292.5053 - val_loss: 132.1516\n",
      "Epoch 3675/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 277.7309 - val_loss: 131.7768\n",
      "Epoch 3676/10000\n",
      "184/184 [==============================] - 0s 493us/step - loss: 268.5353 - val_loss: 131.5719\n",
      "Epoch 3677/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 251.9850 - val_loss: 131.3524\n",
      "Epoch 3678/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 240.9131 - val_loss: 131.1474\n",
      "Epoch 3679/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 222.9637 - val_loss: 130.9528\n",
      "Epoch 3680/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 225.4521 - val_loss: 130.7655\n",
      "Epoch 3681/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 234.1997 - val_loss: 130.6008\n",
      "Epoch 3682/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 210.4277 - val_loss: 130.4589\n",
      "Epoch 3683/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 240.6690 - val_loss: 130.3346\n",
      "Epoch 3684/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 216.8408 - val_loss: 130.2028\n",
      "Epoch 3685/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 198.4091 - val_loss: 130.0018\n",
      "Epoch 3686/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 219.4412 - val_loss: 130.1106\n",
      "Epoch 3687/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 255.8733 - val_loss: 129.6495\n",
      "Epoch 3688/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 203.3037 - val_loss: 129.6552\n",
      "Epoch 3689/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 237.6924 - val_loss: 129.2954\n",
      "Epoch 3690/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 234.4784 - val_loss: 129.2712\n",
      "Epoch 3691/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 183.6128 - val_loss: 129.3561\n",
      "Epoch 3692/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 245.4596 - val_loss: 129.3591\n",
      "Epoch 3693/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 249.9648 - val_loss: 129.4027\n",
      "Epoch 3694/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 207.7261 - val_loss: 129.3651\n",
      "Epoch 3695/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 211.4460 - val_loss: 128.8931\n",
      "Epoch 3696/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 213.7625 - val_loss: 131.3627\n",
      "Epoch 3697/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 236.1551 - val_loss: 131.4307\n",
      "Epoch 3698/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 247.2485 - val_loss: 130.4236\n",
      "Epoch 3699/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 193.2356 - val_loss: 130.0641\n",
      "Epoch 3700/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 230.5927 - val_loss: 129.0902\n",
      "\n",
      "Epoch 03700: loss did not improve from 217.30795\n",
      "Epoch 3701/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 271.4066 - val_loss: 129.4377\n",
      "Epoch 3702/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 511us/step - loss: 299.5949 - val_loss: 128.8711\n",
      "Epoch 3703/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 241.5484 - val_loss: 128.0925\n",
      "Epoch 3704/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 280.9871 - val_loss: 128.1973\n",
      "Epoch 3705/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 231.4548 - val_loss: 127.9896\n",
      "Epoch 3706/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 222.8955 - val_loss: 126.6193\n",
      "Epoch 3707/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 178.311 - 0s 603us/step - loss: 218.3392 - val_loss: 126.2072\n",
      "Epoch 3708/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 193.1822 - val_loss: 126.0157\n",
      "Epoch 3709/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 185.5544 - val_loss: 125.8547\n",
      "Epoch 3710/10000\n",
      "184/184 [==============================] - 0s 842us/step - loss: 246.4298 - val_loss: 125.7244\n",
      "Epoch 3711/10000\n",
      "184/184 [==============================] - 0s 772us/step - loss: 247.3090 - val_loss: 125.5930\n",
      "Epoch 3712/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 216.6227 - val_loss: 125.4593\n",
      "Epoch 3713/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 255.0087 - val_loss: 125.3467\n",
      "Epoch 3714/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 301.6061 - val_loss: 125.2347\n",
      "Epoch 3715/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 193.1170 - val_loss: 125.1364\n",
      "Epoch 3716/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 212.8367 - val_loss: 125.0466\n",
      "Epoch 3717/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 277.7682 - val_loss: 124.9542\n",
      "Epoch 3718/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 205.0843 - val_loss: 124.8656\n",
      "Epoch 3719/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 207.4752 - val_loss: 124.7835\n",
      "Epoch 3720/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 247.8079 - val_loss: 124.7010\n",
      "Epoch 3721/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 219.1734 - val_loss: 124.6214\n",
      "Epoch 3722/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 268.5304 - val_loss: 124.4967\n",
      "Epoch 3723/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 214.7886 - val_loss: 124.3794\n",
      "Epoch 3724/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 241.2628 - val_loss: 124.2850\n",
      "Epoch 3725/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 222.3855 - val_loss: 124.2067\n",
      "Epoch 3726/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 307.5803 - val_loss: 124.1346\n",
      "Epoch 3727/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 258.8968 - val_loss: 124.0590\n",
      "Epoch 3728/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 235.6517 - val_loss: 123.9803\n",
      "Epoch 3729/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 264.2990 - val_loss: 123.9035\n",
      "Epoch 3730/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 203.1130 - val_loss: 123.8227\n",
      "Epoch 3731/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 179.4899 - val_loss: 123.7314\n",
      "Epoch 3732/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 226.1684 - val_loss: 123.6417\n",
      "Epoch 3733/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 280.2183 - val_loss: 123.5604\n",
      "Epoch 3734/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 247.3459 - val_loss: 123.4874\n",
      "Epoch 3735/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 192.8032 - val_loss: 123.4231\n",
      "Epoch 3736/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 192.6273 - val_loss: 123.3946\n",
      "Epoch 3737/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 195.0727 - val_loss: 123.5529\n",
      "Epoch 3738/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 255.0095 - val_loss: 124.0247\n",
      "Epoch 3739/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 248.2279 - val_loss: 124.5181\n",
      "Epoch 3740/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 260.9936 - val_loss: 124.7269\n",
      "Epoch 3741/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 207.3602 - val_loss: 124.6402\n",
      "Epoch 3742/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 273.2331 - val_loss: 124.5554\n",
      "Epoch 3743/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 201.0226 - val_loss: 124.4719\n",
      "Epoch 3744/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 271.9427 - val_loss: 124.3870\n",
      "Epoch 3745/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 259.0379 - val_loss: 124.3011\n",
      "Epoch 3746/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 260.8080 - val_loss: 124.2173\n",
      "Epoch 3747/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 249.2205 - val_loss: 124.1351\n",
      "Epoch 3748/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 197.7300 - val_loss: 124.0471\n",
      "Epoch 3749/10000\n",
      "184/184 [==============================] - 0s 418us/step - loss: 223.6678 - val_loss: 123.9539\n",
      "Epoch 3750/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 303.2502 - val_loss: 123.8614\n",
      "Epoch 3751/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 300.3810 - val_loss: 123.7705\n",
      "Epoch 3752/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 194.0036 - val_loss: 123.6786\n",
      "Epoch 3753/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 231.6187 - val_loss: 123.5854\n",
      "Epoch 3754/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 201.8154 - val_loss: 123.4961\n",
      "Epoch 3755/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 314.9255 - val_loss: 123.3981\n",
      "Epoch 3756/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 233.5598 - val_loss: 123.2895\n",
      "Epoch 3757/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 194.8834 - val_loss: 123.1789\n",
      "Epoch 3758/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 214.0646 - val_loss: 122.7917\n",
      "Epoch 3759/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 199.0565 - val_loss: 122.4823\n",
      "Epoch 3760/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 206.9426 - val_loss: 122.2977\n",
      "Epoch 3761/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 178.8900 - val_loss: 122.1996\n",
      "Epoch 3762/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 273.6197 - val_loss: 121.9097\n",
      "Epoch 3763/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 224.2020 - val_loss: 121.6440\n",
      "Epoch 3764/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 209.9799 - val_loss: 121.4075\n",
      "Epoch 3765/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 247.8288 - val_loss: 121.2800\n",
      "Epoch 3766/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 279.7713 - val_loss: 121.2041\n",
      "Epoch 3767/10000\n",
      "184/184 [==============================] - 0s 435us/step - loss: 271.5751 - val_loss: 121.2328\n",
      "Epoch 3768/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 202.6047 - val_loss: 121.2220\n",
      "Epoch 3769/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 206.6863 - val_loss: 121.1891\n",
      "Epoch 3770/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 202.9683 - val_loss: 121.1141\n",
      "Epoch 3771/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 238.0854 - val_loss: 121.9670\n",
      "Epoch 3772/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 161.5755 - val_loss: 121.9636\n",
      "Epoch 3773/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 311.1713 - val_loss: 121.9327\n",
      "Epoch 3774/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 214.5384 - val_loss: 121.8819\n",
      "Epoch 3775/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 478us/step - loss: 254.9775 - val_loss: 121.8242\n",
      "Epoch 3776/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 185.6480 - val_loss: 121.7661\n",
      "Epoch 3777/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 234.9089 - val_loss: 121.6907\n",
      "Epoch 3778/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 197.2563 - val_loss: 121.6130\n",
      "Epoch 3779/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 215.7359 - val_loss: 121.5347\n",
      "Epoch 3780/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 228.4070 - val_loss: 121.4563\n",
      "Epoch 3781/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 199.8579 - val_loss: 121.3814\n",
      "Epoch 3782/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 221.0705 - val_loss: 121.3057\n",
      "Epoch 3783/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 191.3760 - val_loss: 121.2291\n",
      "Epoch 3784/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 237.5095 - val_loss: 121.1632\n",
      "Epoch 3785/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 205.3580 - val_loss: 121.1011\n",
      "Epoch 3786/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 203.5397 - val_loss: 121.0471\n",
      "Epoch 3787/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 197.4050 - val_loss: 120.9923\n",
      "Epoch 3788/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 290.3045 - val_loss: 120.9440\n",
      "Epoch 3789/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 212.4223 - val_loss: 120.8867\n",
      "Epoch 3790/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 226.0800 - val_loss: 120.8259\n",
      "Epoch 3791/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 230.1176 - val_loss: 120.7623\n",
      "Epoch 3792/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 268.6716 - val_loss: 120.6959\n",
      "Epoch 3793/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 264.3538 - val_loss: 120.6228\n",
      "Epoch 3794/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 172.7896 - val_loss: 120.5492\n",
      "Epoch 3795/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 214.7083 - val_loss: 120.4770\n",
      "Epoch 3796/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 218.9857 - val_loss: 120.3962\n",
      "Epoch 3797/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 182.3145 - val_loss: 120.3038\n",
      "Epoch 3798/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 279.3333 - val_loss: 118.9499\n",
      "Epoch 3799/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 292.3751 - val_loss: 118.7140\n",
      "Epoch 3800/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 203.8100 - val_loss: 118.6316\n",
      "\n",
      "Epoch 03800: loss improved from 217.30795 to 203.80998, saving model to C6007C.hdf5\n",
      "Epoch 3801/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 229.6993 - val_loss: 118.5428\n",
      "Epoch 3802/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 191.0055 - val_loss: 118.4507\n",
      "Epoch 3803/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 254.5473 - val_loss: 118.3609\n",
      "Epoch 3804/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 262.3765 - val_loss: 118.2794\n",
      "Epoch 3805/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 179.8886 - val_loss: 118.2046\n",
      "Epoch 3806/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 197.1864 - val_loss: 118.1386\n",
      "Epoch 3807/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 227.5958 - val_loss: 118.0838\n",
      "Epoch 3808/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 232.6737 - val_loss: 118.0223\n",
      "Epoch 3809/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 254.8799 - val_loss: 117.9610\n",
      "Epoch 3810/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 216.5512 - val_loss: 117.8999\n",
      "Epoch 3811/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 211.0619 - val_loss: 117.8357\n",
      "Epoch 3812/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 228.2088 - val_loss: 117.7746\n",
      "Epoch 3813/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 183.2054 - val_loss: 117.7054\n",
      "Epoch 3814/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 235.5225 - val_loss: 117.6316\n",
      "Epoch 3815/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 180.0793 - val_loss: 117.5664\n",
      "Epoch 3816/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 244.2570 - val_loss: 117.5021\n",
      "Epoch 3817/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 186.2633 - val_loss: 117.4357\n",
      "Epoch 3818/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 241.4090 - val_loss: 117.4132\n",
      "Epoch 3819/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 233.6288 - val_loss: 117.5206\n",
      "Epoch 3820/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 237.0109 - val_loss: 117.6523\n",
      "Epoch 3821/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 247.5460 - val_loss: 117.7217\n",
      "Epoch 3822/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 227.6428 - val_loss: 117.7141\n",
      "Epoch 3823/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 205.7299 - val_loss: 117.6849\n",
      "Epoch 3824/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 223.9709 - val_loss: 117.6336\n",
      "Epoch 3825/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 222.7645 - val_loss: 117.5686\n",
      "Epoch 3826/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 254.6437 - val_loss: 117.5017\n",
      "Epoch 3827/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 209.7671 - val_loss: 117.4356\n",
      "Epoch 3828/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 206.2427 - val_loss: 117.3678\n",
      "Epoch 3829/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 207.1628 - val_loss: 117.2983\n",
      "Epoch 3830/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 181.9076 - val_loss: 117.2355\n",
      "Epoch 3831/10000\n",
      "184/184 [==============================] - 0s 577us/step - loss: 229.0278 - val_loss: 117.1700\n",
      "Epoch 3832/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 229.5422 - val_loss: 117.0936\n",
      "Epoch 3833/10000\n",
      "184/184 [==============================] - 0s 799us/step - loss: 176.5857 - val_loss: 117.0182\n",
      "Epoch 3834/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 282.0970 - val_loss: 116.9361\n",
      "Epoch 3835/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 144.3314 - val_loss: 116.8548\n",
      "Epoch 3836/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 255.6977 - val_loss: 116.7763\n",
      "Epoch 3837/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 185.1855 - val_loss: 116.7020\n",
      "Epoch 3838/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 225.6643 - val_loss: 116.6233\n",
      "Epoch 3839/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 260.6294 - val_loss: 116.5206\n",
      "Epoch 3840/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 188.2547 - val_loss: 116.4279\n",
      "Epoch 3841/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 278.7708 - val_loss: 116.3325\n",
      "Epoch 3842/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 244.7801 - val_loss: 116.2547\n",
      "Epoch 3843/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 188.6275 - val_loss: 116.1873\n",
      "Epoch 3844/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 247.2939 - val_loss: 116.1211\n",
      "Epoch 3845/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 294.9507 - val_loss: 116.0569\n",
      "Epoch 3846/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 158.0477 - val_loss: 115.9945\n",
      "Epoch 3847/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 500us/step - loss: 196.6746 - val_loss: 115.9284\n",
      "Epoch 3848/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 209.7839 - val_loss: 115.8592\n",
      "Epoch 3849/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 292.8967 - val_loss: 115.7927\n",
      "Epoch 3850/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 225.1369 - val_loss: 115.7308\n",
      "Epoch 3851/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 213.3732 - val_loss: 115.6682\n",
      "Epoch 3852/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 198.5201 - val_loss: 115.6061\n",
      "Epoch 3853/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 218.5421 - val_loss: 115.5388\n",
      "Epoch 3854/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 198.4533 - val_loss: 115.4697\n",
      "Epoch 3855/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 234.4296 - val_loss: 115.3982\n",
      "Epoch 3856/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 203.6636 - val_loss: 115.3229\n",
      "Epoch 3857/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 266.9244 - val_loss: 115.2458\n",
      "Epoch 3858/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 187.1986 - val_loss: 115.1723\n",
      "Epoch 3859/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 231.2720 - val_loss: 115.1006\n",
      "Epoch 3860/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 211.8030 - val_loss: 115.0279\n",
      "Epoch 3861/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 199.4113 - val_loss: 114.9534\n",
      "Epoch 3862/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 226.1261 - val_loss: 114.8761\n",
      "Epoch 3863/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 204.6291 - val_loss: 114.8010\n",
      "Epoch 3864/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 216.8956 - val_loss: 114.7262\n",
      "Epoch 3865/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 270.5408 - val_loss: 114.6421\n",
      "Epoch 3866/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 213.9720 - val_loss: 114.5577\n",
      "Epoch 3867/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 213.1962 - val_loss: 114.4736\n",
      "Epoch 3868/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 208.7705 - val_loss: 114.3890\n",
      "Epoch 3869/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 149.6454 - val_loss: 114.3101\n",
      "Epoch 3870/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 191.2256 - val_loss: 114.2319\n",
      "Epoch 3871/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 212.2834 - val_loss: 114.1538\n",
      "Epoch 3872/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 213.3987 - val_loss: 114.0753\n",
      "Epoch 3873/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 238.4153 - val_loss: 113.9958\n",
      "Epoch 3874/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 223.1620 - val_loss: 113.9160\n",
      "Epoch 3875/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 199.3317 - val_loss: 113.8444\n",
      "Epoch 3876/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 191.3075 - val_loss: 113.7763\n",
      "Epoch 3877/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 208.6345 - val_loss: 113.7125\n",
      "Epoch 3878/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 232.4800 - val_loss: 113.6532\n",
      "Epoch 3879/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 215.1366 - val_loss: 113.5868\n",
      "Epoch 3880/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 203.3282 - val_loss: 113.5246\n",
      "Epoch 3881/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 215.6244 - val_loss: 113.4635\n",
      "Epoch 3882/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 197.9450 - val_loss: 113.3986\n",
      "Epoch 3883/10000\n",
      "184/184 [==============================] - 0s 875us/step - loss: 172.4200 - val_loss: 113.3350\n",
      "Epoch 3884/10000\n",
      "184/184 [==============================] - 0s 761us/step - loss: 215.4299 - val_loss: 113.2718\n",
      "Epoch 3885/10000\n",
      "184/184 [==============================] - 0s 804us/step - loss: 257.7096 - val_loss: 113.2052\n",
      "Epoch 3886/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 229.7024 - val_loss: 113.1377\n",
      "Epoch 3887/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 268.3538 - val_loss: 113.0668\n",
      "Epoch 3888/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 182.9552 - val_loss: 112.9950\n",
      "Epoch 3889/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 233.4813 - val_loss: 112.9230\n",
      "Epoch 3890/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 177.0323 - val_loss: 112.8541\n",
      "Epoch 3891/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 221.8246 - val_loss: 112.7783\n",
      "Epoch 3892/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 204.5527 - val_loss: 112.7052\n",
      "Epoch 3893/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 308.9447 - val_loss: 112.6264\n",
      "Epoch 3894/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 224.6168 - val_loss: 112.6542\n",
      "Epoch 3895/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 231.7871 - val_loss: 113.1404\n",
      "Epoch 3896/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 192.1970 - val_loss: 113.3065\n",
      "Epoch 3897/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 230.7972 - val_loss: 112.4058\n",
      "Epoch 3898/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 197.6018 - val_loss: 112.1781\n",
      "Epoch 3899/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 230.9332 - val_loss: 112.7338\n",
      "Epoch 3900/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 212.9358 - val_loss: 112.5190\n",
      "\n",
      "Epoch 03900: loss did not improve from 203.80998\n",
      "Epoch 3901/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 207.4790 - val_loss: 111.8807\n",
      "Epoch 3902/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 163.8216 - val_loss: 111.4324\n",
      "Epoch 3903/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 177.6123 - val_loss: 111.0381\n",
      "Epoch 3904/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 185.4046 - val_loss: 110.7070\n",
      "Epoch 3905/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 187.4432 - val_loss: 110.4193\n",
      "Epoch 3906/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 175.6940 - val_loss: 110.1657\n",
      "Epoch 3907/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 217.1716 - val_loss: 109.9183\n",
      "Epoch 3908/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 197.5754 - val_loss: 109.7068\n",
      "Epoch 3909/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 179.6042 - val_loss: 109.5000\n",
      "Epoch 3910/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 232.4626 - val_loss: 109.3453\n",
      "Epoch 3911/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 250.7996 - val_loss: 109.1782\n",
      "Epoch 3912/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 202.5287 - val_loss: 108.9985\n",
      "Epoch 3913/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 196.3401 - val_loss: 108.8361\n",
      "Epoch 3914/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 171.2768 - val_loss: 108.7055\n",
      "Epoch 3915/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 185.8214 - val_loss: 108.5810\n",
      "Epoch 3916/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 238.1723 - val_loss: 108.4636\n",
      "Epoch 3917/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 159.9787 - val_loss: 108.3440\n",
      "Epoch 3918/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 228.7369 - val_loss: 108.2571\n",
      "Epoch 3919/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 189.2430 - val_loss: 108.1813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3920/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 241.1981 - val_loss: 108.1113\n",
      "Epoch 3921/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 194.1965 - val_loss: 108.0389\n",
      "Epoch 3922/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 214.4361 - val_loss: 107.9642\n",
      "Epoch 3923/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 180.7471 - val_loss: 107.8180\n",
      "Epoch 3924/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 284.1616 - val_loss: 107.6971\n",
      "Epoch 3925/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 191.6244 - val_loss: 107.5900\n",
      "Epoch 3926/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 233.250 - 0s 598us/step - loss: 211.0203 - val_loss: 107.4799\n",
      "Epoch 3927/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 169.8461 - val_loss: 107.3753\n",
      "Epoch 3928/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 158.9825 - val_loss: 107.2673\n",
      "Epoch 3929/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 263.3607 - val_loss: 107.1582\n",
      "Epoch 3930/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 245.2402 - val_loss: 107.0650\n",
      "Epoch 3931/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 205.7840 - val_loss: 106.9603\n",
      "Epoch 3932/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 219.8102 - val_loss: 106.8822\n",
      "Epoch 3933/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 192.8922 - val_loss: 106.8107\n",
      "Epoch 3934/10000\n",
      "184/184 [==============================] - 0s 606us/step - loss: 221.8161 - val_loss: 106.7445\n",
      "Epoch 3935/10000\n",
      "184/184 [==============================] - 0s 459us/step - loss: 219.8272 - val_loss: 106.6816\n",
      "Epoch 3936/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 237.4918 - val_loss: 106.6198\n",
      "Epoch 3937/10000\n",
      "184/184 [==============================] - 0s 682us/step - loss: 189.2325 - val_loss: 106.5546\n",
      "Epoch 3938/10000\n",
      "184/184 [==============================] - 0s 671us/step - loss: 197.3163 - val_loss: 106.4885\n",
      "Epoch 3939/10000\n",
      "184/184 [==============================] - 0s 568us/step - loss: 151.8138 - val_loss: 106.4229\n",
      "Epoch 3940/10000\n",
      "184/184 [==============================] - 0s 579us/step - loss: 217.5951 - val_loss: 106.3622\n",
      "Epoch 3941/10000\n",
      "184/184 [==============================] - 0s 606us/step - loss: 209.1066 - val_loss: 106.3040\n",
      "Epoch 3942/10000\n",
      "184/184 [==============================] - 0s 606us/step - loss: 220.6846 - val_loss: 106.2631\n",
      "Epoch 3943/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 236.0053 - val_loss: 106.2246\n",
      "Epoch 3944/10000\n",
      "184/184 [==============================] - 0s 563us/step - loss: 193.3697 - val_loss: 106.1704\n",
      "Epoch 3945/10000\n",
      "184/184 [==============================] - 0s 704us/step - loss: 227.7659 - val_loss: 106.1172\n",
      "Epoch 3946/10000\n",
      "184/184 [==============================] - 0s 984us/step - loss: 240.5494 - val_loss: 106.0698\n",
      "Epoch 3947/10000\n",
      "184/184 [==============================] - 0s 884us/step - loss: 175.6126 - val_loss: 106.0069\n",
      "Epoch 3948/10000\n",
      "184/184 [==============================] - 0s 918us/step - loss: 232.5950 - val_loss: 105.9415\n",
      "Epoch 3949/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 211.2994 - val_loss: 105.8695\n",
      "Epoch 3950/10000\n",
      "184/184 [==============================] - 0s 870us/step - loss: 213.3933 - val_loss: 105.7903\n",
      "Epoch 3951/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 173.7571 - val_loss: 105.7054\n",
      "Epoch 3952/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 196.8693 - val_loss: 105.6273\n",
      "Epoch 3953/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 256.4726 - val_loss: 105.5585\n",
      "Epoch 3954/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 216.3591 - val_loss: 105.4951\n",
      "Epoch 3955/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 248.4671 - val_loss: 105.4305\n",
      "Epoch 3956/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 209.5377 - val_loss: 105.3669\n",
      "Epoch 3957/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 207.3873 - val_loss: 105.3043\n",
      "Epoch 3958/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 269.3395 - val_loss: 105.2418\n",
      "Epoch 3959/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 192.7817 - val_loss: 105.1773\n",
      "Epoch 3960/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 209.8532 - val_loss: 105.1138\n",
      "Epoch 3961/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 247.8283 - val_loss: 105.0494\n",
      "Epoch 3962/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 193.6839 - val_loss: 104.9869\n",
      "Epoch 3963/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 230.4726 - val_loss: 104.9243\n",
      "Epoch 3964/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 220.7615 - val_loss: 104.8553\n",
      "Epoch 3965/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 181.3230 - val_loss: 104.7857\n",
      "Epoch 3966/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 176.4949 - val_loss: 104.7199\n",
      "Epoch 3967/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 160.3481 - val_loss: 104.6559\n",
      "Epoch 3968/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 173.1645 - val_loss: 104.5878\n",
      "Epoch 3969/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 191.1404 - val_loss: 104.4051\n",
      "Epoch 3970/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 265.0297 - val_loss: 104.0971\n",
      "Epoch 3971/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 180.4414 - val_loss: 103.8475\n",
      "Epoch 3972/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 183.9064 - val_loss: 103.6647\n",
      "Epoch 3973/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 184.0424 - val_loss: 103.5315\n",
      "Epoch 3974/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 209.3320 - val_loss: 103.4093\n",
      "Epoch 3975/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 193.3192 - val_loss: 103.2894\n",
      "Epoch 3976/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 242.0362 - val_loss: 103.1636\n",
      "Epoch 3977/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 185.2528 - val_loss: 103.0499\n",
      "Epoch 3978/10000\n",
      "184/184 [==============================] - 0s 957us/step - loss: 186.5583 - val_loss: 102.9372\n",
      "Epoch 3979/10000\n",
      "184/184 [==============================] - 0s 832us/step - loss: 214.0538 - val_loss: 102.8397\n",
      "Epoch 3980/10000\n",
      "184/184 [==============================] - 0s 848us/step - loss: 226.4456 - val_loss: 102.7398\n",
      "Epoch 3981/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 222.5984 - val_loss: 102.6517\n",
      "Epoch 3982/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 272.8569 - val_loss: 102.5635\n",
      "Epoch 3983/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 217.3285 - val_loss: 102.5474\n",
      "Epoch 3984/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 240.6432 - val_loss: 102.5183\n",
      "Epoch 3985/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 146.5969 - val_loss: 102.4796\n",
      "Epoch 3986/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 213.9993 - val_loss: 102.4306\n",
      "Epoch 3987/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 216.8017 - val_loss: 102.4310\n",
      "Epoch 3988/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 218.2413 - val_loss: 102.4197\n",
      "Epoch 3989/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 201.4155 - val_loss: 102.3816\n",
      "Epoch 3990/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 182.1939 - val_loss: 102.3334\n",
      "Epoch 3991/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 183.5964 - val_loss: 102.2750\n",
      "Epoch 3992/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 201.3243 - val_loss: 102.2067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3993/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 192.0838 - val_loss: 102.1488\n",
      "Epoch 3994/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 164.0121 - val_loss: 102.1015\n",
      "Epoch 3995/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 204.0861 - val_loss: 102.0654\n",
      "Epoch 3996/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 246.2394 - val_loss: 102.0238\n",
      "Epoch 3997/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 178.9182 - val_loss: 101.9785\n",
      "Epoch 3998/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 175.0558 - val_loss: 101.9232\n",
      "Epoch 3999/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 190.5998 - val_loss: 101.8624\n",
      "Epoch 4000/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 191.9775 - val_loss: 101.8467\n",
      "\n",
      "Epoch 04000: loss improved from 203.80998 to 191.97749, saving model to C6007C.hdf5\n",
      "Epoch 4001/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 188.9442 - val_loss: 101.8982\n",
      "Epoch 4002/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 225.0082 - val_loss: 101.9568\n",
      "Epoch 4003/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 263.5955 - val_loss: 101.9809\n",
      "Epoch 4004/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 211.9691 - val_loss: 101.9811\n",
      "Epoch 4005/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 193.2487 - val_loss: 101.9670\n",
      "Epoch 4006/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 175.3681 - val_loss: 101.9402\n",
      "Epoch 4007/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 179.1892 - val_loss: 101.9026\n",
      "Epoch 4008/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 223.4172 - val_loss: 101.8738\n",
      "Epoch 4009/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 206.4436 - val_loss: 101.8420\n",
      "Epoch 4010/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 207.7383 - val_loss: 101.7772\n",
      "Epoch 4011/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 284.1964 - val_loss: 101.6792\n",
      "Epoch 4012/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 205.9780 - val_loss: 101.5835\n",
      "Epoch 4013/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 168.0871 - val_loss: 101.4904\n",
      "Epoch 4014/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 177.9290 - val_loss: 101.4002\n",
      "Epoch 4015/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 186.4737 - val_loss: 101.3164\n",
      "Epoch 4016/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 195.6567 - val_loss: 101.2405\n",
      "Epoch 4017/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 183.4899 - val_loss: 99.0546\n",
      "Epoch 4018/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 175.7569 - val_loss: 98.4368\n",
      "Epoch 4019/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 200.2232 - val_loss: 98.6715\n",
      "Epoch 4020/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 237.3569 - val_loss: 98.8844\n",
      "Epoch 4021/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 147.7115 - val_loss: 98.0800\n",
      "Epoch 4022/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 205.8702 - val_loss: 98.2518\n",
      "Epoch 4023/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 232.1038 - val_loss: 98.3143\n",
      "Epoch 4024/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 215.9880 - val_loss: 98.2049\n",
      "Epoch 4025/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 181.5967 - val_loss: 98.0181\n",
      "Epoch 4026/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 216.3343 - val_loss: 97.8417\n",
      "Epoch 4027/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 189.1013 - val_loss: 97.7131\n",
      "Epoch 4028/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 179.3477 - val_loss: 97.6139\n",
      "Epoch 4029/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 212.6528 - val_loss: 97.5243\n",
      "Epoch 4030/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 171.6616 - val_loss: 97.4400\n",
      "Epoch 4031/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 202.9720 - val_loss: 97.3576\n",
      "Epoch 4032/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 176.2823 - val_loss: 97.2794\n",
      "Epoch 4033/10000\n",
      "184/184 [==============================] - 0s 750us/step - loss: 269.0934 - val_loss: 97.1969\n",
      "Epoch 4034/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 203.8824 - val_loss: 97.0951\n",
      "Epoch 4035/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 254.7860 - val_loss: 97.0158\n",
      "Epoch 4036/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 156.0323 - val_loss: 96.9349\n",
      "Epoch 4037/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 164.6837 - val_loss: 96.8704\n",
      "Epoch 4038/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 230.8362 - val_loss: 96.7959\n",
      "Epoch 4039/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 177.9062 - val_loss: 96.7209\n",
      "Epoch 4040/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 200.1599 - val_loss: 96.6637\n",
      "Epoch 4041/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 199.9711 - val_loss: 96.6162\n",
      "Epoch 4042/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 168.5270 - val_loss: 96.5714\n",
      "Epoch 4043/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 199.6527 - val_loss: 96.5310\n",
      "Epoch 4044/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 261.8089 - val_loss: 96.4990\n",
      "Epoch 4045/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 202.5703 - val_loss: 96.4693\n",
      "Epoch 4046/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 255.8244 - val_loss: 96.4287\n",
      "Epoch 4047/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 211.8126 - val_loss: 96.3799\n",
      "Epoch 4048/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 151.1995 - val_loss: 96.3304\n",
      "Epoch 4049/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 229.0923 - val_loss: 96.2829\n",
      "Epoch 4050/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 163.6236 - val_loss: 96.2639\n",
      "Epoch 4051/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 185.9781 - val_loss: 96.2371\n",
      "Epoch 4052/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 184.1619 - val_loss: 96.2104\n",
      "Epoch 4053/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 175.8145 - val_loss: 96.1701\n",
      "Epoch 4054/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 166.4811 - val_loss: 96.1442\n",
      "Epoch 4055/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 157.7935 - val_loss: 95.8978\n",
      "Epoch 4056/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 232.1910 - val_loss: 95.6970\n",
      "Epoch 4057/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 203.9070 - val_loss: 95.5596\n",
      "Epoch 4058/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 274.0388 - val_loss: 95.4577\n",
      "Epoch 4059/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 195.8867 - val_loss: 95.4000\n",
      "Epoch 4060/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 241.3109 - val_loss: 95.3416\n",
      "Epoch 4061/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 215.4560 - val_loss: 95.2858\n",
      "Epoch 4062/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 167.3438 - val_loss: 95.2277\n",
      "Epoch 4063/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 247.2255 - val_loss: 95.1507\n",
      "Epoch 4064/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 234.7720 - val_loss: 95.0667\n",
      "Epoch 4065/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 187.0653 - val_loss: 94.9670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4066/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 211.2793 - val_loss: 94.8692\n",
      "Epoch 4067/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 219.8999 - val_loss: 94.7800\n",
      "Epoch 4068/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 237.5104 - val_loss: 94.7025\n",
      "Epoch 4069/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 225.5286 - val_loss: 94.6294\n",
      "Epoch 4070/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 213.3498 - val_loss: 94.5578\n",
      "Epoch 4071/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 219.8283 - val_loss: 94.4789\n",
      "Epoch 4072/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 233.2456 - val_loss: 94.3999\n",
      "Epoch 4073/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 264.8168 - val_loss: 94.3169\n",
      "Epoch 4074/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 166.0447 - val_loss: 94.2079\n",
      "Epoch 4075/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 202.5322 - val_loss: 94.1094\n",
      "Epoch 4076/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 173.7930 - val_loss: 94.0169\n",
      "Epoch 4077/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 209.6325 - val_loss: 93.9124\n",
      "Epoch 4078/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 203.4385 - val_loss: 93.8114\n",
      "Epoch 4079/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 220.8572 - val_loss: 93.7219\n",
      "Epoch 4080/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 203.9071 - val_loss: 93.6349\n",
      "Epoch 4081/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 203.1340 - val_loss: 93.5563\n",
      "Epoch 4082/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 176.0239 - val_loss: 93.4843\n",
      "Epoch 4083/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 219.5466 - val_loss: 93.4800\n",
      "Epoch 4084/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 238.913 - 0s 440us/step - loss: 207.9657 - val_loss: 93.5282\n",
      "Epoch 4085/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 200.1403 - val_loss: 93.5554\n",
      "Epoch 4086/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 169.6172 - val_loss: 93.5707\n",
      "Epoch 4087/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 158.7392 - val_loss: 93.5757\n",
      "Epoch 4088/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 214.8591 - val_loss: 93.5653\n",
      "Epoch 4089/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 184.2978 - val_loss: 93.5438\n",
      "Epoch 4090/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 173.542 - 0s 522us/step - loss: 166.1820 - val_loss: 93.5148\n",
      "Epoch 4091/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 199.6077 - val_loss: 93.4702\n",
      "Epoch 4092/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 185.1031 - val_loss: 93.4243\n",
      "Epoch 4093/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 206.1844 - val_loss: 93.3809\n",
      "Epoch 4094/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 165.8256 - val_loss: 93.3431\n",
      "Epoch 4095/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 180.3775 - val_loss: 93.3086\n",
      "Epoch 4096/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 200.4851 - val_loss: 93.2923\n",
      "Epoch 4097/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 239.2603 - val_loss: 93.2580\n",
      "Epoch 4098/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 180.2560 - val_loss: 93.2204\n",
      "Epoch 4099/10000\n",
      "184/184 [==============================] - 0s 698us/step - loss: 169.1905 - val_loss: 93.1797\n",
      "Epoch 4100/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 233.5175 - val_loss: 93.1339\n",
      "\n",
      "Epoch 04100: loss did not improve from 191.97749\n",
      "Epoch 4101/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 255.0214 - val_loss: 93.0801\n",
      "Epoch 4102/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 219.2883 - val_loss: 93.0187\n",
      "Epoch 4103/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 183.6815 - val_loss: 92.9548\n",
      "Epoch 4104/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 176.5993 - val_loss: 92.8913\n",
      "Epoch 4105/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 190.5211 - val_loss: 92.8216\n",
      "Epoch 4106/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 182.394 - 0s 533us/step - loss: 179.9575 - val_loss: 92.7515\n",
      "Epoch 4107/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 194.3905 - val_loss: 92.6901\n",
      "Epoch 4108/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 142.4934 - val_loss: 92.6319\n",
      "Epoch 4109/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 150.1353 - val_loss: 92.5746\n",
      "Epoch 4110/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 168.8739 - val_loss: 92.5201\n",
      "Epoch 4111/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 192.6337 - val_loss: 92.4659\n",
      "Epoch 4112/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 264.3427 - val_loss: 92.4091\n",
      "Epoch 4113/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 158.6965 - val_loss: 92.3516\n",
      "Epoch 4114/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 186.2544 - val_loss: 92.2941\n",
      "Epoch 4115/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 199.3240 - val_loss: 92.2405\n",
      "Epoch 4116/10000\n",
      "184/184 [==============================] - 0s 761us/step - loss: 200.1237 - val_loss: 92.1923\n",
      "Epoch 4117/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 198.2454 - val_loss: 92.1422\n",
      "Epoch 4118/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 190.2264 - val_loss: 92.0941\n",
      "Epoch 4119/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 201.9401 - val_loss: 92.0456\n",
      "Epoch 4120/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 164.4127 - val_loss: 91.9962\n",
      "Epoch 4121/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 159.3959 - val_loss: 91.9475\n",
      "Epoch 4122/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 220.1242 - val_loss: 91.8963\n",
      "Epoch 4123/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 204.5921 - val_loss: 91.8431\n",
      "Epoch 4124/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 172.5125 - val_loss: 91.7904\n",
      "Epoch 4125/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 159.5944 - val_loss: 91.7336\n",
      "Epoch 4126/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 191.5851 - val_loss: 91.6720\n",
      "Epoch 4127/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 172.4296 - val_loss: 91.6134\n",
      "Epoch 4128/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 239.4612 - val_loss: 91.5513\n",
      "Epoch 4129/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 190.3223 - val_loss: 91.4859\n",
      "Epoch 4130/10000\n",
      "184/184 [==============================] - 0s 546us/step - loss: 141.4734 - val_loss: 91.4176\n",
      "Epoch 4131/10000\n",
      "184/184 [==============================] - 0s 535us/step - loss: 172.5359 - val_loss: 91.3476\n",
      "Epoch 4132/10000\n",
      "184/184 [==============================] - 0s 552us/step - loss: 188.8120 - val_loss: 91.2783\n",
      "Epoch 4133/10000\n",
      "184/184 [==============================] - 0s 541us/step - loss: 193.0517 - val_loss: 91.2149\n",
      "Epoch 4134/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 185.7857 - val_loss: 91.1527\n",
      "Epoch 4135/10000\n",
      "184/184 [==============================] - 0s 525us/step - loss: 214.5158 - val_loss: 91.0896\n",
      "Epoch 4136/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 179.3113 - val_loss: 91.0154\n",
      "Epoch 4137/10000\n",
      "184/184 [==============================] - 0s 476us/step - loss: 237.6063 - val_loss: 91.0009\n",
      "Epoch 4138/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 579us/step - loss: 183.9482 - val_loss: 91.0076\n",
      "Epoch 4139/10000\n",
      "184/184 [==============================] - 0s 573us/step - loss: 227.3425 - val_loss: 91.0105\n",
      "Epoch 4140/10000\n",
      "184/184 [==============================] - 0s 514us/step - loss: 175.6055 - val_loss: 91.0033\n",
      "Epoch 4141/10000\n",
      "184/184 [==============================] - 0s 497us/step - loss: 195.9150 - val_loss: 90.9904\n",
      "Epoch 4142/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 293.548 - 0s 530us/step - loss: 272.7590 - val_loss: 90.9721\n",
      "Epoch 4143/10000\n",
      "184/184 [==============================] - 0s 601us/step - loss: 168.9666 - val_loss: 90.9422\n",
      "Epoch 4144/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 188.8121 - val_loss: 90.9054\n",
      "Epoch 4145/10000\n",
      "184/184 [==============================] - 0s 525us/step - loss: 207.6671 - val_loss: 90.8687\n",
      "Epoch 4146/10000\n",
      "184/184 [==============================] - 0s 514us/step - loss: 152.0802 - val_loss: 90.8237\n",
      "Epoch 4147/10000\n",
      "184/184 [==============================] - 0s 606us/step - loss: 206.2936 - val_loss: 90.7786\n",
      "Epoch 4148/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 237.6450 - val_loss: 90.7260\n",
      "Epoch 4149/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 189.7235 - val_loss: 90.6638\n",
      "Epoch 4150/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 189.3244 - val_loss: 90.5984\n",
      "Epoch 4151/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 221.0214 - val_loss: 90.5360\n",
      "Epoch 4152/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 180.3363 - val_loss: 90.4826\n",
      "Epoch 4153/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 157.3297 - val_loss: 90.4364\n",
      "Epoch 4154/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 214.9323 - val_loss: 90.3970\n",
      "Epoch 4155/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 236.1503 - val_loss: 90.3512\n",
      "Epoch 4156/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 176.8848 - val_loss: 90.2997\n",
      "Epoch 4157/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 166.2346 - val_loss: 90.2139\n",
      "Epoch 4158/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 179.1116 - val_loss: 90.1365\n",
      "Epoch 4159/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 165.9361 - val_loss: 90.0602\n",
      "Epoch 4160/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 154.0802 - val_loss: 89.9886\n",
      "Epoch 4161/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 177.3343 - val_loss: 89.9226\n",
      "Epoch 4162/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 205.7531 - val_loss: 89.8611\n",
      "Epoch 4163/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 187.8520 - val_loss: 89.8009\n",
      "Epoch 4164/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 157.8149 - val_loss: 89.7408\n",
      "Epoch 4165/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 183.9878 - val_loss: 89.6795\n",
      "Epoch 4166/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 218.6838 - val_loss: 89.6212\n",
      "Epoch 4167/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 221.4568 - val_loss: 89.5587\n",
      "Epoch 4168/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 179.5306 - val_loss: 89.4996\n",
      "Epoch 4169/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 182.2115 - val_loss: 89.4428\n",
      "Epoch 4170/10000\n",
      "184/184 [==============================] - 0s 535us/step - loss: 174.0172 - val_loss: 89.3821\n",
      "Epoch 4171/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 274.2119 - val_loss: 89.3219\n",
      "Epoch 4172/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 173.3946 - val_loss: 89.2674\n",
      "Epoch 4173/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 145.1248 - val_loss: 89.2162\n",
      "Epoch 4174/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 158.7999 - val_loss: 89.1672\n",
      "Epoch 4175/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 150.4708 - val_loss: 89.1129\n",
      "Epoch 4176/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 179.4212 - val_loss: 89.0632\n",
      "Epoch 4177/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 196.9495 - val_loss: 89.0152\n",
      "Epoch 4178/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 160.9826 - val_loss: 88.9719\n",
      "Epoch 4179/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 171.6519 - val_loss: 88.9293\n",
      "Epoch 4180/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 190.0689 - val_loss: 88.8917\n",
      "Epoch 4181/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 184.3957 - val_loss: 88.8413\n",
      "Epoch 4182/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 155.2770 - val_loss: 88.7937\n",
      "Epoch 4183/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 161.2491 - val_loss: 88.7455\n",
      "Epoch 4184/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 177.5350 - val_loss: 88.6943\n",
      "Epoch 4185/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 211.0648 - val_loss: 88.6444\n",
      "Epoch 4186/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 191.3742 - val_loss: 88.5989\n",
      "Epoch 4187/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 198.6791 - val_loss: 88.5477\n",
      "Epoch 4188/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 204.9355 - val_loss: 88.4956\n",
      "Epoch 4189/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 209.1785 - val_loss: 88.4463\n",
      "Epoch 4190/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 206.8849 - val_loss: 88.4028\n",
      "Epoch 4191/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 203.5965 - val_loss: 88.3659\n",
      "Epoch 4192/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 171.3002 - val_loss: 88.3274\n",
      "Epoch 4193/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 162.9233 - val_loss: 88.2916\n",
      "Epoch 4194/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 198.6739 - val_loss: 88.2419\n",
      "Epoch 4195/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 239.0166 - val_loss: 88.1800\n",
      "Epoch 4196/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 184.0197 - val_loss: 88.1202\n",
      "Epoch 4197/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 242.7256 - val_loss: 88.0595\n",
      "Epoch 4198/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 184.3670 - val_loss: 87.9934\n",
      "Epoch 4199/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 246.9524 - val_loss: 87.9401\n",
      "Epoch 4200/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 201.2064 - val_loss: 87.8661\n",
      "\n",
      "Epoch 04200: loss did not improve from 191.97749\n",
      "Epoch 4201/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 218.4064 - val_loss: 87.7862\n",
      "Epoch 4202/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 169.4346 - val_loss: 87.7153\n",
      "Epoch 4203/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 194.9788 - val_loss: 87.6518\n",
      "Epoch 4204/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 189.9746 - val_loss: 87.5870\n",
      "Epoch 4205/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 235.4219 - val_loss: 87.5120\n",
      "Epoch 4206/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 213.1372 - val_loss: 87.4308\n",
      "Epoch 4207/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 176.1825 - val_loss: 87.3469\n",
      "Epoch 4208/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 161.2221 - val_loss: 87.2709\n",
      "Epoch 4209/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 166.3962 - val_loss: 87.2003\n",
      "Epoch 4210/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 181.5988 - val_loss: 87.1543\n",
      "Epoch 4211/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 489us/step - loss: 146.3934 - val_loss: 87.1292\n",
      "Epoch 4212/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 179.3794 - val_loss: 87.1145\n",
      "Epoch 4213/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 195.1544 - val_loss: 87.0947\n",
      "Epoch 4214/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 200.8999 - val_loss: 87.0720\n",
      "Epoch 4215/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 171.9429 - val_loss: 87.0513\n",
      "Epoch 4216/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 230.1017 - val_loss: 87.0399\n",
      "Epoch 4217/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 148.7486 - val_loss: 87.0240\n",
      "Epoch 4218/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 220.0614 - val_loss: 86.9933\n",
      "Epoch 4219/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 175.9516 - val_loss: 86.9584\n",
      "Epoch 4220/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 198.6924 - val_loss: 86.9143\n",
      "Epoch 4221/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 229.3596 - val_loss: 86.8582\n",
      "Epoch 4222/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 178.3211 - val_loss: 86.8118\n",
      "Epoch 4223/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 166.4758 - val_loss: 86.7689\n",
      "Epoch 4224/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 201.5850 - val_loss: 86.7013\n",
      "Epoch 4225/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 173.9383 - val_loss: 86.6190\n",
      "Epoch 4226/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 189.1317 - val_loss: 86.5457\n",
      "Epoch 4227/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 175.1303 - val_loss: 86.4737\n",
      "Epoch 4228/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 189.4768 - val_loss: 86.4087\n",
      "Epoch 4229/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 137.2091 - val_loss: 86.3504\n",
      "Epoch 4230/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 196.6469 - val_loss: 86.2937\n",
      "Epoch 4231/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 227.7015 - val_loss: 86.2421\n",
      "Epoch 4232/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 180.7411 - val_loss: 86.1945\n",
      "Epoch 4233/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 193.4930 - val_loss: 86.1601\n",
      "Epoch 4234/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 215.0283 - val_loss: 86.1226\n",
      "Epoch 4235/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 212.9423 - val_loss: 86.0915\n",
      "Epoch 4236/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 172.0169 - val_loss: 86.0606\n",
      "Epoch 4237/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 186.4288 - val_loss: 86.0315\n",
      "Epoch 4238/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 174.3757 - val_loss: 86.0001\n",
      "Epoch 4239/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 159.0255 - val_loss: 85.9569\n",
      "Epoch 4240/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 270.4221 - val_loss: 85.9102\n",
      "Epoch 4241/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 187.0851 - val_loss: 85.8563\n",
      "Epoch 4242/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 188.6191 - val_loss: 85.8062\n",
      "Epoch 4243/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 212.3179 - val_loss: 85.7594\n",
      "Epoch 4244/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 224.1038 - val_loss: 85.7201\n",
      "Epoch 4245/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 195.9565 - val_loss: 85.6875\n",
      "Epoch 4246/10000\n",
      "184/184 [==============================] - 0s 492us/step - loss: 219.4597 - val_loss: 85.6489\n",
      "Epoch 4247/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 196.8961 - val_loss: 85.6044\n",
      "Epoch 4248/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 138.8122 - val_loss: 85.5474\n",
      "Epoch 4249/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 207.8342 - val_loss: 85.4854\n",
      "Epoch 4250/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 231.7694 - val_loss: 85.4155\n",
      "Epoch 4251/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 174.5642 - val_loss: 85.3427\n",
      "Epoch 4252/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 234.3495 - val_loss: 85.2740\n",
      "Epoch 4253/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 184.2549 - val_loss: 85.2142\n",
      "Epoch 4254/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 186.4698 - val_loss: 85.1426\n",
      "Epoch 4255/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 188.2376 - val_loss: 85.0760\n",
      "Epoch 4256/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 191.9807 - val_loss: 85.0136\n",
      "Epoch 4257/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 216.6837 - val_loss: 84.9497\n",
      "Epoch 4258/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 183.6597 - val_loss: 84.8907\n",
      "Epoch 4259/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 181.3412 - val_loss: 84.8364\n",
      "Epoch 4260/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 196.6640 - val_loss: 84.6089\n",
      "Epoch 4261/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 162.7317 - val_loss: 84.3540\n",
      "Epoch 4262/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 165.4222 - val_loss: 84.1407\n",
      "Epoch 4263/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 180.1490 - val_loss: 84.0105\n",
      "Epoch 4264/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 165.8288 - val_loss: 83.9484\n",
      "Epoch 4265/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 201.1518 - val_loss: 83.8987\n",
      "Epoch 4266/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 186.1412 - val_loss: 83.8521\n",
      "Epoch 4267/10000\n",
      "184/184 [==============================] - 0s 767us/step - loss: 197.3570 - val_loss: 83.7949\n",
      "Epoch 4268/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 150.9982 - val_loss: 83.7307\n",
      "Epoch 4269/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 198.5494 - val_loss: 83.6583\n",
      "Epoch 4270/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 175.0569 - val_loss: 83.5795\n",
      "Epoch 4271/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 196.3033 - val_loss: 83.4882\n",
      "Epoch 4272/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 200.2627 - val_loss: 83.3984\n",
      "Epoch 4273/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 171.3426 - val_loss: 83.3047\n",
      "Epoch 4274/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 195.2060 - val_loss: 83.2142\n",
      "Epoch 4275/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 171.5445 - val_loss: 83.1289\n",
      "Epoch 4276/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 182.8599 - val_loss: 83.0454\n",
      "Epoch 4277/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 213.5320 - val_loss: 82.9795\n",
      "Epoch 4278/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 123.9760 - val_loss: 82.9097\n",
      "Epoch 4279/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 195.9264 - val_loss: 82.8385\n",
      "Epoch 4280/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 179.9883 - val_loss: 82.7654\n",
      "Epoch 4281/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 206.6084 - val_loss: 82.6947\n",
      "Epoch 4282/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 234.6721 - val_loss: 82.6306\n",
      "Epoch 4283/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 160.2099 - val_loss: 82.5726\n",
      "Epoch 4284/10000\n",
      "184/184 [==============================] - 0s 535us/step - loss: 174.2430 - val_loss: 82.5176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4285/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 220.4391 - val_loss: 82.4711\n",
      "Epoch 4286/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 183.2390 - val_loss: 82.4267\n",
      "Epoch 4287/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 241.7148 - val_loss: 82.3767\n",
      "Epoch 4288/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 219.1272 - val_loss: 82.3187\n",
      "Epoch 4289/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 142.9107 - val_loss: 82.2621\n",
      "Epoch 4290/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 182.2193 - val_loss: 82.2090\n",
      "Epoch 4291/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 155.2797 - val_loss: 82.1559\n",
      "Epoch 4292/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 197.3319 - val_loss: 82.1086\n",
      "Epoch 4293/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 166.4397 - val_loss: 82.0625\n",
      "Epoch 4294/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 188.0690 - val_loss: 82.0123\n",
      "Epoch 4295/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 171.475 - 0s 549us/step - loss: 167.3053 - val_loss: 81.9571\n",
      "Epoch 4296/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 155.8197 - val_loss: 81.9015\n",
      "Epoch 4297/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 194.5687 - val_loss: 81.8472\n",
      "Epoch 4298/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 191.1907 - val_loss: 81.7933\n",
      "Epoch 4299/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 243.0213 - val_loss: 81.7426\n",
      "Epoch 4300/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 211.1054 - val_loss: 81.7157\n",
      "\n",
      "Epoch 04300: loss did not improve from 191.97749\n",
      "Epoch 4301/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 178.0491 - val_loss: 81.6829\n",
      "Epoch 4302/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 240.6983 - val_loss: 81.6511\n",
      "Epoch 4303/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 165.1609 - val_loss: 81.6148\n",
      "Epoch 4304/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 191.0192 - val_loss: 81.5730\n",
      "Epoch 4305/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 185.6142 - val_loss: 81.5290\n",
      "Epoch 4306/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 151.3485 - val_loss: 81.4829\n",
      "Epoch 4307/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 215.4291 - val_loss: 81.4387\n",
      "Epoch 4308/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 194.1743 - val_loss: 81.3874\n",
      "Epoch 4309/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 251.3558 - val_loss: 81.3326\n",
      "Epoch 4310/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 182.6508 - val_loss: 81.2689\n",
      "Epoch 4311/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 171.8879 - val_loss: 81.2034\n",
      "Epoch 4312/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 207.3326 - val_loss: 81.1399\n",
      "Epoch 4313/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 217.0631 - val_loss: 80.9871\n",
      "Epoch 4314/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 208.1072 - val_loss: 80.8531\n",
      "Epoch 4315/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 165.2910 - val_loss: 80.7361\n",
      "Epoch 4316/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 186.8193 - val_loss: 80.6337\n",
      "Epoch 4317/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 146.3049 - val_loss: 80.5477\n",
      "Epoch 4318/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 149.4147 - val_loss: 80.4674\n",
      "Epoch 4319/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 179.8823 - val_loss: 80.3827\n",
      "Epoch 4320/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 170.6517 - val_loss: 80.3028\n",
      "Epoch 4321/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 166.1374 - val_loss: 80.2311\n",
      "Epoch 4322/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 191.1011 - val_loss: 80.1685\n",
      "Epoch 4323/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 172.0972 - val_loss: 80.0525\n",
      "Epoch 4324/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 185.0012 - val_loss: 79.9230\n",
      "Epoch 4325/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 152.9376 - val_loss: 79.8313\n",
      "Epoch 4326/10000\n",
      "184/184 [==============================] - 0s 506us/step - loss: 180.9438 - val_loss: 79.5905\n",
      "Epoch 4327/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 175.2528 - val_loss: 79.6251\n",
      "Epoch 4328/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 211.7722 - val_loss: 79.6723\n",
      "Epoch 4329/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 177.6403 - val_loss: 80.0453\n",
      "Epoch 4330/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 195.3677 - val_loss: 78.7620\n",
      "Epoch 4331/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 274.8570 - val_loss: 78.4637\n",
      "Epoch 4332/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 167.8074 - val_loss: 78.8805\n",
      "Epoch 4333/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 209.2298 - val_loss: 78.6752\n",
      "Epoch 4334/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 162.4148 - val_loss: 78.5242\n",
      "Epoch 4335/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 188.2035 - val_loss: 78.4420\n",
      "Epoch 4336/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 158.0843 - val_loss: 78.3776\n",
      "Epoch 4337/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 170.6489 - val_loss: 78.2755\n",
      "Epoch 4338/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 195.9329 - val_loss: 78.1698\n",
      "Epoch 4339/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 178.2759 - val_loss: 78.0553\n",
      "Epoch 4340/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 176.6739 - val_loss: 77.9356\n",
      "Epoch 4341/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 203.2078 - val_loss: 77.8104\n",
      "Epoch 4342/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 178.0925 - val_loss: 77.6941\n",
      "Epoch 4343/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 180.7781 - val_loss: 77.5990\n",
      "Epoch 4344/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 183.7000 - val_loss: 77.5131\n",
      "Epoch 4345/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 179.1632 - val_loss: 77.4338\n",
      "Epoch 4346/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 203.6855 - val_loss: 77.3599\n",
      "Epoch 4347/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 177.7710 - val_loss: 77.2959\n",
      "Epoch 4348/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 174.4266 - val_loss: 77.2443\n",
      "Epoch 4349/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 171.8111 - val_loss: 77.2074\n",
      "Epoch 4350/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 180.1991 - val_loss: 77.1688\n",
      "Epoch 4351/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 141.9128 - val_loss: 77.1247\n",
      "Epoch 4352/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 203.7639 - val_loss: 77.0730\n",
      "Epoch 4353/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 163.2189 - val_loss: 77.0212\n",
      "Epoch 4354/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 172.5426 - val_loss: 76.9724\n",
      "Epoch 4355/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 181.1241 - val_loss: 76.9241\n",
      "Epoch 4356/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 145.1149 - val_loss: 76.8697\n",
      "Epoch 4357/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 190.3793 - val_loss: 76.8172\n",
      "Epoch 4358/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 603us/step - loss: 185.0176 - val_loss: 76.7616\n",
      "Epoch 4359/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 175.5323 - val_loss: 76.7089\n",
      "Epoch 4360/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 202.7934 - val_loss: 76.6529\n",
      "Epoch 4361/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 205.0399 - val_loss: 76.6060\n",
      "Epoch 4362/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 216.1815 - val_loss: 76.5631\n",
      "Epoch 4363/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 326.4722 - val_loss: 76.5220\n",
      "Epoch 4364/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 194.0394 - val_loss: 76.4773\n",
      "Epoch 4365/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 157.2843 - val_loss: 76.4329\n",
      "Epoch 4366/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 188.8840 - val_loss: 76.3911\n",
      "Epoch 4367/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 197.6688 - val_loss: 76.3541\n",
      "Epoch 4368/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 170.7626 - val_loss: 76.3098\n",
      "Epoch 4369/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 183.5613 - val_loss: 76.2602\n",
      "Epoch 4370/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 229.4406 - val_loss: 76.2129\n",
      "Epoch 4371/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 179.1336 - val_loss: 76.1655\n",
      "Epoch 4372/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 181.8542 - val_loss: 76.1187\n",
      "Epoch 4373/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 171.4291 - val_loss: 76.0734\n",
      "Epoch 4374/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 162.2124 - val_loss: 76.0293\n",
      "Epoch 4375/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 139.5561 - val_loss: 75.9881\n",
      "Epoch 4376/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 194.5370 - val_loss: 75.9506\n",
      "Epoch 4377/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 191.4584 - val_loss: 75.9168\n",
      "Epoch 4378/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 188.4431 - val_loss: 75.8770\n",
      "Epoch 4379/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 164.0431 - val_loss: 75.8316\n",
      "Epoch 4380/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 172.2199 - val_loss: 75.7848\n",
      "Epoch 4381/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 198.8648 - val_loss: 75.4405\n",
      "Epoch 4382/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 204.9636 - val_loss: 75.4035\n",
      "Epoch 4383/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 177.6717 - val_loss: 75.5372\n",
      "Epoch 4384/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 191.4371 - val_loss: 75.3378\n",
      "Epoch 4385/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 178.7300 - val_loss: 75.5746\n",
      "Epoch 4386/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 170.8932 - val_loss: 75.6564\n",
      "Epoch 4387/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 193.3962 - val_loss: 75.2873\n",
      "Epoch 4388/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 173.1863 - val_loss: 75.1932\n",
      "Epoch 4389/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 186.8961 - val_loss: 75.1033\n",
      "Epoch 4390/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 194.5655 - val_loss: 74.9966\n",
      "Epoch 4391/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 191.5715 - val_loss: 74.8894\n",
      "Epoch 4392/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 180.7957 - val_loss: 74.7388\n",
      "Epoch 4393/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 167.5820 - val_loss: 74.6203\n",
      "Epoch 4394/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 164.3347 - val_loss: 74.5810\n",
      "Epoch 4395/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 196.2414 - val_loss: 74.6667\n",
      "Epoch 4396/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 169.2901 - val_loss: 75.0078\n",
      "Epoch 4397/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 172.7643 - val_loss: 74.9413\n",
      "Epoch 4398/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 193.4795 - val_loss: 74.8313\n",
      "Epoch 4399/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 180.0529 - val_loss: 74.7260\n",
      "Epoch 4400/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 216.9677 - val_loss: 74.5999\n",
      "\n",
      "Epoch 04400: loss did not improve from 191.97749\n",
      "Epoch 4401/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 139.8220 - val_loss: 74.4535\n",
      "Epoch 4402/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 172.8935 - val_loss: 74.2703\n",
      "Epoch 4403/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 141.4167 - val_loss: 74.1531\n",
      "Epoch 4404/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 221.0875 - val_loss: 74.0627\n",
      "Epoch 4405/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 213.4702 - val_loss: 73.9725\n",
      "Epoch 4406/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 144.7798 - val_loss: 73.8944\n",
      "Epoch 4407/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 182.6656 - val_loss: 73.8411\n",
      "Epoch 4408/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 178.2167 - val_loss: 73.7894\n",
      "Epoch 4409/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 175.8339 - val_loss: 73.7477\n",
      "Epoch 4410/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 216.6166 - val_loss: 73.7056\n",
      "Epoch 4411/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 155.8822 - val_loss: 73.6615\n",
      "Epoch 4412/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 196.9370 - val_loss: 73.6133\n",
      "Epoch 4413/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 169.2801 - val_loss: 73.5633\n",
      "Epoch 4414/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 193.7147 - val_loss: 73.5159\n",
      "Epoch 4415/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 131.4578 - val_loss: 73.4658\n",
      "Epoch 4416/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 149.5114 - val_loss: 73.4119\n",
      "Epoch 4417/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 149.8422 - val_loss: 73.3617\n",
      "Epoch 4418/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 177.4677 - val_loss: 73.2873\n",
      "Epoch 4419/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 180.0861 - val_loss: 73.2525\n",
      "Epoch 4420/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 159.7945 - val_loss: 73.3312\n",
      "Epoch 4421/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 197.0703 - val_loss: 73.6097\n",
      "Epoch 4422/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 174.1232 - val_loss: 73.9193\n",
      "Epoch 4423/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 176.7469 - val_loss: 74.0163\n",
      "Epoch 4424/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 145.0563 - val_loss: 74.0235\n",
      "Epoch 4425/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 209.4448 - val_loss: 74.0292\n",
      "Epoch 4426/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 129.3469 - val_loss: 73.8929\n",
      "Epoch 4427/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 123.9252 - val_loss: 73.7085\n",
      "Epoch 4428/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 223.9116 - val_loss: 73.5719\n",
      "Epoch 4429/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 170.8142 - val_loss: 73.5255\n",
      "Epoch 4430/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 146.8182 - val_loss: 73.4825\n",
      "Epoch 4431/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 582us/step - loss: 193.5220 - val_loss: 73.4392\n",
      "Epoch 4432/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 215.6620 - val_loss: 73.3908\n",
      "Epoch 4433/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 200.2780 - val_loss: 73.3446\n",
      "Epoch 4434/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 183.0747 - val_loss: 73.2964\n",
      "Epoch 4435/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 191.5235 - val_loss: 73.2440\n",
      "Epoch 4436/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 230.9029 - val_loss: 73.1957\n",
      "Epoch 4437/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 170.5805 - val_loss: 73.1489\n",
      "Epoch 4438/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 177.4467 - val_loss: 73.1053\n",
      "Epoch 4439/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 206.4088 - val_loss: 73.0648\n",
      "Epoch 4440/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 175.6456 - val_loss: 73.0194\n",
      "Epoch 4441/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 165.4592 - val_loss: 72.9784\n",
      "Epoch 4442/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 144.6817 - val_loss: 72.9352\n",
      "Epoch 4443/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 164.7584 - val_loss: 72.8924\n",
      "Epoch 4444/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 125.9362 - val_loss: 72.8499\n",
      "Epoch 4445/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 160.6061 - val_loss: 72.7705\n",
      "Epoch 4446/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 149.8065 - val_loss: 72.6865\n",
      "Epoch 4447/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 210.9825 - val_loss: 72.6142\n",
      "Epoch 4448/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 191.4492 - val_loss: 72.5569\n",
      "Epoch 4449/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 152.0125 - val_loss: 72.5005\n",
      "Epoch 4450/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 154.1663 - val_loss: 72.4466\n",
      "Epoch 4451/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 197.0810 - val_loss: 72.3770\n",
      "Epoch 4452/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 193.7951 - val_loss: 72.3067\n",
      "Epoch 4453/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 152.2702 - val_loss: 72.2439\n",
      "Epoch 4454/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 172.7696 - val_loss: 72.1833\n",
      "Epoch 4455/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 187.1277 - val_loss: 72.1318\n",
      "Epoch 4456/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 192.7856 - val_loss: 72.0821\n",
      "Epoch 4457/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 139.0064 - val_loss: 72.0326\n",
      "Epoch 4458/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 132.2179 - val_loss: 71.9880\n",
      "Epoch 4459/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 153.8262 - val_loss: 71.9442\n",
      "Epoch 4460/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 184.0444 - val_loss: 71.8821\n",
      "Epoch 4461/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 209.0837 - val_loss: 71.8326\n",
      "Epoch 4462/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 264.826 - 0s 473us/step - loss: 221.5852 - val_loss: 71.7790\n",
      "Epoch 4463/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 178.7621 - val_loss: 71.7514\n",
      "Epoch 4464/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 169.7282 - val_loss: 71.7261\n",
      "Epoch 4465/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 140.7505 - val_loss: 71.7021\n",
      "Epoch 4466/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 179.3183 - val_loss: 73.0828\n",
      "Epoch 4467/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 155.3279 - val_loss: 72.8728\n",
      "Epoch 4468/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 155.2864 - val_loss: 72.8266\n",
      "Epoch 4469/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 174.9548 - val_loss: 72.4906\n",
      "Epoch 4470/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 138.3180 - val_loss: 72.4535\n",
      "Epoch 4471/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 200.8104 - val_loss: 72.8142\n",
      "Epoch 4472/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 176.6493 - val_loss: 73.0599\n",
      "Epoch 4473/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 190.1309 - val_loss: 72.7370\n",
      "Epoch 4474/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 171.8812 - val_loss: 71.9311\n",
      "Epoch 4475/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 196.5717 - val_loss: 71.2250\n",
      "Epoch 4476/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 164.5258 - val_loss: 70.5960\n",
      "Epoch 4477/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 157.1182 - val_loss: 70.4529\n",
      "Epoch 4478/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 150.8526 - val_loss: 71.0405\n",
      "Epoch 4479/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 184.6111 - val_loss: 69.2522\n",
      "Epoch 4480/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 149.0928 - val_loss: 68.9185\n",
      "Epoch 4481/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 179.2979 - val_loss: 68.8915\n",
      "Epoch 4482/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 182.8311 - val_loss: 68.8565\n",
      "Epoch 4483/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 166.5630 - val_loss: 68.8425\n",
      "Epoch 4484/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 148.1248 - val_loss: 68.8335\n",
      "Epoch 4485/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 168.169 - 0s 527us/step - loss: 155.4616 - val_loss: 68.8194\n",
      "Epoch 4486/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 183.5068 - val_loss: 68.8076\n",
      "Epoch 4487/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 292.2104 - val_loss: 68.7789\n",
      "Epoch 4488/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 225.4001 - val_loss: 68.7392\n",
      "Epoch 4489/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 151.2195 - val_loss: 68.7010\n",
      "Epoch 4490/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 254.6082 - val_loss: 68.6574\n",
      "Epoch 4491/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 137.0619 - val_loss: 68.6115\n",
      "Epoch 4492/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 204.3857 - val_loss: 68.5668\n",
      "Epoch 4493/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 174.8168 - val_loss: 68.5215\n",
      "Epoch 4494/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 196.8140 - val_loss: 68.4947\n",
      "Epoch 4495/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 211.4772 - val_loss: 68.4680\n",
      "Epoch 4496/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 157.4920 - val_loss: 68.4380\n",
      "Epoch 4497/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 188.3007 - val_loss: 68.4048\n",
      "Epoch 4498/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 144.7343 - val_loss: 68.3707\n",
      "Epoch 4499/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 150.4701 - val_loss: 68.3279\n",
      "Epoch 4500/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 160.7150 - val_loss: 68.2823\n",
      "\n",
      "Epoch 04500: loss improved from 191.97749 to 160.71504, saving model to C6007C.hdf5\n",
      "Epoch 4501/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 168.1391 - val_loss: 68.2360\n",
      "Epoch 4502/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 150.2350 - val_loss: 68.1940\n",
      "Epoch 4503/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 516us/step - loss: 182.5271 - val_loss: 68.1483\n",
      "Epoch 4504/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 151.3334 - val_loss: 68.1038\n",
      "Epoch 4505/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 168.1915 - val_loss: 68.0593\n",
      "Epoch 4506/10000\n",
      "184/184 [==============================] - 0s 682us/step - loss: 160.3497 - val_loss: 68.0135\n",
      "Epoch 4507/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 133.1841 - val_loss: 67.9684\n",
      "Epoch 4508/10000\n",
      "184/184 [==============================] - 0s 535us/step - loss: 146.5869 - val_loss: 67.9277\n",
      "Epoch 4509/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 164.0136 - val_loss: 67.8900\n",
      "Epoch 4510/10000\n",
      "184/184 [==============================] - 0s 606us/step - loss: 203.4624 - val_loss: 67.8545\n",
      "Epoch 4511/10000\n",
      "184/184 [==============================] - 0s 497us/step - loss: 203.7655 - val_loss: 67.8257\n",
      "Epoch 4512/10000\n",
      "184/184 [==============================] - 0s 579us/step - loss: 168.7913 - val_loss: 67.7926\n",
      "Epoch 4513/10000\n",
      "184/184 [==============================] - 0s 546us/step - loss: 172.2386 - val_loss: 67.7587\n",
      "Epoch 4514/10000\n",
      "184/184 [==============================] - 0s 535us/step - loss: 186.3808 - val_loss: 67.7206\n",
      "Epoch 4515/10000\n",
      "184/184 [==============================] - 0s 574us/step - loss: 130.7411 - val_loss: 67.6796\n",
      "Epoch 4516/10000\n",
      "184/184 [==============================] - 0s 666us/step - loss: 190.3256 - val_loss: 67.6388\n",
      "Epoch 4517/10000\n",
      "184/184 [==============================] - 0s 514us/step - loss: 191.6891 - val_loss: 67.5964\n",
      "Epoch 4518/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 128.7888 - val_loss: 67.5566\n",
      "Epoch 4519/10000\n",
      "184/184 [==============================] - 0s 601us/step - loss: 162.0189 - val_loss: 67.5161\n",
      "Epoch 4520/10000\n",
      "184/184 [==============================] - 0s 590us/step - loss: 150.5801 - val_loss: 67.4776\n",
      "Epoch 4521/10000\n",
      "184/184 [==============================] - 0s 465us/step - loss: 198.4182 - val_loss: 67.4059\n",
      "Epoch 4522/10000\n",
      "184/184 [==============================] - 0s 497us/step - loss: 229.1643 - val_loss: 67.3383\n",
      "Epoch 4523/10000\n",
      "184/184 [==============================] - 0s 617us/step - loss: 195.8067 - val_loss: 67.2700\n",
      "Epoch 4524/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 178.5647 - val_loss: 67.2030\n",
      "Epoch 4525/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 158.4643 - val_loss: 67.1443\n",
      "Epoch 4526/10000\n",
      "184/184 [==============================] - 0s 804us/step - loss: 254.2333 - val_loss: 67.0823\n",
      "Epoch 4527/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 163.5452 - val_loss: 67.0191\n",
      "Epoch 4528/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 137.5733 - val_loss: 66.9615\n",
      "Epoch 4529/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 192.2022 - val_loss: 66.9126\n",
      "Epoch 4530/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 209.1674 - val_loss: 66.8644\n",
      "Epoch 4531/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 178.8938 - val_loss: 66.8132\n",
      "Epoch 4532/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 188.5704 - val_loss: 66.7636\n",
      "Epoch 4533/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 145.4826 - val_loss: 66.7117\n",
      "Epoch 4534/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 158.0943 - val_loss: 66.6517\n",
      "Epoch 4535/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 213.8611 - val_loss: 66.5872\n",
      "Epoch 4536/10000\n",
      "184/184 [==============================] - 0s 497us/step - loss: 157.3744 - val_loss: 66.5255\n",
      "Epoch 4537/10000\n",
      "184/184 [==============================] - 0s 546us/step - loss: 155.3778 - val_loss: 66.4694\n",
      "Epoch 4538/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 156.6601 - val_loss: 66.4132\n",
      "Epoch 4539/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 139.1266 - val_loss: 66.3615\n",
      "Epoch 4540/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 202.9813 - val_loss: 66.3151\n",
      "Epoch 4541/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 178.2009 - val_loss: 66.2715\n",
      "Epoch 4542/10000\n",
      "184/184 [==============================] - 0s 544us/step - loss: 175.7563 - val_loss: 66.2282\n",
      "Epoch 4543/10000\n",
      "184/184 [==============================] - 0s 535us/step - loss: 167.1733 - val_loss: 66.1859\n",
      "Epoch 4544/10000\n",
      "184/184 [==============================] - 0s 546us/step - loss: 170.0118 - val_loss: 66.1519\n",
      "Epoch 4545/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 124.9002 - val_loss: 66.1166\n",
      "Epoch 4546/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 166.2943 - val_loss: 66.0814\n",
      "Epoch 4547/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 172.1776 - val_loss: 66.0459\n",
      "Epoch 4548/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 151.3020 - val_loss: 66.0063\n",
      "Epoch 4549/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 187.5065 - val_loss: 65.9594\n",
      "Epoch 4550/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 200.7045 - val_loss: 65.9074\n",
      "Epoch 4551/10000\n",
      "184/184 [==============================] - 0s 544us/step - loss: 153.5314 - val_loss: 65.8592\n",
      "Epoch 4552/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 176.9090 - val_loss: 65.8201\n",
      "Epoch 4553/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 201.7018 - val_loss: 65.7778\n",
      "Epoch 4554/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 190.7730 - val_loss: 65.7317\n",
      "Epoch 4555/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 167.7582 - val_loss: 65.6915\n",
      "Epoch 4556/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 251.7503 - val_loss: 65.6462\n",
      "Epoch 4557/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 151.9145 - val_loss: 65.6104\n",
      "Epoch 4558/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 176.4405 - val_loss: 65.5747\n",
      "Epoch 4559/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 149.9827 - val_loss: 65.5006\n",
      "Epoch 4560/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 155.5740 - val_loss: 65.4315\n",
      "Epoch 4561/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 163.6258 - val_loss: 65.3671\n",
      "Epoch 4562/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 159.2731 - val_loss: 65.3078\n",
      "Epoch 4563/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 186.4990 - val_loss: 65.2529\n",
      "Epoch 4564/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 168.3304 - val_loss: 65.1860\n",
      "Epoch 4565/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 145.4958 - val_loss: 65.1160\n",
      "Epoch 4566/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 187.3443 - val_loss: 65.0502\n",
      "Epoch 4567/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 164.3203 - val_loss: 64.9898\n",
      "Epoch 4568/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 198.0602 - val_loss: 64.9355\n",
      "Epoch 4569/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 147.0398 - val_loss: 64.8869\n",
      "Epoch 4570/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 141.9030 - val_loss: 64.8403\n",
      "Epoch 4571/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 186.4995 - val_loss: 64.7845\n",
      "Epoch 4572/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 166.2455 - val_loss: 64.7422\n",
      "Epoch 4573/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 155.3672 - val_loss: 64.7006\n",
      "Epoch 4574/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 129.3328 - val_loss: 64.6598\n",
      "Epoch 4575/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 205.3852 - val_loss: 64.6162\n",
      "Epoch 4576/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 175.4845 - val_loss: 64.5771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4577/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 214.6288 - val_loss: 64.5414\n",
      "Epoch 4578/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 144.1268 - val_loss: 64.5096\n",
      "Epoch 4579/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 187.5876 - val_loss: 64.4776\n",
      "Epoch 4580/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 193.5256 - val_loss: 64.4454\n",
      "Epoch 4581/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 158.9435 - val_loss: 64.4086\n",
      "Epoch 4582/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 226.1383 - val_loss: 64.3725\n",
      "Epoch 4583/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 143.5628 - val_loss: 64.3341\n",
      "Epoch 4584/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 142.9472 - val_loss: 64.2999\n",
      "Epoch 4585/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 217.6282 - val_loss: 64.2616\n",
      "Epoch 4586/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 185.1686 - val_loss: 64.2200\n",
      "Epoch 4587/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 216.4964 - val_loss: 64.1808\n",
      "Epoch 4588/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 215.9259 - val_loss: 64.1395\n",
      "Epoch 4589/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 178.5564 - val_loss: 64.0955\n",
      "Epoch 4590/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 179.6119 - val_loss: 64.0527\n",
      "Epoch 4591/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 180.0758 - val_loss: 64.0120\n",
      "Epoch 4592/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 229.4324 - val_loss: 63.9465\n",
      "Epoch 4593/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 144.3809 - val_loss: 63.8829\n",
      "Epoch 4594/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 178.1829 - val_loss: 63.8245\n",
      "Epoch 4595/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 144.4405 - val_loss: 63.7701\n",
      "Epoch 4596/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 171.0203 - val_loss: 63.7183\n",
      "Epoch 4597/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 125.7559 - val_loss: 63.6707\n",
      "Epoch 4598/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 146.4822 - val_loss: 63.6286\n",
      "Epoch 4599/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 169.0900 - val_loss: 63.5921\n",
      "Epoch 4600/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 137.5657 - val_loss: 63.5583\n",
      "\n",
      "Epoch 04600: loss improved from 160.71504 to 137.56569, saving model to C6007C.hdf5\n",
      "Epoch 4601/10000\n",
      "184/184 [==============================] - 0s 566us/step - loss: 130.1824 - val_loss: 63.5272\n",
      "Epoch 4602/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 151.2820 - val_loss: 63.4920\n",
      "Epoch 4603/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 196.3533 - val_loss: 63.4509\n",
      "Epoch 4604/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 142.4492 - val_loss: 63.4200\n",
      "Epoch 4605/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 158.4036 - val_loss: 63.3892\n",
      "Epoch 4606/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 156.7968 - val_loss: 63.3562\n",
      "Epoch 4607/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 155.8122 - val_loss: 63.3200\n",
      "Epoch 4608/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 124.9327 - val_loss: 63.2857\n",
      "Epoch 4609/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 208.0832 - val_loss: 63.2517\n",
      "Epoch 4610/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 160.2717 - val_loss: 63.2072\n",
      "Epoch 4611/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 173.0654 - val_loss: 63.1626\n",
      "Epoch 4612/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 179.3613 - val_loss: 63.1230\n",
      "Epoch 4613/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 167.9277 - val_loss: 63.0830\n",
      "Epoch 4614/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 177.1049 - val_loss: 63.0424\n",
      "Epoch 4615/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 159.1702 - val_loss: 62.9994\n",
      "Epoch 4616/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 183.2609 - val_loss: 62.9529\n",
      "Epoch 4617/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 134.4297 - val_loss: 62.9092\n",
      "Epoch 4618/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 156.4092 - val_loss: 62.8663\n",
      "Epoch 4619/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 114.5250 - val_loss: 62.8270\n",
      "Epoch 4620/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 154.0168 - val_loss: 62.7910\n",
      "Epoch 4621/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 155.0792 - val_loss: 62.7539\n",
      "Epoch 4622/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 203.5962 - val_loss: 62.7119\n",
      "Epoch 4623/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 157.8747 - val_loss: 62.6703\n",
      "Epoch 4624/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 158.1504 - val_loss: 62.6294\n",
      "Epoch 4625/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 131.5125 - val_loss: 62.5914\n",
      "Epoch 4626/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 161.5711 - val_loss: 62.5554\n",
      "Epoch 4627/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 168.2766 - val_loss: 62.5171\n",
      "Epoch 4628/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 179.1778 - val_loss: 62.4790\n",
      "Epoch 4629/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 173.5023 - val_loss: 62.4342\n",
      "Epoch 4630/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 237.1487 - val_loss: 62.3834\n",
      "Epoch 4631/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 178.0450 - val_loss: 62.3334\n",
      "Epoch 4632/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 168.7908 - val_loss: 62.2884\n",
      "Epoch 4633/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 200.7631 - val_loss: 62.2448\n",
      "Epoch 4634/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 162.6306 - val_loss: 62.2016\n",
      "Epoch 4635/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 140.2015 - val_loss: 62.1574\n",
      "Epoch 4636/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 162.3725 - val_loss: 62.1104\n",
      "Epoch 4637/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 143.4559 - val_loss: 62.0707\n",
      "Epoch 4638/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 202.5566 - val_loss: 62.0352\n",
      "Epoch 4639/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 180.2189 - val_loss: 61.9992\n",
      "Epoch 4640/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 198.4476 - val_loss: 61.9558\n",
      "Epoch 4641/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 131.0443 - val_loss: 61.9108\n",
      "Epoch 4642/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 204.6918 - val_loss: 61.8643\n",
      "Epoch 4643/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 176.2752 - val_loss: 61.8155\n",
      "Epoch 4644/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 158.5983 - val_loss: 61.7749\n",
      "Epoch 4645/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 183.8638 - val_loss: 61.7371\n",
      "Epoch 4646/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 164.1191 - val_loss: 61.7002\n",
      "Epoch 4647/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 184.8108 - val_loss: 61.6639\n",
      "Epoch 4648/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 136.7850 - val_loss: 61.6266\n",
      "Epoch 4649/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 133.282 - 0s 495us/step - loss: 119.5527 - val_loss: 61.5890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4650/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 154.8998 - val_loss: 61.5557\n",
      "Epoch 4651/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 151.1950 - val_loss: 61.5215\n",
      "Epoch 4652/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 157.0772 - val_loss: 61.4736\n",
      "Epoch 4653/10000\n",
      "184/184 [==============================] - 0s 456us/step - loss: 158.7671 - val_loss: 61.4295\n",
      "Epoch 4654/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 145.8452 - val_loss: 61.3884\n",
      "Epoch 4655/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 197.7043 - val_loss: 61.3471\n",
      "Epoch 4656/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 155.3082 - val_loss: 61.3103\n",
      "Epoch 4657/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 167.4865 - val_loss: 61.2702\n",
      "Epoch 4658/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 140.0106 - val_loss: 61.2324\n",
      "Epoch 4659/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 183.8775 - val_loss: 61.1916\n",
      "Epoch 4660/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 168.3003 - val_loss: 61.1468\n",
      "Epoch 4661/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 128.5845 - val_loss: 61.1049\n",
      "Epoch 4662/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 168.2164 - val_loss: 61.0623\n",
      "Epoch 4663/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 137.5424 - val_loss: 61.0194\n",
      "Epoch 4664/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 198.6282 - val_loss: 60.9805\n",
      "Epoch 4665/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 169.1490 - val_loss: 60.9362\n",
      "Epoch 4666/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 170.0573 - val_loss: 60.8919\n",
      "Epoch 4667/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 146.8511 - val_loss: 60.8513\n",
      "Epoch 4668/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 116.3101 - val_loss: 60.8138\n",
      "Epoch 4669/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 147.0374 - val_loss: 60.7780\n",
      "Epoch 4670/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 188.1861 - val_loss: 60.7397\n",
      "Epoch 4671/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 121.3655 - val_loss: 60.7030\n",
      "Epoch 4672/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 140.8810 - val_loss: 60.6643\n",
      "Epoch 4673/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 178.7365 - val_loss: 60.6159\n",
      "Epoch 4674/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 152.9476 - val_loss: 60.5677\n",
      "Epoch 4675/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 144.1138 - val_loss: 60.5217\n",
      "Epoch 4676/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 167.1804 - val_loss: 60.4931\n",
      "Epoch 4677/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 142.6640 - val_loss: 60.4698\n",
      "Epoch 4678/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 182.2695 - val_loss: 60.4435\n",
      "Epoch 4679/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 153.8429 - val_loss: 60.4161\n",
      "Epoch 4680/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 188.5608 - val_loss: 60.3838\n",
      "Epoch 4681/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 144.1536 - val_loss: 60.3485\n",
      "Epoch 4682/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 166.4960 - val_loss: 60.3220\n",
      "Epoch 4683/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 187.5102 - val_loss: 60.2935\n",
      "Epoch 4684/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 181.6183 - val_loss: 60.2580\n",
      "Epoch 4685/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 151.8225 - val_loss: 60.2185\n",
      "Epoch 4686/10000\n",
      "184/184 [==============================] - 0s 506us/step - loss: 192.3039 - val_loss: 60.1813\n",
      "Epoch 4687/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 144.7088 - val_loss: 60.1486\n",
      "Epoch 4688/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 153.3843 - val_loss: 60.1140\n",
      "Epoch 4689/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 178.7300 - val_loss: 60.0808\n",
      "Epoch 4690/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 132.9799 - val_loss: 60.0495\n",
      "Epoch 4691/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 149.0242 - val_loss: 60.0225\n",
      "Epoch 4692/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 163.3432 - val_loss: 59.9905\n",
      "Epoch 4693/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 122.5350 - val_loss: 59.9567\n",
      "Epoch 4694/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 172.6215 - val_loss: 59.9251\n",
      "Epoch 4695/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 149.9010 - val_loss: 59.8902\n",
      "Epoch 4696/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 170.4905 - val_loss: 59.8480\n",
      "Epoch 4697/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 153.0876 - val_loss: 59.8223\n",
      "Epoch 4698/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 168.9588 - val_loss: 59.7992\n",
      "Epoch 4699/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 148.4391 - val_loss: 59.7462\n",
      "Epoch 4700/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 203.4310 - val_loss: 59.6798\n",
      "\n",
      "Epoch 04700: loss did not improve from 137.56569\n",
      "Epoch 4701/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 184.4343 - val_loss: 59.6082\n",
      "Epoch 4702/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 142.7542 - val_loss: 59.5253\n",
      "Epoch 4703/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 154.2431 - val_loss: 59.4511\n",
      "Epoch 4704/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 164.0790 - val_loss: 59.3885\n",
      "Epoch 4705/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 154.5546 - val_loss: 59.3280\n",
      "Epoch 4706/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 167.2428 - val_loss: 59.2735\n",
      "Epoch 4707/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 145.1235 - val_loss: 59.2298\n",
      "Epoch 4708/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 177.8105 - val_loss: 59.1831\n",
      "Epoch 4709/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 223.1669 - val_loss: 59.1375\n",
      "Epoch 4710/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 140.1791 - val_loss: 59.0911\n",
      "Epoch 4711/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 170.7579 - val_loss: 59.0452\n",
      "Epoch 4712/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 149.8589 - val_loss: 59.0117\n",
      "Epoch 4713/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 151.0177 - val_loss: 58.9773\n",
      "Epoch 4714/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 187.0977 - val_loss: 58.9421\n",
      "Epoch 4715/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 159.2911 - val_loss: 58.9157\n",
      "Epoch 4716/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 149.8922 - val_loss: 58.8942\n",
      "Epoch 4717/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 180.1924 - val_loss: 58.9150\n",
      "Epoch 4718/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 174.4668 - val_loss: 58.9310\n",
      "Epoch 4719/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 131.1152 - val_loss: 58.9440\n",
      "Epoch 4720/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 140.1779 - val_loss: 58.9555\n",
      "Epoch 4721/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 180.9358 - val_loss: 58.9551\n",
      "Epoch 4722/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 157.5038 - val_loss: 58.9615\n",
      "Epoch 4723/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 543us/step - loss: 171.1713 - val_loss: 58.9551\n",
      "Epoch 4724/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 135.6178 - val_loss: 58.9435\n",
      "Epoch 4725/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 205.6395 - val_loss: 58.9234\n",
      "Epoch 4726/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 164.5208 - val_loss: 58.8173\n",
      "Epoch 4727/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 166.0437 - val_loss: 58.6467\n",
      "Epoch 4728/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 159.8817 - val_loss: 58.5317\n",
      "Epoch 4729/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 158.0133 - val_loss: 58.4290\n",
      "Epoch 4730/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 179.1487 - val_loss: 58.3469\n",
      "Epoch 4731/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 167.6846 - val_loss: 58.2758\n",
      "Epoch 4732/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 146.7611 - val_loss: 58.2142\n",
      "Epoch 4733/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 142.7380 - val_loss: 58.1607\n",
      "Epoch 4734/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 140.3582 - val_loss: 58.1153\n",
      "Epoch 4735/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 162.0543 - val_loss: 58.0716\n",
      "Epoch 4736/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 130.3623 - val_loss: 58.0265\n",
      "Epoch 4737/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 174.9402 - val_loss: 57.9818\n",
      "Epoch 4738/10000\n",
      "184/184 [==============================] - 0s 541us/step - loss: 191.7565 - val_loss: 57.9356\n",
      "Epoch 4739/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 142.3033 - val_loss: 57.8784\n",
      "Epoch 4740/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 152.2869 - val_loss: 57.8264\n",
      "Epoch 4741/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 186.7702 - val_loss: 57.7760\n",
      "Epoch 4742/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 139.7459 - val_loss: 57.7378\n",
      "Epoch 4743/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 171.7799 - val_loss: 57.7037\n",
      "Epoch 4744/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 174.6910 - val_loss: 57.6706\n",
      "Epoch 4745/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 160.4671 - val_loss: 57.6331\n",
      "Epoch 4746/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 142.0519 - val_loss: 57.5946\n",
      "Epoch 4747/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 193.6120 - val_loss: 57.5452\n",
      "Epoch 4748/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 167.9639 - val_loss: 57.4968\n",
      "Epoch 4749/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 180.5269 - val_loss: 57.4474\n",
      "Epoch 4750/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 179.8440 - val_loss: 57.4008\n",
      "Epoch 4751/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 178.5698 - val_loss: 57.3524\n",
      "Epoch 4752/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 148.5478 - val_loss: 57.3034\n",
      "Epoch 4753/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 152.0541 - val_loss: 57.2614\n",
      "Epoch 4754/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 138.3202 - val_loss: 57.2203\n",
      "Epoch 4755/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 149.7533 - val_loss: 57.1820\n",
      "Epoch 4756/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 172.9621 - val_loss: 57.1432\n",
      "Epoch 4757/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 170.8399 - val_loss: 57.1063\n",
      "Epoch 4758/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 139.7267 - val_loss: 57.0665\n",
      "Epoch 4759/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 152.4145 - val_loss: 57.0286\n",
      "Epoch 4760/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 155.6398 - val_loss: 56.9935\n",
      "Epoch 4761/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 173.0481 - val_loss: 56.9595\n",
      "Epoch 4762/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 160.1491 - val_loss: 56.9259\n",
      "Epoch 4763/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 141.6004 - val_loss: 56.8922\n",
      "Epoch 4764/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 145.0577 - val_loss: 56.8582\n",
      "Epoch 4765/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 158.5751 - val_loss: 56.8200\n",
      "Epoch 4766/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 143.3505 - val_loss: 56.7795\n",
      "Epoch 4767/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 179.0161 - val_loss: 56.7354\n",
      "Epoch 4768/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 137.0772 - val_loss: 56.6906\n",
      "Epoch 4769/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 178.1449 - val_loss: 56.6448\n",
      "Epoch 4770/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 145.9379 - val_loss: 56.6019\n",
      "Epoch 4771/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 147.2052 - val_loss: 56.5644\n",
      "Epoch 4772/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 149.9921 - val_loss: 56.5303\n",
      "Epoch 4773/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 151.2469 - val_loss: 56.4999\n",
      "Epoch 4774/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 151.2158 - val_loss: 56.4701\n",
      "Epoch 4775/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 154.0022 - val_loss: 56.4388\n",
      "Epoch 4776/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 184.2588 - val_loss: 56.4076\n",
      "Epoch 4777/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 175.7758 - val_loss: 56.3722\n",
      "Epoch 4778/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 125.7900 - val_loss: 56.3332\n",
      "Epoch 4779/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 118.9111 - val_loss: 56.2933\n",
      "Epoch 4780/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 168.9749 - val_loss: 56.2525\n",
      "Epoch 4781/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 120.4544 - val_loss: 56.2177\n",
      "Epoch 4782/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 137.2862 - val_loss: 56.1843\n",
      "Epoch 4783/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 140.4745 - val_loss: 56.1543\n",
      "Epoch 4784/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 148.6396 - val_loss: 56.1244\n",
      "Epoch 4785/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 174.1641 - val_loss: 56.0837\n",
      "Epoch 4786/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 154.9708 - val_loss: 56.0385\n",
      "Epoch 4787/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 142.2876 - val_loss: 55.9937\n",
      "Epoch 4788/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 168.8877 - val_loss: 55.9515\n",
      "Epoch 4789/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 157.5461 - val_loss: 55.9110\n",
      "Epoch 4790/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 171.8745 - val_loss: 55.8708\n",
      "Epoch 4791/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 155.8997 - val_loss: 55.8310\n",
      "Epoch 4792/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 132.4717 - val_loss: 55.7903\n",
      "Epoch 4793/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 117.4636 - val_loss: 55.7483\n",
      "Epoch 4794/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 157.1469 - val_loss: 55.7051\n",
      "Epoch 4795/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 184.6671 - val_loss: 55.6667\n",
      "Epoch 4796/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 173.3574 - val_loss: 55.6361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4797/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 186.3662 - val_loss: 55.6080\n",
      "Epoch 4798/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 146.7100 - val_loss: 55.5775\n",
      "Epoch 4799/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 124.9227 - val_loss: 55.5463\n",
      "Epoch 4800/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 136.3285 - val_loss: 55.5140\n",
      "\n",
      "Epoch 04800: loss improved from 137.56569 to 136.32855, saving model to C6007C.hdf5\n",
      "Epoch 4801/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 163.4785 - val_loss: 55.4801\n",
      "Epoch 4802/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 197.9474 - val_loss: 55.8923\n",
      "Epoch 4803/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 140.9564 - val_loss: 57.4040\n",
      "Epoch 4804/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 140.9544 - val_loss: 58.7184\n",
      "Epoch 4805/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 156.6495 - val_loss: 59.4116\n",
      "Epoch 4806/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 154.9735 - val_loss: 59.6998\n",
      "Epoch 4807/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 134.0039 - val_loss: 59.8805\n",
      "Epoch 4808/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 158.0858 - val_loss: 60.0152\n",
      "Epoch 4809/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 218.3252 - val_loss: 60.0696\n",
      "Epoch 4810/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 197.7105 - val_loss: 60.1125\n",
      "Epoch 4811/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 161.5290 - val_loss: 60.0258\n",
      "Epoch 4812/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 124.0611 - val_loss: 59.9315\n",
      "Epoch 4813/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 157.0652 - val_loss: 59.7997\n",
      "Epoch 4814/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 162.1594 - val_loss: 59.7610\n",
      "Epoch 4815/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 121.4707 - val_loss: 59.7047\n",
      "Epoch 4816/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 144.8307 - val_loss: 59.6515\n",
      "Epoch 4817/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 130.9430 - val_loss: 59.6016\n",
      "Epoch 4818/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 124.0556 - val_loss: 59.5607\n",
      "Epoch 4819/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 129.2391 - val_loss: 59.5198\n",
      "Epoch 4820/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 179.2026 - val_loss: 59.4792\n",
      "Epoch 4821/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 181.2624 - val_loss: 59.4416\n",
      "Epoch 4822/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 138.7144 - val_loss: 59.4056\n",
      "Epoch 4823/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 122.8973 - val_loss: 59.3687\n",
      "Epoch 4824/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 190.3964 - val_loss: 59.3338\n",
      "Epoch 4825/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 153.8181 - val_loss: 59.3464\n",
      "Epoch 4826/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 169.7862 - val_loss: 59.3806\n",
      "Epoch 4827/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 140.4025 - val_loss: 59.4154\n",
      "Epoch 4828/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 170.4219 - val_loss: 59.4459\n",
      "Epoch 4829/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 173.1160 - val_loss: 59.4577\n",
      "Epoch 4830/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 310.2330 - val_loss: 59.4184\n",
      "Epoch 4831/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 142.2468 - val_loss: 59.3495\n",
      "Epoch 4832/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 128.3172 - val_loss: 59.2512\n",
      "Epoch 4833/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 130.2037 - val_loss: 59.1615\n",
      "Epoch 4834/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 141.9354 - val_loss: 59.0689\n",
      "Epoch 4835/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 167.3149 - val_loss: 58.9812\n",
      "Epoch 4836/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 149.2403 - val_loss: 58.9062\n",
      "Epoch 4837/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 144.3399 - val_loss: 58.8553\n",
      "Epoch 4838/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 148.9124 - val_loss: 58.8097\n",
      "Epoch 4839/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 165.8308 - val_loss: 58.7649\n",
      "Epoch 4840/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 147.9066 - val_loss: 58.7213\n",
      "Epoch 4841/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 172.5233 - val_loss: 58.6684\n",
      "Epoch 4842/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 162.2727 - val_loss: 58.6188\n",
      "Epoch 4843/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 164.0644 - val_loss: 58.5745\n",
      "Epoch 4844/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 164.2575 - val_loss: 58.5679\n",
      "Epoch 4845/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 140.6625 - val_loss: 58.5819\n",
      "Epoch 4846/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 161.5896 - val_loss: 58.5843\n",
      "Epoch 4847/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 132.7698 - val_loss: 58.5243\n",
      "Epoch 4848/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 127.0713 - val_loss: 58.4685\n",
      "Epoch 4849/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 151.4779 - val_loss: 58.4126\n",
      "Epoch 4850/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 127.5440 - val_loss: 58.3672\n",
      "Epoch 4851/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 126.2086 - val_loss: 58.3430\n",
      "Epoch 4852/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 150.5549 - val_loss: 58.3202\n",
      "Epoch 4853/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 143.6737 - val_loss: 58.2949\n",
      "Epoch 4854/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 116.5245 - val_loss: 58.2675\n",
      "Epoch 4855/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 125.4532 - val_loss: 58.2460\n",
      "Epoch 4856/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 142.6459 - val_loss: 58.2273\n",
      "Epoch 4857/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 131.9414 - val_loss: 58.2015\n",
      "Epoch 4858/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 141.2577 - val_loss: 58.1745\n",
      "Epoch 4859/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 138.1736 - val_loss: 58.1469\n",
      "Epoch 4860/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 153.4753 - val_loss: 58.1215\n",
      "Epoch 4861/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 188.2484 - val_loss: 58.0920\n",
      "Epoch 4862/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 163.6742 - val_loss: 58.0595\n",
      "Epoch 4863/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 119.3705 - val_loss: 58.0257\n",
      "Epoch 4864/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 129.7841 - val_loss: 57.9915\n",
      "Epoch 4865/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 156.2481 - val_loss: 57.9580\n",
      "Epoch 4866/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 161.4501 - val_loss: 57.9816\n",
      "Epoch 4867/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 166.8324 - val_loss: 58.0561\n",
      "Epoch 4868/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 147.1508 - val_loss: 58.0814\n",
      "Epoch 4869/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 153.9154 - val_loss: 58.0506\n",
      "Epoch 4870/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 582us/step - loss: 153.4999 - val_loss: 57.8874\n",
      "Epoch 4871/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 158.0138 - val_loss: 57.7429\n",
      "Epoch 4872/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 132.4836 - val_loss: 57.6662\n",
      "Epoch 4873/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 152.3408 - val_loss: 57.5780\n",
      "Epoch 4874/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 149.0955 - val_loss: 57.4049\n",
      "Epoch 4875/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 151.3234 - val_loss: 57.2006\n",
      "Epoch 4876/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 160.2220 - val_loss: 56.9763\n",
      "Epoch 4877/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 151.8053 - val_loss: 56.7891\n",
      "Epoch 4878/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 146.0351 - val_loss: 56.6699\n",
      "Epoch 4879/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 103.0498 - val_loss: 56.6125\n",
      "Epoch 4880/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 151.7652 - val_loss: 56.5631\n",
      "Epoch 4881/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 146.5099 - val_loss: 56.4876\n",
      "Epoch 4882/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 184.9230 - val_loss: 56.4008\n",
      "Epoch 4883/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 144.2062 - val_loss: 56.3410\n",
      "Epoch 4884/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 124.3597 - val_loss: 56.2895\n",
      "Epoch 4885/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 191.0941 - val_loss: 56.2440\n",
      "Epoch 4886/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 210.6161 - val_loss: 56.1970\n",
      "Epoch 4887/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 133.1633 - val_loss: 56.1574\n",
      "Epoch 4888/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 163.6567 - val_loss: 56.1210\n",
      "Epoch 4889/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 199.5572 - val_loss: 56.0862\n",
      "Epoch 4890/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 132.3921 - val_loss: 56.0518\n",
      "Epoch 4891/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 162.2939 - val_loss: 56.0172\n",
      "Epoch 4892/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 151.9714 - val_loss: 55.9825\n",
      "Epoch 4893/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 137.2793 - val_loss: 55.9560\n",
      "Epoch 4894/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 154.9095 - val_loss: 55.9008\n",
      "Epoch 4895/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 150.7622 - val_loss: 55.8514\n",
      "Epoch 4896/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 149.3782 - val_loss: 55.8027\n",
      "Epoch 4897/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 166.7059 - val_loss: 55.7587\n",
      "Epoch 4898/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 126.9720 - val_loss: 55.7204\n",
      "Epoch 4899/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 146.4944 - val_loss: 55.6856\n",
      "Epoch 4900/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 166.3092 - val_loss: 55.6520\n",
      "\n",
      "Epoch 04900: loss did not improve from 136.32855\n",
      "Epoch 4901/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 138.3709 - val_loss: 55.6266\n",
      "Epoch 4902/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 124.4231 - val_loss: 55.6174\n",
      "Epoch 4903/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 129.6452 - val_loss: 55.6216\n",
      "Epoch 4904/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 182.4655 - val_loss: 55.6217\n",
      "Epoch 4905/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 183.4985 - val_loss: 55.6511\n",
      "Epoch 4906/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 132.1615 - val_loss: 55.6758\n",
      "Epoch 4907/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 136.7972 - val_loss: 55.6927\n",
      "Epoch 4908/10000\n",
      "184/184 [==============================] - 0s 497us/step - loss: 147.3018 - val_loss: 55.6982\n",
      "Epoch 4909/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 143.096 - 0s 484us/step - loss: 149.6695 - val_loss: 55.7863\n",
      "Epoch 4910/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 143.5109 - val_loss: 55.8611\n",
      "Epoch 4911/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 143.8270 - val_loss: 55.9183\n",
      "Epoch 4912/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 136.4866 - val_loss: 55.9586\n",
      "Epoch 4913/10000\n",
      "184/184 [==============================] - 0s 546us/step - loss: 172.8600 - val_loss: 55.9892\n",
      "Epoch 4914/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 178.9403 - val_loss: 56.0045\n",
      "Epoch 4915/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 115.1597 - val_loss: 56.0045\n",
      "Epoch 4916/10000\n",
      "184/184 [==============================] - 0s 525us/step - loss: 108.9394 - val_loss: 55.9895\n",
      "Epoch 4917/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 168.6802 - val_loss: 55.9775\n",
      "Epoch 4918/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 130.4676 - val_loss: 55.9535\n",
      "Epoch 4919/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 171.6242 - val_loss: 55.9223\n",
      "Epoch 4920/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 138.117 - 0s 511us/step - loss: 148.2698 - val_loss: 55.9029\n",
      "Epoch 4921/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 176.5912 - val_loss: 55.8048\n",
      "Epoch 4922/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 166.4968 - val_loss: 55.7077\n",
      "Epoch 4923/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 146.9670 - val_loss: 55.3042\n",
      "Epoch 4924/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 140.0109 - val_loss: 54.9715\n",
      "Epoch 4925/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 144.4674 - val_loss: 54.8359\n",
      "Epoch 4926/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 170.9789 - val_loss: 54.7477\n",
      "Epoch 4927/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 158.4137 - val_loss: 54.6789\n",
      "Epoch 4928/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 159.2942 - val_loss: 54.6264\n",
      "Epoch 4929/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 153.4463 - val_loss: 54.6131\n",
      "Epoch 4930/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 162.4995 - val_loss: 55.0043\n",
      "Epoch 4931/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 111.9363 - val_loss: 54.8219\n",
      "Epoch 4932/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 148.5510 - val_loss: 54.4869\n",
      "Epoch 4933/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 168.1016 - val_loss: 54.3854\n",
      "Epoch 4934/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 173.4737 - val_loss: 54.3495\n",
      "Epoch 4935/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 182.4846 - val_loss: 54.4070\n",
      "Epoch 4936/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 133.9630 - val_loss: 54.4225\n",
      "Epoch 4937/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 137.3131 - val_loss: 54.3999\n",
      "Epoch 4938/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 153.4467 - val_loss: 54.3673\n",
      "Epoch 4939/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 154.8888 - val_loss: 54.3139\n",
      "Epoch 4940/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 136.4478 - val_loss: 54.1380\n",
      "Epoch 4941/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 181.8844 - val_loss: 54.0928\n",
      "Epoch 4942/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 146.0719 - val_loss: 54.2092\n",
      "Epoch 4943/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 560us/step - loss: 155.1539 - val_loss: 54.2001\n",
      "Epoch 4944/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 159.4929 - val_loss: 54.2834\n",
      "Epoch 4945/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 147.2324 - val_loss: 54.0998\n",
      "Epoch 4946/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 194.5267 - val_loss: 53.8280\n",
      "Epoch 4947/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 174.5220 - val_loss: 53.6624\n",
      "Epoch 4948/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 130.6243 - val_loss: 53.5613\n",
      "Epoch 4949/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 134.9541 - val_loss: 53.4992\n",
      "Epoch 4950/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 134.2288 - val_loss: 53.4434\n",
      "Epoch 4951/10000\n",
      "184/184 [==============================] - 0s 506us/step - loss: 171.9349 - val_loss: 53.3983\n",
      "Epoch 4952/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 151.6260 - val_loss: 53.3542\n",
      "Epoch 4953/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 168.8756 - val_loss: 52.8151\n",
      "Epoch 4954/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 127.1884 - val_loss: 52.3268\n",
      "Epoch 4955/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 115.7260 - val_loss: 52.2550\n",
      "Epoch 4956/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 170.7188 - val_loss: 52.2194\n",
      "Epoch 4957/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 138.5303 - val_loss: 52.1881\n",
      "Epoch 4958/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 125.2333 - val_loss: 52.1566\n",
      "Epoch 4959/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 132.2580 - val_loss: 52.1110\n",
      "Epoch 4960/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 165.8630 - val_loss: 52.0778\n",
      "Epoch 4961/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 171.5874 - val_loss: 52.0516\n",
      "Epoch 4962/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 153.5148 - val_loss: 52.0248\n",
      "Epoch 4963/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 142.4857 - val_loss: 51.9945\n",
      "Epoch 4964/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 159.6413 - val_loss: 51.9612\n",
      "Epoch 4965/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 169.6995 - val_loss: 51.9259\n",
      "Epoch 4966/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 138.6032 - val_loss: 51.8879\n",
      "Epoch 4967/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 239.9374 - val_loss: 51.8477\n",
      "Epoch 4968/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 135.1608 - val_loss: 51.8077\n",
      "Epoch 4969/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 171.1576 - val_loss: 51.7704\n",
      "Epoch 4970/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 137.5970 - val_loss: 51.7328\n",
      "Epoch 4971/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 131.7994 - val_loss: 51.6908\n",
      "Epoch 4972/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 138.2482 - val_loss: 51.6402\n",
      "Epoch 4973/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 124.6453 - val_loss: 51.5880\n",
      "Epoch 4974/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 146.8170 - val_loss: 51.5379\n",
      "Epoch 4975/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 187.4123 - val_loss: 51.4895\n",
      "Epoch 4976/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 170.0788 - val_loss: 51.4482\n",
      "Epoch 4977/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 150.2670 - val_loss: 51.4144\n",
      "Epoch 4978/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 140.9117 - val_loss: 51.3833\n",
      "Epoch 4979/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 143.8238 - val_loss: 51.3521\n",
      "Epoch 4980/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 150.7678 - val_loss: 51.3245\n",
      "Epoch 4981/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 138.7541 - val_loss: 51.2988\n",
      "Epoch 4982/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 145.8918 - val_loss: 51.2726\n",
      "Epoch 4983/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 153.6100 - val_loss: 51.3198\n",
      "Epoch 4984/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 154.2495 - val_loss: 51.3627\n",
      "Epoch 4985/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 130.5018 - val_loss: 51.3952\n",
      "Epoch 4986/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 98.0213 - val_loss: 51.4135\n",
      "Epoch 4987/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 151.5832 - val_loss: 51.4663\n",
      "Epoch 4988/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 173.5004 - val_loss: 51.4818\n",
      "Epoch 4989/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 112.9583 - val_loss: 51.4922\n",
      "Epoch 4990/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 151.6084 - val_loss: 51.4928\n",
      "Epoch 4991/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 135.3556 - val_loss: 51.4809\n",
      "Epoch 4992/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 167.9991 - val_loss: 51.4588\n",
      "Epoch 4993/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 144.9544 - val_loss: 51.4270\n",
      "Epoch 4994/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 145.7274 - val_loss: 51.3935\n",
      "Epoch 4995/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 149.2530 - val_loss: 51.3662\n",
      "Epoch 4996/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 134.6724 - val_loss: 51.3464\n",
      "Epoch 4997/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 179.2003 - val_loss: 51.3289\n",
      "Epoch 4998/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 146.0945 - val_loss: 51.3102\n",
      "Epoch 4999/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 148.3988 - val_loss: 51.2868\n",
      "Epoch 5000/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 146.1407 - val_loss: 51.2549\n",
      "\n",
      "Epoch 05000: loss did not improve from 136.32855\n",
      "Epoch 5001/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 142.4285 - val_loss: 51.2169\n",
      "Epoch 5002/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 142.4596 - val_loss: 51.1706\n",
      "Epoch 5003/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 167.3267 - val_loss: 51.1237\n",
      "Epoch 5004/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 150.8255 - val_loss: 51.0152\n",
      "Epoch 5005/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 132.1257 - val_loss: 51.0511\n",
      "Epoch 5006/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 134.3405 - val_loss: 50.5551\n",
      "Epoch 5007/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 157.2635 - val_loss: 50.7667\n",
      "Epoch 5008/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 148.5262 - val_loss: 51.9024\n",
      "Epoch 5009/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 144.9256 - val_loss: 51.7467\n",
      "Epoch 5010/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 155.4075 - val_loss: 51.6841\n",
      "Epoch 5011/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 139.4606 - val_loss: 51.4560\n",
      "Epoch 5012/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 142.1939 - val_loss: 51.3417\n",
      "Epoch 5013/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 175.3927 - val_loss: 51.2914\n",
      "Epoch 5014/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 135.1710 - val_loss: 51.2182\n",
      "Epoch 5015/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 146.9293 - val_loss: 51.1450\n",
      "Epoch 5016/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 582us/step - loss: 193.3063 - val_loss: 51.0810\n",
      "Epoch 5017/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 155.3746 - val_loss: 51.0856\n",
      "Epoch 5018/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 122.8509 - val_loss: 51.0980\n",
      "Epoch 5019/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 159.9101 - val_loss: 51.2573\n",
      "Epoch 5020/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 175.8857 - val_loss: 50.7712\n",
      "Epoch 5021/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 177.6696 - val_loss: 50.0206\n",
      "Epoch 5022/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 113.6286 - val_loss: 49.2194\n",
      "Epoch 5023/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 161.4472 - val_loss: 49.1721\n",
      "Epoch 5024/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 127.8421 - val_loss: 49.0121\n",
      "Epoch 5025/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 117.9253 - val_loss: 49.2517\n",
      "Epoch 5026/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 142.3370 - val_loss: 49.3665\n",
      "Epoch 5027/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 143.1772 - val_loss: 49.2977\n",
      "Epoch 5028/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 162.7056 - val_loss: 49.2796\n",
      "Epoch 5029/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 128.8669 - val_loss: 49.2840\n",
      "Epoch 5030/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 155.4280 - val_loss: 49.4740\n",
      "Epoch 5031/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 160.4702 - val_loss: 49.2619\n",
      "Epoch 5032/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 133.1193 - val_loss: 49.0936\n",
      "Epoch 5033/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 129.1480 - val_loss: 49.0106\n",
      "Epoch 5034/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 159.7588 - val_loss: 48.9766\n",
      "Epoch 5035/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 162.8341 - val_loss: 48.7481\n",
      "Epoch 5036/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 135.5706 - val_loss: 48.5538\n",
      "Epoch 5037/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 127.9181 - val_loss: 48.5039\n",
      "Epoch 5038/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 143.1857 - val_loss: 48.3758\n",
      "Epoch 5039/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 113.1114 - val_loss: 48.3408\n",
      "Epoch 5040/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 195.3080 - val_loss: 48.3441\n",
      "Epoch 5041/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 190.3618 - val_loss: 48.4406\n",
      "Epoch 5042/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 184.8663 - val_loss: 48.4578\n",
      "Epoch 5043/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 160.3900 - val_loss: 48.4347\n",
      "Epoch 5044/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 166.6604 - val_loss: 48.4619\n",
      "Epoch 5045/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 197.7983 - val_loss: 48.4495\n",
      "Epoch 5046/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 120.5333 - val_loss: 48.4473\n",
      "Epoch 5047/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 139.3419 - val_loss: 48.4466\n",
      "Epoch 5048/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 128.5720 - val_loss: 48.4376\n",
      "Epoch 5049/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 152.6417 - val_loss: 48.4325\n",
      "Epoch 5050/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 156.9133 - val_loss: 48.4183\n",
      "Epoch 5051/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 151.7321 - val_loss: 48.4122\n",
      "Epoch 5052/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 149.7532 - val_loss: 48.4497\n",
      "Epoch 5053/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 188.9837 - val_loss: 48.4857\n",
      "Epoch 5054/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 133.1434 - val_loss: 48.3912\n",
      "Epoch 5055/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 177.2753 - val_loss: 48.4151\n",
      "Epoch 5056/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 139.3161 - val_loss: 48.4632\n",
      "Epoch 5057/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 173.5445 - val_loss: 48.5068\n",
      "Epoch 5058/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 133.9119 - val_loss: 48.7412\n",
      "Epoch 5059/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 158.4478 - val_loss: 48.4377\n",
      "Epoch 5060/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 122.1140 - val_loss: 48.3887\n",
      "Epoch 5061/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 125.2979 - val_loss: 48.4002\n",
      "Epoch 5062/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 148.5971 - val_loss: 48.4457\n",
      "Epoch 5063/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 154.8924 - val_loss: 48.5117\n",
      "Epoch 5064/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 165.0838 - val_loss: 48.5486\n",
      "Epoch 5065/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 162.7209 - val_loss: 48.5777\n",
      "Epoch 5066/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 137.0683 - val_loss: 48.5806\n",
      "Epoch 5067/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 135.4501 - val_loss: 48.5507\n",
      "Epoch 5068/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 113.4832 - val_loss: 48.4942\n",
      "Epoch 5069/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 148.9914 - val_loss: 48.4030\n",
      "Epoch 5070/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 125.4423 - val_loss: 48.3143\n",
      "Epoch 5071/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 168.0209 - val_loss: 48.2299\n",
      "Epoch 5072/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 141.6912 - val_loss: 48.1978\n",
      "Epoch 5073/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 121.6016 - val_loss: 48.2121\n",
      "Epoch 5074/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 156.5956 - val_loss: 48.1881\n",
      "Epoch 5075/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 121.4261 - val_loss: 48.3660\n",
      "Epoch 5076/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 134.1850 - val_loss: 48.2973\n",
      "Epoch 5077/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 137.7448 - val_loss: 48.2284\n",
      "Epoch 5078/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 111.0167 - val_loss: 48.2074\n",
      "Epoch 5079/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 143.0667 - val_loss: 48.1581\n",
      "Epoch 5080/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 141.7203 - val_loss: 47.9988\n",
      "Epoch 5081/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 105.8789 - val_loss: 47.8708\n",
      "Epoch 5082/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 116.4664 - val_loss: 47.8412\n",
      "Epoch 5083/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 141.1291 - val_loss: 47.8406\n",
      "Epoch 5084/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 121.9043 - val_loss: 47.8250\n",
      "Epoch 5085/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 119.8607 - val_loss: 47.8001\n",
      "Epoch 5086/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 154.2505 - val_loss: 47.7731\n",
      "Epoch 5087/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 119.1141 - val_loss: 47.7434\n",
      "Epoch 5088/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 155.2103 - val_loss: 47.7208\n",
      "Epoch 5089/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 125.8805 - val_loss: 47.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5090/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 132.6014 - val_loss: 47.5963\n",
      "Epoch 5091/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 126.3936 - val_loss: 47.7913\n",
      "Epoch 5092/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 125.9244 - val_loss: 47.5375\n",
      "Epoch 5093/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 146.8007 - val_loss: 47.4576\n",
      "Epoch 5094/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 160.5807 - val_loss: 47.4338\n",
      "Epoch 5095/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 110.3617 - val_loss: 47.4205\n",
      "Epoch 5096/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 106.2742 - val_loss: 47.3677\n",
      "Epoch 5097/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 130.9413 - val_loss: 47.3066\n",
      "Epoch 5098/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 203.1394 - val_loss: 47.2567\n",
      "Epoch 5099/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 150.7907 - val_loss: 47.2139\n",
      "Epoch 5100/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 141.6172 - val_loss: 47.1336\n",
      "\n",
      "Epoch 05100: loss did not improve from 136.32855\n",
      "Epoch 5101/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 155.8824 - val_loss: 47.1903\n",
      "Epoch 5102/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 159.7726 - val_loss: 47.3011\n",
      "Epoch 5103/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 157.3598 - val_loss: 47.3649\n",
      "Epoch 5104/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 105.5685 - val_loss: 47.5566\n",
      "Epoch 5105/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 164.5663 - val_loss: 47.5938\n",
      "Epoch 5106/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 163.4637 - val_loss: 47.5984\n",
      "Epoch 5107/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 201.2355 - val_loss: 47.6778\n",
      "Epoch 5108/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 162.5883 - val_loss: 47.6826\n",
      "Epoch 5109/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 151.6894 - val_loss: 47.6045\n",
      "Epoch 5110/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 121.7439 - val_loss: 47.5478\n",
      "Epoch 5111/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 143.4791 - val_loss: 47.3737\n",
      "Epoch 5112/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 164.0750 - val_loss: 46.9208\n",
      "Epoch 5113/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 132.5854 - val_loss: 46.7223\n",
      "Epoch 5114/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 167.0603 - val_loss: 46.5544\n",
      "Epoch 5115/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 173.1369 - val_loss: 46.6057\n",
      "Epoch 5116/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 148.9496 - val_loss: 46.6595\n",
      "Epoch 5117/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 154.5227 - val_loss: 46.6997\n",
      "Epoch 5118/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 111.2810 - val_loss: 46.6813\n",
      "Epoch 5119/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 170.6208 - val_loss: 46.6449\n",
      "Epoch 5120/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 150.2087 - val_loss: 46.6407\n",
      "Epoch 5121/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 141.2226 - val_loss: 46.6236\n",
      "Epoch 5122/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 123.6320 - val_loss: 46.5863\n",
      "Epoch 5123/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 171.2213 - val_loss: 46.5246\n",
      "Epoch 5124/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 138.5281 - val_loss: 46.5014\n",
      "Epoch 5125/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 155.7465 - val_loss: 46.4659\n",
      "Epoch 5126/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 134.0603 - val_loss: 46.6666\n",
      "Epoch 5127/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 167.5449 - val_loss: 46.9609\n",
      "Epoch 5128/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 112.0862 - val_loss: 47.0907\n",
      "Epoch 5129/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 155.8509 - val_loss: 47.1239\n",
      "Epoch 5130/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 136.1798 - val_loss: 47.1165\n",
      "Epoch 5131/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 202.5604 - val_loss: 47.1051\n",
      "Epoch 5132/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 117.9513 - val_loss: 47.1157\n",
      "Epoch 5133/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 135.6579 - val_loss: 47.1329\n",
      "Epoch 5134/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 135.6162 - val_loss: 47.1690\n",
      "Epoch 5135/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 135.9703 - val_loss: 47.1325\n",
      "Epoch 5136/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 163.1282 - val_loss: 47.1311\n",
      "Epoch 5137/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 135.8529 - val_loss: 47.2080\n",
      "Epoch 5138/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 141.8771 - val_loss: 47.3685\n",
      "Epoch 5139/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 138.8713 - val_loss: 47.3944\n",
      "Epoch 5140/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 157.7680 - val_loss: 47.3911\n",
      "Epoch 5141/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 121.4186 - val_loss: 47.4401\n",
      "Epoch 5142/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 108.9429 - val_loss: 47.6067\n",
      "Epoch 5143/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 138.1869 - val_loss: 47.3479\n",
      "Epoch 5144/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 165.0854 - val_loss: 47.3464\n",
      "Epoch 5145/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 131.3208 - val_loss: 47.3134\n",
      "Epoch 5146/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 158.1522 - val_loss: 47.2745\n",
      "Epoch 5147/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 131.1847 - val_loss: 47.2297\n",
      "Epoch 5148/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 122.9742 - val_loss: 47.1884\n",
      "Epoch 5149/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 126.5334 - val_loss: 47.1525\n",
      "Epoch 5150/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 112.0749 - val_loss: 47.0983\n",
      "Epoch 5151/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 117.5739 - val_loss: 47.0237\n",
      "Epoch 5152/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 133.9100 - val_loss: 46.9065\n",
      "Epoch 5153/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 130.7837 - val_loss: 46.8974\n",
      "Epoch 5154/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 126.2771 - val_loss: 46.9906\n",
      "Epoch 5155/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 122.8728 - val_loss: 47.0549\n",
      "Epoch 5156/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 133.7181 - val_loss: 47.0612\n",
      "Epoch 5157/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 110.1654 - val_loss: 47.0409\n",
      "Epoch 5158/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 120.9720 - val_loss: 47.0330\n",
      "Epoch 5159/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 135.0582 - val_loss: 47.0151\n",
      "Epoch 5160/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 150.8559 - val_loss: 46.9868\n",
      "Epoch 5161/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 151.1222 - val_loss: 46.9615\n",
      "Epoch 5162/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 124.0866 - val_loss: 46.9416\n",
      "Epoch 5163/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 511us/step - loss: 140.1358 - val_loss: 46.9539\n",
      "Epoch 5164/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 135.9293 - val_loss: 46.9729\n",
      "Epoch 5165/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 128.7463 - val_loss: 46.9964\n",
      "Epoch 5166/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 179.3420 - val_loss: 47.2060\n",
      "Epoch 5167/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 119.6062 - val_loss: 47.2123\n",
      "Epoch 5168/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 141.2357 - val_loss: 47.2161\n",
      "Epoch 5169/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 140.9855 - val_loss: 47.2006\n",
      "Epoch 5170/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 123.4888 - val_loss: 47.1747\n",
      "Epoch 5171/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 129.3944 - val_loss: 47.1453\n",
      "Epoch 5172/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 166.7849 - val_loss: 47.0838\n",
      "Epoch 5173/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 150.4815 - val_loss: 47.0945\n",
      "Epoch 5174/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 160.6157 - val_loss: 46.8736\n",
      "Epoch 5175/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 113.4199 - val_loss: 46.8098\n",
      "Epoch 5176/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 133.0008 - val_loss: 46.8331\n",
      "Epoch 5177/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 163.3887 - val_loss: 46.6760\n",
      "Epoch 5178/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 111.1314 - val_loss: 46.6232\n",
      "Epoch 5179/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 117.4189 - val_loss: 46.5161\n",
      "Epoch 5180/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 122.1893 - val_loss: 46.3948\n",
      "Epoch 5181/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 136.6811 - val_loss: 46.3007\n",
      "Epoch 5182/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 149.2864 - val_loss: 46.1934\n",
      "Epoch 5183/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 174.3478 - val_loss: 46.2792\n",
      "Epoch 5184/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 151.8005 - val_loss: 46.3142\n",
      "Epoch 5185/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 115.5769 - val_loss: 46.3104\n",
      "Epoch 5186/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 140.7945 - val_loss: 46.2836\n",
      "Epoch 5187/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 163.0840 - val_loss: 46.3154\n",
      "Epoch 5188/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 154.8194 - val_loss: 46.4031\n",
      "Epoch 5189/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 126.8055 - val_loss: 46.4278\n",
      "Epoch 5190/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 114.7731 - val_loss: 46.3204\n",
      "Epoch 5191/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 213.2345 - val_loss: 46.1310\n",
      "Epoch 5192/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 129.4532 - val_loss: 46.0669\n",
      "Epoch 5193/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 143.4116 - val_loss: 46.2112\n",
      "Epoch 5194/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 152.9349 - val_loss: 46.0882\n",
      "Epoch 5195/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 181.8235 - val_loss: 46.0244\n",
      "Epoch 5196/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 101.0382 - val_loss: 45.9981\n",
      "Epoch 5197/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 128.7512 - val_loss: 45.9883\n",
      "Epoch 5198/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 124.2131 - val_loss: 45.9674\n",
      "Epoch 5199/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 131.5496 - val_loss: 45.9673\n",
      "Epoch 5200/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 133.9541 - val_loss: 45.9952\n",
      "\n",
      "Epoch 05200: loss improved from 136.32855 to 133.95408, saving model to C6007C.hdf5\n",
      "Epoch 5201/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 172.2987 - val_loss: 46.0061\n",
      "Epoch 5202/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 124.2810 - val_loss: 46.0065\n",
      "Epoch 5203/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 140.8962 - val_loss: 46.0010\n",
      "Epoch 5204/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 133.5376 - val_loss: 45.9926\n",
      "Epoch 5205/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 160.9997 - val_loss: 46.0317\n",
      "Epoch 5206/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 123.0895 - val_loss: 46.0661\n",
      "Epoch 5207/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 140.3198 - val_loss: 46.0792\n",
      "Epoch 5208/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 129.7574 - val_loss: 46.0754\n",
      "Epoch 5209/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 149.6779 - val_loss: 46.0620\n",
      "Epoch 5210/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 161.3621 - val_loss: 46.0379\n",
      "Epoch 5211/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 148.1794 - val_loss: 46.0318\n",
      "Epoch 5212/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 135.7626 - val_loss: 46.0152\n",
      "Epoch 5213/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 163.0648 - val_loss: 45.9830\n",
      "Epoch 5214/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 145.9708 - val_loss: 45.9543\n",
      "Epoch 5215/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 157.4173 - val_loss: 45.9273\n",
      "Epoch 5216/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 157.4606 - val_loss: 45.8995\n",
      "Epoch 5217/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 130.9776 - val_loss: 45.8617\n",
      "Epoch 5218/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 131.6340 - val_loss: 45.8121\n",
      "Epoch 5219/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 126.4244 - val_loss: 45.7654\n",
      "Epoch 5220/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 139.9570 - val_loss: 45.7217\n",
      "Epoch 5221/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 130.3868 - val_loss: 45.6698\n",
      "Epoch 5222/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 144.7788 - val_loss: 45.6084\n",
      "Epoch 5223/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 182.3753 - val_loss: 45.5508\n",
      "Epoch 5224/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 122.7219 - val_loss: 45.4985\n",
      "Epoch 5225/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 140.8630 - val_loss: 45.4535\n",
      "Epoch 5226/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 127.0006 - val_loss: 45.4131\n",
      "Epoch 5227/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 148.4914 - val_loss: 45.3778\n",
      "Epoch 5228/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 136.6808 - val_loss: 45.3447\n",
      "Epoch 5229/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 173.3282 - val_loss: 45.3216\n",
      "Epoch 5230/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 118.8373 - val_loss: 45.2980\n",
      "Epoch 5231/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 127.5565 - val_loss: 45.2748\n",
      "Epoch 5232/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 126.2959 - val_loss: 45.2494\n",
      "Epoch 5233/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 131.0149 - val_loss: 45.2227\n",
      "Epoch 5234/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 149.4171 - val_loss: 45.2034\n",
      "Epoch 5235/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 166.6582 - val_loss: 45.1896\n",
      "Epoch 5236/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 538us/step - loss: 109.0107 - val_loss: 45.1835\n",
      "Epoch 5237/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 130.6981 - val_loss: 45.1800\n",
      "Epoch 5238/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 152.9865 - val_loss: 45.1769\n",
      "Epoch 5239/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 99.5126 - val_loss: 45.1904\n",
      "Epoch 5240/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 129.7510 - val_loss: 45.1993\n",
      "Epoch 5241/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 150.4478 - val_loss: 45.2171\n",
      "Epoch 5242/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 135.5288 - val_loss: 45.2401\n",
      "Epoch 5243/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 125.6049 - val_loss: 45.2554\n",
      "Epoch 5244/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 156.4108 - val_loss: 45.2520\n",
      "Epoch 5245/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 101.5327 - val_loss: 45.2406\n",
      "Epoch 5246/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 105.1376 - val_loss: 45.2243\n",
      "Epoch 5247/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 108.3759 - val_loss: 45.2039\n",
      "Epoch 5248/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 145.7349 - val_loss: 45.1805\n",
      "Epoch 5249/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 151.6762 - val_loss: 45.1536\n",
      "Epoch 5250/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 103.7407 - val_loss: 45.1250\n",
      "Epoch 5251/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 134.3746 - val_loss: 45.1028\n",
      "Epoch 5252/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 165.9031 - val_loss: 45.0800\n",
      "Epoch 5253/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 148.4232 - val_loss: 45.0539\n",
      "Epoch 5254/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 111.1708 - val_loss: 45.0337\n",
      "Epoch 5255/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 120.2183 - val_loss: 44.7526\n",
      "Epoch 5256/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 131.3376 - val_loss: 44.4077\n",
      "Epoch 5257/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 128.2696 - val_loss: 43.9934\n",
      "Epoch 5258/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 105.0026 - val_loss: 43.8358\n",
      "Epoch 5259/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 123.6945 - val_loss: 43.7900\n",
      "Epoch 5260/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 155.1308 - val_loss: 43.7568\n",
      "Epoch 5261/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 132.1585 - val_loss: 43.6839\n",
      "Epoch 5262/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 120.1624 - val_loss: 43.5819\n",
      "Epoch 5263/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 155.4175 - val_loss: 43.3979\n",
      "Epoch 5264/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 187.4096 - val_loss: 43.3236\n",
      "Epoch 5265/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 139.8363 - val_loss: 43.2903\n",
      "Epoch 5266/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 131.6306 - val_loss: 43.2709\n",
      "Epoch 5267/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 136.1441 - val_loss: 43.4191\n",
      "Epoch 5268/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 142.0665 - val_loss: 43.1710\n",
      "Epoch 5269/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 122.6141 - val_loss: 43.0774\n",
      "Epoch 5270/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 147.5801 - val_loss: 43.4137\n",
      "Epoch 5271/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 132.2626 - val_loss: 43.4624\n",
      "Epoch 5272/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 130.2397 - val_loss: 43.4492\n",
      "Epoch 5273/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 157.5551 - val_loss: 43.4806\n",
      "Epoch 5274/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 120.9146 - val_loss: 43.5349\n",
      "Epoch 5275/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 119.2500 - val_loss: 43.5844\n",
      "Epoch 5276/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 186.4312 - val_loss: 43.6159\n",
      "Epoch 5277/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 112.8014 - val_loss: 43.6320\n",
      "Epoch 5278/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 139.4143 - val_loss: 43.6410\n",
      "Epoch 5279/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 134.1463 - val_loss: 43.6436\n",
      "Epoch 5280/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 112.3544 - val_loss: 43.6309\n",
      "Epoch 5281/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 147.6935 - val_loss: 43.6119\n",
      "Epoch 5282/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 143.7614 - val_loss: 43.5892\n",
      "Epoch 5283/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 145.7673 - val_loss: 43.5751\n",
      "Epoch 5284/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 165.6283 - val_loss: 43.5665\n",
      "Epoch 5285/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 123.8252 - val_loss: 43.5813\n",
      "Epoch 5286/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 179.4045 - val_loss: 43.6062\n",
      "Epoch 5287/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 149.3048 - val_loss: 43.6118\n",
      "Epoch 5288/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 108.3744 - val_loss: 43.6120\n",
      "Epoch 5289/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 161.0833 - val_loss: 43.6053\n",
      "Epoch 5290/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 117.1866 - val_loss: 43.5942\n",
      "Epoch 5291/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 183.7575 - val_loss: 43.5835\n",
      "Epoch 5292/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 121.7159 - val_loss: 43.5715\n",
      "Epoch 5293/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 114.8354 - val_loss: 43.5519\n",
      "Epoch 5294/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 145.2946 - val_loss: 43.5355\n",
      "Epoch 5295/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 181.1058 - val_loss: 43.5204\n",
      "Epoch 5296/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 185.8298 - val_loss: 43.4786\n",
      "Epoch 5297/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 104.8878 - val_loss: 43.4324\n",
      "Epoch 5298/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 136.5373 - val_loss: 43.3911\n",
      "Epoch 5299/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 122.8716 - val_loss: 43.3426\n",
      "Epoch 5300/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 137.1672 - val_loss: 43.2928\n",
      "\n",
      "Epoch 05300: loss did not improve from 133.95408\n",
      "Epoch 5301/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 137.3712 - val_loss: 43.2389\n",
      "Epoch 5302/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 116.6995 - val_loss: 43.1932\n",
      "Epoch 5303/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 125.4578 - val_loss: 43.1497\n",
      "Epoch 5304/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 116.4178 - val_loss: 43.1099\n",
      "Epoch 5305/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 149.0789 - val_loss: 43.0914\n",
      "Epoch 5306/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 121.9676 - val_loss: 43.0912\n",
      "Epoch 5307/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 118.4598 - val_loss: 43.0880\n",
      "Epoch 5308/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 152.6233 - val_loss: 43.0793\n",
      "Epoch 5309/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 522us/step - loss: 114.2575 - val_loss: 43.0686\n",
      "Epoch 5310/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 156.3113 - val_loss: 43.0569\n",
      "Epoch 5311/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 144.7053 - val_loss: 43.0426\n",
      "Epoch 5312/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 171.2394 - val_loss: 43.0216\n",
      "Epoch 5313/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 118.3678 - val_loss: 43.0020\n",
      "Epoch 5314/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 114.4516 - val_loss: 42.9869\n",
      "Epoch 5315/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 169.7238 - val_loss: 42.9692\n",
      "Epoch 5316/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 136.8976 - val_loss: 42.9502\n",
      "Epoch 5317/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 127.1726 - val_loss: 42.9282\n",
      "Epoch 5318/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 101.7380 - val_loss: 42.9085\n",
      "Epoch 5319/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 129.2459 - val_loss: 42.8886\n",
      "Epoch 5320/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 114.2801 - val_loss: 42.8717\n",
      "Epoch 5321/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 150.6804 - val_loss: 42.8543\n",
      "Epoch 5322/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 157.4835 - val_loss: 42.8319\n",
      "Epoch 5323/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 115.0715 - val_loss: 42.8086\n",
      "Epoch 5324/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 115.1627 - val_loss: 42.7856\n",
      "Epoch 5325/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 126.5559 - val_loss: 42.7639\n",
      "Epoch 5326/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 148.8412 - val_loss: 42.7452\n",
      "Epoch 5327/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 153.3070 - val_loss: 42.7210\n",
      "Epoch 5328/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 112.7969 - val_loss: 42.6953\n",
      "Epoch 5329/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 145.2196 - val_loss: 42.6630\n",
      "Epoch 5330/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 160.4751 - val_loss: 42.6284\n",
      "Epoch 5331/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 143.5954 - val_loss: 42.5949\n",
      "Epoch 5332/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 138.6674 - val_loss: 42.5657\n",
      "Epoch 5333/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 136.3097 - val_loss: 42.5358\n",
      "Epoch 5334/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 140.8493 - val_loss: 42.5057\n",
      "Epoch 5335/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 140.8442 - val_loss: 42.4723\n",
      "Epoch 5336/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 129.8708 - val_loss: 42.4403\n",
      "Epoch 5337/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 135.1679 - val_loss: 42.4026\n",
      "Epoch 5338/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 126.9170 - val_loss: 42.3640\n",
      "Epoch 5339/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 120.1730 - val_loss: 42.3308\n",
      "Epoch 5340/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 119.5806 - val_loss: 42.3051\n",
      "Epoch 5341/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 120.5685 - val_loss: 42.2767\n",
      "Epoch 5342/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 129.6487 - val_loss: 42.2473\n",
      "Epoch 5343/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 128.4463 - val_loss: 42.2169\n",
      "Epoch 5344/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 115.1255 - val_loss: 42.1856\n",
      "Epoch 5345/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 138.5936 - val_loss: 42.1546\n",
      "Epoch 5346/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 109.5984 - val_loss: 42.1245\n",
      "Epoch 5347/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 123.6236 - val_loss: 42.0945\n",
      "Epoch 5348/10000\n",
      "184/184 [==============================] - 0s 886us/step - loss: 140.6181 - val_loss: 42.0701\n",
      "Epoch 5349/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 120.8196 - val_loss: 42.0466\n",
      "Epoch 5350/10000\n",
      "184/184 [==============================] - 0s 918us/step - loss: 123.1306 - val_loss: 42.0261\n",
      "Epoch 5351/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 110.3895 - val_loss: 42.0073\n",
      "Epoch 5352/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 128.9770 - val_loss: 41.9862\n",
      "Epoch 5353/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 123.6416 - val_loss: 41.9621\n",
      "Epoch 5354/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 124.6592 - val_loss: 41.9348\n",
      "Epoch 5355/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 109.2682 - val_loss: 41.9212\n",
      "Epoch 5356/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 134.5823 - val_loss: 41.9127\n",
      "Epoch 5357/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 176.9125 - val_loss: 41.8974\n",
      "Epoch 5358/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 107.9421 - val_loss: 41.8806\n",
      "Epoch 5359/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 164.5348 - val_loss: 41.8624\n",
      "Epoch 5360/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 148.0189 - val_loss: 41.8454\n",
      "Epoch 5361/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 147.9364 - val_loss: 41.8234\n",
      "Epoch 5362/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 156.7431 - val_loss: 41.7964\n",
      "Epoch 5363/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 158.7138 - val_loss: 41.7658\n",
      "Epoch 5364/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 169.9779 - val_loss: 41.7315\n",
      "Epoch 5365/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 148.6171 - val_loss: 41.6905\n",
      "Epoch 5366/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 137.3702 - val_loss: 41.6363\n",
      "Epoch 5367/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 123.4474 - val_loss: 41.5668\n",
      "Epoch 5368/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 114.6361 - val_loss: 41.4947\n",
      "Epoch 5369/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 119.9505 - val_loss: 41.4228\n",
      "Epoch 5370/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 119.3677 - val_loss: 41.3575\n",
      "Epoch 5371/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 156.7258 - val_loss: 41.5066\n",
      "Epoch 5372/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 122.7193 - val_loss: 41.7030\n",
      "Epoch 5373/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 153.7847 - val_loss: 41.6980\n",
      "Epoch 5374/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 126.3437 - val_loss: 40.6989\n",
      "Epoch 5375/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 134.8806 - val_loss: 41.1408\n",
      "Epoch 5376/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 140.6338 - val_loss: 41.1385\n",
      "Epoch 5377/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 109.0035 - val_loss: 40.5465\n",
      "Epoch 5378/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 185.5313 - val_loss: 40.1713\n",
      "Epoch 5379/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 140.6045 - val_loss: 39.8071\n",
      "Epoch 5380/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 154.7179 - val_loss: 39.6045\n",
      "Epoch 5381/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 127.1902 - val_loss: 39.4355\n",
      "Epoch 5382/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 137.1958 - val_loss: 39.4459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5383/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 129.6797 - val_loss: 40.1086\n",
      "Epoch 5384/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 140.5756 - val_loss: 40.5094\n",
      "Epoch 5385/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 126.8159 - val_loss: 40.6148\n",
      "Epoch 5386/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 149.2519 - val_loss: 40.7364\n",
      "Epoch 5387/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 135.8487 - val_loss: 41.1950\n",
      "Epoch 5388/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 134.6206 - val_loss: 41.5863\n",
      "Epoch 5389/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 142.7326 - val_loss: 41.7869\n",
      "Epoch 5390/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 109.6993 - val_loss: 41.9037\n",
      "Epoch 5391/10000\n",
      "184/184 [==============================] - 0s 848us/step - loss: 121.5209 - val_loss: 41.9720\n",
      "Epoch 5392/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 129.8915 - val_loss: 42.0268\n",
      "Epoch 5393/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 127.6000 - val_loss: 42.0721\n",
      "Epoch 5394/10000\n",
      "184/184 [==============================] - 0s 793us/step - loss: 142.8684 - val_loss: 42.1004\n",
      "Epoch 5395/10000\n",
      "184/184 [==============================] - 0s 788us/step - loss: 110.8010 - val_loss: 42.1168\n",
      "Epoch 5396/10000\n",
      "184/184 [==============================] - 0s 967us/step - loss: 140.2369 - val_loss: 42.1234\n",
      "Epoch 5397/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 104.3854 - val_loss: 42.1339\n",
      "Epoch 5398/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 140.1604 - val_loss: 42.1380\n",
      "Epoch 5399/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 155.1402 - val_loss: 42.1489\n",
      "Epoch 5400/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 116.2720 - val_loss: 42.1830\n",
      "\n",
      "Epoch 05400: loss improved from 133.95408 to 116.27201, saving model to C6007C.hdf5\n",
      "Epoch 5401/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 116.5583 - val_loss: 42.2029\n",
      "Epoch 5402/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 129.1866 - val_loss: 42.2101\n",
      "Epoch 5403/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 131.4504 - val_loss: 42.2102\n",
      "Epoch 5404/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 136.2937 - val_loss: 42.2056\n",
      "Epoch 5405/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 152.2226 - val_loss: 42.1944\n",
      "Epoch 5406/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 125.7919 - val_loss: 42.1903\n",
      "Epoch 5407/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 129.6564 - val_loss: 42.1972\n",
      "Epoch 5408/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 136.4673 - val_loss: 42.1991\n",
      "Epoch 5409/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 150.2990 - val_loss: 42.2008\n",
      "Epoch 5410/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 125.3170 - val_loss: 42.1980\n",
      "Epoch 5411/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 128.3083 - val_loss: 42.1909\n",
      "Epoch 5412/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 155.2878 - val_loss: 42.1814\n",
      "Epoch 5413/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 119.9435 - val_loss: 42.1588\n",
      "Epoch 5414/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 133.1762 - val_loss: 42.1349\n",
      "Epoch 5415/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 110.3993 - val_loss: 42.1141\n",
      "Epoch 5416/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 117.6800 - val_loss: 42.0933\n",
      "Epoch 5417/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 141.3371 - val_loss: 42.0716\n",
      "Epoch 5418/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 98.2427 - val_loss: 42.0503\n",
      "Epoch 5419/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 119.8929 - val_loss: 42.0261\n",
      "Epoch 5420/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 127.1625 - val_loss: 42.0067\n",
      "Epoch 5421/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 130.2216 - val_loss: 41.9884\n",
      "Epoch 5422/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 112.9843 - val_loss: 41.9718\n",
      "Epoch 5423/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 110.9021 - val_loss: 41.9532\n",
      "Epoch 5424/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 131.2291 - val_loss: 41.9308\n",
      "Epoch 5425/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 187.9593 - val_loss: 41.9098\n",
      "Epoch 5426/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 114.7771 - val_loss: 41.8935\n",
      "Epoch 5427/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 135.6852 - val_loss: 41.8770\n",
      "Epoch 5428/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 116.8960 - val_loss: 41.8630\n",
      "Epoch 5429/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 112.2486 - val_loss: 41.8470\n",
      "Epoch 5430/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 126.6586 - val_loss: 41.8278\n",
      "Epoch 5431/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 120.2513 - val_loss: 41.8051\n",
      "Epoch 5432/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 113.3028 - val_loss: 41.7777\n",
      "Epoch 5433/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 144.7302 - val_loss: 41.7395\n",
      "Epoch 5434/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 130.7397 - val_loss: 41.7008\n",
      "Epoch 5435/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 129.1960 - val_loss: 41.6609\n",
      "Epoch 5436/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 136.1050 - val_loss: 41.6231\n",
      "Epoch 5437/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 130.1799 - val_loss: 41.5874\n",
      "Epoch 5438/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 123.1890 - val_loss: 41.5529\n",
      "Epoch 5439/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 126.8715 - val_loss: 41.5219\n",
      "Epoch 5440/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 120.3811 - val_loss: 41.4976\n",
      "Epoch 5441/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 157.3431 - val_loss: 41.4705\n",
      "Epoch 5442/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 121.4682 - val_loss: 41.4426\n",
      "Epoch 5443/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 121.0913 - val_loss: 41.4172\n",
      "Epoch 5444/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 130.8973 - val_loss: 41.3984\n",
      "Epoch 5445/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 131.1477 - val_loss: 41.3792\n",
      "Epoch 5446/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 92.8377 - val_loss: 41.3591\n",
      "Epoch 5447/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 107.0035 - val_loss: 41.3400\n",
      "Epoch 5448/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 143.9525 - val_loss: 41.3207\n",
      "Epoch 5449/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 130.4272 - val_loss: 41.3016\n",
      "Epoch 5450/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 163.1024 - val_loss: 41.2772\n",
      "Epoch 5451/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 140.9471 - val_loss: 41.2504\n",
      "Epoch 5452/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 134.7244 - val_loss: 41.2191\n",
      "Epoch 5453/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 118.8567 - val_loss: 41.1861\n",
      "Epoch 5454/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 136.9529 - val_loss: 41.1544\n",
      "Epoch 5455/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 124.5961 - val_loss: 41.1175\n",
      "Epoch 5456/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 522us/step - loss: 153.8252 - val_loss: 41.0795\n",
      "Epoch 5457/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 131.9580 - val_loss: 41.0457\n",
      "Epoch 5458/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 145.6174 - val_loss: 41.0179\n",
      "Epoch 5459/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 142.5429 - val_loss: 40.9943\n",
      "Epoch 5460/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 132.2373 - val_loss: 40.9717\n",
      "Epoch 5461/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 134.9658 - val_loss: 40.9508\n",
      "Epoch 5462/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 148.8595 - val_loss: 40.9295\n",
      "Epoch 5463/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 117.9407 - val_loss: 40.9090\n",
      "Epoch 5464/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 128.4455 - val_loss: 40.8879\n",
      "Epoch 5465/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 148.1660 - val_loss: 40.8667\n",
      "Epoch 5466/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 139.5898 - val_loss: 40.8409\n",
      "Epoch 5467/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 157.4882 - val_loss: 40.8144\n",
      "Epoch 5468/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 124.2671 - val_loss: 40.7800\n",
      "Epoch 5469/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 110.7181 - val_loss: 40.7464\n",
      "Epoch 5470/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 114.4251 - val_loss: 40.7148\n",
      "Epoch 5471/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 146.9637 - val_loss: 40.6949\n",
      "Epoch 5472/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 110.0834 - val_loss: 40.6760\n",
      "Epoch 5473/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 138.7716 - val_loss: 40.6546\n",
      "Epoch 5474/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 116.8020 - val_loss: 40.6287\n",
      "Epoch 5475/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 133.2633 - val_loss: 40.6034\n",
      "Epoch 5476/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 105.5461 - val_loss: 40.5757\n",
      "Epoch 5477/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 131.6216 - val_loss: 40.5475\n",
      "Epoch 5478/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 119.8342 - val_loss: 40.5191\n",
      "Epoch 5479/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 122.3758 - val_loss: 40.4830\n",
      "Epoch 5480/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 123.0907 - val_loss: 40.4420\n",
      "Epoch 5481/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 120.8388 - val_loss: 40.4164\n",
      "Epoch 5482/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 133.1672 - val_loss: 40.3913\n",
      "Epoch 5483/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 124.9425 - val_loss: 40.3679\n",
      "Epoch 5484/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 125.0064 - val_loss: 40.3465\n",
      "Epoch 5485/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 112.8182 - val_loss: 40.2875\n",
      "Epoch 5486/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 129.9176 - val_loss: 40.2288\n",
      "Epoch 5487/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 120.4259 - val_loss: 40.1656\n",
      "Epoch 5488/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 145.8127 - val_loss: 40.1067\n",
      "Epoch 5489/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 137.1984 - val_loss: 40.0562\n",
      "Epoch 5490/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 114.2905 - val_loss: 40.0090\n",
      "Epoch 5491/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 120.8854 - val_loss: 39.9713\n",
      "Epoch 5492/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 137.4420 - val_loss: 39.9417\n",
      "Epoch 5493/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 141.5242 - val_loss: 39.9165\n",
      "Epoch 5494/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 119.1114 - val_loss: 39.9022\n",
      "Epoch 5495/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 131.1286 - val_loss: 39.8839\n",
      "Epoch 5496/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 126.2702 - val_loss: 39.8627\n",
      "Epoch 5497/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 169.0630 - val_loss: 39.8372\n",
      "Epoch 5498/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 135.4132 - val_loss: 39.8057\n",
      "Epoch 5499/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 120.1704 - val_loss: 39.7728\n",
      "Epoch 5500/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 106.0906 - val_loss: 39.7429\n",
      "\n",
      "Epoch 05500: loss improved from 116.27201 to 106.09057, saving model to C6007C.hdf5\n",
      "Epoch 5501/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 122.9411 - val_loss: 39.7116\n",
      "Epoch 5502/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 119.2583 - val_loss: 39.6819\n",
      "Epoch 5503/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 149.5068 - val_loss: 39.6567\n",
      "Epoch 5504/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 146.1353 - val_loss: 39.6313\n",
      "Epoch 5505/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 115.5136 - val_loss: 39.5840\n",
      "Epoch 5506/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 145.5632 - val_loss: 39.5502\n",
      "Epoch 5507/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 110.6802 - val_loss: 39.5269\n",
      "Epoch 5508/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 129.0132 - val_loss: 39.5104\n",
      "Epoch 5509/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 127.6734 - val_loss: 39.3715\n",
      "Epoch 5510/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 125.4109 - val_loss: 39.1243\n",
      "Epoch 5511/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 127.1144 - val_loss: 38.9235\n",
      "Epoch 5512/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 127.5796 - val_loss: 38.6740\n",
      "Epoch 5513/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 160.0005 - val_loss: 38.4143\n",
      "Epoch 5514/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 125.9552 - val_loss: 38.1678\n",
      "Epoch 5515/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 113.3131 - val_loss: 38.0345\n",
      "Epoch 5516/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 108.6857 - val_loss: 37.8914\n",
      "Epoch 5517/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 120.7882 - val_loss: 37.7734\n",
      "Epoch 5518/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 143.4315 - val_loss: 37.6983\n",
      "Epoch 5519/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 145.7709 - val_loss: 37.6320\n",
      "Epoch 5520/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 145.0265 - val_loss: 37.5893\n",
      "Epoch 5521/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 117.2595 - val_loss: 37.5525\n",
      "Epoch 5522/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 149.1781 - val_loss: 37.5258\n",
      "Epoch 5523/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 115.9780 - val_loss: 37.4906\n",
      "Epoch 5524/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 106.7830 - val_loss: 37.4730\n",
      "Epoch 5525/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 142.2165 - val_loss: 37.4687\n",
      "Epoch 5526/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 114.9543 - val_loss: 37.4621\n",
      "Epoch 5527/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 184.7534 - val_loss: 37.4279\n",
      "Epoch 5528/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 155.1155 - val_loss: 37.3744\n",
      "Epoch 5529/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 511us/step - loss: 135.4913 - val_loss: 37.2956\n",
      "Epoch 5530/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 93.3857 - val_loss: 37.2195\n",
      "Epoch 5531/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 114.9513 - val_loss: 37.1667\n",
      "Epoch 5532/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 107.5906 - val_loss: 37.1465\n",
      "Epoch 5533/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 119.4779 - val_loss: 37.1002\n",
      "Epoch 5534/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 194.9552 - val_loss: 37.0726\n",
      "Epoch 5535/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 147.5679 - val_loss: 37.0347\n",
      "Epoch 5536/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 146.0510 - val_loss: 37.0139\n",
      "Epoch 5537/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 118.9115 - val_loss: 37.0422\n",
      "Epoch 5538/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 136.2107 - val_loss: 36.9683\n",
      "Epoch 5539/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 119.5607 - val_loss: 36.9486\n",
      "Epoch 5540/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 131.2699 - val_loss: 36.9272\n",
      "Epoch 5541/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 103.6849 - val_loss: 36.9057\n",
      "Epoch 5542/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 129.9252 - val_loss: 36.8918\n",
      "Epoch 5543/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 120.4661 - val_loss: 36.8817\n",
      "Epoch 5544/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 120.3528 - val_loss: 36.8970\n",
      "Epoch 5545/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 133.0800 - val_loss: 36.8584\n",
      "Epoch 5546/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 180.6191 - val_loss: 36.8497\n",
      "Epoch 5547/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 137.9833 - val_loss: 36.8404\n",
      "Epoch 5548/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 108.5826 - val_loss: 36.8703\n",
      "Epoch 5549/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 134.4766 - val_loss: 36.8239\n",
      "Epoch 5550/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 119.7034 - val_loss: 36.7646\n",
      "Epoch 5551/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 185.7520 - val_loss: 36.7023\n",
      "Epoch 5552/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 111.7953 - val_loss: 36.6963\n",
      "Epoch 5553/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 127.0657 - val_loss: 36.6034\n",
      "Epoch 5554/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 140.9749 - val_loss: 36.5530\n",
      "Epoch 5555/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 141.1852 - val_loss: 36.5028\n",
      "Epoch 5556/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 104.8828 - val_loss: 36.4561\n",
      "Epoch 5557/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 145.9528 - val_loss: 36.4324\n",
      "Epoch 5558/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 124.7747 - val_loss: 36.4936\n",
      "Epoch 5559/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 120.4009 - val_loss: 36.4257\n",
      "Epoch 5560/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 114.2925 - val_loss: 36.3377\n",
      "Epoch 5561/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 113.5239 - val_loss: 36.3249\n",
      "Epoch 5562/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 125.6915 - val_loss: 36.3158\n",
      "Epoch 5563/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 116.8649 - val_loss: 36.2939\n",
      "Epoch 5564/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 125.1624 - val_loss: 36.2702\n",
      "Epoch 5565/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 121.0680 - val_loss: 36.2461\n",
      "Epoch 5566/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 130.9712 - val_loss: 36.2222\n",
      "Epoch 5567/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 102.0369 - val_loss: 36.2289\n",
      "Epoch 5568/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 140.7003 - val_loss: 36.2054\n",
      "Epoch 5569/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 125.8806 - val_loss: 36.1841\n",
      "Epoch 5570/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 121.7082 - val_loss: 36.1642\n",
      "Epoch 5571/10000\n",
      "184/184 [==============================] - 0s 494us/step - loss: 162.5536 - val_loss: 36.1486\n",
      "Epoch 5572/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 122.4554 - val_loss: 36.1432\n",
      "Epoch 5573/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 135.1605 - val_loss: 36.1461\n",
      "Epoch 5574/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 134.2576 - val_loss: 36.1312\n",
      "Epoch 5575/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 107.5415 - val_loss: 36.0974\n",
      "Epoch 5576/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 104.9786 - val_loss: 35.6290\n",
      "Epoch 5577/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 149.4488 - val_loss: 34.8281\n",
      "Epoch 5578/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 128.8270 - val_loss: 34.7352\n",
      "Epoch 5579/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 140.1824 - val_loss: 34.7374\n",
      "Epoch 5580/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 141.2477 - val_loss: 34.7742\n",
      "Epoch 5581/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 128.2267 - val_loss: 34.7909\n",
      "Epoch 5582/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 125.2960 - val_loss: 34.8068\n",
      "Epoch 5583/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 112.6519 - val_loss: 34.8178\n",
      "Epoch 5584/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 134.9072 - val_loss: 34.8249\n",
      "Epoch 5585/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 147.1878 - val_loss: 34.8361\n",
      "Epoch 5586/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 122.6284 - val_loss: 34.8623\n",
      "Epoch 5587/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 105.1419 - val_loss: 34.8983\n",
      "Epoch 5588/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 116.6395 - val_loss: 34.9215\n",
      "Epoch 5589/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 144.7254 - val_loss: 34.9333\n",
      "Epoch 5590/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 96.7158 - val_loss: 34.9374\n",
      "Epoch 5591/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 117.6194 - val_loss: 34.9330\n",
      "Epoch 5592/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 108.4678 - val_loss: 34.9286\n",
      "Epoch 5593/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 111.8209 - val_loss: 34.9222\n",
      "Epoch 5594/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 125.6295 - val_loss: 34.9134\n",
      "Epoch 5595/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 147.1451 - val_loss: 34.9370\n",
      "Epoch 5596/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 106.8558 - val_loss: 35.0004\n",
      "Epoch 5597/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 117.7497 - val_loss: 35.0942\n",
      "Epoch 5598/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 119.1096 - val_loss: 35.1475\n",
      "Epoch 5599/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 127.8125 - val_loss: 35.1714\n",
      "Epoch 5600/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 132.2652 - val_loss: 35.2072\n",
      "\n",
      "Epoch 05600: loss did not improve from 106.09057\n",
      "Epoch 5601/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 169.9952 - val_loss: 35.3296\n",
      "Epoch 5602/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 500us/step - loss: 153.8391 - val_loss: 35.3022\n",
      "Epoch 5603/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 144.3788 - val_loss: 35.2887\n",
      "Epoch 5604/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 122.9919 - val_loss: 35.2346\n",
      "Epoch 5605/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 186.0924 - val_loss: 35.2628\n",
      "Epoch 5606/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 139.4387 - val_loss: 35.3849\n",
      "Epoch 5607/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 143.9759 - val_loss: 35.2928\n",
      "Epoch 5608/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 143.0401 - val_loss: 35.2705\n",
      "Epoch 5609/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 106.3167 - val_loss: 35.1816\n",
      "Epoch 5610/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 130.8223 - val_loss: 35.0560\n",
      "Epoch 5611/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 105.6948 - val_loss: 34.9695\n",
      "Epoch 5612/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 150.0519 - val_loss: 34.8746\n",
      "Epoch 5613/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 138.7598 - val_loss: 34.7515\n",
      "Epoch 5614/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 133.1288 - val_loss: 34.6657\n",
      "Epoch 5615/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 138.5190 - val_loss: 34.8533\n",
      "Epoch 5616/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 124.6472 - val_loss: 35.0487\n",
      "Epoch 5617/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 124.8994 - val_loss: 35.2844\n",
      "Epoch 5618/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 113.8673 - val_loss: 35.4235\n",
      "Epoch 5619/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 102.5596 - val_loss: 35.7789\n",
      "Epoch 5620/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 140.2179 - val_loss: 35.7895\n",
      "Epoch 5621/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 110.6682 - val_loss: 35.8364\n",
      "Epoch 5622/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 129.3415 - val_loss: 35.8403\n",
      "Epoch 5623/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 120.9412 - val_loss: 35.7395\n",
      "Epoch 5624/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 113.1048 - val_loss: 35.6393\n",
      "Epoch 5625/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 124.8032 - val_loss: 35.6126\n",
      "Epoch 5626/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 158.6453 - val_loss: 35.5857\n",
      "Epoch 5627/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 99.8545 - val_loss: 35.5434\n",
      "Epoch 5628/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 124.2511 - val_loss: 35.4974\n",
      "Epoch 5629/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 179.9579 - val_loss: 35.4486\n",
      "Epoch 5630/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 126.1457 - val_loss: 35.4041\n",
      "Epoch 5631/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 137.4865 - val_loss: 35.3715\n",
      "Epoch 5632/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 118.4504 - val_loss: 35.3431\n",
      "Epoch 5633/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 103.5278 - val_loss: 35.3144\n",
      "Epoch 5634/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 105.1712 - val_loss: 35.2848\n",
      "Epoch 5635/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 115.2370 - val_loss: 35.2596\n",
      "Epoch 5636/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 125.4413 - val_loss: 35.2332\n",
      "Epoch 5637/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 142.4154 - val_loss: 35.2092\n",
      "Epoch 5638/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 92.7238 - val_loss: 35.1877\n",
      "Epoch 5639/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 131.2191 - val_loss: 35.1611\n",
      "Epoch 5640/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 133.4113 - val_loss: 35.1345\n",
      "Epoch 5641/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 105.2459 - val_loss: 35.1099\n",
      "Epoch 5642/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 90.5391 - val_loss: 35.0833\n",
      "Epoch 5643/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 133.4631 - val_loss: 35.0573\n",
      "Epoch 5644/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 121.0578 - val_loss: 35.0317\n",
      "Epoch 5645/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 117.7873 - val_loss: 35.0063\n",
      "Epoch 5646/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 129.7145 - val_loss: 34.9790\n",
      "Epoch 5647/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 152.7715 - val_loss: 34.9457\n",
      "Epoch 5648/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 90.3101 - val_loss: 34.9136\n",
      "Epoch 5649/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 128.4020 - val_loss: 34.8839\n",
      "Epoch 5650/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 127.2682 - val_loss: 34.8573\n",
      "Epoch 5651/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 158.5290 - val_loss: 34.8287\n",
      "Epoch 5652/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 142.7262 - val_loss: 34.7994\n",
      "Epoch 5653/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 141.7025 - val_loss: 34.7729\n",
      "Epoch 5654/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 143.9094 - val_loss: 34.7452\n",
      "Epoch 5655/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 92.8178 - val_loss: 34.7205\n",
      "Epoch 5656/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 108.0799 - val_loss: 34.6960\n",
      "Epoch 5657/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 127.7686 - val_loss: 34.6730\n",
      "Epoch 5658/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 122.4545 - val_loss: 34.6486\n",
      "Epoch 5659/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 103.0524 - val_loss: 34.6246\n",
      "Epoch 5660/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 81.7465 - val_loss: 34.5977\n",
      "Epoch 5661/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 99.5446 - val_loss: 34.5706\n",
      "Epoch 5662/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 106.1932 - val_loss: 34.5410\n",
      "Epoch 5663/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 119.1144 - val_loss: 34.5149\n",
      "Epoch 5664/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 98.3051 - val_loss: 34.4915\n",
      "Epoch 5665/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 94.2910 - val_loss: 34.4701\n",
      "Epoch 5666/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 103.4832 - val_loss: 34.4493\n",
      "Epoch 5667/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 107.7658 - val_loss: 34.4260\n",
      "Epoch 5668/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 133.0252 - val_loss: 34.4039\n",
      "Epoch 5669/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 96.8795 - val_loss: 34.3809\n",
      "Epoch 5670/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 143.4828 - val_loss: 34.3599\n",
      "Epoch 5671/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 151.4681 - val_loss: 34.3380\n",
      "Epoch 5672/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 132.4491 - val_loss: 34.3122\n",
      "Epoch 5673/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 109.0115 - val_loss: 34.3028\n",
      "Epoch 5674/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 117.7847 - val_loss: 34.3238\n",
      "Epoch 5675/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 135.5071 - val_loss: 34.3366\n",
      "Epoch 5676/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 511us/step - loss: 105.8244 - val_loss: 34.3375\n",
      "Epoch 5677/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 119.8179 - val_loss: 34.3269\n",
      "Epoch 5678/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 107.6868 - val_loss: 34.3142\n",
      "Epoch 5679/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 93.0857 - val_loss: 34.2973\n",
      "Epoch 5680/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 128.5660 - val_loss: 34.4876\n",
      "Epoch 5681/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 119.3500 - val_loss: 34.6556\n",
      "Epoch 5682/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 132.8258 - val_loss: 34.7359\n",
      "Epoch 5683/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 127.9055 - val_loss: 34.6621\n",
      "Epoch 5684/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 99.4747 - val_loss: 34.8428\n",
      "Epoch 5685/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 144.9336 - val_loss: 34.5226\n",
      "Epoch 5686/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 131.0901 - val_loss: 34.1955\n",
      "Epoch 5687/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 118.5526 - val_loss: 34.1630\n",
      "Epoch 5688/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 101.6267 - val_loss: 34.1205\n",
      "Epoch 5689/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 120.6693 - val_loss: 34.1100\n",
      "Epoch 5690/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 141.9315 - val_loss: 34.1229\n",
      "Epoch 5691/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 97.7017 - val_loss: 34.0325\n",
      "Epoch 5692/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 111.3733 - val_loss: 33.8670\n",
      "Epoch 5693/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 91.1378 - val_loss: 33.8209\n",
      "Epoch 5694/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 102.6556 - val_loss: 33.7946\n",
      "Epoch 5695/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 136.7323 - val_loss: 33.7961\n",
      "Epoch 5696/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 131.0235 - val_loss: 33.7142\n",
      "Epoch 5697/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 131.4818 - val_loss: 33.6350\n",
      "Epoch 5698/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 101.9416 - val_loss: 33.6491\n",
      "Epoch 5699/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 111.7219 - val_loss: 33.5993\n",
      "Epoch 5700/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 111.6520 - val_loss: 33.5674\n",
      "\n",
      "Epoch 05700: loss did not improve from 106.09057\n",
      "Epoch 5701/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 114.8019 - val_loss: 33.7154\n",
      "Epoch 5702/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 118.1090 - val_loss: 33.6366\n",
      "Epoch 5703/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 130.5168 - val_loss: 33.5851\n",
      "Epoch 5704/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 103.4822 - val_loss: 33.5691\n",
      "Epoch 5705/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 127.6136 - val_loss: 33.5562\n",
      "Epoch 5706/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 133.6055 - val_loss: 33.5353\n",
      "Epoch 5707/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 87.5504 - val_loss: 33.8110\n",
      "Epoch 5708/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 102.1956 - val_loss: 34.4095\n",
      "Epoch 5709/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 111.2875 - val_loss: 34.0885\n",
      "Epoch 5710/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 113.7032 - val_loss: 33.7856\n",
      "Epoch 5711/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 87.8592 - val_loss: 33.5571\n",
      "Epoch 5712/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 97.8435 - val_loss: 33.3688\n",
      "Epoch 5713/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 84.0834 - val_loss: 33.2311\n",
      "Epoch 5714/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 112.2955 - val_loss: 33.1474\n",
      "Epoch 5715/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 107.7723 - val_loss: 33.0883\n",
      "Epoch 5716/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 112.2104 - val_loss: 33.0390\n",
      "Epoch 5717/10000\n",
      "184/184 [==============================] - 0s 595us/step - loss: 141.9079 - val_loss: 33.0002\n",
      "Epoch 5718/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 131.0368 - val_loss: 32.9612\n",
      "Epoch 5719/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 104.3613 - val_loss: 32.9330\n",
      "Epoch 5720/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 99.7173 - val_loss: 32.9506\n",
      "Epoch 5721/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 97.9877 - val_loss: 33.0430\n",
      "Epoch 5722/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 118.4896 - val_loss: 33.0612\n",
      "Epoch 5723/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 100.6024 - val_loss: 32.9729\n",
      "Epoch 5724/10000\n",
      "184/184 [==============================] - 0s 848us/step - loss: 119.0386 - val_loss: 32.8234\n",
      "Epoch 5725/10000\n",
      "184/184 [==============================] - 0s 821us/step - loss: 194.9369 - val_loss: 32.7837\n",
      "Epoch 5726/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 101.4630 - val_loss: 32.5516\n",
      "Epoch 5727/10000\n",
      "184/184 [==============================] - 0s 755us/step - loss: 116.9914 - val_loss: 32.5771\n",
      "Epoch 5728/10000\n",
      "184/184 [==============================] - 0s 693us/step - loss: 121.0157 - val_loss: 32.6457\n",
      "Epoch 5729/10000\n",
      "184/184 [==============================] - 0s 832us/step - loss: 123.2051 - val_loss: 32.6655\n",
      "Epoch 5730/10000\n",
      "184/184 [==============================] - 0s 886us/step - loss: 98.5513 - val_loss: 32.6737\n",
      "Epoch 5731/10000\n",
      "184/184 [==============================] - 0s 875us/step - loss: 139.0488 - val_loss: 32.7176\n",
      "Epoch 5732/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 127.8986 - val_loss: 32.7232\n",
      "Epoch 5733/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 91.7027 - val_loss: 32.6803\n",
      "Epoch 5734/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 133.3988 - val_loss: 32.4897\n",
      "Epoch 5735/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 147.3813 - val_loss: 31.7017\n",
      "Epoch 5736/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 126.6690 - val_loss: 31.6905\n",
      "Epoch 5737/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 132.0567 - val_loss: 31.8096\n",
      "Epoch 5738/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 148.7172 - val_loss: 31.9807\n",
      "Epoch 5739/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 109.1383 - val_loss: 31.8322\n",
      "Epoch 5740/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 127.6310 - val_loss: 31.4490\n",
      "Epoch 5741/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 130.2114 - val_loss: 31.2681\n",
      "Epoch 5742/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 113.0887 - val_loss: 31.2404\n",
      "Epoch 5743/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 126.4340 - val_loss: 31.2446\n",
      "Epoch 5744/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 105.3191 - val_loss: 31.2482\n",
      "Epoch 5745/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 111.3127 - val_loss: 31.2359\n",
      "Epoch 5746/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 102.8734 - val_loss: 31.8990\n",
      "Epoch 5747/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 129.5950 - val_loss: 32.7738\n",
      "Epoch 5748/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 113.1019 - val_loss: 33.2001\n",
      "Epoch 5749/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 473us/step - loss: 101.1464 - val_loss: 33.6150\n",
      "Epoch 5750/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 112.6998 - val_loss: 33.7112\n",
      "Epoch 5751/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 135.5090 - val_loss: 33.6144\n",
      "Epoch 5752/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 128.0819 - val_loss: 33.4875\n",
      "Epoch 5753/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 75.3110 - val_loss: 33.3541\n",
      "Epoch 5754/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 101.5637 - val_loss: 33.1899\n",
      "Epoch 5755/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 124.4182 - val_loss: 33.0221\n",
      "Epoch 5756/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 102.2131 - val_loss: 32.8761\n",
      "Epoch 5757/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 94.1705 - val_loss: 32.6914\n",
      "Epoch 5758/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 148.3792 - val_loss: 32.4210\n",
      "Epoch 5759/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 98.4649 - val_loss: 31.9864\n",
      "Epoch 5760/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 131.3923 - val_loss: 31.3578\n",
      "Epoch 5761/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 96.9289 - val_loss: 31.2005\n",
      "Epoch 5762/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 132.7161 - val_loss: 31.1292\n",
      "Epoch 5763/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 95.1583 - val_loss: 31.0848\n",
      "Epoch 5764/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 100.8238 - val_loss: 31.0534\n",
      "Epoch 5765/10000\n",
      "184/184 [==============================] - 0s 429us/step - loss: 96.0660 - val_loss: 31.0230\n",
      "Epoch 5766/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 98.1147 - val_loss: 30.9950\n",
      "Epoch 5767/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 119.7923 - val_loss: 30.9799\n",
      "Epoch 5768/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 135.6705 - val_loss: 30.9689\n",
      "Epoch 5769/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 104.1439 - val_loss: 30.9456\n",
      "Epoch 5770/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 138.7918 - val_loss: 30.9132\n",
      "Epoch 5771/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 120.7375 - val_loss: 30.8687\n",
      "Epoch 5772/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 103.5992 - val_loss: 30.7867\n",
      "Epoch 5773/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 114.3479 - val_loss: 30.7301\n",
      "Epoch 5774/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 108.7034 - val_loss: 30.6667\n",
      "Epoch 5775/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 151.7989 - val_loss: 30.5792\n",
      "Epoch 5776/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 116.9313 - val_loss: 30.5467\n",
      "Epoch 5777/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 142.8687 - val_loss: 30.5360\n",
      "Epoch 5778/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 104.7590 - val_loss: 30.5307\n",
      "Epoch 5779/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 151.0540 - val_loss: 30.5229\n",
      "Epoch 5780/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 106.7284 - val_loss: 30.5059\n",
      "Epoch 5781/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 122.2596 - val_loss: 30.4844\n",
      "Epoch 5782/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 115.9937 - val_loss: 30.4672\n",
      "Epoch 5783/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 123.7543 - val_loss: 30.4486\n",
      "Epoch 5784/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 112.7737 - val_loss: 30.4248\n",
      "Epoch 5785/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 130.1680 - val_loss: 30.4697\n",
      "Epoch 5786/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 113.8164 - val_loss: 30.4803\n",
      "Epoch 5787/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 106.9641 - val_loss: 30.4824\n",
      "Epoch 5788/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 118.4339 - val_loss: 30.4870\n",
      "Epoch 5789/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 123.4294 - val_loss: 30.4760\n",
      "Epoch 5790/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 116.1582 - val_loss: 30.5017\n",
      "Epoch 5791/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 103.0690 - val_loss: 30.5514\n",
      "Epoch 5792/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 132.3368 - val_loss: 30.7301\n",
      "Epoch 5793/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 114.5441 - val_loss: 30.6848\n",
      "Epoch 5794/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 114.5793 - val_loss: 30.5886\n",
      "Epoch 5795/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 84.6517 - val_loss: 30.5400\n",
      "Epoch 5796/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 111.7873 - val_loss: 30.4406\n",
      "Epoch 5797/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 152.1539 - val_loss: 30.3843\n",
      "Epoch 5798/10000\n",
      "184/184 [==============================] - 0s 465us/step - loss: 100.0690 - val_loss: 30.3574\n",
      "Epoch 5799/10000\n",
      "184/184 [==============================] - 0s 525us/step - loss: 123.5426 - val_loss: 30.3295\n",
      "Epoch 5800/10000\n",
      "184/184 [==============================] - 0s 481us/step - loss: 134.5649 - val_loss: 30.3011\n",
      "\n",
      "Epoch 05800: loss did not improve from 106.09057\n",
      "Epoch 5801/10000\n",
      "184/184 [==============================] - 0s 568us/step - loss: 101.9191 - val_loss: 30.2845\n",
      "Epoch 5802/10000\n",
      "184/184 [==============================] - 0s 650us/step - loss: 97.5415 - val_loss: 30.2757\n",
      "Epoch 5803/10000\n",
      "184/184 [==============================] - 0s 568us/step - loss: 94.1449 - val_loss: 30.2665\n",
      "Epoch 5804/10000\n",
      "184/184 [==============================] - 0s 807us/step - loss: 110.9638 - val_loss: 30.2487\n",
      "Epoch 5805/10000\n",
      "184/184 [==============================] - 0s 650us/step - loss: 109.2991 - val_loss: 30.2318\n",
      "Epoch 5806/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 126.9021 - val_loss: 30.2157\n",
      "Epoch 5807/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 133.4796 - val_loss: 30.2002\n",
      "Epoch 5808/10000\n",
      "184/184 [==============================] - 0s 557us/step - loss: 120.5215 - val_loss: 30.1852\n",
      "Epoch 5809/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 157.3538 - val_loss: 30.1808\n",
      "Epoch 5810/10000\n",
      "184/184 [==============================] - 0s 761us/step - loss: 146.7677 - val_loss: 30.1748\n",
      "Epoch 5811/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 103.3967 - val_loss: 30.1681\n",
      "Epoch 5812/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 129.1072 - val_loss: 30.1603\n",
      "Epoch 5813/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 163.4881 - val_loss: 30.1712\n",
      "Epoch 5814/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 108.1150 - val_loss: 30.1866\n",
      "Epoch 5815/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 103.6946 - val_loss: 30.1967\n",
      "Epoch 5816/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 99.5582 - val_loss: 30.2092\n",
      "Epoch 5817/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 114.9505 - val_loss: 30.2230\n",
      "Epoch 5818/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 126.1772 - val_loss: 30.1359\n",
      "Epoch 5819/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 143.3701 - val_loss: 30.0677\n",
      "Epoch 5820/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 105.4994 - val_loss: 30.0107\n",
      "Epoch 5821/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 124.5042 - val_loss: 29.9541\n",
      "Epoch 5822/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 511us/step - loss: 91.2048 - val_loss: 29.8958\n",
      "Epoch 5823/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 117.0621 - val_loss: 29.8455\n",
      "Epoch 5824/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 113.5322 - val_loss: 29.8052\n",
      "Epoch 5825/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 115.0752 - val_loss: 29.7737\n",
      "Epoch 5826/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 101.9390 - val_loss: 29.7419\n",
      "Epoch 5827/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 144.6189 - val_loss: 29.7098\n",
      "Epoch 5828/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 119.0810 - val_loss: 29.6778\n",
      "Epoch 5829/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 106.2433 - val_loss: 29.6463\n",
      "Epoch 5830/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 110.7944 - val_loss: 29.6165\n",
      "Epoch 5831/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 125.8195 - val_loss: 29.5901\n",
      "Epoch 5832/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 146.7916 - val_loss: 29.5656\n",
      "Epoch 5833/10000\n",
      "184/184 [==============================] - 0s 546us/step - loss: 125.5287 - val_loss: 29.5479\n",
      "Epoch 5834/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 125.7655 - val_loss: 29.5258\n",
      "Epoch 5835/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 103.6073 - val_loss: 29.5041\n",
      "Epoch 5836/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 90.4090 - val_loss: 29.4819\n",
      "Epoch 5837/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 102.3913 - val_loss: 29.4620\n",
      "Epoch 5838/10000\n",
      "184/184 [==============================] - 0s 720us/step - loss: 100.1883 - val_loss: 29.4498\n",
      "Epoch 5839/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 95.4483 - val_loss: 29.4410\n",
      "Epoch 5840/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 94.7906 - val_loss: 29.4291\n",
      "Epoch 5841/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 88.9867 - val_loss: 29.4163\n",
      "Epoch 5842/10000\n",
      "184/184 [==============================] - 0s 699us/step - loss: 130.5974 - val_loss: 29.4046\n",
      "Epoch 5843/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 85.9983 - val_loss: 29.3942\n",
      "Epoch 5844/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 86.8004 - val_loss: 29.3842\n",
      "Epoch 5845/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 95.3002 - val_loss: 29.3738\n",
      "Epoch 5846/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 103.6817 - val_loss: 29.3632\n",
      "Epoch 5847/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 131.1474 - val_loss: 29.3712\n",
      "Epoch 5848/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 131.6506 - val_loss: 29.3870\n",
      "Epoch 5849/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 97.7643 - val_loss: 29.4038\n",
      "Epoch 5850/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 105.7662 - val_loss: 29.4160\n",
      "Epoch 5851/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 96.6442 - val_loss: 29.4233\n",
      "Epoch 5852/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 110.0653 - val_loss: 29.4258\n",
      "Epoch 5853/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 97.8200 - val_loss: 29.4175\n",
      "Epoch 5854/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 94.3416 - val_loss: 29.4071\n",
      "Epoch 5855/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 115.3538 - val_loss: 29.3961\n",
      "Epoch 5856/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 98.0508 - val_loss: 29.3883\n",
      "Epoch 5857/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 109.2406 - val_loss: 29.3811\n",
      "Epoch 5858/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 91.3867 - val_loss: 29.3324\n",
      "Epoch 5859/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 120.1073 - val_loss: 29.2427\n",
      "Epoch 5860/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 85.4071 - val_loss: 29.1628\n",
      "Epoch 5861/10000\n",
      "184/184 [==============================] - 0s 590us/step - loss: 141.4304 - val_loss: 29.1059\n",
      "Epoch 5862/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 108.3224 - val_loss: 29.0450\n",
      "Epoch 5863/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 81.2991 - val_loss: 28.9734\n",
      "Epoch 5864/10000\n",
      "184/184 [==============================] - 0s 595us/step - loss: 113.3599 - val_loss: 28.9373\n",
      "Epoch 5865/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 141.3919 - val_loss: 28.9111\n",
      "Epoch 5866/10000\n",
      "184/184 [==============================] - 0s 783us/step - loss: 122.0347 - val_loss: 28.8909\n",
      "Epoch 5867/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 95.0568 - val_loss: 28.8696\n",
      "Epoch 5868/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 115.4425 - val_loss: 28.8489\n",
      "Epoch 5869/10000\n",
      "184/184 [==============================] - 0s 644us/step - loss: 124.8498 - val_loss: 28.8303\n",
      "Epoch 5870/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 108.0821 - val_loss: 28.8111\n",
      "Epoch 5871/10000\n",
      "184/184 [==============================] - 0s 568us/step - loss: 109.0730 - val_loss: 28.7969\n",
      "Epoch 5872/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 97.0868 - val_loss: 28.7901\n",
      "Epoch 5873/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 113.7341 - val_loss: 28.7812\n",
      "Epoch 5874/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 124.5799 - val_loss: 28.8004\n",
      "Epoch 5875/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 118.0752 - val_loss: 28.8019\n",
      "Epoch 5876/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 100.1202 - val_loss: 28.8121\n",
      "Epoch 5877/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 121.0546 - val_loss: 28.8603\n",
      "Epoch 5878/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 121.0625 - val_loss: 28.8883\n",
      "Epoch 5879/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 105.0636 - val_loss: 28.8959\n",
      "Epoch 5880/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 99.2049 - val_loss: 28.8943\n",
      "Epoch 5881/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 106.8332 - val_loss: 28.8829\n",
      "Epoch 5882/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 118.1590 - val_loss: 28.8738\n",
      "Epoch 5883/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 160.3543 - val_loss: 28.8618\n",
      "Epoch 5884/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 95.7731 - val_loss: 28.8476\n",
      "Epoch 5885/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 106.3098 - val_loss: 28.8313\n",
      "Epoch 5886/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 104.2824 - val_loss: 28.8151\n",
      "Epoch 5887/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 89.3956 - val_loss: 28.7973\n",
      "Epoch 5888/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 104.8324 - val_loss: 28.7881\n",
      "Epoch 5889/10000\n",
      "184/184 [==============================] - 0s 601us/step - loss: 158.0107 - val_loss: 28.7865\n",
      "Epoch 5890/10000\n",
      "184/184 [==============================] - 0s 645us/step - loss: 121.9267 - val_loss: 28.7826\n",
      "Epoch 5891/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 119.2264 - val_loss: 28.7710\n",
      "Epoch 5892/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 108.4355 - val_loss: 28.7564\n",
      "Epoch 5893/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 87.7280 - val_loss: 28.7332\n",
      "Epoch 5894/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 115.6065 - val_loss: 28.7081\n",
      "Epoch 5895/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 123.9171 - val_loss: 28.6825\n",
      "Epoch 5896/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 582us/step - loss: 136.8154 - val_loss: 28.6572\n",
      "Epoch 5897/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 104.4555 - val_loss: 28.6367\n",
      "Epoch 5898/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 104.4526 - val_loss: 28.6172\n",
      "Epoch 5899/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 118.0616 - val_loss: 28.6000\n",
      "Epoch 5900/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 117.8322 - val_loss: 28.5851\n",
      "\n",
      "Epoch 05900: loss did not improve from 106.09057\n",
      "Epoch 5901/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 118.5474 - val_loss: 28.5691\n",
      "Epoch 5902/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 97.9251 - val_loss: 28.5536\n",
      "Epoch 5903/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 99.8803 - val_loss: 28.5410\n",
      "Epoch 5904/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 97.7303 - val_loss: 28.5301\n",
      "Epoch 5905/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 100.3254 - val_loss: 28.5236\n",
      "Epoch 5906/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 118.1951 - val_loss: 28.5131\n",
      "Epoch 5907/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 99.3753 - val_loss: 28.4966\n",
      "Epoch 5908/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 117.6578 - val_loss: 28.4785\n",
      "Epoch 5909/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 136.5626 - val_loss: 28.4461\n",
      "Epoch 5910/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 93.6315 - val_loss: 28.4232\n",
      "Epoch 5911/10000\n",
      "184/184 [==============================] - 0s 435us/step - loss: 144.6629 - val_loss: 28.4149\n",
      "Epoch 5912/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 97.3183 - val_loss: 28.4197\n",
      "Epoch 5913/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 102.9779 - val_loss: 28.4221\n",
      "Epoch 5914/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 99.5529 - val_loss: 28.3960\n",
      "Epoch 5915/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 90.9247 - val_loss: 28.3640\n",
      "Epoch 5916/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 126.2362 - val_loss: 28.3247\n",
      "Epoch 5917/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 118.1386 - val_loss: 28.2783\n",
      "Epoch 5918/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 127.5415 - val_loss: 28.2234\n",
      "Epoch 5919/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 108.8691 - val_loss: 28.1702\n",
      "Epoch 5920/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 121.2515 - val_loss: 28.1231\n",
      "Epoch 5921/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 128.4219 - val_loss: 28.0721\n",
      "Epoch 5922/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 157.6665 - val_loss: 28.0222\n",
      "Epoch 5923/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 113.5237 - val_loss: 27.9776\n",
      "Epoch 5924/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 94.1818 - val_loss: 27.9409\n",
      "Epoch 5925/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 111.1004 - val_loss: 27.9112\n",
      "Epoch 5926/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 108.5173 - val_loss: 27.8834\n",
      "Epoch 5927/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 113.6456 - val_loss: 27.8524\n",
      "Epoch 5928/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 134.4801 - val_loss: 27.8688\n",
      "Epoch 5929/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 115.2938 - val_loss: 27.9075\n",
      "Epoch 5930/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 92.9527 - val_loss: 27.9141\n",
      "Epoch 5931/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 111.9685 - val_loss: 27.8843\n",
      "Epoch 5932/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 111.1711 - val_loss: 27.8232\n",
      "Epoch 5933/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 96.7062 - val_loss: 27.7728\n",
      "Epoch 5934/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 163.7513 - val_loss: 27.7345\n",
      "Epoch 5935/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 95.7391 - val_loss: 27.7020\n",
      "Epoch 5936/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 107.2277 - val_loss: 27.6823\n",
      "Epoch 5937/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 112.5231 - val_loss: 27.6677\n",
      "Epoch 5938/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 95.4476 - val_loss: 27.6589\n",
      "Epoch 5939/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 84.0154 - val_loss: 27.6547\n",
      "Epoch 5940/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 115.7101 - val_loss: 27.6500\n",
      "Epoch 5941/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 144.8071 - val_loss: 27.6504\n",
      "Epoch 5942/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 100.1319 - val_loss: 27.6512\n",
      "Epoch 5943/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 102.0233 - val_loss: 27.6466\n",
      "Epoch 5944/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 110.4970 - val_loss: 27.6418\n",
      "Epoch 5945/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 103.2089 - val_loss: 27.6387\n",
      "Epoch 5946/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 133.4247 - val_loss: 27.6332\n",
      "Epoch 5947/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 107.8097 - val_loss: 27.6272\n",
      "Epoch 5948/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 126.0461 - val_loss: 27.6222\n",
      "Epoch 5949/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 81.8527 - val_loss: 27.6138\n",
      "Epoch 5950/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 100.7496 - val_loss: 27.6008\n",
      "Epoch 5951/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 96.7232 - val_loss: 27.5867\n",
      "Epoch 5952/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 108.7802 - val_loss: 27.5724\n",
      "Epoch 5953/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 103.7352 - val_loss: 27.5567\n",
      "Epoch 5954/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 117.8109 - val_loss: 27.5409\n",
      "Epoch 5955/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 117.8181 - val_loss: 27.5227\n",
      "Epoch 5956/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 127.4967 - val_loss: 27.5058\n",
      "Epoch 5957/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 120.1746 - val_loss: 27.4882\n",
      "Epoch 5958/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 143.4067 - val_loss: 27.4700\n",
      "Epoch 5959/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 120.7939 - val_loss: 27.4419\n",
      "Epoch 5960/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 119.0893 - val_loss: 27.4174\n",
      "Epoch 5961/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 127.6373 - val_loss: 27.3943\n",
      "Epoch 5962/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 97.9492 - val_loss: 27.3774\n",
      "Epoch 5963/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 107.041 - 0s 533us/step - loss: 97.5612 - val_loss: 27.3603\n",
      "Epoch 5964/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 78.4420 - val_loss: 27.3435\n",
      "Epoch 5965/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 97.1190 - val_loss: 27.3256\n",
      "Epoch 5966/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 97.7490 - val_loss: 27.3095\n",
      "Epoch 5967/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 110.4464 - val_loss: 27.2964\n",
      "Epoch 5968/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 114.4457 - val_loss: 27.2861\n",
      "Epoch 5969/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 527us/step - loss: 139.6914 - val_loss: 27.2793\n",
      "Epoch 5970/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 104.2430 - val_loss: 27.2734\n",
      "Epoch 5971/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 143.0310 - val_loss: 27.2674\n",
      "Epoch 5972/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 106.2405 - val_loss: 27.2581\n",
      "Epoch 5973/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 97.6734 - val_loss: 27.2437\n",
      "Epoch 5974/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 102.2222 - val_loss: 27.2288\n",
      "Epoch 5975/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 109.0119 - val_loss: 27.2158\n",
      "Epoch 5976/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 106.1118 - val_loss: 27.2032\n",
      "Epoch 5977/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 95.8812 - val_loss: 27.1934\n",
      "Epoch 5978/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 102.8268 - val_loss: 27.1837\n",
      "Epoch 5979/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 112.5395 - val_loss: 27.1627\n",
      "Epoch 5980/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 144.4785 - val_loss: 27.1410\n",
      "Epoch 5981/10000\n",
      "184/184 [==============================] - 0s 864us/step - loss: 103.1786 - val_loss: 27.1216\n",
      "Epoch 5982/10000\n",
      "184/184 [==============================] - 0s 709us/step - loss: 110.8136 - val_loss: 27.0980\n",
      "Epoch 5983/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 98.1629 - val_loss: 27.0711\n",
      "Epoch 5984/10000\n",
      "184/184 [==============================] - 0s 671us/step - loss: 111.5704 - val_loss: 27.0469\n",
      "Epoch 5985/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 104.2999 - val_loss: 27.0404\n",
      "Epoch 5986/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 108.8756 - val_loss: 27.0368\n",
      "Epoch 5987/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 105.8748 - val_loss: 27.0221\n",
      "Epoch 5988/10000\n",
      "184/184 [==============================] - 0s 633us/step - loss: 119.1550 - val_loss: 27.0016\n",
      "Epoch 5989/10000\n",
      "184/184 [==============================] - 0s 584us/step - loss: 97.8661 - val_loss: 26.9443\n",
      "Epoch 5990/10000\n",
      "184/184 [==============================] - 0s 486us/step - loss: 124.8636 - val_loss: 26.8369\n",
      "Epoch 5991/10000\n",
      "184/184 [==============================] - 0s 514us/step - loss: 94.9040 - val_loss: 26.7579\n",
      "Epoch 5992/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 119.6938 - val_loss: 26.7291\n",
      "Epoch 5993/10000\n",
      "184/184 [==============================] - 0s 584us/step - loss: 111.7954 - val_loss: 26.7102\n",
      "Epoch 5994/10000\n",
      "184/184 [==============================] - 0s 579us/step - loss: 115.2782 - val_loss: 26.6888\n",
      "Epoch 5995/10000\n",
      "184/184 [==============================] - 0s 487us/step - loss: 95.7843 - val_loss: 26.6728\n",
      "Epoch 5996/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 141.7882 - val_loss: 26.6584\n",
      "Epoch 5997/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 113.1017 - val_loss: 26.6462\n",
      "Epoch 5998/10000\n",
      "184/184 [==============================] - 0s 525us/step - loss: 105.7678 - val_loss: 26.6364\n",
      "Epoch 5999/10000\n",
      "184/184 [==============================] - 0s 514us/step - loss: 130.1124 - val_loss: 26.6238\n",
      "Epoch 6000/10000\n",
      "184/184 [==============================] - 0s 514us/step - loss: 107.5195 - val_loss: 26.6109\n",
      "\n",
      "Epoch 06000: loss did not improve from 106.09057\n",
      "Epoch 6001/10000\n",
      "184/184 [==============================] - 0s 655us/step - loss: 104.9545 - val_loss: 26.5974\n",
      "Epoch 6002/10000\n",
      "184/184 [==============================] - 0s 584us/step - loss: 114.6759 - val_loss: 26.5841\n",
      "Epoch 6003/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 124.9302 - val_loss: 26.5697\n",
      "Epoch 6004/10000\n",
      "184/184 [==============================] - 0s 568us/step - loss: 98.9324 - val_loss: 26.5517\n",
      "Epoch 6005/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 105.9850 - val_loss: 26.5340\n",
      "Epoch 6006/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 110.0828 - val_loss: 26.5151\n",
      "Epoch 6007/10000\n",
      "184/184 [==============================] - 0s 476us/step - loss: 116.5226 - val_loss: 26.4962\n",
      "Epoch 6008/10000\n",
      "184/184 [==============================] - 0s 535us/step - loss: 111.7531 - val_loss: 26.4772\n",
      "Epoch 6009/10000\n",
      "184/184 [==============================] - 0s 601us/step - loss: 86.4361 - val_loss: 26.4588\n",
      "Epoch 6010/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 111.7490 - val_loss: 26.4394\n",
      "Epoch 6011/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 108.3269 - val_loss: 26.4213\n",
      "Epoch 6012/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 121.9693 - val_loss: 26.4050\n",
      "Epoch 6013/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 94.4338 - val_loss: 26.3894\n",
      "Epoch 6014/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 116.3199 - val_loss: 26.3749\n",
      "Epoch 6015/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 107.4278 - val_loss: 26.3596\n",
      "Epoch 6016/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 110.8702 - val_loss: 26.3418\n",
      "Epoch 6017/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 132.3008 - val_loss: 26.3192\n",
      "Epoch 6018/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 113.7098 - val_loss: 26.2958\n",
      "Epoch 6019/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 91.5869 - val_loss: 26.2729\n",
      "Epoch 6020/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 101.4430 - val_loss: 26.2515\n",
      "Epoch 6021/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 99.4380 - val_loss: 26.2332\n",
      "Epoch 6022/10000\n",
      "184/184 [==============================] - 0s 487us/step - loss: 111.2776 - val_loss: 26.2151\n",
      "Epoch 6023/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 90.9264 - val_loss: 26.1970\n",
      "Epoch 6024/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 119.2499 - val_loss: 26.1767\n",
      "Epoch 6025/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 97.3566 - val_loss: 26.1545\n",
      "Epoch 6026/10000\n",
      "184/184 [==============================] - 0s 535us/step - loss: 108.7906 - val_loss: 26.1353\n",
      "Epoch 6027/10000\n",
      "184/184 [==============================] - 0s 552us/step - loss: 99.8098 - val_loss: 26.1181\n",
      "Epoch 6028/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 92.5506 - val_loss: 26.1037\n",
      "Epoch 6029/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 114.8341 - val_loss: 26.0857\n",
      "Epoch 6030/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 107.0613 - val_loss: 26.0567\n",
      "Epoch 6031/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 113.5250 - val_loss: 26.0239\n",
      "Epoch 6032/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 97.9527 - val_loss: 25.9785\n",
      "Epoch 6033/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 125.6139 - val_loss: 25.9397\n",
      "Epoch 6034/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 94.6926 - val_loss: 25.9060\n",
      "Epoch 6035/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 165.8879 - val_loss: 25.8563\n",
      "Epoch 6036/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 101.0326 - val_loss: 25.8447\n",
      "Epoch 6037/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 128.7269 - val_loss: 25.8567\n",
      "Epoch 6038/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 84.6827 - val_loss: 25.8481\n",
      "Epoch 6039/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 90.0214 - val_loss: 25.8055\n",
      "Epoch 6040/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 96.6277 - val_loss: 25.7632\n",
      "Epoch 6041/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 113.3443 - val_loss: 25.7397\n",
      "Epoch 6042/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 467us/step - loss: 101.4075 - val_loss: 25.7320\n",
      "Epoch 6043/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 149.6605 - val_loss: 25.7218\n",
      "Epoch 6044/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 124.3913 - val_loss: 25.7109\n",
      "Epoch 6045/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 99.7232 - val_loss: 25.6973\n",
      "Epoch 6046/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 120.2649 - val_loss: 25.6839\n",
      "Epoch 6047/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 117.3423 - val_loss: 25.6771\n",
      "Epoch 6048/10000\n",
      "184/184 [==============================] - 0s 536us/step - loss: 108.4892 - val_loss: 25.6724\n",
      "Epoch 6049/10000\n",
      "184/184 [==============================] - 0s 486us/step - loss: 110.4336 - val_loss: 25.6704\n",
      "Epoch 6050/10000\n",
      "184/184 [==============================] - 0s 514us/step - loss: 126.6281 - val_loss: 25.6671\n",
      "Epoch 6051/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 120.7121 - val_loss: 25.6647\n",
      "Epoch 6052/10000\n",
      "184/184 [==============================] - 0s 525us/step - loss: 96.4881 - val_loss: 25.6530\n",
      "Epoch 6053/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 115.2177 - val_loss: 25.6337\n",
      "Epoch 6054/10000\n",
      "184/184 [==============================] - 0s 552us/step - loss: 120.4507 - val_loss: 25.6128\n",
      "Epoch 6055/10000\n",
      "184/184 [==============================] - 0s 568us/step - loss: 147.7836 - val_loss: 25.5945\n",
      "Epoch 6056/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 103.8311 - val_loss: 25.5786\n",
      "Epoch 6057/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 116.4119 - val_loss: 25.5599\n",
      "Epoch 6058/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 93.5550 - val_loss: 25.5383\n",
      "Epoch 6059/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 116.0323 - val_loss: 25.5240\n",
      "Epoch 6060/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 106.7419 - val_loss: 25.5116\n",
      "Epoch 6061/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 111.8330 - val_loss: 25.4126\n",
      "Epoch 6062/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 111.9686 - val_loss: 25.7253\n",
      "Epoch 6063/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 116.7038 - val_loss: 26.0609\n",
      "Epoch 6064/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 106.7619 - val_loss: 26.2633\n",
      "Epoch 6065/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 101.1268 - val_loss: 26.9784\n",
      "Epoch 6066/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 110.0187 - val_loss: 26.9335\n",
      "Epoch 6067/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 96.6033 - val_loss: 27.0680\n",
      "Epoch 6068/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 130.8315 - val_loss: 27.2136\n",
      "Epoch 6069/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 107.1787 - val_loss: 27.3115\n",
      "Epoch 6070/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 159.8016 - val_loss: 27.1852\n",
      "Epoch 6071/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 97.5724 - val_loss: 27.0339\n",
      "Epoch 6072/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 140.9389 - val_loss: 26.8898\n",
      "Epoch 6073/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 95.7104 - val_loss: 26.7592\n",
      "Epoch 6074/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 100.9680 - val_loss: 26.6634\n",
      "Epoch 6075/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 105.6248 - val_loss: 26.5918\n",
      "Epoch 6076/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 97.4589 - val_loss: 26.5195\n",
      "Epoch 6077/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 112.8431 - val_loss: 26.4914\n",
      "Epoch 6078/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 73.1876 - val_loss: 26.4688\n",
      "Epoch 6079/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 97.8597 - val_loss: 26.4796\n",
      "Epoch 6080/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 100.8243 - val_loss: 26.5025\n",
      "Epoch 6081/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 117.9794 - val_loss: 26.5291\n",
      "Epoch 6082/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 117.1982 - val_loss: 26.5554\n",
      "Epoch 6083/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 92.0879 - val_loss: 26.5588\n",
      "Epoch 6084/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 90.0627 - val_loss: 26.5413\n",
      "Epoch 6085/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 99.6641 - val_loss: 26.5240\n",
      "Epoch 6086/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 115.3774 - val_loss: 26.5073\n",
      "Epoch 6087/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 128.7733 - val_loss: 26.4901\n",
      "Epoch 6088/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 101.4773 - val_loss: 26.4823\n",
      "Epoch 6089/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 96.7938 - val_loss: 26.4749\n",
      "Epoch 6090/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 100.3640 - val_loss: 26.4632\n",
      "Epoch 6091/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 109.7186 - val_loss: 26.4357\n",
      "Epoch 6092/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 115.5966 - val_loss: 26.3925\n",
      "Epoch 6093/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 120.6560 - val_loss: 26.3537\n",
      "Epoch 6094/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 83.5070 - val_loss: 26.3177\n",
      "Epoch 6095/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 130.1622 - val_loss: 26.2871\n",
      "Epoch 6096/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 111.5296 - val_loss: 26.2618\n",
      "Epoch 6097/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 98.2376 - val_loss: 26.2456\n",
      "Epoch 6098/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 106.0584 - val_loss: 26.2354\n",
      "Epoch 6099/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 103.2114 - val_loss: 26.2286\n",
      "Epoch 6100/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 106.0317 - val_loss: 26.2010\n",
      "\n",
      "Epoch 06100: loss improved from 106.09057 to 106.03168, saving model to C6007C.hdf5\n",
      "Epoch 6101/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 140.3455 - val_loss: 26.0395\n",
      "Epoch 6102/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 93.7770 - val_loss: 25.8950\n",
      "Epoch 6103/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 89.5825 - val_loss: 25.7525\n",
      "Epoch 6104/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 116.9617 - val_loss: 25.7269\n",
      "Epoch 6105/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 101.5758 - val_loss: 25.4985\n",
      "Epoch 6106/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 93.1208 - val_loss: 25.4032\n",
      "Epoch 6107/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 91.1839 - val_loss: 25.3594\n",
      "Epoch 6108/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 87.2714 - val_loss: 25.3343\n",
      "Epoch 6109/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 99.9285 - val_loss: 25.3148\n",
      "Epoch 6110/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 107.0540 - val_loss: 25.2969\n",
      "Epoch 6111/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 116.2874 - val_loss: 25.2793\n",
      "Epoch 6112/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 97.2598 - val_loss: 25.2623\n",
      "Epoch 6113/10000\n",
      "184/184 [==============================] - 0s 788us/step - loss: 119.8232 - val_loss: 25.2427\n",
      "Epoch 6114/10000\n",
      "184/184 [==============================] - 0s 804us/step - loss: 121.6951 - val_loss: 25.2233\n",
      "Epoch 6115/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 853us/step - loss: 108.6224 - val_loss: 25.2069\n",
      "Epoch 6116/10000\n",
      "184/184 [==============================] - 0s 815us/step - loss: 117.9019 - val_loss: 25.1922\n",
      "Epoch 6117/10000\n",
      "184/184 [==============================] - 0s 864us/step - loss: 117.1647 - val_loss: 25.1796\n",
      "Epoch 6118/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 119.7295 - val_loss: 25.1687\n",
      "Epoch 6119/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 108.4890 - val_loss: 25.1617\n",
      "Epoch 6120/10000\n",
      "184/184 [==============================] - 0s 864us/step - loss: 130.6246 - val_loss: 25.1498\n",
      "Epoch 6121/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 101.1421 - val_loss: 25.1978\n",
      "Epoch 6122/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 119.1403 - val_loss: 25.2691\n",
      "Epoch 6123/10000\n",
      "184/184 [==============================] - 0s 761us/step - loss: 98.2207 - val_loss: 25.3285\n",
      "Epoch 6124/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 112.3626 - val_loss: 25.3413\n",
      "Epoch 6125/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 136.1936 - val_loss: 25.3601\n",
      "Epoch 6126/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 93.2324 - val_loss: 25.3529\n",
      "Epoch 6127/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 90.1687 - val_loss: 25.3620\n",
      "Epoch 6128/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 101.2117 - val_loss: 25.3686\n",
      "Epoch 6129/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 98.5236 - val_loss: 25.3723\n",
      "Epoch 6130/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 72.4161 - val_loss: 25.3768\n",
      "Epoch 6131/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 88.0188 - val_loss: 25.3705\n",
      "Epoch 6132/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 86.6358 - val_loss: 25.3631\n",
      "Epoch 6133/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 93.7710 - val_loss: 25.3776\n",
      "Epoch 6134/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 115.5154 - val_loss: 25.3971\n",
      "Epoch 6135/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 126.5346 - val_loss: 25.4132\n",
      "Epoch 6136/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 123.8285 - val_loss: 25.4023\n",
      "Epoch 6137/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 93.5365 - val_loss: 25.3828\n",
      "Epoch 6138/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 84.9953 - val_loss: 25.3682\n",
      "Epoch 6139/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 129.6777 - val_loss: 25.3609\n",
      "Epoch 6140/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 122.5160 - val_loss: 25.3579\n",
      "Epoch 6141/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 100.9101 - val_loss: 25.3858\n",
      "Epoch 6142/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 100.6861 - val_loss: 25.4739\n",
      "Epoch 6143/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 95.3908 - val_loss: 25.5545\n",
      "Epoch 6144/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 93.5136 - val_loss: 25.5761\n",
      "Epoch 6145/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 118.0393 - val_loss: 25.6142\n",
      "Epoch 6146/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 137.1916 - val_loss: 25.6540\n",
      "Epoch 6147/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 97.6175 - val_loss: 25.7021\n",
      "Epoch 6148/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 79.6440 - val_loss: 25.7294\n",
      "Epoch 6149/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 79.0463 - val_loss: 25.7933\n",
      "Epoch 6150/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 103.9529 - val_loss: 25.8547\n",
      "Epoch 6151/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 106.8009 - val_loss: 25.8845\n",
      "Epoch 6152/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 79.5935 - val_loss: 25.8951\n",
      "Epoch 6153/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 108.6825 - val_loss: 25.8965\n",
      "Epoch 6154/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 93.9449 - val_loss: 25.8884\n",
      "Epoch 6155/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 87.0129 - val_loss: 25.8800\n",
      "Epoch 6156/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 99.3385 - val_loss: 25.8390\n",
      "Epoch 6157/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 91.2495 - val_loss: 25.7512\n",
      "Epoch 6158/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 95.9157 - val_loss: 25.7484\n",
      "Epoch 6159/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 122.1289 - val_loss: 25.7378\n",
      "Epoch 6160/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 104.2067 - val_loss: 25.7244\n",
      "Epoch 6161/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 103.0219 - val_loss: 25.7118\n",
      "Epoch 6162/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 113.5477 - val_loss: 25.6948\n",
      "Epoch 6163/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 96.8775 - val_loss: 25.6768\n",
      "Epoch 6164/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 100.5637 - val_loss: 25.6563\n",
      "Epoch 6165/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 101.7408 - val_loss: 25.6516\n",
      "Epoch 6166/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 103.6613 - val_loss: 25.6221\n",
      "Epoch 6167/10000\n",
      "184/184 [==============================] - 0s 435us/step - loss: 109.9984 - val_loss: 25.6425\n",
      "Epoch 6168/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 160.2645 - val_loss: 25.6597\n",
      "Epoch 6169/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 98.6753 - val_loss: 25.6604\n",
      "Epoch 6170/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 100.1782 - val_loss: 25.6606\n",
      "Epoch 6171/10000\n",
      "184/184 [==============================] - 0s 429us/step - loss: 105.0501 - val_loss: 25.6566\n",
      "Epoch 6172/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 104.0097 - val_loss: 25.6506\n",
      "Epoch 6173/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 104.3019 - val_loss: 25.6966\n",
      "Epoch 6174/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 85.7530 - val_loss: 25.8232\n",
      "Epoch 6175/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 97.6099 - val_loss: 25.9171\n",
      "Epoch 6176/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 110.5213 - val_loss: 25.9970\n",
      "Epoch 6177/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 112.8738 - val_loss: 26.0559\n",
      "Epoch 6178/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 91.2012 - val_loss: 26.0998\n",
      "Epoch 6179/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 103.8447 - val_loss: 26.3070\n",
      "Epoch 6180/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 96.4613 - val_loss: 26.3678\n",
      "Epoch 6181/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 105.4733 - val_loss: 26.4848\n",
      "Epoch 6182/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 85.3820 - val_loss: 26.5136\n",
      "Epoch 6183/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 119.5093 - val_loss: 26.0383\n",
      "Epoch 6184/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 105.8092 - val_loss: 25.8473\n",
      "Epoch 6185/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 120.4986 - val_loss: 25.8304\n",
      "Epoch 6186/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 101.8090 - val_loss: 25.9120\n",
      "Epoch 6187/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 101.2048 - val_loss: 25.8595\n",
      "Epoch 6188/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 100.7843 - val_loss: 25.8027\n",
      "Epoch 6189/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 527us/step - loss: 95.2978 - val_loss: 25.8801\n",
      "Epoch 6190/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 89.9506 - val_loss: 25.9319\n",
      "Epoch 6191/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 106.4984 - val_loss: 25.9839\n",
      "Epoch 6192/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 112.7930 - val_loss: 26.0150\n",
      "Epoch 6193/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 100.1510 - val_loss: 26.0360\n",
      "Epoch 6194/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 85.1779 - val_loss: 26.0468\n",
      "Epoch 6195/10000\n",
      "184/184 [==============================] - 0s 506us/step - loss: 102.2678 - val_loss: 26.0754\n",
      "Epoch 6196/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 91.9405 - val_loss: 26.0958\n",
      "Epoch 6197/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 97.7025 - val_loss: 26.1118\n",
      "Epoch 6198/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 100.3472 - val_loss: 26.1212\n",
      "Epoch 6199/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 100.7018 - val_loss: 26.1234\n",
      "Epoch 6200/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 104.7712 - val_loss: 26.1423\n",
      "\n",
      "Epoch 06200: loss improved from 106.03168 to 104.77121, saving model to C6007C.hdf5\n",
      "Epoch 6201/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 115.8136 - val_loss: 26.1485\n",
      "Epoch 6202/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 113.7946 - val_loss: 26.1684\n",
      "Epoch 6203/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 133.1015 - val_loss: 26.1640\n",
      "Epoch 6204/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 115.8071 - val_loss: 26.1460\n",
      "Epoch 6205/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 141.5693 - val_loss: 26.0397\n",
      "Epoch 6206/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 94.4459 - val_loss: 25.9572\n",
      "Epoch 6207/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 111.0520 - val_loss: 25.8858\n",
      "Epoch 6208/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 87.7334 - val_loss: 25.8270\n",
      "Epoch 6209/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 119.4969 - val_loss: 25.7737\n",
      "Epoch 6210/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 106.3394 - val_loss: 25.7213\n",
      "Epoch 6211/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 93.7788 - val_loss: 25.6708\n",
      "Epoch 6212/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 106.2570 - val_loss: 25.6227\n",
      "Epoch 6213/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 95.3040 - val_loss: 25.5887\n",
      "Epoch 6214/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 103.0022 - val_loss: 25.5667\n",
      "Epoch 6215/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 129.1724 - val_loss: 25.5145\n",
      "Epoch 6216/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 104.9858 - val_loss: 25.4651\n",
      "Epoch 6217/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 96.9511 - val_loss: 25.4148\n",
      "Epoch 6218/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 110.1531 - val_loss: 25.3950\n",
      "Epoch 6219/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 120.0821 - val_loss: 25.3693\n",
      "Epoch 6220/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 94.9306 - val_loss: 25.3973\n",
      "Epoch 6221/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 95.3225 - val_loss: 25.4060\n",
      "Epoch 6222/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 96.4577 - val_loss: 25.4159\n",
      "Epoch 6223/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 90.1318 - val_loss: 25.4288\n",
      "Epoch 6224/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 98.1492 - val_loss: 25.4348\n",
      "Epoch 6225/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 89.7547 - val_loss: 25.4281\n",
      "Epoch 6226/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 111.8738 - val_loss: 25.4144\n",
      "Epoch 6227/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 82.0985 - val_loss: 25.3977\n",
      "Epoch 6228/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 97.6297 - val_loss: 25.3874\n",
      "Epoch 6229/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 98.8931 - val_loss: 25.3778\n",
      "Epoch 6230/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 91.6308 - val_loss: 25.3842\n",
      "Epoch 6231/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 79.4008 - val_loss: 25.4091\n",
      "Epoch 6232/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 112.5890 - val_loss: 25.4135\n",
      "Epoch 6233/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 109.0397 - val_loss: 25.4001\n",
      "Epoch 6234/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 103.7391 - val_loss: 25.3918\n",
      "Epoch 6235/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 101.8799 - val_loss: 25.3662\n",
      "Epoch 6236/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 92.3390 - val_loss: 25.3349\n",
      "Epoch 6237/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 120.4084 - val_loss: 25.3074\n",
      "Epoch 6238/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 124.5749 - val_loss: 25.3257\n",
      "Epoch 6239/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 98.2281 - val_loss: 25.3364\n",
      "Epoch 6240/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 94.5404 - val_loss: 25.3434\n",
      "Epoch 6241/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 115.0622 - val_loss: 25.3442\n",
      "Epoch 6242/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 93.1788 - val_loss: 25.1457\n",
      "Epoch 6243/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 99.9883 - val_loss: 25.1926\n",
      "Epoch 6244/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 102.1237 - val_loss: 25.1631\n",
      "Epoch 6245/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 81.8630 - val_loss: 25.0960\n",
      "Epoch 6246/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 114.1732 - val_loss: 25.0699\n",
      "Epoch 6247/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 89.7925 - val_loss: 25.0445\n",
      "Epoch 6248/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 100.4900 - val_loss: 25.0264\n",
      "Epoch 6249/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 104.5200 - val_loss: 25.0178\n",
      "Epoch 6250/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 90.4355 - val_loss: 25.0131\n",
      "Epoch 6251/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 113.4787 - val_loss: 25.0130\n",
      "Epoch 6252/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 138.2944 - val_loss: 25.0128\n",
      "Epoch 6253/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 117.4739 - val_loss: 25.0069\n",
      "Epoch 6254/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 100.0859 - val_loss: 25.0247\n",
      "Epoch 6255/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 94.2510 - val_loss: 25.0396\n",
      "Epoch 6256/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 101.7131 - val_loss: 25.0487\n",
      "Epoch 6257/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 113.6730 - val_loss: 25.0537\n",
      "Epoch 6258/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 94.7675 - val_loss: 25.0541\n",
      "Epoch 6259/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 88.1655 - val_loss: 25.0498\n",
      "Epoch 6260/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 86.2094 - val_loss: 25.0469\n",
      "Epoch 6261/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 99.5284 - val_loss: 25.0461\n",
      "Epoch 6262/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 592us/step - loss: 104.4075 - val_loss: 25.0455\n",
      "Epoch 6263/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 119.7537 - val_loss: 25.0432\n",
      "Epoch 6264/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 113.0384 - val_loss: 25.0315\n",
      "Epoch 6265/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 93.9980 - val_loss: 25.0197\n",
      "Epoch 6266/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 83.9317 - val_loss: 25.0086\n",
      "Epoch 6267/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 115.0560 - val_loss: 25.0192\n",
      "Epoch 6268/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 152.0159 - val_loss: 25.0394\n",
      "Epoch 6269/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 106.5119 - val_loss: 25.0306\n",
      "Epoch 6270/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 105.0571 - val_loss: 25.0171\n",
      "Epoch 6271/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 118.0406 - val_loss: 24.9981\n",
      "Epoch 6272/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 122.9550 - val_loss: 24.9868\n",
      "Epoch 6273/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 88.9610 - val_loss: 24.9648\n",
      "Epoch 6274/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 99.5264 - val_loss: 24.9347\n",
      "Epoch 6275/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 119.7840 - val_loss: 24.9132\n",
      "Epoch 6276/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 84.3566 - val_loss: 24.8934\n",
      "Epoch 6277/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 100.0815 - val_loss: 24.8780\n",
      "Epoch 6278/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 102.8336 - val_loss: 24.8459\n",
      "Epoch 6279/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 93.5347 - val_loss: 24.8189\n",
      "Epoch 6280/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 118.6713 - val_loss: 24.7948\n",
      "Epoch 6281/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 94.1856 - val_loss: 24.7695\n",
      "Epoch 6282/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 98.3027 - val_loss: 24.7508\n",
      "Epoch 6283/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 107.0403 - val_loss: 24.7345\n",
      "Epoch 6284/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 108.1163 - val_loss: 24.7083\n",
      "Epoch 6285/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 100.9124 - val_loss: 24.6762\n",
      "Epoch 6286/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 115.3667 - val_loss: 24.6476\n",
      "Epoch 6287/10000\n",
      "184/184 [==============================] - 0s 581us/step - loss: 79.7773 - val_loss: 24.6252\n",
      "Epoch 6288/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 137.1584 - val_loss: 24.6040\n",
      "Epoch 6289/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 120.7837 - val_loss: 24.5847\n",
      "Epoch 6290/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 92.7432 - val_loss: 24.5696\n",
      "Epoch 6291/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 97.0389 - val_loss: 24.5588\n",
      "Epoch 6292/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 115.5721 - val_loss: 24.5619\n",
      "Epoch 6293/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 96.7365 - val_loss: 24.6105\n",
      "Epoch 6294/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 87.3344 - val_loss: 24.6506\n",
      "Epoch 6295/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 91.9749 - val_loss: 24.7004\n",
      "Epoch 6296/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 109.1804 - val_loss: 24.7431\n",
      "Epoch 6297/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 105.2695 - val_loss: 24.6833\n",
      "Epoch 6298/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 114.5494 - val_loss: 24.6694\n",
      "Epoch 6299/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 90.2818 - val_loss: 24.6580\n",
      "Epoch 6300/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 92.6139 - val_loss: 24.6321\n",
      "\n",
      "Epoch 06300: loss improved from 104.77121 to 92.61394, saving model to C6007C.hdf5\n",
      "Epoch 6301/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 84.5575 - val_loss: 24.6003\n",
      "Epoch 6302/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 91.2143 - val_loss: 24.5658\n",
      "Epoch 6303/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 109.2236 - val_loss: 24.2492\n",
      "Epoch 6304/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 87.1169 - val_loss: 24.0070\n",
      "Epoch 6305/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 102.7619 - val_loss: 23.8246\n",
      "Epoch 6306/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 114.0219 - val_loss: 23.6649\n",
      "Epoch 6307/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 95.9160 - val_loss: 23.5807\n",
      "Epoch 6308/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 125.8430 - val_loss: 23.5055\n",
      "Epoch 6309/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 118.8862 - val_loss: 23.4388\n",
      "Epoch 6310/10000\n",
      "184/184 [==============================] - 0s 583us/step - loss: 99.3962 - val_loss: 23.3769\n",
      "Epoch 6311/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 79.1053 - val_loss: 23.3164\n",
      "Epoch 6312/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 94.7970 - val_loss: 23.2658\n",
      "Epoch 6313/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 90.8680 - val_loss: 23.2106\n",
      "Epoch 6314/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 104.8900 - val_loss: 23.1600\n",
      "Epoch 6315/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 94.2146 - val_loss: 23.1230\n",
      "Epoch 6316/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 95.2381 - val_loss: 23.0918\n",
      "Epoch 6317/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 98.5984 - val_loss: 23.0607\n",
      "Epoch 6318/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 95.5189 - val_loss: 23.0344\n",
      "Epoch 6319/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 103.7081 - val_loss: 23.0097\n",
      "Epoch 6320/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 86.9845 - val_loss: 22.9920\n",
      "Epoch 6321/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 110.1793 - val_loss: 22.9735\n",
      "Epoch 6322/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 104.5764 - val_loss: 22.9540\n",
      "Epoch 6323/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 78.9250 - val_loss: 22.9412\n",
      "Epoch 6324/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 117.9669 - val_loss: 22.9026\n",
      "Epoch 6325/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 94.2166 - val_loss: 22.8839\n",
      "Epoch 6326/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 101.0346 - val_loss: 22.8645\n",
      "Epoch 6327/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 97.5265 - val_loss: 22.7980\n",
      "Epoch 6328/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 96.6985 - val_loss: 22.7765\n",
      "Epoch 6329/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 86.3353 - val_loss: 22.7322\n",
      "Epoch 6330/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 91.9475 - val_loss: 22.6540\n",
      "Epoch 6331/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 76.4856 - val_loss: 22.6217\n",
      "Epoch 6332/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 96.5333 - val_loss: 22.5963\n",
      "Epoch 6333/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 84.3866 - val_loss: 22.6524\n",
      "Epoch 6334/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 131.2189 - val_loss: 22.6352\n",
      "Epoch 6335/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 554us/step - loss: 82.2408 - val_loss: 22.5702\n",
      "Epoch 6336/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 76.9231 - val_loss: 22.5716\n",
      "Epoch 6337/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 96.7856 - val_loss: 22.5990\n",
      "Epoch 6338/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 150.9288 - val_loss: 22.6100\n",
      "Epoch 6339/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 103.5968 - val_loss: 22.6252\n",
      "Epoch 6340/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 92.6450 - val_loss: 22.6217\n",
      "Epoch 6341/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 102.1567 - val_loss: 22.6213\n",
      "Epoch 6342/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 103.8867 - val_loss: 22.5977\n",
      "Epoch 6343/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 99.8520 - val_loss: 22.5610\n",
      "Epoch 6344/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 99.2041 - val_loss: 22.5193\n",
      "Epoch 6345/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 96.5736 - val_loss: 22.4792\n",
      "Epoch 6346/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 99.8252 - val_loss: 22.4599\n",
      "Epoch 6347/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 96.1820 - val_loss: 22.4525\n",
      "Epoch 6348/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 102.1214 - val_loss: 22.4490\n",
      "Epoch 6349/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 72.3138 - val_loss: 22.4393\n",
      "Epoch 6350/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 107.6494 - val_loss: 22.4322\n",
      "Epoch 6351/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 94.8840 - val_loss: 22.4251\n",
      "Epoch 6352/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 103.5468 - val_loss: 22.4170\n",
      "Epoch 6353/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 104.3624 - val_loss: 22.4088\n",
      "Epoch 6354/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 94.5586 - val_loss: 22.4011\n",
      "Epoch 6355/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 121.1260 - val_loss: 22.3929\n",
      "Epoch 6356/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 105.9608 - val_loss: 22.3834\n",
      "Epoch 6357/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 103.7708 - val_loss: 22.3732\n",
      "Epoch 6358/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 103.8688 - val_loss: 22.3803\n",
      "Epoch 6359/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 98.2357 - val_loss: 22.3922\n",
      "Epoch 6360/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 96.3918 - val_loss: 22.3907\n",
      "Epoch 6361/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 96.11 - 0s 467us/step - loss: 106.7230 - val_loss: 22.3610\n",
      "Epoch 6362/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 102.0400 - val_loss: 22.3193\n",
      "Epoch 6363/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 107.3211 - val_loss: 22.2863\n",
      "Epoch 6364/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 94.6962 - val_loss: 22.2602\n",
      "Epoch 6365/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 92.1715 - val_loss: 22.2395\n",
      "Epoch 6366/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 138.9070 - val_loss: 22.2324\n",
      "Epoch 6367/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 102.7043 - val_loss: 22.2259\n",
      "Epoch 6368/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 109.8642 - val_loss: 22.2117\n",
      "Epoch 6369/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 99.9197 - val_loss: 22.1950\n",
      "Epoch 6370/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 101.6160 - val_loss: 22.1831\n",
      "Epoch 6371/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 103.7500 - val_loss: 22.1817\n",
      "Epoch 6372/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 90.9821 - val_loss: 22.2165\n",
      "Epoch 6373/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 86.5989 - val_loss: 22.2439\n",
      "Epoch 6374/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 87.6235 - val_loss: 22.2967\n",
      "Epoch 6375/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 98.2523 - val_loss: 22.1879\n",
      "Epoch 6376/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 82.1528 - val_loss: 22.1892\n",
      "Epoch 6377/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 98.7461 - val_loss: 22.2543\n",
      "Epoch 6378/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 104.7292 - val_loss: 22.1889\n",
      "Epoch 6379/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 91.6015 - val_loss: 22.1523\n",
      "Epoch 6380/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 102.0323 - val_loss: 22.1462\n",
      "Epoch 6381/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 93.1806 - val_loss: 22.1370\n",
      "Epoch 6382/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 98.2130 - val_loss: 22.1278\n",
      "Epoch 6383/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 80.7161 - val_loss: 22.1209\n",
      "Epoch 6384/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 92.9538 - val_loss: 22.1137\n",
      "Epoch 6385/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 109.4367 - val_loss: 22.1077\n",
      "Epoch 6386/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 95.1525 - val_loss: 22.1025\n",
      "Epoch 6387/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 94.2803 - val_loss: 22.0975\n",
      "Epoch 6388/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 95.5907 - val_loss: 22.0919\n",
      "Epoch 6389/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 91.8583 - val_loss: 22.0869\n",
      "Epoch 6390/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 94.1031 - val_loss: 22.0829\n",
      "Epoch 6391/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 120.3217 - val_loss: 22.0773\n",
      "Epoch 6392/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 104.0823 - val_loss: 22.0679\n",
      "Epoch 6393/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 133.8235 - val_loss: 22.0563\n",
      "Epoch 6394/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 88.6230 - val_loss: 22.0459\n",
      "Epoch 6395/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 96.3492 - val_loss: 22.0355\n",
      "Epoch 6396/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 85.4926 - val_loss: 22.0261\n",
      "Epoch 6397/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 109.4158 - val_loss: 22.0153\n",
      "Epoch 6398/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 104.8882 - val_loss: 22.0077\n",
      "Epoch 6399/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 84.3535 - val_loss: 22.0001\n",
      "Epoch 6400/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 129.4887 - val_loss: 22.0102\n",
      "\n",
      "Epoch 06400: loss did not improve from 92.61394\n",
      "Epoch 6401/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 86.5359 - val_loss: 22.0176\n",
      "Epoch 6402/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 100.0988 - val_loss: 22.0148\n",
      "Epoch 6403/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 102.4452 - val_loss: 21.9906\n",
      "Epoch 6404/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 80.1602 - val_loss: 21.9501\n",
      "Epoch 6405/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 84.5078 - val_loss: 21.9277\n",
      "Epoch 6406/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 98.5507 - val_loss: 21.9260\n",
      "Epoch 6407/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 111.9452 - val_loss: 21.9229\n",
      "Epoch 6408/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 467us/step - loss: 96.1204 - val_loss: 21.9142\n",
      "Epoch 6409/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 100.1213 - val_loss: 21.9008\n",
      "Epoch 6410/10000\n",
      "184/184 [==============================] - 0s 581us/step - loss: 100.8008 - val_loss: 21.8851\n",
      "Epoch 6411/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 108.9959 - val_loss: 21.8703\n",
      "Epoch 6412/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 106.5019 - val_loss: 21.8477\n",
      "Epoch 6413/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 87.4320 - val_loss: 21.8295\n",
      "Epoch 6414/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 95.0884 - val_loss: 21.8153\n",
      "Epoch 6415/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 93.9660 - val_loss: 21.8000\n",
      "Epoch 6416/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 139.6404 - val_loss: 21.7844\n",
      "Epoch 6417/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 94.1760 - val_loss: 21.7677\n",
      "Epoch 6418/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 85.5593 - val_loss: 21.7552\n",
      "Epoch 6419/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 90.2176 - val_loss: 21.7357\n",
      "Epoch 6420/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 91.2406 - val_loss: 21.7194\n",
      "Epoch 6421/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 97.0550 - val_loss: 21.6954\n",
      "Epoch 6422/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 75.5605 - val_loss: 21.6748\n",
      "Epoch 6423/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 117.1518 - val_loss: 21.6557\n",
      "Epoch 6424/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 127.6828 - val_loss: 21.6356\n",
      "Epoch 6425/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 85.6830 - val_loss: 21.6203\n",
      "Epoch 6426/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 86.2022 - val_loss: 21.6048\n",
      "Epoch 6427/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 90.0823 - val_loss: 21.5917\n",
      "Epoch 6428/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 106.6004 - val_loss: 21.5787\n",
      "Epoch 6429/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 123.1525 - val_loss: 21.5665\n",
      "Epoch 6430/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 107.6927 - val_loss: 21.5528\n",
      "Epoch 6431/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 102.6214 - val_loss: 21.5376\n",
      "Epoch 6432/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 106.7870 - val_loss: 21.5227\n",
      "Epoch 6433/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 97.0300 - val_loss: 21.5099\n",
      "Epoch 6434/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 80.9397 - val_loss: 21.4953\n",
      "Epoch 6435/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 83.6517 - val_loss: 21.4832\n",
      "Epoch 6436/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 123.5023 - val_loss: 21.4777\n",
      "Epoch 6437/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 91.1383 - val_loss: 21.5110\n",
      "Epoch 6438/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 93.7630 - val_loss: 21.5380\n",
      "Epoch 6439/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 93.1982 - val_loss: 21.4183\n",
      "Epoch 6440/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 117.0885 - val_loss: 21.3997\n",
      "Epoch 6441/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 86.1663 - val_loss: 21.3734\n",
      "Epoch 6442/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 116.9754 - val_loss: 21.3384\n",
      "Epoch 6443/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 96.3435 - val_loss: 21.3068\n",
      "Epoch 6444/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 92.6228 - val_loss: 21.2850\n",
      "Epoch 6445/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 100.9378 - val_loss: 21.2649\n",
      "Epoch 6446/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 98.7747 - val_loss: 21.2476\n",
      "Epoch 6447/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 90.7528 - val_loss: 21.2327\n",
      "Epoch 6448/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 82.6710 - val_loss: 21.2194\n",
      "Epoch 6449/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 85.7589 - val_loss: 21.2001\n",
      "Epoch 6450/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 82.6788 - val_loss: 21.1966\n",
      "Epoch 6451/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 110.0027 - val_loss: 21.2144\n",
      "Epoch 6452/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 98.3104 - val_loss: 21.2430\n",
      "Epoch 6453/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 87.7809 - val_loss: 21.1939\n",
      "Epoch 6454/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 101.8214 - val_loss: 21.2508\n",
      "Epoch 6455/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 92.7431 - val_loss: 21.2612\n",
      "Epoch 6456/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 97.6229 - val_loss: 21.1911\n",
      "Epoch 6457/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 100.1494 - val_loss: 21.1461\n",
      "Epoch 6458/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 98.7928 - val_loss: 21.1327\n",
      "Epoch 6459/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 107.8698 - val_loss: 21.1202\n",
      "Epoch 6460/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 126.4072 - val_loss: 21.1147\n",
      "Epoch 6461/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 80.4906 - val_loss: 21.1094\n",
      "Epoch 6462/10000\n",
      "184/184 [==============================] - 0s 581us/step - loss: 82.2280 - val_loss: 21.1029\n",
      "Epoch 6463/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 103.4743 - val_loss: 21.0953\n",
      "Epoch 6464/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 62.0051 - val_loss: 21.0856\n",
      "Epoch 6465/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 104.6943 - val_loss: 21.0696\n",
      "Epoch 6466/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 94.6924 - val_loss: 21.0532\n",
      "Epoch 6467/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 86.9211 - val_loss: 21.0362\n",
      "Epoch 6468/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 110.4425 - val_loss: 21.0189\n",
      "Epoch 6469/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 100.8478 - val_loss: 21.0023\n",
      "Epoch 6470/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 88.8426 - val_loss: 20.9848\n",
      "Epoch 6471/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 71.9013 - val_loss: 20.9734\n",
      "Epoch 6472/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 104.7788 - val_loss: 20.9641\n",
      "Epoch 6473/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 92.1821 - val_loss: 20.9548\n",
      "Epoch 6474/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 105.8723 - val_loss: 20.9397\n",
      "Epoch 6475/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 100.8931 - val_loss: 20.9267\n",
      "Epoch 6476/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 101.6346 - val_loss: 20.9124\n",
      "Epoch 6477/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 108.5553 - val_loss: 20.8994\n",
      "Epoch 6478/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 101.7288 - val_loss: 20.8881\n",
      "Epoch 6479/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 91.3373 - val_loss: 20.8768\n",
      "Epoch 6480/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 89.7272 - val_loss: 20.8655\n",
      "Epoch 6481/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 110.1678 - val_loss: 20.8542\n",
      "Epoch 6482/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 457us/step - loss: 78.1032 - val_loss: 20.8454\n",
      "Epoch 6483/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 106.5930 - val_loss: 20.8361\n",
      "Epoch 6484/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 86.7269 - val_loss: 20.8238\n",
      "Epoch 6485/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 91.1311 - val_loss: 20.8100\n",
      "Epoch 6486/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 93.1640 - val_loss: 20.7966\n",
      "Epoch 6487/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 91.6504 - val_loss: 20.7862\n",
      "Epoch 6488/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 110.5067 - val_loss: 20.7766\n",
      "Epoch 6489/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 90.0767 - val_loss: 20.7659\n",
      "Epoch 6490/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 94.2530 - val_loss: 20.7548\n",
      "Epoch 6491/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 88.5461 - val_loss: 20.7446\n",
      "Epoch 6492/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 101.4119 - val_loss: 20.7354\n",
      "Epoch 6493/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 92.4719 - val_loss: 20.7264\n",
      "Epoch 6494/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 98.4400 - val_loss: 20.7211\n",
      "Epoch 6495/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 91.0997 - val_loss: 20.7173\n",
      "Epoch 6496/10000\n",
      "184/184 [==============================] - 0s 848us/step - loss: 111.0462 - val_loss: 20.7119\n",
      "Epoch 6497/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 100.8404 - val_loss: 20.7055\n",
      "Epoch 6498/10000\n",
      "184/184 [==============================] - 0s 837us/step - loss: 89.3717 - val_loss: 20.6953\n",
      "Epoch 6499/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 112.4340 - val_loss: 20.6844\n",
      "Epoch 6500/10000\n",
      "184/184 [==============================] - 0s 859us/step - loss: 103.4741 - val_loss: 20.6701\n",
      "\n",
      "Epoch 06500: loss did not improve from 92.61394\n",
      "Epoch 6501/10000\n",
      "184/184 [==============================] - 0s 864us/step - loss: 98.6094 - val_loss: 20.6588\n",
      "Epoch 6502/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 88.9128 - val_loss: 20.6471\n",
      "Epoch 6503/10000\n",
      "184/184 [==============================] - 0s 867us/step - loss: 133.2514 - val_loss: 20.6354\n",
      "Epoch 6504/10000\n",
      "184/184 [==============================] - 0s 864us/step - loss: 100.6326 - val_loss: 20.6209\n",
      "Epoch 6505/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 97.0899 - val_loss: 20.6081\n",
      "Epoch 6506/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 97.1979 - val_loss: 20.5967\n",
      "Epoch 6507/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 86.2312 - val_loss: 20.5935\n",
      "Epoch 6508/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 103.2161 - val_loss: 20.5741\n",
      "Epoch 6509/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 123.0686 - val_loss: 20.5385\n",
      "Epoch 6510/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 85.2233 - val_loss: 20.5246\n",
      "Epoch 6511/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 128.7821 - val_loss: 20.5096\n",
      "Epoch 6512/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 85.9733 - val_loss: 20.4983\n",
      "Epoch 6513/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 99.4887 - val_loss: 20.4865\n",
      "Epoch 6514/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 96.8491 - val_loss: 20.4768\n",
      "Epoch 6515/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 92.6160 - val_loss: 20.4655\n",
      "Epoch 6516/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 114.0599 - val_loss: 20.4492\n",
      "Epoch 6517/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 90.9584 - val_loss: 20.4362\n",
      "Epoch 6518/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 166.5096 - val_loss: 20.4245\n",
      "Epoch 6519/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 99.9223 - val_loss: 20.4095\n",
      "Epoch 6520/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 119.4829 - val_loss: 20.3985\n",
      "Epoch 6521/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 96.9888 - val_loss: 20.3929\n",
      "Epoch 6522/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 103.6708 - val_loss: 20.3849\n",
      "Epoch 6523/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 81.5090 - val_loss: 20.3778\n",
      "Epoch 6524/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 119.1571 - val_loss: 20.3710\n",
      "Epoch 6525/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 111.3624 - val_loss: 20.3638\n",
      "Epoch 6526/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 101.1662 - val_loss: 20.3544\n",
      "Epoch 6527/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 92.4567 - val_loss: 20.3445\n",
      "Epoch 6528/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 95.7031 - val_loss: 20.3338\n",
      "Epoch 6529/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 70.6227 - val_loss: 20.3223\n",
      "Epoch 6530/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 93.9902 - val_loss: 20.3119\n",
      "Epoch 6531/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 95.1642 - val_loss: 20.3020\n",
      "Epoch 6532/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 82.3411 - val_loss: 20.2927\n",
      "Epoch 6533/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 86.9545 - val_loss: 20.2889\n",
      "Epoch 6534/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 96.3880 - val_loss: 20.2827\n",
      "Epoch 6535/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 91.6161 - val_loss: 20.2742\n",
      "Epoch 6536/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 138.1447 - val_loss: 20.2629\n",
      "Epoch 6537/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 82.0005 - val_loss: 20.2509\n",
      "Epoch 6538/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 102.2997 - val_loss: 20.2397\n",
      "Epoch 6539/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 98.8602 - val_loss: 20.2302\n",
      "Epoch 6540/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 101.6701 - val_loss: 20.2201\n",
      "Epoch 6541/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 109.9152 - val_loss: 20.2094\n",
      "Epoch 6542/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 95.4087 - val_loss: 20.1974\n",
      "Epoch 6543/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 80.9947 - val_loss: 20.1850\n",
      "Epoch 6544/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 93.2128 - val_loss: 20.1685\n",
      "Epoch 6545/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 81.8028 - val_loss: 20.1346\n",
      "Epoch 6546/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 106.3603 - val_loss: 20.1022\n",
      "Epoch 6547/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 78.3692 - val_loss: 20.0762\n",
      "Epoch 6548/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 85.8829 - val_loss: 20.0526\n",
      "Epoch 6549/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 108.9820 - val_loss: 20.0337\n",
      "Epoch 6550/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 109.6437 - val_loss: 20.0162\n",
      "Epoch 6551/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 77.2909 - val_loss: 20.0130\n",
      "Epoch 6552/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 86.4859 - val_loss: 19.9944\n",
      "Epoch 6553/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 70.1658 - val_loss: 19.9815\n",
      "Epoch 6554/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 100.3864 - val_loss: 19.9760\n",
      "Epoch 6555/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 81.5664 - val_loss: 19.9767\n",
      "Epoch 6556/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 484us/step - loss: 94.1183 - val_loss: 19.9832\n",
      "Epoch 6557/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 88.5572 - val_loss: 19.9929\n",
      "Epoch 6558/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 72.2218 - val_loss: 19.9963\n",
      "Epoch 6559/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 131.5384 - val_loss: 19.9877\n",
      "Epoch 6560/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 96.2079 - val_loss: 19.9755\n",
      "Epoch 6561/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 123.8824 - val_loss: 19.9637\n",
      "Epoch 6562/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 111.3409 - val_loss: 19.9509\n",
      "Epoch 6563/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 97.3332 - val_loss: 19.9338\n",
      "Epoch 6564/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 94.1939 - val_loss: 19.9022\n",
      "Epoch 6565/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 77.5265 - val_loss: 19.8763\n",
      "Epoch 6566/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 95.0663 - val_loss: 19.8530\n",
      "Epoch 6567/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 94.9052 - val_loss: 19.8321\n",
      "Epoch 6568/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 87.5231 - val_loss: 19.8125\n",
      "Epoch 6569/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 128.3615 - val_loss: 19.7949\n",
      "Epoch 6570/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 73.8315 - val_loss: 19.7798\n",
      "Epoch 6571/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 87.2015 - val_loss: 19.7664\n",
      "Epoch 6572/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 76.4426 - val_loss: 19.7534\n",
      "Epoch 6573/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 79.6449 - val_loss: 19.7397\n",
      "Epoch 6574/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 88.0499 - val_loss: 19.7280\n",
      "Epoch 6575/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 130.0289 - val_loss: 19.7144\n",
      "Epoch 6576/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 73.3737 - val_loss: 19.7002\n",
      "Epoch 6577/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 99.2523 - val_loss: 19.6843\n",
      "Epoch 6578/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 88.8320 - val_loss: 19.6681\n",
      "Epoch 6579/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 99.2856 - val_loss: 19.6523\n",
      "Epoch 6580/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 94.1370 - val_loss: 19.6141\n",
      "Epoch 6581/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 87.8962 - val_loss: 19.5894\n",
      "Epoch 6582/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 87.5613 - val_loss: 19.5754\n",
      "Epoch 6583/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 104.5039 - val_loss: 19.5640\n",
      "Epoch 6584/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 92.4711 - val_loss: 19.5517\n",
      "Epoch 6585/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 83.2806 - val_loss: 19.5420\n",
      "Epoch 6586/10000\n",
      "184/184 [==============================] - 0s 804us/step - loss: 100.0634 - val_loss: 19.6460\n",
      "Epoch 6587/10000\n",
      "184/184 [==============================] - 0s 810us/step - loss: 78.9796 - val_loss: 19.7779\n",
      "Epoch 6588/10000\n",
      "184/184 [==============================] - 0s 804us/step - loss: 103.3722 - val_loss: 19.6974\n",
      "Epoch 6589/10000\n",
      "184/184 [==============================] - 0s 821us/step - loss: 88.0535 - val_loss: 19.7229\n",
      "Epoch 6590/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 75.4624 - val_loss: 19.8237\n",
      "Epoch 6591/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 79.0832 - val_loss: 19.9451\n",
      "Epoch 6592/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 80.1756 - val_loss: 19.9616\n",
      "Epoch 6593/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 98.7132 - val_loss: 19.9893\n",
      "Epoch 6594/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 94.1992 - val_loss: 19.9491\n",
      "Epoch 6595/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 110.2252 - val_loss: 19.9545\n",
      "Epoch 6596/10000\n",
      "184/184 [==============================] - 0s 459us/step - loss: 100.1771 - val_loss: 19.9502\n",
      "Epoch 6597/10000\n",
      "184/184 [==============================] - 0s 454us/step - loss: 116.0248 - val_loss: 19.9739\n",
      "Epoch 6598/10000\n",
      "184/184 [==============================] - 0s 465us/step - loss: 101.8965 - val_loss: 19.9877\n",
      "Epoch 6599/10000\n",
      "184/184 [==============================] - 0s 443us/step - loss: 107.2577 - val_loss: 19.9951\n",
      "Epoch 6600/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 120.8594 - val_loss: 20.0109\n",
      "\n",
      "Epoch 06600: loss did not improve from 92.61394\n",
      "Epoch 6601/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 82.5768 - val_loss: 20.0241\n",
      "Epoch 6602/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 103.1356 - val_loss: 20.0259\n",
      "Epoch 6603/10000\n",
      "184/184 [==============================] - 0s 525us/step - loss: 100.1609 - val_loss: 20.0194\n",
      "Epoch 6604/10000\n",
      "184/184 [==============================] - 0s 535us/step - loss: 132.7469 - val_loss: 20.0145\n",
      "Epoch 6605/10000\n",
      "184/184 [==============================] - 0s 497us/step - loss: 99.6011 - val_loss: 19.9866\n",
      "Epoch 6606/10000\n",
      "184/184 [==============================] - 0s 535us/step - loss: 85.4261 - val_loss: 19.9437\n",
      "Epoch 6607/10000\n",
      "184/184 [==============================] - 0s 492us/step - loss: 79.5858 - val_loss: 19.9516\n",
      "Epoch 6608/10000\n",
      "184/184 [==============================] - 0s 568us/step - loss: 65.3564 - val_loss: 20.0547\n",
      "Epoch 6609/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 84.8966 - val_loss: 19.9994\n",
      "Epoch 6610/10000\n",
      "184/184 [==============================] - 0s 492us/step - loss: 111.7772 - val_loss: 19.9176\n",
      "Epoch 6611/10000\n",
      "184/184 [==============================] - 0s 481us/step - loss: 90.3155 - val_loss: 19.9020\n",
      "Epoch 6612/10000\n",
      "184/184 [==============================] - 0s 546us/step - loss: 103.8070 - val_loss: 19.8798\n",
      "Epoch 6613/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 108.0660 - val_loss: 19.8664\n",
      "Epoch 6614/10000\n",
      "184/184 [==============================] - 0s 584us/step - loss: 76.9333 - val_loss: 19.8405\n",
      "Epoch 6615/10000\n",
      "184/184 [==============================] - 0s 465us/step - loss: 100.2728 - val_loss: 19.8099\n",
      "Epoch 6616/10000\n",
      "184/184 [==============================] - 0s 481us/step - loss: 117.8689 - val_loss: 19.7811\n",
      "Epoch 6617/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 110.1941 - val_loss: 19.7606\n",
      "Epoch 6618/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 84.0443 - val_loss: 19.7423\n",
      "Epoch 6619/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 114.2032 - val_loss: 19.7256\n",
      "Epoch 6620/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 93.8997 - val_loss: 19.7084\n",
      "Epoch 6621/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 77.2988 - val_loss: 19.6960\n",
      "Epoch 6622/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 84.9707 - val_loss: 19.6862\n",
      "Epoch 6623/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 89.3624 - val_loss: 19.6756\n",
      "Epoch 6624/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 96.9353 - val_loss: 19.6633\n",
      "Epoch 6625/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 101.9061 - val_loss: 19.6480\n",
      "Epoch 6626/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 83.0022 - val_loss: 19.6363\n",
      "Epoch 6627/10000\n",
      "184/184 [==============================] - 0s 546us/step - loss: 79.6557 - val_loss: 19.6268\n",
      "Epoch 6628/10000\n",
      "184/184 [==============================] - 0s 552us/step - loss: 101.9744 - val_loss: 19.6355\n",
      "Epoch 6629/10000\n",
      "184/184 [==============================] - 0s 617us/step - loss: 119.2634 - val_loss: 19.6558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6630/10000\n",
      "184/184 [==============================] - 0s 606us/step - loss: 89.0455 - val_loss: 19.7478\n",
      "Epoch 6631/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 87.0982 - val_loss: 19.6340\n",
      "Epoch 6632/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 85.7515 - val_loss: 19.6644\n",
      "Epoch 6633/10000\n",
      "184/184 [==============================] - 0s 465us/step - loss: 82.6044 - val_loss: 19.6489\n",
      "Epoch 6634/10000\n",
      "184/184 [==============================] - 0s 486us/step - loss: 94.5756 - val_loss: 19.6392\n",
      "Epoch 6635/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 82.9374 - val_loss: 19.6429\n",
      "Epoch 6636/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 93.2785 - val_loss: 19.6445\n",
      "Epoch 6637/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 84.3720 - val_loss: 19.6484\n",
      "Epoch 6638/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 111.2174 - val_loss: 19.6490\n",
      "Epoch 6639/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 99.9754 - val_loss: 19.6477\n",
      "Epoch 6640/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 85.4097 - val_loss: 19.6448\n",
      "Epoch 6641/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 99.0468 - val_loss: 19.6437\n",
      "Epoch 6642/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 83.3070 - val_loss: 19.6356\n",
      "Epoch 6643/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 102.5793 - val_loss: 19.6267\n",
      "Epoch 6644/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 83.5486 - val_loss: 19.6212\n",
      "Epoch 6645/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 89.3740 - val_loss: 19.6165\n",
      "Epoch 6646/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 84.1966 - val_loss: 19.6077\n",
      "Epoch 6647/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 113.7437 - val_loss: 19.5918\n",
      "Epoch 6648/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 100.7114 - val_loss: 19.5651\n",
      "Epoch 6649/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 96.3120 - val_loss: 19.5446\n",
      "Epoch 6650/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 102.3316 - val_loss: 19.5241\n",
      "Epoch 6651/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 91.8287 - val_loss: 19.5037\n",
      "Epoch 6652/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 97.4772 - val_loss: 19.4896\n",
      "Epoch 6653/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 78.5515 - val_loss: 19.4746\n",
      "Epoch 6654/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 108.0907 - val_loss: 19.4599\n",
      "Epoch 6655/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 81.6823 - val_loss: 19.4530\n",
      "Epoch 6656/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 96.7950 - val_loss: 19.4480\n",
      "Epoch 6657/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 96.3961 - val_loss: 19.4405\n",
      "Epoch 6658/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 79.6200 - val_loss: 19.4250\n",
      "Epoch 6659/10000\n",
      "184/184 [==============================] - 0s 793us/step - loss: 88.6797 - val_loss: 19.4118\n",
      "Epoch 6660/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 79.4129 - val_loss: 19.3892\n",
      "Epoch 6661/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 99.3224 - val_loss: 19.3597\n",
      "Epoch 6662/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 83.1232 - val_loss: 19.3358\n",
      "Epoch 6663/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 83.4699 - val_loss: 19.3124\n",
      "Epoch 6664/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 82.7897 - val_loss: 19.2932\n",
      "Epoch 6665/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 90.8434 - val_loss: 19.2890\n",
      "Epoch 6666/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 84.4755 - val_loss: 19.2794\n",
      "Epoch 6667/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 83.8395 - val_loss: 19.2627\n",
      "Epoch 6668/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 92.5539 - val_loss: 19.2419\n",
      "Epoch 6669/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 96.8799 - val_loss: 19.2234\n",
      "Epoch 6670/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 92.6017 - val_loss: 19.2084\n",
      "Epoch 6671/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 63.5009 - val_loss: 19.1868\n",
      "Epoch 6672/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 128.1367 - val_loss: 19.1580\n",
      "Epoch 6673/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 97.2491 - val_loss: 19.1397\n",
      "Epoch 6674/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 86.0717 - val_loss: 19.1333\n",
      "Epoch 6675/10000\n",
      "184/184 [==============================] - 0s 528us/step - loss: 83.1491 - val_loss: 19.1247\n",
      "Epoch 6676/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 100.1800 - val_loss: 19.1123\n",
      "Epoch 6677/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 105.2238 - val_loss: 19.0985\n",
      "Epoch 6678/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 82.2301 - val_loss: 19.0837\n",
      "Epoch 6679/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 98.8049 - val_loss: 19.0682\n",
      "Epoch 6680/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 78.5764 - val_loss: 19.0521\n",
      "Epoch 6681/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 88.3045 - val_loss: 19.0343\n",
      "Epoch 6682/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 99.3082 - val_loss: 19.0188\n",
      "Epoch 6683/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 76.3413 - val_loss: 19.0052\n",
      "Epoch 6684/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 106.4308 - val_loss: 18.9881\n",
      "Epoch 6685/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 79.0330 - val_loss: 18.9695\n",
      "Epoch 6686/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 103.5274 - val_loss: 18.9580\n",
      "Epoch 6687/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 86.7144 - val_loss: 18.9448\n",
      "Epoch 6688/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 116.1968 - val_loss: 18.9369\n",
      "Epoch 6689/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 101.5768 - val_loss: 18.9291\n",
      "Epoch 6690/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 100.3479 - val_loss: 18.9114\n",
      "Epoch 6691/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 84.6493 - val_loss: 18.8958\n",
      "Epoch 6692/10000\n",
      "184/184 [==============================] - 0s 821us/step - loss: 108.6316 - val_loss: 18.8803\n",
      "Epoch 6693/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 93.2037 - val_loss: 18.8698\n",
      "Epoch 6694/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 114.6171 - val_loss: 18.8629\n",
      "Epoch 6695/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 88.7968 - val_loss: 18.8603\n",
      "Epoch 6696/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 84.9271 - val_loss: 18.8620\n",
      "Epoch 6697/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 74.8093 - val_loss: 18.8600\n",
      "Epoch 6698/10000\n",
      "184/184 [==============================] - 0s 544us/step - loss: 89.7084 - val_loss: 18.8557\n",
      "Epoch 6699/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 81.3417 - val_loss: 18.6622\n",
      "Epoch 6700/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 98.2617 - val_loss: 18.1884\n",
      "\n",
      "Epoch 06700: loss did not improve from 92.61394\n",
      "Epoch 6701/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 86.8585 - val_loss: 17.2782\n",
      "Epoch 6702/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 87.8283 - val_loss: 17.0749\n",
      "Epoch 6703/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 100.8949 - val_loss: 17.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6704/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 78.4374 - val_loss: 17.0729\n",
      "Epoch 6705/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 96.5005 - val_loss: 18.0995\n",
      "Epoch 6706/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 86.7980 - val_loss: 18.4958\n",
      "Epoch 6707/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 85.4649 - val_loss: 18.7522\n",
      "Epoch 6708/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 88.8019 - val_loss: 18.7926\n",
      "Epoch 6709/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 93.0039 - val_loss: 18.7242\n",
      "Epoch 6710/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 83.8223 - val_loss: 18.6764\n",
      "Epoch 6711/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 95.0776 - val_loss: 18.6332\n",
      "Epoch 6712/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 95.8399 - val_loss: 18.6039\n",
      "Epoch 6713/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 75.4692 - val_loss: 18.5785\n",
      "Epoch 6714/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 91.7106 - val_loss: 18.5616\n",
      "Epoch 6715/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 101.6290 - val_loss: 18.5491\n",
      "Epoch 6716/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 81.6225 - val_loss: 18.5366\n",
      "Epoch 6717/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 83.8114 - val_loss: 18.5251\n",
      "Epoch 6718/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 108.3050 - val_loss: 18.5122\n",
      "Epoch 6719/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 88.6092 - val_loss: 18.4991\n",
      "Epoch 6720/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 94.5087 - val_loss: 18.4896\n",
      "Epoch 6721/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 88.9547 - val_loss: 18.4793\n",
      "Epoch 6722/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 81.3059 - val_loss: 18.4659\n",
      "Epoch 6723/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 88.8222 - val_loss: 18.4460\n",
      "Epoch 6724/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 78.1852 - val_loss: 18.4239\n",
      "Epoch 6725/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 84.8569 - val_loss: 18.4042\n",
      "Epoch 6726/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 58.7958 - val_loss: 18.3851\n",
      "Epoch 6727/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 102.2123 - val_loss: 18.3724\n",
      "Epoch 6728/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 93.7211 - val_loss: 18.3642\n",
      "Epoch 6729/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 91.6746 - val_loss: 18.3567\n",
      "Epoch 6730/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 84.0402 - val_loss: 18.3477\n",
      "Epoch 6731/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 108.4677 - val_loss: 18.3357\n",
      "Epoch 6732/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 90.4991 - val_loss: 18.3249\n",
      "Epoch 6733/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 86.3637 - val_loss: 18.3159\n",
      "Epoch 6734/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 88.5613 - val_loss: 18.3066\n",
      "Epoch 6735/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 104.8347 - val_loss: 18.2987\n",
      "Epoch 6736/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 80.9141 - val_loss: 18.2930\n",
      "Epoch 6737/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 107.5437 - val_loss: 18.2866\n",
      "Epoch 6738/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 95.3405 - val_loss: 18.2822\n",
      "Epoch 6739/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 80.0003 - val_loss: 18.2789\n",
      "Epoch 6740/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 63.9639 - val_loss: 18.2486\n",
      "Epoch 6741/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 131.1036 - val_loss: 18.1660\n",
      "Epoch 6742/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 92.0741 - val_loss: 18.0852\n",
      "Epoch 6743/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 96.2964 - val_loss: 18.0408\n",
      "Epoch 6744/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 79.9269 - val_loss: 18.0582\n",
      "Epoch 6745/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 81.5755 - val_loss: 16.8941\n",
      "Epoch 6746/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 82.3732 - val_loss: 17.1207\n",
      "Epoch 6747/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 83.5624 - val_loss: 18.2182\n",
      "Epoch 6748/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 107.3412 - val_loss: 18.5898\n",
      "Epoch 6749/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 88.7068 - val_loss: 18.7758\n",
      "Epoch 6750/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 93.6236 - val_loss: 19.3922\n",
      "Epoch 6751/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 115.4684 - val_loss: 19.5301\n",
      "Epoch 6752/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 73.2928 - val_loss: 19.6286\n",
      "Epoch 6753/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 80.0698 - val_loss: 19.7313\n",
      "Epoch 6754/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 89.1267 - val_loss: 19.9087\n",
      "Epoch 6755/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 76.3510 - val_loss: 20.0875\n",
      "Epoch 6756/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 83.6365 - val_loss: 20.2981\n",
      "Epoch 6757/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 85.1894 - val_loss: 20.4154\n",
      "Epoch 6758/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 85.9144 - val_loss: 20.4818\n",
      "Epoch 6759/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 105.8088 - val_loss: 20.5137\n",
      "Epoch 6760/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 82.3223 - val_loss: 20.5402\n",
      "Epoch 6761/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 84.0431 - val_loss: 20.5569\n",
      "Epoch 6762/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 84.1957 - val_loss: 20.5641\n",
      "Epoch 6763/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 100.9202 - val_loss: 20.5659\n",
      "Epoch 6764/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 72.2966 - val_loss: 20.5497\n",
      "Epoch 6765/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 80.9775 - val_loss: 20.5156\n",
      "Epoch 6766/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 96.4970 - val_loss: 20.3645\n",
      "Epoch 6767/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 78.5202 - val_loss: 20.2458\n",
      "Epoch 6768/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 78.5118 - val_loss: 20.1614\n",
      "Epoch 6769/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 84.1479 - val_loss: 20.1010\n",
      "Epoch 6770/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 113.4085 - val_loss: 20.0503\n",
      "Epoch 6771/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 97.7470 - val_loss: 20.0138\n",
      "Epoch 6772/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 103.7119 - val_loss: 19.9943\n",
      "Epoch 6773/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 98.6622 - val_loss: 19.9803\n",
      "Epoch 6774/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 78.7299 - val_loss: 19.9679\n",
      "Epoch 6775/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 119.5997 - val_loss: 19.9579\n",
      "Epoch 6776/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 83.1830 - val_loss: 19.9439\n",
      "Epoch 6777/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 88.3876 - val_loss: 19.9249\n",
      "Epoch 6778/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 576us/step - loss: 93.1579 - val_loss: 19.9060\n",
      "Epoch 6779/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 77.7998 - val_loss: 19.8901\n",
      "Epoch 6780/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 87.8379 - val_loss: 19.8729\n",
      "Epoch 6781/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 84.7344 - val_loss: 19.8581\n",
      "Epoch 6782/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 86.4343 - val_loss: 19.8432\n",
      "Epoch 6783/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 81.2098 - val_loss: 19.8302\n",
      "Epoch 6784/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 80.9532 - val_loss: 19.8207\n",
      "Epoch 6785/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 97.5568 - val_loss: 19.8114\n",
      "Epoch 6786/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 93.7939 - val_loss: 19.8007\n",
      "Epoch 6787/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 92.4031 - val_loss: 19.7890\n",
      "Epoch 6788/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 75.5560 - val_loss: 19.7789\n",
      "Epoch 6789/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 78.8972 - val_loss: 19.7663\n",
      "Epoch 6790/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 102.7036 - val_loss: 19.7541\n",
      "Epoch 6791/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 71.5106 - val_loss: 19.7440\n",
      "Epoch 6792/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 89.3918 - val_loss: 19.7349\n",
      "Epoch 6793/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 72.1912 - val_loss: 19.7278\n",
      "Epoch 6794/10000\n",
      "184/184 [==============================] - 0s 546us/step - loss: 86.5035 - val_loss: 19.7201\n",
      "Epoch 6795/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 97.4643 - val_loss: 19.7121\n",
      "Epoch 6796/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 79.1764 - val_loss: 19.7177\n",
      "Epoch 6797/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 99.0010 - val_loss: 19.7213\n",
      "Epoch 6798/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 84.8152 - val_loss: 19.7232\n",
      "Epoch 6799/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 90.4432 - val_loss: 19.7242\n",
      "Epoch 6800/10000\n",
      "184/184 [==============================] - 0s 886us/step - loss: 87.4957 - val_loss: 19.7235\n",
      "\n",
      "Epoch 06800: loss improved from 92.61394 to 87.49568, saving model to C6007C.hdf5\n",
      "Epoch 6801/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 104.0563 - val_loss: 19.7201\n",
      "Epoch 6802/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 76.7312 - val_loss: 19.7142\n",
      "Epoch 6803/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 99.3260 - val_loss: 19.7083\n",
      "Epoch 6804/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 82.0980 - val_loss: 19.6998\n",
      "Epoch 6805/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 77.5513 - val_loss: 19.7014\n",
      "Epoch 6806/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 101.2402 - val_loss: 19.7075\n",
      "Epoch 6807/10000\n",
      "184/184 [==============================] - 0s 429us/step - loss: 93.3789 - val_loss: 19.7150\n",
      "Epoch 6808/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 76.6999 - val_loss: 19.7279\n",
      "Epoch 6809/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 81.8436 - val_loss: 19.7627\n",
      "Epoch 6810/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 101.9112 - val_loss: 19.7961\n",
      "Epoch 6811/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 88.6013 - val_loss: 19.8266\n",
      "Epoch 6812/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 87.4543 - val_loss: 19.8498\n",
      "Epoch 6813/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 85.3106 - val_loss: 19.8644\n",
      "Epoch 6814/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 95.7879 - val_loss: 19.8757\n",
      "Epoch 6815/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 90.8765 - val_loss: 19.8874\n",
      "Epoch 6816/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 90.4343 - val_loss: 19.8776\n",
      "Epoch 6817/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 86.0605 - val_loss: 19.8679\n",
      "Epoch 6818/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 69.5515 - val_loss: 19.8608\n",
      "Epoch 6819/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 93.0121 - val_loss: 19.8546\n",
      "Epoch 6820/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 94.1597 - val_loss: 19.8472\n",
      "Epoch 6821/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 90.8295 - val_loss: 19.8374\n",
      "Epoch 6822/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 73.7437 - val_loss: 19.8306\n",
      "Epoch 6823/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 86.2013 - val_loss: 19.8201\n",
      "Epoch 6824/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 93.6302 - val_loss: 19.8080\n",
      "Epoch 6825/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 92.9239 - val_loss: 19.7951\n",
      "Epoch 6826/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 71.6846 - val_loss: 19.7800\n",
      "Epoch 6827/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 66.2518 - val_loss: 19.7656\n",
      "Epoch 6828/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 104.1338 - val_loss: 19.7521\n",
      "Epoch 6829/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 94.60 - 0s 495us/step - loss: 90.8185 - val_loss: 19.7417\n",
      "Epoch 6830/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 73.0142 - val_loss: 19.7302\n",
      "Epoch 6831/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 84.0699 - val_loss: 19.7180\n",
      "Epoch 6832/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 76.2311 - val_loss: 19.7096\n",
      "Epoch 6833/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 94.6157 - val_loss: 19.7062\n",
      "Epoch 6834/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 94.2098 - val_loss: 19.7031\n",
      "Epoch 6835/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 83.9482 - val_loss: 19.6984\n",
      "Epoch 6836/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 84.7122 - val_loss: 19.6947\n",
      "Epoch 6837/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 87.0465 - val_loss: 19.6902\n",
      "Epoch 6838/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 79.9250 - val_loss: 19.6807\n",
      "Epoch 6839/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 72.7720 - val_loss: 19.6684\n",
      "Epoch 6840/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 84.7109 - val_loss: 19.6599\n",
      "Epoch 6841/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 76.17 - 0s 462us/step - loss: 83.6932 - val_loss: 19.6232\n",
      "Epoch 6842/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 89.1588 - val_loss: 19.5903\n",
      "Epoch 6843/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 86.2010 - val_loss: 19.5635\n",
      "Epoch 6844/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 70.2206 - val_loss: 19.5388\n",
      "Epoch 6845/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 92.5941 - val_loss: 19.5173\n",
      "Epoch 6846/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 101.4153 - val_loss: 19.5002\n",
      "Epoch 6847/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 94.7312 - val_loss: 19.4839\n",
      "Epoch 6848/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 80.4503 - val_loss: 19.4732\n",
      "Epoch 6849/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 85.1933 - val_loss: 19.4655\n",
      "Epoch 6850/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 89.5965 - val_loss: 19.4599\n",
      "Epoch 6851/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 467us/step - loss: 83.9398 - val_loss: 19.4530\n",
      "Epoch 6852/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 75.1066 - val_loss: 19.4421\n",
      "Epoch 6853/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 70.0056 - val_loss: 19.4305\n",
      "Epoch 6854/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 75.4260 - val_loss: 19.4191\n",
      "Epoch 6855/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 81.5256 - val_loss: 19.4083\n",
      "Epoch 6856/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 95.4078 - val_loss: 19.3965\n",
      "Epoch 6857/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 79.9294 - val_loss: 19.3842\n",
      "Epoch 6858/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 75.1838 - val_loss: 19.3709\n",
      "Epoch 6859/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 91.6935 - val_loss: 19.3691\n",
      "Epoch 6860/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 81.0984 - val_loss: 19.3699\n",
      "Epoch 6861/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 107.2265 - val_loss: 19.3630\n",
      "Epoch 6862/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 104.3415 - val_loss: 19.3494\n",
      "Epoch 6863/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 100.0402 - val_loss: 19.3331\n",
      "Epoch 6864/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 107.2995 - val_loss: 19.3195\n",
      "Epoch 6865/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 109.4799 - val_loss: 19.3065\n",
      "Epoch 6866/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 80.2032 - val_loss: 19.2986\n",
      "Epoch 6867/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 78.7396 - val_loss: 19.2739\n",
      "Epoch 6868/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 90.4322 - val_loss: 19.2511\n",
      "Epoch 6869/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 69.5156 - val_loss: 19.2666\n",
      "Epoch 6870/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 123.8487 - val_loss: 19.2784\n",
      "Epoch 6871/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 71.8252 - val_loss: 19.2798\n",
      "Epoch 6872/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 108.7508 - val_loss: 19.2814\n",
      "Epoch 6873/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 93.7379 - val_loss: 19.2806\n",
      "Epoch 6874/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 81.3655 - val_loss: 19.2801\n",
      "Epoch 6875/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 82.1532 - val_loss: 19.2741\n",
      "Epoch 6876/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 96.8622 - val_loss: 19.2768\n",
      "Epoch 6877/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 81.4839 - val_loss: 19.3063\n",
      "Epoch 6878/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 99.7508 - val_loss: 19.3254\n",
      "Epoch 6879/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 123.4598 - val_loss: 19.3524\n",
      "Epoch 6880/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 86.4903 - val_loss: 19.3802\n",
      "Epoch 6881/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 94.0303 - val_loss: 19.4087\n",
      "Epoch 6882/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 84.3041 - val_loss: 19.4433\n",
      "Epoch 6883/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 77.1529 - val_loss: 19.4603\n",
      "Epoch 6884/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 104.2685 - val_loss: 19.4828\n",
      "Epoch 6885/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 92.2249 - val_loss: 19.5103\n",
      "Epoch 6886/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 98.7647 - val_loss: 19.5332\n",
      "Epoch 6887/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 74.3912 - val_loss: 19.5526\n",
      "Epoch 6888/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 124.1054 - val_loss: 19.5507\n",
      "Epoch 6889/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 71.4315 - val_loss: 19.5630\n",
      "Epoch 6890/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 91.5277 - val_loss: 19.5660\n",
      "Epoch 6891/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 89.4788 - val_loss: 19.5720\n",
      "Epoch 6892/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 92.6470 - val_loss: 19.5728\n",
      "Epoch 6893/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 83.9700 - val_loss: 19.5500\n",
      "Epoch 6894/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 74.7587 - val_loss: 19.5572\n",
      "Epoch 6895/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 87.4589 - val_loss: 19.5506\n",
      "Epoch 6896/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 90.3615 - val_loss: 19.5564\n",
      "Epoch 6897/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 82.7650 - val_loss: 19.5774\n",
      "Epoch 6898/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 96.8370 - val_loss: 19.6007\n",
      "Epoch 6899/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 89.1490 - val_loss: 19.6142\n",
      "Epoch 6900/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 98.8612 - val_loss: 19.6312\n",
      "\n",
      "Epoch 06900: loss did not improve from 87.49568\n",
      "Epoch 6901/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 112.3285 - val_loss: 19.6822\n",
      "Epoch 6902/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 89.6479 - val_loss: 19.7112\n",
      "Epoch 6903/10000\n",
      "184/184 [==============================] - 0s 775us/step - loss: 74.2677 - val_loss: 19.7288\n",
      "Epoch 6904/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 75.2332 - val_loss: 19.7281\n",
      "Epoch 6905/10000\n",
      "184/184 [==============================] - 0s 799us/step - loss: 85.9448 - val_loss: 19.6691\n",
      "Epoch 6906/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 95.4136 - val_loss: 19.6248\n",
      "Epoch 6907/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 91.7068 - val_loss: 19.5934\n",
      "Epoch 6908/10000\n",
      "184/184 [==============================] - 0s 563us/step - loss: 80.3984 - val_loss: 19.5679\n",
      "Epoch 6909/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 92.6359 - val_loss: 19.5452\n",
      "Epoch 6910/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 101.0724 - val_loss: 19.5253\n",
      "Epoch 6911/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 71.9287 - val_loss: 19.5076\n",
      "Epoch 6912/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 87.4099 - val_loss: 19.4900\n",
      "Epoch 6913/10000\n",
      "184/184 [==============================] - 0s 429us/step - loss: 92.7319 - val_loss: 19.4704\n",
      "Epoch 6914/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 90.1426 - val_loss: 19.4516\n",
      "Epoch 6915/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 75.1065 - val_loss: 19.4342\n",
      "Epoch 6916/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 84.8810 - val_loss: 19.4168\n",
      "Epoch 6917/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 89.9534 - val_loss: 19.4224\n",
      "Epoch 6918/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 83.3932 - val_loss: 19.4462\n",
      "Epoch 6919/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 89.0188 - val_loss: 19.4847\n",
      "Epoch 6920/10000\n",
      "184/184 [==============================] - 0s 761us/step - loss: 86.8846 - val_loss: 19.5568\n",
      "Epoch 6921/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 93.9599 - val_loss: 19.6170\n",
      "Epoch 6922/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 99.6831 - val_loss: 19.6608\n",
      "Epoch 6923/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 80.9828 - val_loss: 19.6843\n",
      "Epoch 6924/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 76.8593 - val_loss: 19.6930\n",
      "Epoch 6925/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 500us/step - loss: 93.5095 - val_loss: 19.6928\n",
      "Epoch 6926/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 72.2821 - val_loss: 19.7118\n",
      "Epoch 6927/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 90.2182 - val_loss: 19.7227\n",
      "Epoch 6928/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 78.4958 - val_loss: 19.6939\n",
      "Epoch 6929/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 94.1802 - val_loss: 19.6614\n",
      "Epoch 6930/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 75.7569 - val_loss: 19.6262\n",
      "Epoch 6931/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 89.7228 - val_loss: 19.5844\n",
      "Epoch 6932/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 87.5253 - val_loss: 19.5563\n",
      "Epoch 6933/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 92.6615 - val_loss: 19.5732\n",
      "Epoch 6934/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 74.1696 - val_loss: 19.5405\n",
      "Epoch 6935/10000\n",
      "184/184 [==============================] - 0s 704us/step - loss: 94.0416 - val_loss: 19.4770\n",
      "Epoch 6936/10000\n",
      "184/184 [==============================] - 0s 886us/step - loss: 85.8910 - val_loss: 19.4529\n",
      "Epoch 6937/10000\n",
      "184/184 [==============================] - 0s 769us/step - loss: 84.8357 - val_loss: 19.4331\n",
      "Epoch 6938/10000\n",
      "184/184 [==============================] - 0s 530us/step - loss: 72.3896 - val_loss: 19.4082\n",
      "Epoch 6939/10000\n",
      "184/184 [==============================] - 0s 492us/step - loss: 114.4128 - val_loss: 19.3991\n",
      "Epoch 6940/10000\n",
      "184/184 [==============================] - 0s 492us/step - loss: 79.0805 - val_loss: 19.3888\n",
      "Epoch 6941/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 93.2269 - val_loss: 19.2828\n",
      "Epoch 6942/10000\n",
      "184/184 [==============================] - 0s 573us/step - loss: 99.2263 - val_loss: 19.2061\n",
      "Epoch 6943/10000\n",
      "184/184 [==============================] - 0s 568us/step - loss: 67.0003 - val_loss: 19.1349\n",
      "Epoch 6944/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 90.2053 - val_loss: 19.1005\n",
      "Epoch 6945/10000\n",
      "184/184 [==============================] - 0s 476us/step - loss: 110.3651 - val_loss: 19.0969\n",
      "Epoch 6946/10000\n",
      "184/184 [==============================] - 0s 481us/step - loss: 74.0788 - val_loss: 19.0907\n",
      "Epoch 6947/10000\n",
      "184/184 [==============================] - 0s 470us/step - loss: 81.5135 - val_loss: 19.1051\n",
      "Epoch 6948/10000\n",
      "184/184 [==============================] - 0s 465us/step - loss: 90.6803 - val_loss: 19.1096\n",
      "Epoch 6949/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 103.8555 - val_loss: 19.1137\n",
      "Epoch 6950/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 93.6915 - val_loss: 19.1154\n",
      "Epoch 6951/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 88.8876 - val_loss: 19.1169\n",
      "Epoch 6952/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 81.1619 - val_loss: 19.1219\n",
      "Epoch 6953/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 82.3850 - val_loss: 19.1204\n",
      "Epoch 6954/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 81.5890 - val_loss: 19.0783\n",
      "Epoch 6955/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 78.6020 - val_loss: 19.0332\n",
      "Epoch 6956/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 82.6850 - val_loss: 18.9335\n",
      "Epoch 6957/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 104.2613 - val_loss: 19.0090\n",
      "Epoch 6958/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 87.1142 - val_loss: 18.9384\n",
      "Epoch 6959/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 88.7945 - val_loss: 18.9775\n",
      "Epoch 6960/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 65.8894 - val_loss: 19.0483\n",
      "Epoch 6961/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 75.6111 - val_loss: 19.0710\n",
      "Epoch 6962/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 69.0516 - val_loss: 19.1913\n",
      "Epoch 6963/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 82.9768 - val_loss: 19.1188\n",
      "Epoch 6964/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 87.3682 - val_loss: 19.1178\n",
      "Epoch 6965/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 76.5743 - val_loss: 19.0898\n",
      "Epoch 6966/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 76.1858 - val_loss: 19.0525\n",
      "Epoch 6967/10000\n",
      "184/184 [==============================] - 0s 755us/step - loss: 70.5823 - val_loss: 19.0244\n",
      "Epoch 6968/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 92.9354 - val_loss: 19.0036\n",
      "Epoch 6969/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 92.1094 - val_loss: 18.9894\n",
      "Epoch 6970/10000\n",
      "184/184 [==============================] - 0s 418us/step - loss: 77.6474 - val_loss: 18.9740\n",
      "Epoch 6971/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 95.2445 - val_loss: 18.9529\n",
      "Epoch 6972/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 100.6905 - val_loss: 18.9306\n",
      "Epoch 6973/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 76.3251 - val_loss: 18.9058\n",
      "Epoch 6974/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 82.8881 - val_loss: 18.8700\n",
      "Epoch 6975/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 79.1643 - val_loss: 18.8396\n",
      "Epoch 6976/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 93.6974 - val_loss: 18.8220\n",
      "Epoch 6977/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 90.2808 - val_loss: 18.7979\n",
      "Epoch 6978/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 81.6390 - val_loss: 18.8074\n",
      "Epoch 6979/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 88.1353 - val_loss: 18.8133\n",
      "Epoch 6980/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 77.5847 - val_loss: 18.8233\n",
      "Epoch 6981/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 80.6224 - val_loss: 18.8383\n",
      "Epoch 6982/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 76.0451 - val_loss: 18.8495\n",
      "Epoch 6983/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 98.6826 - val_loss: 18.8582\n",
      "Epoch 6984/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 81.5905 - val_loss: 18.8617\n",
      "Epoch 6985/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 85.9565 - val_loss: 18.8549\n",
      "Epoch 6986/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 85.2996 - val_loss: 18.8469\n",
      "Epoch 6987/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 93.1385 - val_loss: 18.8446\n",
      "Epoch 6988/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 68.6354 - val_loss: 18.8340\n",
      "Epoch 6989/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 96.7040 - val_loss: 18.8077\n",
      "Epoch 6990/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 83.03 - 0s 478us/step - loss: 95.2545 - val_loss: 18.7574\n",
      "Epoch 6991/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 81.0644 - val_loss: 18.7160\n",
      "Epoch 6992/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 62.2819 - val_loss: 18.6803\n",
      "Epoch 6993/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 77.7293 - val_loss: 18.6443\n",
      "Epoch 6994/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 87.8499 - val_loss: 18.6303\n",
      "Epoch 6995/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 89.7615 - val_loss: 18.6186\n",
      "Epoch 6996/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 85.0388 - val_loss: 18.6061\n",
      "Epoch 6997/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 97.4100 - val_loss: 18.5276\n",
      "Epoch 6998/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 83.4931 - val_loss: 18.4174\n",
      "Epoch 6999/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 516us/step - loss: 75.2437 - val_loss: 18.3528\n",
      "Epoch 7000/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 108.6749 - val_loss: 18.3032\n",
      "\n",
      "Epoch 07000: loss did not improve from 87.49568\n",
      "Epoch 7001/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 76.1408 - val_loss: 18.2633\n",
      "Epoch 7002/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 88.4606 - val_loss: 18.2334\n",
      "Epoch 7003/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 78.6388 - val_loss: 18.2084\n",
      "Epoch 7004/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 74.1060 - val_loss: 18.1862\n",
      "Epoch 7005/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 90.5308 - val_loss: 18.1695\n",
      "Epoch 7006/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 85.9560 - val_loss: 18.1532\n",
      "Epoch 7007/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 82.6935 - val_loss: 18.1450\n",
      "Epoch 7008/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 92.4084 - val_loss: 18.1355\n",
      "Epoch 7009/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 85.3234 - val_loss: 18.0909\n",
      "Epoch 7010/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 69.8707 - val_loss: 18.0518\n",
      "Epoch 7011/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 85.3630 - val_loss: 18.0177\n",
      "Epoch 7012/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 109.7178 - val_loss: 17.9830\n",
      "Epoch 7013/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 76.6207 - val_loss: 17.9559\n",
      "Epoch 7014/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 84.4720 - val_loss: 17.9349\n",
      "Epoch 7015/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 97.5247 - val_loss: 17.8775\n",
      "Epoch 7016/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 68.4934 - val_loss: 17.8287\n",
      "Epoch 7017/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 71.0659 - val_loss: 17.7859\n",
      "Epoch 7018/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 78.9592 - val_loss: 17.7431\n",
      "Epoch 7019/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 85.3220 - val_loss: 17.7076\n",
      "Epoch 7020/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 86.8440 - val_loss: 17.6813\n",
      "Epoch 7021/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 74.4793 - val_loss: 17.6540\n",
      "Epoch 7022/10000\n",
      "184/184 [==============================] - 0s 429us/step - loss: 75.4613 - val_loss: 17.6009\n",
      "Epoch 7023/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 94.7348 - val_loss: 17.5364\n",
      "Epoch 7024/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 102.3393 - val_loss: 17.4918\n",
      "Epoch 7025/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 79.7483 - val_loss: 17.4534\n",
      "Epoch 7026/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 80.1952 - val_loss: 17.4210\n",
      "Epoch 7027/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 91.0542 - val_loss: 17.3986\n",
      "Epoch 7028/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 84.1727 - val_loss: 17.3806\n",
      "Epoch 7029/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 84.1567 - val_loss: 17.3648\n",
      "Epoch 7030/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 68.8206 - val_loss: 17.3489\n",
      "Epoch 7031/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 81.8879 - val_loss: 17.3340\n",
      "Epoch 7032/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 83.8914 - val_loss: 17.3188\n",
      "Epoch 7033/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 87.2580 - val_loss: 17.3038\n",
      "Epoch 7034/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 80.3789 - val_loss: 17.2901\n",
      "Epoch 7035/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 92.9521 - val_loss: 17.2732\n",
      "Epoch 7036/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 81.4243 - val_loss: 17.2567\n",
      "Epoch 7037/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 91.3712 - val_loss: 17.2396\n",
      "Epoch 7038/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 93.4392 - val_loss: 17.2124\n",
      "Epoch 7039/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 77.5576 - val_loss: 17.1883\n",
      "Epoch 7040/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 66.3241 - val_loss: 17.1674\n",
      "Epoch 7041/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 130.1247 - val_loss: 17.1510\n",
      "Epoch 7042/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 72.0492 - val_loss: 17.1377\n",
      "Epoch 7043/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 71.8073 - val_loss: 17.1162\n",
      "Epoch 7044/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 76.9502 - val_loss: 17.0976\n",
      "Epoch 7045/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 75.0333 - val_loss: 17.0800\n",
      "Epoch 7046/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 67.1387 - val_loss: 17.0635\n",
      "Epoch 7047/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 69.4885 - val_loss: 17.0473\n",
      "Epoch 7048/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 78.27 - 0s 473us/step - loss: 76.3326 - val_loss: 17.0326\n",
      "Epoch 7049/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 88.0309 - val_loss: 17.0193\n",
      "Epoch 7050/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 85.0997 - val_loss: 17.0038\n",
      "Epoch 7051/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 74.5883 - val_loss: 16.9912\n",
      "Epoch 7052/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 93.0296 - val_loss: 16.9785\n",
      "Epoch 7053/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 80.5751 - val_loss: 16.9665\n",
      "Epoch 7054/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 78.8325 - val_loss: 16.9558\n",
      "Epoch 7055/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 91.0340 - val_loss: 16.9462\n",
      "Epoch 7056/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 90.7258 - val_loss: 16.9369\n",
      "Epoch 7057/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 96.4909 - val_loss: 16.9240\n",
      "Epoch 7058/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 62.0065 - val_loss: 16.9121\n",
      "Epoch 7059/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 84.3891 - val_loss: 16.9031\n",
      "Epoch 7060/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 80.2096 - val_loss: 16.8973\n",
      "Epoch 7061/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 71.5713 - val_loss: 16.8916\n",
      "Epoch 7062/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 90.5928 - val_loss: 16.8933\n",
      "Epoch 7063/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 81.6956 - val_loss: 16.8841\n",
      "Epoch 7064/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 96.9644 - val_loss: 16.8778\n",
      "Epoch 7065/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 90.8200 - val_loss: 16.8704\n",
      "Epoch 7066/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 71.4058 - val_loss: 16.8600\n",
      "Epoch 7067/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 85.8367 - val_loss: 16.8521\n",
      "Epoch 7068/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 72.6239 - val_loss: 16.8463\n",
      "Epoch 7069/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 94.8451 - val_loss: 16.8404\n",
      "Epoch 7070/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 70.8645 - val_loss: 16.8355\n",
      "Epoch 7071/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 82.0088 - val_loss: 16.8307\n",
      "Epoch 7072/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 96.3788 - val_loss: 16.8271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7073/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 69.9033 - val_loss: 16.8220\n",
      "Epoch 7074/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 68.6778 - val_loss: 16.8158\n",
      "Epoch 7075/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 95.7251 - val_loss: 16.8099\n",
      "Epoch 7076/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 95.6305 - val_loss: 16.8016\n",
      "Epoch 7077/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 85.3144 - val_loss: 16.7865\n",
      "Epoch 7078/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 86.5857 - val_loss: 16.7718\n",
      "Epoch 7079/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 68.7654 - val_loss: 16.7568\n",
      "Epoch 7080/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 76.7530 - val_loss: 16.7450\n",
      "Epoch 7081/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 75.2005 - val_loss: 16.7338\n",
      "Epoch 7082/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 79.4648 - val_loss: 16.7230\n",
      "Epoch 7083/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 97.7833 - val_loss: 16.7146\n",
      "Epoch 7084/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 89.5797 - val_loss: 16.7070\n",
      "Epoch 7085/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 69.3178 - val_loss: 16.6999\n",
      "Epoch 7086/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 69.6375 - val_loss: 16.6920\n",
      "Epoch 7087/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 72.4109 - val_loss: 16.6831\n",
      "Epoch 7088/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 78.7443 - val_loss: 16.6745\n",
      "Epoch 7089/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 92.9183 - val_loss: 16.6641\n",
      "Epoch 7090/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 100.0714 - val_loss: 16.6544\n",
      "Epoch 7091/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 76.2307 - val_loss: 16.6459\n",
      "Epoch 7092/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 71.3139 - val_loss: 16.6381\n",
      "Epoch 7093/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 102.0718 - val_loss: 16.6313\n",
      "Epoch 7094/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 84.2046 - val_loss: 16.6245\n",
      "Epoch 7095/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 67.9705 - val_loss: 16.6181\n",
      "Epoch 7096/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 71.5187 - val_loss: 16.6126\n",
      "Epoch 7097/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 97.8471 - val_loss: 16.6069\n",
      "Epoch 7098/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 67.7548 - val_loss: 16.6048\n",
      "Epoch 7099/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 82.3811 - val_loss: 16.6019\n",
      "Epoch 7100/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 93.5436 - val_loss: 16.5977\n",
      "\n",
      "Epoch 07100: loss did not improve from 87.49568\n",
      "Epoch 7101/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 76.2023 - val_loss: 16.5932\n",
      "Epoch 7102/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 100.1833 - val_loss: 16.5879\n",
      "Epoch 7103/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 92.0406 - val_loss: 16.5886\n",
      "Epoch 7104/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 78.9268 - val_loss: 16.5946\n",
      "Epoch 7105/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 69.0672 - val_loss: 16.5983\n",
      "Epoch 7106/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 82.6535 - val_loss: 16.6152\n",
      "Epoch 7107/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 70.3444 - val_loss: 16.6282\n",
      "Epoch 7108/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 74.0602 - val_loss: 16.6371\n",
      "Epoch 7109/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 95.7848 - val_loss: 16.6440\n",
      "Epoch 7110/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 80.1491 - val_loss: 16.6484\n",
      "Epoch 7111/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 82.1677 - val_loss: 16.6510\n",
      "Epoch 7112/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 83.2344 - val_loss: 16.6525\n",
      "Epoch 7113/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 76.3074 - val_loss: 16.6512\n",
      "Epoch 7114/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 77.4399 - val_loss: 16.6478\n",
      "Epoch 7115/10000\n",
      "184/184 [==============================] - 0s 891us/step - loss: 81.3800 - val_loss: 16.6449\n",
      "Epoch 7116/10000\n",
      "184/184 [==============================] - 0s 821us/step - loss: 82.8874 - val_loss: 16.6395\n",
      "Epoch 7117/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 80.5280 - val_loss: 16.6345\n",
      "Epoch 7118/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 76.7247 - val_loss: 16.6368\n",
      "Epoch 7119/10000\n",
      "184/184 [==============================] - 0s 908us/step - loss: 79.6546 - val_loss: 16.6404\n",
      "Epoch 7120/10000\n",
      "184/184 [==============================] - 0s 995us/step - loss: 73.4880 - val_loss: 16.6386\n",
      "Epoch 7121/10000\n",
      "184/184 [==============================] - 0s 875us/step - loss: 75.5025 - val_loss: 16.6374\n",
      "Epoch 7122/10000\n",
      "184/184 [==============================] - 0s 929us/step - loss: 103.2439 - val_loss: 16.6338\n",
      "Epoch 7123/10000\n",
      "184/184 [==============================] - 0s 880us/step - loss: 71.8438 - val_loss: 16.6297\n",
      "Epoch 7124/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 99.4026 - val_loss: 16.6234\n",
      "Epoch 7125/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 99.5884 - val_loss: 16.6215\n",
      "Epoch 7126/10000\n",
      "184/184 [==============================] - 0s 949us/step - loss: 87.3486 - val_loss: 16.6164\n",
      "Epoch 7127/10000\n",
      "184/184 [==============================] - 0s 660us/step - loss: 107.3741 - val_loss: 16.6091\n",
      "Epoch 7128/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 74.1760 - val_loss: 16.6012\n",
      "Epoch 7129/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 100.0347 - val_loss: 16.5978\n",
      "Epoch 7130/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 87.8243 - val_loss: 16.5897\n",
      "Epoch 7131/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 75.9228 - val_loss: 16.5828\n",
      "Epoch 7132/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 59.4114 - val_loss: 16.5817\n",
      "Epoch 7133/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 84.1267 - val_loss: 16.5821\n",
      "Epoch 7134/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 78.8255 - val_loss: 16.5784\n",
      "Epoch 7135/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 90.9113 - val_loss: 16.5692\n",
      "Epoch 7136/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 102.7979 - val_loss: 16.5571\n",
      "Epoch 7137/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 90.9435 - val_loss: 16.5399\n",
      "Epoch 7138/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 86.3585 - val_loss: 16.5261\n",
      "Epoch 7139/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 87.6293 - val_loss: 16.5140\n",
      "Epoch 7140/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 73.0529 - val_loss: 16.5058\n",
      "Epoch 7141/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 91.7810 - val_loss: 16.4996\n",
      "Epoch 7142/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 86.1456 - val_loss: 16.4949\n",
      "Epoch 7143/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 85.4073 - val_loss: 16.4892\n",
      "Epoch 7144/10000\n",
      "184/184 [==============================] - 0s 842us/step - loss: 83.5336 - val_loss: 16.4756\n",
      "Epoch 7145/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 67.4897 - val_loss: 16.4651\n",
      "Epoch 7146/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 76.0706 - val_loss: 16.4572\n",
      "Epoch 7147/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 489us/step - loss: 68.8829 - val_loss: 16.4517\n",
      "Epoch 7148/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 80.8511 - val_loss: 16.4475\n",
      "Epoch 7149/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 84.5358 - val_loss: 16.4420\n",
      "Epoch 7150/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 73.5171 - val_loss: 16.4349\n",
      "Epoch 7151/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 116.3357 - val_loss: 16.4256\n",
      "Epoch 7152/10000\n",
      "184/184 [==============================] - 0s 962us/step - loss: 85.2819 - val_loss: 16.4160\n",
      "Epoch 7153/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 82.2522 - val_loss: 16.3411\n",
      "Epoch 7154/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 100.4954 - val_loss: 16.2772\n",
      "Epoch 7155/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 91.8588 - val_loss: 16.2474\n",
      "Epoch 7156/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 78.5209 - val_loss: 16.3272\n",
      "Epoch 7157/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 99.2732 - val_loss: 16.4354\n",
      "Epoch 7158/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 69.8275 - val_loss: 16.5190\n",
      "Epoch 7159/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 75.5074 - val_loss: 16.6566\n",
      "Epoch 7160/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 82.3335 - val_loss: 16.7738\n",
      "Epoch 7161/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 82.3834 - val_loss: 16.8810\n",
      "Epoch 7162/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 69.5229 - val_loss: 16.9604\n",
      "Epoch 7163/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 69.7823 - val_loss: 17.0136\n",
      "Epoch 7164/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 68.4790 - val_loss: 17.0712\n",
      "Epoch 7165/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 78.1852 - val_loss: 17.1206\n",
      "Epoch 7166/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 77.2668 - val_loss: 17.1609\n",
      "Epoch 7167/10000\n",
      "184/184 [==============================] - 0s 788us/step - loss: 81.0806 - val_loss: 17.1962\n",
      "Epoch 7168/10000\n",
      "184/184 [==============================] - 0s 815us/step - loss: 62.8114 - val_loss: 17.2195\n",
      "Epoch 7169/10000\n",
      "184/184 [==============================] - 0s 859us/step - loss: 63.3429 - val_loss: 17.2347\n",
      "Epoch 7170/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 79.5175 - val_loss: 17.2409\n",
      "Epoch 7171/10000\n",
      "184/184 [==============================] - 0s 837us/step - loss: 70.4722 - val_loss: 17.2484\n",
      "Epoch 7172/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 78.5037 - val_loss: 17.2560\n",
      "Epoch 7173/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 75.0516 - val_loss: 17.2544\n",
      "Epoch 7174/10000\n",
      "184/184 [==============================] - 0s 755us/step - loss: 102.7405 - val_loss: 17.2436\n",
      "Epoch 7175/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 79.7365 - val_loss: 17.2286\n",
      "Epoch 7176/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 87.0421 - val_loss: 17.2132\n",
      "Epoch 7177/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 67.9349 - val_loss: 17.1975\n",
      "Epoch 7178/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 80.5637 - val_loss: 17.1987\n",
      "Epoch 7179/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 83.4270 - val_loss: 17.2136\n",
      "Epoch 7180/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 85.1376 - val_loss: 17.2225\n",
      "Epoch 7181/10000\n",
      "184/184 [==============================] - 0s 761us/step - loss: 86.5855 - val_loss: 17.2206\n",
      "Epoch 7182/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 80.7234 - val_loss: 17.2153\n",
      "Epoch 7183/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 87.9825 - val_loss: 17.2098\n",
      "Epoch 7184/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 70.7299 - val_loss: 17.2010\n",
      "Epoch 7185/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 70.2414 - val_loss: 17.1897\n",
      "Epoch 7186/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 80.8980 - val_loss: 17.1745\n",
      "Epoch 7187/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 75.3487 - val_loss: 17.1517\n",
      "Epoch 7188/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 75.5335 - val_loss: 17.1309\n",
      "Epoch 7189/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 67.0440 - val_loss: 17.1166\n",
      "Epoch 7190/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 64.8563 - val_loss: 17.0993\n",
      "Epoch 7191/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 67.0274 - val_loss: 17.0849\n",
      "Epoch 7192/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 81.5900 - val_loss: 17.0728\n",
      "Epoch 7193/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 68.9447 - val_loss: 17.0605\n",
      "Epoch 7194/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 72.6859 - val_loss: 17.0520\n",
      "Epoch 7195/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 98.0395 - val_loss: 17.0295\n",
      "Epoch 7196/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 74.3710 - val_loss: 17.0101\n",
      "Epoch 7197/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 73.1685 - val_loss: 16.9928\n",
      "Epoch 7198/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 79.1747 - val_loss: 16.9769\n",
      "Epoch 7199/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 76.8202 - val_loss: 16.9607\n",
      "Epoch 7200/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 85.3171 - val_loss: 16.9467\n",
      "\n",
      "Epoch 07200: loss improved from 87.49568 to 85.31708, saving model to C6007C.hdf5\n",
      "Epoch 7201/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 81.7127 - val_loss: 16.9766\n",
      "Epoch 7202/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 78.5515 - val_loss: 17.0019\n",
      "Epoch 7203/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 80.4386 - val_loss: 17.0233\n",
      "Epoch 7204/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 69.2578 - val_loss: 17.0389\n",
      "Epoch 7205/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 88.9551 - val_loss: 17.0523\n",
      "Epoch 7206/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 87.7264 - val_loss: 17.0582\n",
      "Epoch 7207/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 75.6217 - val_loss: 17.0634\n",
      "Epoch 7208/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 68.1847 - val_loss: 17.0679\n",
      "Epoch 7209/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 66.1278 - val_loss: 17.0486\n",
      "Epoch 7210/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 76.5011 - val_loss: 17.0300\n",
      "Epoch 7211/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 78.6520 - val_loss: 17.0139\n",
      "Epoch 7212/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 74.3176 - val_loss: 17.0004\n",
      "Epoch 7213/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 78.4494 - val_loss: 17.0079\n",
      "Epoch 7214/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 66.1992 - val_loss: 17.0113\n",
      "Epoch 7215/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 83.8864 - val_loss: 17.0158\n",
      "Epoch 7216/10000\n",
      "184/184 [==============================] - 0s 736us/step - loss: 75.0280 - val_loss: 17.0266\n",
      "Epoch 7217/10000\n",
      "184/184 [==============================] - 0s 650us/step - loss: 80.0914 - val_loss: 17.0364\n",
      "Epoch 7218/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 76.8972 - val_loss: 17.0445\n",
      "Epoch 7219/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 80.9869 - val_loss: 17.0484\n",
      "Epoch 7220/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 74.2625 - val_loss: 17.0475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7221/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 93.4020 - val_loss: 17.0461\n",
      "Epoch 7222/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 90.7965 - val_loss: 17.0447\n",
      "Epoch 7223/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 70.5582 - val_loss: 17.0120\n",
      "Epoch 7224/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 80.4060 - val_loss: 16.9909\n",
      "Epoch 7225/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 84.1422 - val_loss: 16.9723\n",
      "Epoch 7226/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 65.1515 - val_loss: 16.9550\n",
      "Epoch 7227/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 84.8052 - val_loss: 16.9385\n",
      "Epoch 7228/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 82.9106 - val_loss: 16.9280\n",
      "Epoch 7229/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 88.4457 - val_loss: 16.8919\n",
      "Epoch 7230/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 81.57 - 0s 451us/step - loss: 83.4349 - val_loss: 16.8429\n",
      "Epoch 7231/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 79.0613 - val_loss: 16.8041\n",
      "Epoch 7232/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 82.4761 - val_loss: 16.7680\n",
      "Epoch 7233/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 67.7927 - val_loss: 16.7367\n",
      "Epoch 7234/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 79.4589 - val_loss: 16.7112\n",
      "Epoch 7235/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 70.1887 - val_loss: 16.6874\n",
      "Epoch 7236/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 96.3459 - val_loss: 16.4848\n",
      "Epoch 7237/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 70.4587 - val_loss: 16.3661\n",
      "Epoch 7238/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 78.5605 - val_loss: 16.2688\n",
      "Epoch 7239/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 81.7846 - val_loss: 16.1993\n",
      "Epoch 7240/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 87.9493 - val_loss: 16.1424\n",
      "Epoch 7241/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 104.9882 - val_loss: 16.0975\n",
      "Epoch 7242/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 91.6201 - val_loss: 16.0612\n",
      "Epoch 7243/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 90.9953 - val_loss: 16.0321\n",
      "Epoch 7244/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 89.3999 - val_loss: 16.0138\n",
      "Epoch 7245/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 87.3124 - val_loss: 15.9990\n",
      "Epoch 7246/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 100.2529 - val_loss: 15.9833\n",
      "Epoch 7247/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 79.0773 - val_loss: 15.9690\n",
      "Epoch 7248/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 94.7022 - val_loss: 15.9568\n",
      "Epoch 7249/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 74.4284 - val_loss: 15.9457\n",
      "Epoch 7250/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 79.4511 - val_loss: 15.9329\n",
      "Epoch 7251/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 65.8297 - val_loss: 15.9198\n",
      "Epoch 7252/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 92.0497 - val_loss: 15.9060\n",
      "Epoch 7253/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 74.5413 - val_loss: 15.8933\n",
      "Epoch 7254/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 81.3138 - val_loss: 15.8811\n",
      "Epoch 7255/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 83.8253 - val_loss: 15.8705\n",
      "Epoch 7256/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 75.8346 - val_loss: 15.8684\n",
      "Epoch 7257/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 87.3514 - val_loss: 15.8633\n",
      "Epoch 7258/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 81.2167 - val_loss: 15.8576\n",
      "Epoch 7259/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 81.9949 - val_loss: 15.8457\n",
      "Epoch 7260/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 85.7970 - val_loss: 15.8343\n",
      "Epoch 7261/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 71.8443 - val_loss: 15.8291\n",
      "Epoch 7262/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 83.4148 - val_loss: 15.8301\n",
      "Epoch 7263/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 67.6775 - val_loss: 15.8241\n",
      "Epoch 7264/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 89.1990 - val_loss: 15.8196\n",
      "Epoch 7265/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 80.8657 - val_loss: 15.8141\n",
      "Epoch 7266/10000\n",
      "184/184 [==============================] - 0s 525us/step - loss: 75.2470 - val_loss: 15.8090\n",
      "Epoch 7267/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 86.5754 - val_loss: 15.8033\n",
      "Epoch 7268/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 77.1586 - val_loss: 15.7917\n",
      "Epoch 7269/10000\n",
      "184/184 [==============================] - 0s 568us/step - loss: 73.3834 - val_loss: 15.7853\n",
      "Epoch 7270/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 82.4159 - val_loss: 15.7745\n",
      "Epoch 7271/10000\n",
      "184/184 [==============================] - 0s 465us/step - loss: 64.1546 - val_loss: 15.7666\n",
      "Epoch 7272/10000\n",
      "184/184 [==============================] - 0s 481us/step - loss: 75.1576 - val_loss: 15.7586\n",
      "Epoch 7273/10000\n",
      "184/184 [==============================] - 0s 584us/step - loss: 75.8763 - val_loss: 15.7320\n",
      "Epoch 7274/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 61.8836 - val_loss: 15.7079\n",
      "Epoch 7275/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 71.0540 - val_loss: 15.6878\n",
      "Epoch 7276/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 83.2249 - val_loss: 15.6714\n",
      "Epoch 7277/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 77.9365 - val_loss: 15.6556\n",
      "Epoch 7278/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 88.1376 - val_loss: 15.6388\n",
      "Epoch 7279/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 71.2350 - val_loss: 15.6228\n",
      "Epoch 7280/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 71.2567 - val_loss: 15.6072\n",
      "Epoch 7281/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 78.4292 - val_loss: 15.5937\n",
      "Epoch 7282/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 87.2578 - val_loss: 15.5820\n",
      "Epoch 7283/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 68.0666 - val_loss: 15.5740\n",
      "Epoch 7284/10000\n",
      "184/184 [==============================] - 0s 508us/step - loss: 73.2314 - val_loss: 15.5670\n",
      "Epoch 7285/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 83.8221 - val_loss: 15.5613\n",
      "Epoch 7286/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 86.4004 - val_loss: 15.5551\n",
      "Epoch 7287/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 97.5584 - val_loss: 15.5501\n",
      "Epoch 7288/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 89.7563 - val_loss: 15.5458\n",
      "Epoch 7289/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 63.7711 - val_loss: 15.5403\n",
      "Epoch 7290/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 69.2181 - val_loss: 15.5359\n",
      "Epoch 7291/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 81.8928 - val_loss: 15.5368\n",
      "Epoch 7292/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 72.1694 - val_loss: 15.5396\n",
      "Epoch 7293/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 74.9714 - val_loss: 15.5438\n",
      "Epoch 7294/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 77.4369 - val_loss: 15.5458\n",
      "Epoch 7295/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 554us/step - loss: 78.6670 - val_loss: 15.5478\n",
      "Epoch 7296/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 78.6159 - val_loss: 15.5494\n",
      "Epoch 7297/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 77.7065 - val_loss: 15.5526\n",
      "Epoch 7298/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 101.9851 - val_loss: 15.5638\n",
      "Epoch 7299/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 63.4640 - val_loss: 15.5853\n",
      "Epoch 7300/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 76.3584 - val_loss: 15.6125\n",
      "\n",
      "Epoch 07300: loss improved from 85.31708 to 76.35844, saving model to C6007C.hdf5\n",
      "Epoch 7301/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 82.7748 - val_loss: 15.6363\n",
      "Epoch 7302/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 91.8969 - val_loss: 15.6550\n",
      "Epoch 7303/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 89.4271 - val_loss: 15.6673\n",
      "Epoch 7304/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 96.2630 - val_loss: 15.6748\n",
      "Epoch 7305/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 77.4983 - val_loss: 15.6807\n",
      "Epoch 7306/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 59.2026 - val_loss: 15.6844\n",
      "Epoch 7307/10000\n",
      "184/184 [==============================] - 0s 566us/step - loss: 67.8969 - val_loss: 15.6872\n",
      "Epoch 7308/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 100.4445 - val_loss: 15.6885\n",
      "Epoch 7309/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 73.0136 - val_loss: 15.6869\n",
      "Epoch 7310/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 93.8817 - val_loss: 15.7178\n",
      "Epoch 7311/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 69.8107 - val_loss: 15.7254\n",
      "Epoch 7312/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 70.7252 - val_loss: 15.7330\n",
      "Epoch 7313/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 74.0943 - val_loss: 15.7357\n",
      "Epoch 7314/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 80.6062 - val_loss: 15.7355\n",
      "Epoch 7315/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 75.2148 - val_loss: 15.7339\n",
      "Epoch 7316/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 74.7670 - val_loss: 15.7312\n",
      "Epoch 7317/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 74.6229 - val_loss: 15.7337\n",
      "Epoch 7318/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 82.6664 - val_loss: 15.7351\n",
      "Epoch 7319/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 94.5544 - val_loss: 15.7349\n",
      "Epoch 7320/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 68.2886 - val_loss: 15.7333\n",
      "Epoch 7321/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 66.9163 - val_loss: 15.7317\n",
      "Epoch 7322/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 116.0132 - val_loss: 15.7301\n",
      "Epoch 7323/10000\n",
      "184/184 [==============================] - 0s 698us/step - loss: 86.0286 - val_loss: 15.7302\n",
      "Epoch 7324/10000\n",
      "184/184 [==============================] - 0s 563us/step - loss: 80.7340 - val_loss: 15.7359\n",
      "Epoch 7325/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 65.4723 - val_loss: 15.7450\n",
      "Epoch 7326/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 74.0187 - val_loss: 15.7490\n",
      "Epoch 7327/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 100.3539 - val_loss: 15.7491\n",
      "Epoch 7328/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 78.7970 - val_loss: 15.7471\n",
      "Epoch 7329/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 79.6278 - val_loss: 15.7446\n",
      "Epoch 7330/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 96.8145 - val_loss: 15.7375\n",
      "Epoch 7331/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 73.6789 - val_loss: 15.7287\n",
      "Epoch 7332/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 70.2453 - val_loss: 15.7155\n",
      "Epoch 7333/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 84.7499 - val_loss: 15.7073\n",
      "Epoch 7334/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 82.8242 - val_loss: 15.6922\n",
      "Epoch 7335/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 81.0674 - val_loss: 15.6818\n",
      "Epoch 7336/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 76.0481 - val_loss: 15.6699\n",
      "Epoch 7337/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 75.3037 - val_loss: 15.6581\n",
      "Epoch 7338/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 84.7864 - val_loss: 15.6431\n",
      "Epoch 7339/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 82.2906 - val_loss: 15.6277\n",
      "Epoch 7340/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 75.1984 - val_loss: 15.5995\n",
      "Epoch 7341/10000\n",
      "184/184 [==============================] - 0s 761us/step - loss: 91.4630 - val_loss: 15.5748\n",
      "Epoch 7342/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 70.1521 - val_loss: 15.5483\n",
      "Epoch 7343/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 64.1205 - val_loss: 15.5184\n",
      "Epoch 7344/10000\n",
      "184/184 [==============================] - 0s 666us/step - loss: 76.0634 - val_loss: 15.4951\n",
      "Epoch 7345/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 69.7684 - val_loss: 15.4758\n",
      "Epoch 7346/10000\n",
      "184/184 [==============================] - 0s 607us/step - loss: 79.4840 - val_loss: 15.4548\n",
      "Epoch 7347/10000\n",
      "184/184 [==============================] - 0s 897us/step - loss: 87.3401 - val_loss: 15.4355\n",
      "Epoch 7348/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 73.1691 - val_loss: 15.4178\n",
      "Epoch 7349/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 71.9777 - val_loss: 15.4011\n",
      "Epoch 7350/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 83.1646 - val_loss: 15.3884\n",
      "Epoch 7351/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 64.1610 - val_loss: 15.3712\n",
      "Epoch 7352/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 96.4023 - val_loss: 15.3484\n",
      "Epoch 7353/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 87.9658 - val_loss: 15.3283\n",
      "Epoch 7354/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 73.0677 - val_loss: 15.3118\n",
      "Epoch 7355/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 89.9411 - val_loss: 15.2977\n",
      "Epoch 7356/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 73.4673 - val_loss: 15.2848\n",
      "Epoch 7357/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 66.3519 - val_loss: 15.2736\n",
      "Epoch 7358/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 79.2301 - val_loss: 15.2632\n",
      "Epoch 7359/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 72.6625 - val_loss: 15.2546\n",
      "Epoch 7360/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 71.5674 - val_loss: 15.2467\n",
      "Epoch 7361/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 84.2719 - val_loss: 15.2424\n",
      "Epoch 7362/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 94.9557 - val_loss: 15.2361\n",
      "Epoch 7363/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 83.9739 - val_loss: 15.2295\n",
      "Epoch 7364/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 107.3691 - val_loss: 15.2226\n",
      "Epoch 7365/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 93.0564 - val_loss: 15.2164\n",
      "Epoch 7366/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 78.9951 - val_loss: 15.2113\n",
      "Epoch 7367/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 77.8398 - val_loss: 15.1946\n",
      "Epoch 7368/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 69.0225 - val_loss: 15.1769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7369/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 67.8792 - val_loss: 15.1621\n",
      "Epoch 7370/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 84.5614 - val_loss: 15.1522\n",
      "Epoch 7371/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 81.5040 - val_loss: 15.1519\n",
      "Epoch 7372/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 73.6796 - val_loss: 15.1585\n",
      "Epoch 7373/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 77.21 - 0s 451us/step - loss: 86.5314 - val_loss: 15.1543\n",
      "Epoch 7374/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 85.9556 - val_loss: 15.1492\n",
      "Epoch 7375/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 72.9148 - val_loss: 15.1466\n",
      "Epoch 7376/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 82.3840 - val_loss: 15.2206\n",
      "Epoch 7377/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 89.9074 - val_loss: 15.1994\n",
      "Epoch 7378/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 70.5662 - val_loss: 15.1759\n",
      "Epoch 7379/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 100.4081 - val_loss: 15.0811\n",
      "Epoch 7380/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 88.9032 - val_loss: 14.9050\n",
      "Epoch 7381/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 71.9116 - val_loss: 14.8697\n",
      "Epoch 7382/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 72.6614 - val_loss: 14.8335\n",
      "Epoch 7383/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 72.9774 - val_loss: 14.8135\n",
      "Epoch 7384/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 95.9980 - val_loss: 14.8020\n",
      "Epoch 7385/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 71.0670 - val_loss: 14.7904\n",
      "Epoch 7386/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 85.0328 - val_loss: 14.7826\n",
      "Epoch 7387/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 69.0594 - val_loss: 14.7840\n",
      "Epoch 7388/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 68.9361 - val_loss: 14.7836\n",
      "Epoch 7389/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 70.8407 - val_loss: 14.7733\n",
      "Epoch 7390/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 100.0168 - val_loss: 14.7626\n",
      "Epoch 7391/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 95.7441 - val_loss: 14.7544\n",
      "Epoch 7392/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 67.8425 - val_loss: 14.7462\n",
      "Epoch 7393/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 85.4637 - val_loss: 14.7399\n",
      "Epoch 7394/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 62.7420 - val_loss: 14.7306\n",
      "Epoch 7395/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 84.4386 - val_loss: 14.7157\n",
      "Epoch 7396/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 69.5011 - val_loss: 14.6996\n",
      "Epoch 7397/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 75.5596 - val_loss: 14.6719\n",
      "Epoch 7398/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 81.6155 - val_loss: 14.6439\n",
      "Epoch 7399/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 76.8787 - val_loss: 14.6224\n",
      "Epoch 7400/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 89.3037 - val_loss: 14.6043\n",
      "\n",
      "Epoch 07400: loss did not improve from 76.35844\n",
      "Epoch 7401/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 83.7671 - val_loss: 14.5893\n",
      "Epoch 7402/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 96.4456 - val_loss: 14.5885\n",
      "Epoch 7403/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 59.0088 - val_loss: 14.5866\n",
      "Epoch 7404/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 67.6261 - val_loss: 14.5801\n",
      "Epoch 7405/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 84.0855 - val_loss: 14.5742\n",
      "Epoch 7406/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 72.8436 - val_loss: 14.5675\n",
      "Epoch 7407/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 98.5906 - val_loss: 14.5607\n",
      "Epoch 7408/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 87.8412 - val_loss: 14.5514\n",
      "Epoch 7409/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 76.8307 - val_loss: 14.5410\n",
      "Epoch 7410/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 87.3405 - val_loss: 14.5312\n",
      "Epoch 7411/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 54.6751 - val_loss: 14.5221\n",
      "Epoch 7412/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 81.1075 - val_loss: 14.5137\n",
      "Epoch 7413/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 81.8077 - val_loss: 14.5078\n",
      "Epoch 7414/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 79.9295 - val_loss: 14.5005\n",
      "Epoch 7415/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 97.8089 - val_loss: 14.4937\n",
      "Epoch 7416/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 85.1013 - val_loss: 14.4868\n",
      "Epoch 7417/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 64.5331 - val_loss: 14.4788\n",
      "Epoch 7418/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 85.0127 - val_loss: 14.4702\n",
      "Epoch 7419/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 83.0541 - val_loss: 14.4586\n",
      "Epoch 7420/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 79.5537 - val_loss: 14.4462\n",
      "Epoch 7421/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 80.6456 - val_loss: 14.4408\n",
      "Epoch 7422/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 117.9600 - val_loss: 14.4340\n",
      "Epoch 7423/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 85.3696 - val_loss: 14.4280\n",
      "Epoch 7424/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 56.1213 - val_loss: 14.4224\n",
      "Epoch 7425/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 63.6577 - val_loss: 14.4186\n",
      "Epoch 7426/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 82.7888 - val_loss: 14.4140\n",
      "Epoch 7427/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 94.0162 - val_loss: 14.4068\n",
      "Epoch 7428/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 77.2168 - val_loss: 14.4012\n",
      "Epoch 7429/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 77.7859 - val_loss: 14.4439\n",
      "Epoch 7430/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 68.1277 - val_loss: 14.4800\n",
      "Epoch 7431/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 80.0270 - val_loss: 14.5096\n",
      "Epoch 7432/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 78.2154 - val_loss: 14.5333\n",
      "Epoch 7433/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 70.7627 - val_loss: 14.5569\n",
      "Epoch 7434/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 87.0676 - val_loss: 14.5751\n",
      "Epoch 7435/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 85.4757 - val_loss: 14.5890\n",
      "Epoch 7436/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 65.2537 - val_loss: 14.5981\n",
      "Epoch 7437/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 63.7840 - val_loss: 14.6104\n",
      "Epoch 7438/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 80.3902 - val_loss: 14.6191\n",
      "Epoch 7439/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 78.4243 - val_loss: 14.6248\n",
      "Epoch 7440/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 81.1337 - val_loss: 14.6306\n",
      "Epoch 7441/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 91.9595 - val_loss: 14.6357\n",
      "Epoch 7442/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 76.2684 - val_loss: 14.6410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7443/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 68.5513 - val_loss: 14.6454\n",
      "Epoch 7444/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 81.4110 - val_loss: 14.6483\n",
      "Epoch 7445/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 83.8295 - val_loss: 14.6507\n",
      "Epoch 7446/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 89.8437 - val_loss: 14.6500\n",
      "Epoch 7447/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 60.5028 - val_loss: 14.6498\n",
      "Epoch 7448/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 67.3556 - val_loss: 14.6460\n",
      "Epoch 7449/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 74.3817 - val_loss: 14.6405\n",
      "Epoch 7450/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 70.6210 - val_loss: 14.6335\n",
      "Epoch 7451/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 74.4280 - val_loss: 14.6266\n",
      "Epoch 7452/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 80.4708 - val_loss: 14.6186\n",
      "Epoch 7453/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 64.8094 - val_loss: 14.6089\n",
      "Epoch 7454/10000\n",
      "184/184 [==============================] - 0s 573us/step - loss: 83.2843 - val_loss: 14.6008\n",
      "Epoch 7455/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 81.2155 - val_loss: 14.5963\n",
      "Epoch 7456/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 86.5433 - val_loss: 14.5899\n",
      "Epoch 7457/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 98.8255 - val_loss: 14.5829\n",
      "Epoch 7458/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 73.3377 - val_loss: 14.5803\n",
      "Epoch 7459/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 73.1175 - val_loss: 14.5914\n",
      "Epoch 7460/10000\n",
      "184/184 [==============================] - 0s 435us/step - loss: 87.0499 - val_loss: 14.5969\n",
      "Epoch 7461/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 61.2880 - val_loss: 14.6027\n",
      "Epoch 7462/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 65.5819 - val_loss: 14.6093\n",
      "Epoch 7463/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 63.1999 - val_loss: 14.6146\n",
      "Epoch 7464/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 59.0841 - val_loss: 14.6181\n",
      "Epoch 7465/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 79.3704 - val_loss: 14.6188\n",
      "Epoch 7466/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 79.6148 - val_loss: 14.6192\n",
      "Epoch 7467/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 78.3144 - val_loss: 14.6179\n",
      "Epoch 7468/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 68.2203 - val_loss: 14.6134\n",
      "Epoch 7469/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 56.8357 - val_loss: 14.6072\n",
      "Epoch 7470/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 68.6820 - val_loss: 14.5949\n",
      "Epoch 7471/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 73.1222 - val_loss: 14.5871\n",
      "Epoch 7472/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 73.8972 - val_loss: 14.5754\n",
      "Epoch 7473/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 61.8166 - val_loss: 14.5631\n",
      "Epoch 7474/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 80.4338 - val_loss: 14.5536\n",
      "Epoch 7475/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 95.6421 - val_loss: 14.5436\n",
      "Epoch 7476/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 61.5554 - val_loss: 14.5309\n",
      "Epoch 7477/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 93.1339 - val_loss: 14.5178\n",
      "Epoch 7478/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 84.6832 - val_loss: 14.5028\n",
      "Epoch 7479/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 73.1160 - val_loss: 14.4881\n",
      "Epoch 7480/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 72.8168 - val_loss: 14.4743\n",
      "Epoch 7481/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 61.4459 - val_loss: 14.4665\n",
      "Epoch 7482/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 87.9605 - val_loss: 14.4582\n",
      "Epoch 7483/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 69.2073 - val_loss: 14.4505\n",
      "Epoch 7484/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 77.3293 - val_loss: 14.4490\n",
      "Epoch 7485/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 85.7376 - val_loss: 14.4455\n",
      "Epoch 7486/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 83.3075 - val_loss: 14.4394\n",
      "Epoch 7487/10000\n",
      "184/184 [==============================] - 0s 506us/step - loss: 72.7377 - val_loss: 14.4340\n",
      "Epoch 7488/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 84.9029 - val_loss: 14.4269\n",
      "Epoch 7489/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 76.5038 - val_loss: 14.4342\n",
      "Epoch 7490/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 86.0175 - val_loss: 14.4355\n",
      "Epoch 7491/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 76.5611 - val_loss: 14.4397\n",
      "Epoch 7492/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 82.3941 - val_loss: 14.4458\n",
      "Epoch 7493/10000\n",
      "184/184 [==============================] - 0s 544us/step - loss: 56.5424 - val_loss: 14.4496\n",
      "Epoch 7494/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 63.2303 - val_loss: 14.4523\n",
      "Epoch 7495/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 75.7071 - val_loss: 14.4495\n",
      "Epoch 7496/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 67.6094 - val_loss: 14.4322\n",
      "Epoch 7497/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 70.2585 - val_loss: 14.4168\n",
      "Epoch 7498/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 75.5849 - val_loss: 14.3994\n",
      "Epoch 7499/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 77.0800 - val_loss: 14.3811\n",
      "Epoch 7500/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 73.5794 - val_loss: 14.3632\n",
      "\n",
      "Epoch 07500: loss improved from 76.35844 to 73.57941, saving model to C6007C.hdf5\n",
      "Epoch 7501/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 74.8067 - val_loss: 14.3456\n",
      "Epoch 7502/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 84.1012 - val_loss: 14.3306\n",
      "Epoch 7503/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 88.2058 - val_loss: 14.3177\n",
      "Epoch 7504/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 91.8416 - val_loss: 14.3087\n",
      "Epoch 7505/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 72.1454 - val_loss: 14.3010\n",
      "Epoch 7506/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 94.2608 - val_loss: 14.3067\n",
      "Epoch 7507/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 95.1517 - val_loss: 14.3095\n",
      "Epoch 7508/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 72.5967 - val_loss: 14.5049\n",
      "Epoch 7509/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 87.7505 - val_loss: 15.0270\n",
      "Epoch 7510/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 87.4042 - val_loss: 15.2386\n",
      "Epoch 7511/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 72.5036 - val_loss: 15.3362\n",
      "Epoch 7512/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 66.3101 - val_loss: 15.4410\n",
      "Epoch 7513/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 84.3877 - val_loss: 15.5830\n",
      "Epoch 7514/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 58.2328 - val_loss: 15.6740\n",
      "Epoch 7515/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 78.3413 - val_loss: 15.6626\n",
      "Epoch 7516/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 462us/step - loss: 74.1129 - val_loss: 15.9514\n",
      "Epoch 7517/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 77.1602 - val_loss: 16.5473\n",
      "Epoch 7518/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 58.9621 - val_loss: 16.1986\n",
      "Epoch 7519/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 74.5720 - val_loss: 16.0179\n",
      "Epoch 7520/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 60.5587 - val_loss: 16.2361\n",
      "Epoch 7521/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 73.8859 - val_loss: 15.4329\n",
      "Epoch 7522/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 83.6934 - val_loss: 15.3763\n",
      "Epoch 7523/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 68.9458 - val_loss: 15.3706\n",
      "Epoch 7524/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 71.8691 - val_loss: 15.2692\n",
      "Epoch 7525/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 63.6208 - val_loss: 15.4474\n",
      "Epoch 7526/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 72.9093 - val_loss: 16.2305\n",
      "Epoch 7527/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 86.1885 - val_loss: 16.1045\n",
      "Epoch 7528/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 60.8003 - val_loss: 15.9591\n",
      "Epoch 7529/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 90.7890 - val_loss: 16.0309\n",
      "Epoch 7530/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 80.1267 - val_loss: 16.0112\n",
      "Epoch 7531/10000\n",
      "184/184 [==============================] - 0s 429us/step - loss: 62.1320 - val_loss: 15.9853\n",
      "Epoch 7532/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 70.1888 - val_loss: 15.9474\n",
      "Epoch 7533/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 70.8748 - val_loss: 15.9316\n",
      "Epoch 7534/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 69.4007 - val_loss: 15.9076\n",
      "Epoch 7535/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 92.5195 - val_loss: 15.8878\n",
      "Epoch 7536/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 89.2261 - val_loss: 15.8733\n",
      "Epoch 7537/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 65.5691 - val_loss: 15.8679\n",
      "Epoch 7538/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 84.7119 - val_loss: 15.8247\n",
      "Epoch 7539/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 82.9240 - val_loss: 15.7270\n",
      "Epoch 7540/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 61.7610 - val_loss: 15.8674\n",
      "Epoch 7541/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 80.6295 - val_loss: 16.5313\n",
      "Epoch 7542/10000\n",
      "184/184 [==============================] - 0s 929us/step - loss: 87.4049 - val_loss: 15.5926\n",
      "Epoch 7543/10000\n",
      "184/184 [==============================] - 0s 813us/step - loss: 82.2576 - val_loss: 15.5962\n",
      "Epoch 7544/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 85.9527 - val_loss: 15.7019\n",
      "Epoch 7545/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 64.0217 - val_loss: 15.6744\n",
      "Epoch 7546/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 76.8237 - val_loss: 15.6837\n",
      "Epoch 7547/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 58.1817 - val_loss: 15.7083\n",
      "Epoch 7548/10000\n",
      "184/184 [==============================] - 0s 935us/step - loss: 69.1061 - val_loss: 15.6135\n",
      "Epoch 7549/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 80.0872 - val_loss: 15.5312\n",
      "Epoch 7550/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 80.3237 - val_loss: 15.4906\n",
      "Epoch 7551/10000\n",
      "184/184 [==============================] - 0s 750us/step - loss: 90.5678 - val_loss: 15.6366\n",
      "Epoch 7552/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 76.8831 - val_loss: 15.6640\n",
      "Epoch 7553/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 73.0194 - val_loss: 15.4296\n",
      "Epoch 7554/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 67.2325 - val_loss: 15.4362\n",
      "Epoch 7555/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 67.7577 - val_loss: 15.5963\n",
      "Epoch 7556/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 62.0065 - val_loss: 15.5576\n",
      "Epoch 7557/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 71.1581 - val_loss: 15.3833\n",
      "Epoch 7558/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 66.9245 - val_loss: 15.4176\n",
      "Epoch 7559/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 64.3997 - val_loss: 15.4914\n",
      "Epoch 7560/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 83.0968 - val_loss: 15.6771\n",
      "Epoch 7561/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 66.8403 - val_loss: 15.0841\n",
      "Epoch 7562/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 69.2399 - val_loss: 15.2378\n",
      "Epoch 7563/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 78.3370 - val_loss: 13.7645\n",
      "Epoch 7564/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 82.3802 - val_loss: 13.3202\n",
      "Epoch 7565/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 87.1586 - val_loss: 13.3023\n",
      "Epoch 7566/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 67.8721 - val_loss: 13.5648\n",
      "Epoch 7567/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 68.7059 - val_loss: 13.7053\n",
      "Epoch 7568/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 79.8695 - val_loss: 13.9309\n",
      "Epoch 7569/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 64.6167 - val_loss: 14.2100\n",
      "Epoch 7570/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 65.5295 - val_loss: 14.3486\n",
      "Epoch 7571/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 68.9158 - val_loss: 14.0920\n",
      "Epoch 7572/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 79.0335 - val_loss: 14.1643\n",
      "Epoch 7573/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 70.8385 - val_loss: 14.1513\n",
      "Epoch 7574/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 82.1395 - val_loss: 14.2072\n",
      "Epoch 7575/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 84.1421 - val_loss: 14.2083\n",
      "Epoch 7576/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 70.6497 - val_loss: 14.2450\n",
      "Epoch 7577/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 76.5561 - val_loss: 14.1618\n",
      "Epoch 7578/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 64.0399 - val_loss: 14.2061\n",
      "Epoch 7579/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 74.3060 - val_loss: 14.2403\n",
      "Epoch 7580/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 61.6364 - val_loss: 14.2347\n",
      "Epoch 7581/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 74.0683 - val_loss: 14.2227\n",
      "Epoch 7582/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 65.0792 - val_loss: 14.2138\n",
      "Epoch 7583/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 72.8574 - val_loss: 14.2092\n",
      "Epoch 7584/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 65.6572 - val_loss: 14.1866\n",
      "Epoch 7585/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 76.1240 - val_loss: 14.0219\n",
      "Epoch 7586/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 72.6982 - val_loss: 14.0818\n",
      "Epoch 7587/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 61.9919 - val_loss: 14.0424\n",
      "Epoch 7588/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 66.5007 - val_loss: 14.0065\n",
      "Epoch 7589/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 86.7807 - val_loss: 13.9994\n",
      "Epoch 7590/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 451us/step - loss: 69.3614 - val_loss: 14.1042\n",
      "Epoch 7591/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 74.0130 - val_loss: 14.0167\n",
      "Epoch 7592/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 80.4071 - val_loss: 13.8894\n",
      "Epoch 7593/10000\n",
      "184/184 [==============================] - 0s 731us/step - loss: 76.8644 - val_loss: 13.7755\n",
      "Epoch 7594/10000\n",
      "184/184 [==============================] - 0s 753us/step - loss: 75.0465 - val_loss: 13.7333\n",
      "Epoch 7595/10000\n",
      "184/184 [==============================] - 0s 573us/step - loss: 66.8334 - val_loss: 13.7553\n",
      "Epoch 7596/10000\n",
      "184/184 [==============================] - 0s 655us/step - loss: 76.9782 - val_loss: 13.7352\n",
      "Epoch 7597/10000\n",
      "184/184 [==============================] - 0s 535us/step - loss: 73.2141 - val_loss: 13.7355\n",
      "Epoch 7598/10000\n",
      "184/184 [==============================] - 0s 617us/step - loss: 68.6482 - val_loss: 13.7252\n",
      "Epoch 7599/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 65.3044 - val_loss: 13.6154\n",
      "Epoch 7600/10000\n",
      "184/184 [==============================] - 0s 590us/step - loss: 56.7404 - val_loss: 13.5970\n",
      "\n",
      "Epoch 07600: loss improved from 73.57941 to 56.74038, saving model to C6007C.hdf5\n",
      "Epoch 7601/10000\n",
      "184/184 [==============================] - 0s 606us/step - loss: 58.5127 - val_loss: 13.5794\n",
      "Epoch 7602/10000\n",
      "184/184 [==============================] - 0s 546us/step - loss: 75.6909 - val_loss: 13.6188\n",
      "Epoch 7603/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 64.0711 - val_loss: 13.6811\n",
      "Epoch 7604/10000\n",
      "184/184 [==============================] - 0s 497us/step - loss: 91.9852 - val_loss: 13.6722\n",
      "Epoch 7605/10000\n",
      "184/184 [==============================] - 0s 486us/step - loss: 82.9811 - val_loss: 13.6453\n",
      "Epoch 7606/10000\n",
      "184/184 [==============================] - 0s 432us/step - loss: 60.8090 - val_loss: 13.5625\n",
      "Epoch 7607/10000\n",
      "184/184 [==============================] - 0s 497us/step - loss: 78.6061 - val_loss: 13.5317\n",
      "Epoch 7608/10000\n",
      "184/184 [==============================] - 0s 470us/step - loss: 78.7023 - val_loss: 13.5114\n",
      "Epoch 7609/10000\n",
      "184/184 [==============================] - 0s 535us/step - loss: 83.6424 - val_loss: 13.4998\n",
      "Epoch 7610/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 62.2198 - val_loss: 13.5089\n",
      "Epoch 7611/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 78.8357 - val_loss: 13.5364\n",
      "Epoch 7612/10000\n",
      "184/184 [==============================] - 0s 579us/step - loss: 67.9842 - val_loss: 13.5430\n",
      "Epoch 7613/10000\n",
      "184/184 [==============================] - 0s 639us/step - loss: 60.1278 - val_loss: 13.5502\n",
      "Epoch 7614/10000\n",
      "184/184 [==============================] - 0s 563us/step - loss: 71.0935 - val_loss: 13.5631\n",
      "Epoch 7615/10000\n",
      "184/184 [==============================] - 0s 492us/step - loss: 75.9920 - val_loss: 13.5728\n",
      "Epoch 7616/10000\n",
      "184/184 [==============================] - 0s 448us/step - loss: 74.3200 - val_loss: 13.5836\n",
      "Epoch 7617/10000\n",
      "184/184 [==============================] - 0s 666us/step - loss: 80.2226 - val_loss: 13.5846\n",
      "Epoch 7618/10000\n",
      "184/184 [==============================] - 0s 590us/step - loss: 67.8755 - val_loss: 13.5824\n",
      "Epoch 7619/10000\n",
      "184/184 [==============================] - 0s 666us/step - loss: 62.7274 - val_loss: 13.5811\n",
      "Epoch 7620/10000\n",
      "184/184 [==============================] - 0s 853us/step - loss: 63.6126 - val_loss: 13.5749\n",
      "Epoch 7621/10000\n",
      "184/184 [==============================] - 0s 810us/step - loss: 72.8483 - val_loss: 13.5579\n",
      "Epoch 7622/10000\n",
      "184/184 [==============================] - 0s 908us/step - loss: 69.7907 - val_loss: 13.5617\n",
      "Epoch 7623/10000\n",
      "184/184 [==============================] - 0s 793us/step - loss: 77.4429 - val_loss: 13.5676\n",
      "Epoch 7624/10000\n",
      "184/184 [==============================] - 0s 902us/step - loss: 70.3690 - val_loss: 13.5739\n",
      "Epoch 7625/10000\n",
      "184/184 [==============================] - 0s 875us/step - loss: 72.0489 - val_loss: 13.5736\n",
      "Epoch 7626/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 63.6752 - val_loss: 13.5561\n",
      "Epoch 7627/10000\n",
      "184/184 [==============================] - 0s 744us/step - loss: 68.1662 - val_loss: 13.5587\n",
      "Epoch 7628/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 85.1471 - val_loss: 13.5736\n",
      "Epoch 7629/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 100.2513 - val_loss: 13.5759\n",
      "Epoch 7630/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 60.0417 - val_loss: 13.6239\n",
      "Epoch 7631/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 69.9756 - val_loss: 13.6482\n",
      "Epoch 7632/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 87.1960 - val_loss: 13.6634\n",
      "Epoch 7633/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 74.6854 - val_loss: 13.5275\n",
      "Epoch 7634/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 81.6894 - val_loss: 13.5247\n",
      "Epoch 7635/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 75.7448 - val_loss: 13.5616\n",
      "Epoch 7636/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 57.9399 - val_loss: 13.5901\n",
      "Epoch 7637/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 62.6746 - val_loss: 13.5922\n",
      "Epoch 7638/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 73.4729 - val_loss: 13.5844\n",
      "Epoch 7639/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 76.2362 - val_loss: 13.5060\n",
      "Epoch 7640/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 88.6605 - val_loss: 13.4742\n",
      "Epoch 7641/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 63.6227 - val_loss: 13.4676\n",
      "Epoch 7642/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 77.7068 - val_loss: 13.4797\n",
      "Epoch 7643/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 64.6072 - val_loss: 13.5338\n",
      "Epoch 7644/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 113.9908 - val_loss: 13.5380\n",
      "Epoch 7645/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 64.9982 - val_loss: 13.5300\n",
      "Epoch 7646/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 69.6753 - val_loss: 13.5196\n",
      "Epoch 7647/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 71.6595 - val_loss: 13.5123\n",
      "Epoch 7648/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 66.1084 - val_loss: 13.4896\n",
      "Epoch 7649/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 82.5527 - val_loss: 13.4209\n",
      "Epoch 7650/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 75.9114 - val_loss: 13.4807\n",
      "Epoch 7651/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 67.3794 - val_loss: 13.4523\n",
      "Epoch 7652/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 75.7129 - val_loss: 13.4165\n",
      "Epoch 7653/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 64.5446 - val_loss: 13.3984\n",
      "Epoch 7654/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 71.8413 - val_loss: 13.3913\n",
      "Epoch 7655/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 80.6762 - val_loss: 13.3682\n",
      "Epoch 7656/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 60.3668 - val_loss: 13.3499\n",
      "Epoch 7657/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 72.6109 - val_loss: 13.3383\n",
      "Epoch 7658/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 63.7733 - val_loss: 13.3289\n",
      "Epoch 7659/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 87.6475 - val_loss: 13.3190\n",
      "Epoch 7660/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 71.9061 - val_loss: 13.3112\n",
      "Epoch 7661/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 60.6027 - val_loss: 13.3033\n",
      "Epoch 7662/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 72.1579 - val_loss: 13.2953\n",
      "Epoch 7663/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 80.8078 - val_loss: 13.2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7664/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 79.2744 - val_loss: 13.2826\n",
      "Epoch 7665/10000\n",
      "184/184 [==============================] - 0s 886us/step - loss: 59.4398 - val_loss: 13.2782\n",
      "Epoch 7666/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 77.0770 - val_loss: 13.2705\n",
      "Epoch 7667/10000\n",
      "184/184 [==============================] - 0s 848us/step - loss: 84.8464 - val_loss: 13.2606\n",
      "Epoch 7668/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 71.9088 - val_loss: 13.2513\n",
      "Epoch 7669/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 89.50 - 0s 636us/step - loss: 80.5860 - val_loss: 13.2435\n",
      "Epoch 7670/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 72.0460 - val_loss: 13.2364\n",
      "Epoch 7671/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 79.2188 - val_loss: 13.2307\n",
      "Epoch 7672/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 65.2031 - val_loss: 13.2251\n",
      "Epoch 7673/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 70.4710 - val_loss: 13.2176\n",
      "Epoch 7674/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 74.6114 - val_loss: 13.2095\n",
      "Epoch 7675/10000\n",
      "184/184 [==============================] - 0s 465us/step - loss: 65.5867 - val_loss: 13.1994\n",
      "Epoch 7676/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 71.6068 - val_loss: 13.1915\n",
      "Epoch 7677/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 72.5237 - val_loss: 13.1828\n",
      "Epoch 7678/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 80.5820 - val_loss: 13.1751\n",
      "Epoch 7679/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 77.66 - 0s 516us/step - loss: 71.8333 - val_loss: 13.1690\n",
      "Epoch 7680/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 69.0259 - val_loss: 13.2123\n",
      "Epoch 7681/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 62.1367 - val_loss: 13.1827\n",
      "Epoch 7682/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 68.3361 - val_loss: 13.4628\n",
      "Epoch 7683/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 56.1620 - val_loss: 13.2760\n",
      "Epoch 7684/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 70.6693 - val_loss: 13.3171\n",
      "Epoch 7685/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 72.1812 - val_loss: 13.4060\n",
      "Epoch 7686/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 85.5419 - val_loss: 13.4887\n",
      "Epoch 7687/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 77.6298 - val_loss: 13.5703\n",
      "Epoch 7688/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 78.7457 - val_loss: 13.5240\n",
      "Epoch 7689/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 60.1509 - val_loss: 13.4148\n",
      "Epoch 7690/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 67.7830 - val_loss: 13.3413\n",
      "Epoch 7691/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 111.4702 - val_loss: 13.2781\n",
      "Epoch 7692/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 64.7465 - val_loss: 13.2259\n",
      "Epoch 7693/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 82.2185 - val_loss: 13.1798\n",
      "Epoch 7694/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 71.9335 - val_loss: 13.2811\n",
      "Epoch 7695/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 61.3152 - val_loss: 13.4055\n",
      "Epoch 7696/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 78.3840 - val_loss: 13.5644\n",
      "Epoch 7697/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 72.3359 - val_loss: 13.4942\n",
      "Epoch 7698/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 91.3287 - val_loss: 13.5450\n",
      "Epoch 7699/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 63.0816 - val_loss: 13.6096\n",
      "Epoch 7700/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 59.6125 - val_loss: 13.5436\n",
      "\n",
      "Epoch 07700: loss did not improve from 56.74038\n",
      "Epoch 7701/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 67.5426 - val_loss: 13.5471\n",
      "Epoch 7702/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 62.0780 - val_loss: 13.5874\n",
      "Epoch 7703/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 67.7084 - val_loss: 13.5015\n",
      "Epoch 7704/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 89.5531 - val_loss: 13.5604\n",
      "Epoch 7705/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 56.1308 - val_loss: 13.4628\n",
      "Epoch 7706/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 75.4836 - val_loss: 13.4030\n",
      "Epoch 7707/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 86.6675 - val_loss: 13.4411\n",
      "Epoch 7708/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 57.9666 - val_loss: 13.3193\n",
      "Epoch 7709/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 52.5464 - val_loss: 13.3524\n",
      "Epoch 7710/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 75.4113 - val_loss: 13.2000\n",
      "Epoch 7711/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 56.9067 - val_loss: 13.1580\n",
      "Epoch 7712/10000\n",
      "184/184 [==============================] - 0s 424us/step - loss: 60.1904 - val_loss: 13.1057\n",
      "Epoch 7713/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 63.6908 - val_loss: 13.0341\n",
      "Epoch 7714/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 76.2753 - val_loss: 12.9999\n",
      "Epoch 7715/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 84.9207 - val_loss: 12.9817\n",
      "Epoch 7716/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 73.7334 - val_loss: 12.9646\n",
      "Epoch 7717/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 60.7521 - val_loss: 12.9509\n",
      "Epoch 7718/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 60.9464 - val_loss: 12.9394\n",
      "Epoch 7719/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 68.3987 - val_loss: 12.9305\n",
      "Epoch 7720/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 89.2646 - val_loss: 12.9232\n",
      "Epoch 7721/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 72.1094 - val_loss: 12.9146\n",
      "Epoch 7722/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 62.5816 - val_loss: 12.9096\n",
      "Epoch 7723/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 61.54 - 0s 467us/step - loss: 62.0696 - val_loss: 12.9091\n",
      "Epoch 7724/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 65.5918 - val_loss: 12.8914\n",
      "Epoch 7725/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 67.8523 - val_loss: 12.8625\n",
      "Epoch 7726/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 68.8160 - val_loss: 12.8364\n",
      "Epoch 7727/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 69.1111 - val_loss: 12.8173\n",
      "Epoch 7728/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 61.7043 - val_loss: 12.8042\n",
      "Epoch 7729/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 73.3871 - val_loss: 12.7964\n",
      "Epoch 7730/10000\n",
      "184/184 [==============================] - 0s 573us/step - loss: 65.4971 - val_loss: 12.7893\n",
      "Epoch 7731/10000\n",
      "184/184 [==============================] - 0s 465us/step - loss: 69.8005 - val_loss: 12.7825\n",
      "Epoch 7732/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 65.0528 - val_loss: 12.7711\n",
      "Epoch 7733/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 78.6560 - val_loss: 12.7621\n",
      "Epoch 7734/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 67.0665 - val_loss: 12.7538\n",
      "Epoch 7735/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 78.8945 - val_loss: 12.7476\n",
      "Epoch 7736/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 71.2436 - val_loss: 12.7451\n",
      "Epoch 7737/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 505us/step - loss: 71.3595 - val_loss: 12.7406\n",
      "Epoch 7738/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 73.3647 - val_loss: 12.7362\n",
      "Epoch 7739/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 101.2851 - val_loss: 12.7280\n",
      "Epoch 7740/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 82.3044 - val_loss: 12.7189\n",
      "Epoch 7741/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 66.5186 - val_loss: 12.7150\n",
      "Epoch 7742/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 71.9508 - val_loss: 12.7117\n",
      "Epoch 7743/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 64.6093 - val_loss: 12.7209\n",
      "Epoch 7744/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 63.4884 - val_loss: 12.7295\n",
      "Epoch 7745/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 77.0708 - val_loss: 12.7340\n",
      "Epoch 7746/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 72.8634 - val_loss: 12.7346\n",
      "Epoch 7747/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 84.2665 - val_loss: 12.7345\n",
      "Epoch 7748/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 61.4153 - val_loss: 12.7336\n",
      "Epoch 7749/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 67.5254 - val_loss: 12.7308\n",
      "Epoch 7750/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 63.1909 - val_loss: 12.7240\n",
      "Epoch 7751/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 64.3956 - val_loss: 12.7147\n",
      "Epoch 7752/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 59.5260 - val_loss: 12.7063\n",
      "Epoch 7753/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 60.3902 - val_loss: 12.7042\n",
      "Epoch 7754/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 77.1989 - val_loss: 12.7023\n",
      "Epoch 7755/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 70.1439 - val_loss: 12.7014\n",
      "Epoch 7756/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 76.3223 - val_loss: 12.7011\n",
      "Epoch 7757/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 59.9546 - val_loss: 12.6957\n",
      "Epoch 7758/10000\n",
      "184/184 [==============================] - 0s 503us/step - loss: 59.4943 - val_loss: 12.6897\n",
      "Epoch 7759/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 70.1130 - val_loss: 12.6859\n",
      "Epoch 7760/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 60.1202 - val_loss: 12.6834\n",
      "Epoch 7761/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 57.0582 - val_loss: 12.6840\n",
      "Epoch 7762/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 79.8938 - val_loss: 12.6826\n",
      "Epoch 7763/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 70.8472 - val_loss: 12.6809\n",
      "Epoch 7764/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 67.0260 - val_loss: 12.6791\n",
      "Epoch 7765/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 76.8647 - val_loss: 12.6789\n",
      "Epoch 7766/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 67.0579 - val_loss: 12.6822\n",
      "Epoch 7767/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 82.2988 - val_loss: 12.6842\n",
      "Epoch 7768/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 71.9318 - val_loss: 12.6843\n",
      "Epoch 7769/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 79.2020 - val_loss: 12.6836\n",
      "Epoch 7770/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 64.2688 - val_loss: 12.6808\n",
      "Epoch 7771/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 81.2870 - val_loss: 12.6787\n",
      "Epoch 7772/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 60.5810 - val_loss: 12.6744\n",
      "Epoch 7773/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 78.0859 - val_loss: 12.6513\n",
      "Epoch 7774/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 69.7649 - val_loss: 12.6250\n",
      "Epoch 7775/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 77.6441 - val_loss: 12.6091\n",
      "Epoch 7776/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 74.2019 - val_loss: 12.5963\n",
      "Epoch 7777/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 75.1204 - val_loss: 12.5834\n",
      "Epoch 7778/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 63.3821 - val_loss: 12.5761\n",
      "Epoch 7779/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 72.0281 - val_loss: 12.5502\n",
      "Epoch 7780/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 67.5275 - val_loss: 12.5382\n",
      "Epoch 7781/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 68.9895 - val_loss: 12.5331\n",
      "Epoch 7782/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 63.3362 - val_loss: 12.5323\n",
      "Epoch 7783/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 66.1696 - val_loss: 12.5325\n",
      "Epoch 7784/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 67.9881 - val_loss: 12.5310\n",
      "Epoch 7785/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 64.3837 - val_loss: 12.5330\n",
      "Epoch 7786/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 81.5244 - val_loss: 12.5386\n",
      "Epoch 7787/10000\n",
      "184/184 [==============================] - 0s 581us/step - loss: 65.8870 - val_loss: 12.5446\n",
      "Epoch 7788/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 74.4559 - val_loss: 12.5390\n",
      "Epoch 7789/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 55.6973 - val_loss: 12.5338\n",
      "Epoch 7790/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 77.2035 - val_loss: 12.5303\n",
      "Epoch 7791/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 67.6543 - val_loss: 12.5279\n",
      "Epoch 7792/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 65.2004 - val_loss: 12.5243\n",
      "Epoch 7793/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 56.0178 - val_loss: 12.5203\n",
      "Epoch 7794/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 52.4157 - val_loss: 12.5165\n",
      "Epoch 7795/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 64.4903 - val_loss: 12.5128\n",
      "Epoch 7796/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 61.0286 - val_loss: 12.5245\n",
      "Epoch 7797/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 59.2736 - val_loss: 12.5424\n",
      "Epoch 7798/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 62.3692 - val_loss: 12.5804\n",
      "Epoch 7799/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 69.6305 - val_loss: 12.6127\n",
      "Epoch 7800/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 63.9195 - val_loss: 12.6381\n",
      "\n",
      "Epoch 07800: loss did not improve from 56.74038\n",
      "Epoch 7801/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 69.4643 - val_loss: 12.6811\n",
      "Epoch 7802/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 65.1836 - val_loss: 12.6926\n",
      "Epoch 7803/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 72.4077 - val_loss: 12.6994\n",
      "Epoch 7804/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 58.7653 - val_loss: 12.6988\n",
      "Epoch 7805/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 62.4700 - val_loss: 12.6994\n",
      "Epoch 7806/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 62.5625 - val_loss: 12.7109\n",
      "Epoch 7807/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 62.1004 - val_loss: 12.7274\n",
      "Epoch 7808/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 73.5188 - val_loss: 12.7434\n",
      "Epoch 7809/10000\n",
      "184/184 [==============================] - 0s 494us/step - loss: 58.6386 - val_loss: 12.7559\n",
      "Epoch 7810/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 59.0870 - val_loss: 12.7739\n",
      "Epoch 7811/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 467us/step - loss: 68.6335 - val_loss: 12.7154\n",
      "Epoch 7812/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 65.7896 - val_loss: 12.7172\n",
      "Epoch 7813/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 83.5433 - val_loss: 12.7613\n",
      "Epoch 7814/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 76.8873 - val_loss: 12.8141\n",
      "Epoch 7815/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 78.7302 - val_loss: 12.7915\n",
      "Epoch 7816/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 59.6661 - val_loss: 12.7689\n",
      "Epoch 7817/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 64.1009 - val_loss: 12.7926\n",
      "Epoch 7818/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 56.9713 - val_loss: 12.7999\n",
      "Epoch 7819/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 70.6797 - val_loss: 12.7103\n",
      "Epoch 7820/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 64.3915 - val_loss: 12.6649\n",
      "Epoch 7821/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 63.1555 - val_loss: 12.8470\n",
      "Epoch 7822/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 84.1128 - val_loss: 12.9207\n",
      "Epoch 7823/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 67.1470 - val_loss: 12.8662\n",
      "Epoch 7824/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 82.3478 - val_loss: 12.7846\n",
      "Epoch 7825/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 53.99 - 0s 516us/step - loss: 49.5545 - val_loss: 12.8117\n",
      "Epoch 7826/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 73.8940 - val_loss: 12.8995\n",
      "Epoch 7827/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 76.1375 - val_loss: 13.0108\n",
      "Epoch 7828/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 60.5019 - val_loss: 13.1226\n",
      "Epoch 7829/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 62.2884 - val_loss: 13.1471\n",
      "Epoch 7830/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 53.9278 - val_loss: 13.1273\n",
      "Epoch 7831/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 78.4369 - val_loss: 13.1355\n",
      "Epoch 7832/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 60.3220 - val_loss: 13.1406\n",
      "Epoch 7833/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 71.7572 - val_loss: 13.1374\n",
      "Epoch 7834/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 86.2487 - val_loss: 13.1355\n",
      "Epoch 7835/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 75.7536 - val_loss: 13.1284\n",
      "Epoch 7836/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 75.5323 - val_loss: 13.1203\n",
      "Epoch 7837/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 71.9520 - val_loss: 13.1093\n",
      "Epoch 7838/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 73.2771 - val_loss: 13.0765\n",
      "Epoch 7839/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 64.4186 - val_loss: 13.0860\n",
      "Epoch 7840/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 65.1749 - val_loss: 13.0729\n",
      "Epoch 7841/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 50.3554 - val_loss: 13.0498\n",
      "Epoch 7842/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 61.6703 - val_loss: 13.0423\n",
      "Epoch 7843/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 75.7511 - val_loss: 13.0758\n",
      "Epoch 7844/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 69.2300 - val_loss: 13.0227\n",
      "Epoch 7845/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 72.4168 - val_loss: 13.0406\n",
      "Epoch 7846/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 78.6078 - val_loss: 13.0151\n",
      "Epoch 7847/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 72.2519 - val_loss: 13.0202\n",
      "Epoch 7848/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 46.4167 - val_loss: 13.0301\n",
      "Epoch 7849/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 67.6303 - val_loss: 13.0058\n",
      "Epoch 7850/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 62.1332 - val_loss: 12.9944\n",
      "Epoch 7851/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 90.3146 - val_loss: 13.0128\n",
      "Epoch 7852/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 64.0272 - val_loss: 13.0081\n",
      "Epoch 7853/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 79.3085 - val_loss: 13.0003\n",
      "Epoch 7854/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 78.3410 - val_loss: 12.9879\n",
      "Epoch 7855/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 61.1214 - val_loss: 12.9782\n",
      "Epoch 7856/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 55.1142 - val_loss: 12.9479\n",
      "Epoch 7857/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 69.1853 - val_loss: 12.8509\n",
      "Epoch 7858/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 64.6892 - val_loss: 12.8229\n",
      "Epoch 7859/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 51.9440 - val_loss: 12.8005\n",
      "Epoch 7860/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 65.8983 - val_loss: 12.7847\n",
      "Epoch 7861/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 67.5982 - val_loss: 12.8049\n",
      "Epoch 7862/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 59.2938 - val_loss: 12.8270\n",
      "Epoch 7863/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 64.61 - 0s 478us/step - loss: 61.6650 - val_loss: 12.8304\n",
      "Epoch 7864/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 64.6440 - val_loss: 12.8219\n",
      "Epoch 7865/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 78.6410 - val_loss: 12.9384\n",
      "Epoch 7866/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 54.1953 - val_loss: 12.9094\n",
      "Epoch 7867/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 76.4727 - val_loss: 12.9192\n",
      "Epoch 7868/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 74.2093 - val_loss: 12.9675\n",
      "Epoch 7869/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 89.6242 - val_loss: 12.9682\n",
      "Epoch 7870/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 64.8091 - val_loss: 12.9671\n",
      "Epoch 7871/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 66.8921 - val_loss: 12.9662\n",
      "Epoch 7872/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 67.0636 - val_loss: 12.9666\n",
      "Epoch 7873/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 75.7284 - val_loss: 12.9622\n",
      "Epoch 7874/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 58.3257 - val_loss: 12.9570\n",
      "Epoch 7875/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 54.8985 - val_loss: 12.9568\n",
      "Epoch 7876/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 64.3423 - val_loss: 12.9552\n",
      "Epoch 7877/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 62.3956 - val_loss: 12.9522\n",
      "Epoch 7878/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 74.4909 - val_loss: 12.9536\n",
      "Epoch 7879/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 68.0214 - val_loss: 12.9464\n",
      "Epoch 7880/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 70.4660 - val_loss: 12.9214\n",
      "Epoch 7881/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 66.9683 - val_loss: 12.8648\n",
      "Epoch 7882/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 84.5402 - val_loss: 12.8809\n",
      "Epoch 7883/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 69.5665 - val_loss: 12.9434\n",
      "Epoch 7884/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 82.7248 - val_loss: 12.9636\n",
      "Epoch 7885/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 489us/step - loss: 79.8917 - val_loss: 12.9531\n",
      "Epoch 7886/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 77.4906 - val_loss: 12.8060\n",
      "Epoch 7887/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 63.3318 - val_loss: 12.3412\n",
      "Epoch 7888/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 53.1523 - val_loss: 12.2323\n",
      "Epoch 7889/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 70.7442 - val_loss: 12.2453\n",
      "Epoch 7890/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 58.0178 - val_loss: 12.3087\n",
      "Epoch 7891/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 61.2660 - val_loss: 12.3481\n",
      "Epoch 7892/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 77.8952 - val_loss: 12.3536\n",
      "Epoch 7893/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 67.9874 - val_loss: 12.3605\n",
      "Epoch 7894/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 64.0351 - val_loss: 12.3729\n",
      "Epoch 7895/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 65.6399 - val_loss: 12.3957\n",
      "Epoch 7896/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 74.4548 - val_loss: 12.4292\n",
      "Epoch 7897/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 58.9726 - val_loss: 12.4477\n",
      "Epoch 7898/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 68.7239 - val_loss: 12.4655\n",
      "Epoch 7899/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 61.8434 - val_loss: 12.4818\n",
      "Epoch 7900/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 60.9122 - val_loss: 12.4936\n",
      "\n",
      "Epoch 07900: loss did not improve from 56.74038\n",
      "Epoch 7901/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 57.3779 - val_loss: 12.4950\n",
      "Epoch 7902/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 67.5547 - val_loss: 12.4782\n",
      "Epoch 7903/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 58.2070 - val_loss: 12.4638\n",
      "Epoch 7904/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 67.7023 - val_loss: 12.4355\n",
      "Epoch 7905/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 63.6878 - val_loss: 12.4042\n",
      "Epoch 7906/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 66.7319 - val_loss: 12.3756\n",
      "Epoch 7907/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 98.2888 - val_loss: 12.3743\n",
      "Epoch 7908/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 62.1084 - val_loss: 12.3851\n",
      "Epoch 7909/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 63.1980 - val_loss: 12.3949\n",
      "Epoch 7910/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 77.3812 - val_loss: 12.4038\n",
      "Epoch 7911/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 69.2199 - val_loss: 12.4025\n",
      "Epoch 7912/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 81.1763 - val_loss: 12.4032\n",
      "Epoch 7913/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 75.0075 - val_loss: 12.4144\n",
      "Epoch 7914/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 55.8243 - val_loss: 12.4260\n",
      "Epoch 7915/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 62.6111 - val_loss: 12.4337\n",
      "Epoch 7916/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 62.1646 - val_loss: 12.4378\n",
      "Epoch 7917/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 80.8035 - val_loss: 12.4411\n",
      "Epoch 7918/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 65.1030 - val_loss: 12.4436\n",
      "Epoch 7919/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 76.0354 - val_loss: 12.4445\n",
      "Epoch 7920/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 63.8691 - val_loss: 12.4446\n",
      "Epoch 7921/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 74.3675 - val_loss: 12.4484\n",
      "Epoch 7922/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 66.1096 - val_loss: 12.4479\n",
      "Epoch 7923/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 77.2303 - val_loss: 12.4455\n",
      "Epoch 7924/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 62.1375 - val_loss: 12.4436\n",
      "Epoch 7925/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 65.8654 - val_loss: 12.4410\n",
      "Epoch 7926/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 88.9276 - val_loss: 12.4389\n",
      "Epoch 7927/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 71.9400 - val_loss: 12.4360\n",
      "Epoch 7928/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 75.0639 - val_loss: 12.4293\n",
      "Epoch 7929/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 67.93 - 0s 489us/step - loss: 71.5252 - val_loss: 12.4257\n",
      "Epoch 7930/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 50.8256 - val_loss: 12.4264\n",
      "Epoch 7931/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 67.8437 - val_loss: 12.4259\n",
      "Epoch 7932/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 64.5964 - val_loss: 12.4230\n",
      "Epoch 7933/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 70.3074 - val_loss: 12.4045\n",
      "Epoch 7934/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 67.3125 - val_loss: 12.3891\n",
      "Epoch 7935/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 67.6287 - val_loss: 12.3750\n",
      "Epoch 7936/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 67.8111 - val_loss: 12.3618\n",
      "Epoch 7937/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 68.8071 - val_loss: 12.3523\n",
      "Epoch 7938/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 60.2342 - val_loss: 12.3458\n",
      "Epoch 7939/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 71.5484 - val_loss: 12.3397\n",
      "Epoch 7940/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 62.8152 - val_loss: 12.3320\n",
      "Epoch 7941/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 79.1166 - val_loss: 12.3240\n",
      "Epoch 7942/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 68.3018 - val_loss: 12.3149\n",
      "Epoch 7943/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 65.5492 - val_loss: 12.3058\n",
      "Epoch 7944/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 80.8394 - val_loss: 12.2969\n",
      "Epoch 7945/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 55.1819 - val_loss: 12.2879\n",
      "Epoch 7946/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 67.4289 - val_loss: 12.2824\n",
      "Epoch 7947/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 65.9692 - val_loss: 12.2679\n",
      "Epoch 7948/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 53.3583 - val_loss: 12.2514\n",
      "Epoch 7949/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 53.1822 - val_loss: 12.2361\n",
      "Epoch 7950/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 62.9278 - val_loss: 12.2832\n",
      "Epoch 7951/10000\n",
      "184/184 [==============================] - 0s 581us/step - loss: 77.1582 - val_loss: 12.3024\n",
      "Epoch 7952/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 67.9520 - val_loss: 12.3175\n",
      "Epoch 7953/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 65.0399 - val_loss: 12.3225\n",
      "Epoch 7954/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 78.0052 - val_loss: 12.3214\n",
      "Epoch 7955/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 61.9937 - val_loss: 12.3165\n",
      "Epoch 7956/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 74.8452 - val_loss: 12.3142\n",
      "Epoch 7957/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 67.6263 - val_loss: 12.3100\n",
      "Epoch 7958/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 58.3757 - val_loss: 12.3033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7959/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 70.9390 - val_loss: 12.2952\n",
      "Epoch 7960/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 63.7670 - val_loss: 12.2821\n",
      "Epoch 7961/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 72.3673 - val_loss: 12.2653\n",
      "Epoch 7962/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 62.3767 - val_loss: 12.2439\n",
      "Epoch 7963/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 63.2526 - val_loss: 12.2152\n",
      "Epoch 7964/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 67.97 - 0s 495us/step - loss: 66.7986 - val_loss: 12.1855\n",
      "Epoch 7965/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 79.4120 - val_loss: 12.1644\n",
      "Epoch 7966/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 73.2075 - val_loss: 12.1441\n",
      "Epoch 7967/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 66.5036 - val_loss: 12.1414\n",
      "Epoch 7968/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 66.4117 - val_loss: 12.1452\n",
      "Epoch 7969/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 78.3453 - val_loss: 12.2093\n",
      "Epoch 7970/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 64.0913 - val_loss: 12.2545\n",
      "Epoch 7971/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 54.3847 - val_loss: 12.2813\n",
      "Epoch 7972/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 59.7313 - val_loss: 12.2972\n",
      "Epoch 7973/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 58.0526 - val_loss: 12.3025\n",
      "Epoch 7974/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 68.8992 - val_loss: 12.2973\n",
      "Epoch 7975/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 59.7003 - val_loss: 12.2683\n",
      "Epoch 7976/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 58.7493 - val_loss: 12.2390\n",
      "Epoch 7977/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 64.8611 - val_loss: 12.2120\n",
      "Epoch 7978/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 63.6935 - val_loss: 12.1829\n",
      "Epoch 7979/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 82.0649 - val_loss: 12.1598\n",
      "Epoch 7980/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 68.6818 - val_loss: 12.1418\n",
      "Epoch 7981/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 58.3623 - val_loss: 12.1231\n",
      "Epoch 7982/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 78.6479 - val_loss: 12.0980\n",
      "Epoch 7983/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 64.7356 - val_loss: 12.0798\n",
      "Epoch 7984/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 62.6463 - val_loss: 12.0681\n",
      "Epoch 7985/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 60.4280 - val_loss: 12.0577\n",
      "Epoch 7986/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 64.5134 - val_loss: 12.0403\n",
      "Epoch 7987/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 65.1770 - val_loss: 12.0225\n",
      "Epoch 7988/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 66.2678 - val_loss: 11.9858\n",
      "Epoch 7989/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 91.4783 - val_loss: 11.9523\n",
      "Epoch 7990/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 65.6037 - val_loss: 11.9337\n",
      "Epoch 7991/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 96.4173 - val_loss: 11.9234\n",
      "Epoch 7992/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 57.3383 - val_loss: 11.9099\n",
      "Epoch 7993/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 60.7245 - val_loss: 11.8952\n",
      "Epoch 7994/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 53.7183 - val_loss: 11.8831\n",
      "Epoch 7995/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 72.9331 - val_loss: 11.8704\n",
      "Epoch 7996/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 72.8445 - val_loss: 11.8657\n",
      "Epoch 7997/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 70.8953 - val_loss: 11.9421\n",
      "Epoch 7998/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 76.0468 - val_loss: 12.0290\n",
      "Epoch 7999/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 77.3116 - val_loss: 12.0507\n",
      "Epoch 8000/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 66.6874 - val_loss: 12.0926\n",
      "\n",
      "Epoch 08000: loss did not improve from 56.74038\n",
      "Epoch 8001/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 55.8986 - val_loss: 12.1166\n",
      "Epoch 8002/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 72.5874 - val_loss: 12.1332\n",
      "Epoch 8003/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 61.6871 - val_loss: 12.1522\n",
      "Epoch 8004/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 61.8274 - val_loss: 12.1656\n",
      "Epoch 8005/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 61.1769 - val_loss: 12.1752\n",
      "Epoch 8006/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 57.5166 - val_loss: 12.1811\n",
      "Epoch 8007/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 57.9645 - val_loss: 12.1851\n",
      "Epoch 8008/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 57.5796 - val_loss: 12.1923\n",
      "Epoch 8009/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 67.8426 - val_loss: 12.2008\n",
      "Epoch 8010/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 58.7897 - val_loss: 12.2100\n",
      "Epoch 8011/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 56.3370 - val_loss: 12.2055\n",
      "Epoch 8012/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 77.8392 - val_loss: 12.2022\n",
      "Epoch 8013/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 67.4473 - val_loss: 12.1975\n",
      "Epoch 8014/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 67.6662 - val_loss: 12.2051\n",
      "Epoch 8015/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 75.9112 - val_loss: 12.2177\n",
      "Epoch 8016/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 62.6800 - val_loss: 12.2266\n",
      "Epoch 8017/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 72.9189 - val_loss: 12.2204\n",
      "Epoch 8018/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 61.7102 - val_loss: 12.2122\n",
      "Epoch 8019/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 57.0140 - val_loss: 12.1972\n",
      "Epoch 8020/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 56.6499 - val_loss: 12.1749\n",
      "Epoch 8021/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 56.8570 - val_loss: 12.1522\n",
      "Epoch 8022/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 73.3801 - val_loss: 12.1333\n",
      "Epoch 8023/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 76.7826 - val_loss: 12.1195\n",
      "Epoch 8024/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 53.6562 - val_loss: 12.0982\n",
      "Epoch 8025/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 87.8603 - val_loss: 12.0751\n",
      "Epoch 8026/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 78.5667 - val_loss: 12.0497\n",
      "Epoch 8027/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 49.1275 - val_loss: 12.1224\n",
      "Epoch 8028/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 66.2321 - val_loss: 12.2095\n",
      "Epoch 8029/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 67.2300 - val_loss: 12.2405\n",
      "Epoch 8030/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 68.6903 - val_loss: 12.2493\n",
      "Epoch 8031/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 66.1491 - val_loss: 12.2366\n",
      "Epoch 8032/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 51.3559 - val_loss: 12.1911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8033/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 72.3735 - val_loss: 12.1073\n",
      "Epoch 8034/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 71.0375 - val_loss: 12.0570\n",
      "Epoch 8035/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 57.5293 - val_loss: 12.0240\n",
      "Epoch 8036/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 84.5576 - val_loss: 12.0357\n",
      "Epoch 8037/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 66.9241 - val_loss: 12.0516\n",
      "Epoch 8038/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 65.5583 - val_loss: 12.0610\n",
      "Epoch 8039/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 73.9815 - val_loss: 12.0853\n",
      "Epoch 8040/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 66.3167 - val_loss: 12.0589\n",
      "Epoch 8041/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 68.7697 - val_loss: 12.0249\n",
      "Epoch 8042/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 56.3115 - val_loss: 11.9830\n",
      "Epoch 8043/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 63.9839 - val_loss: 11.9560\n",
      "Epoch 8044/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 63.1395 - val_loss: 11.9394\n",
      "Epoch 8045/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 90.5259 - val_loss: 11.9246\n",
      "Epoch 8046/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 55.9387 - val_loss: 11.9310\n",
      "Epoch 8047/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 59.3229 - val_loss: 11.9334\n",
      "Epoch 8048/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 53.0234 - val_loss: 11.9314\n",
      "Epoch 8049/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 57.9302 - val_loss: 11.9329\n",
      "Epoch 8050/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 50.9182 - val_loss: 11.9389\n",
      "Epoch 8051/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 60.7309 - val_loss: 11.9395\n",
      "Epoch 8052/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 66.0195 - val_loss: 11.9480\n",
      "Epoch 8053/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 71.0649 - val_loss: 11.9407\n",
      "Epoch 8054/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 70.6327 - val_loss: 11.9322\n",
      "Epoch 8055/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 61.3745 - val_loss: 11.9231\n",
      "Epoch 8056/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 70.5173 - val_loss: 11.9160\n",
      "Epoch 8057/10000\n",
      "184/184 [==============================] - 0s 456us/step - loss: 56.0458 - val_loss: 12.1571\n",
      "Epoch 8058/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 82.4469 - val_loss: 12.0422\n",
      "Epoch 8059/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 62.4706 - val_loss: 11.8199\n",
      "Epoch 8060/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 59.4186 - val_loss: 11.7113\n",
      "Epoch 8061/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 67.1926 - val_loss: 11.6487\n",
      "Epoch 8062/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 56.1207 - val_loss: 11.6059\n",
      "Epoch 8063/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 69.2757 - val_loss: 11.5856\n",
      "Epoch 8064/10000\n",
      "184/184 [==============================] - 0s 783us/step - loss: 87.0833 - val_loss: 11.5712\n",
      "Epoch 8065/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 95.0477 - val_loss: 11.9696\n",
      "Epoch 8066/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 79.2237 - val_loss: 12.0470\n",
      "Epoch 8067/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 69.4345 - val_loss: 11.9662\n",
      "Epoch 8068/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 66.3289 - val_loss: 11.8881\n",
      "Epoch 8069/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 57.1225 - val_loss: 11.8402\n",
      "Epoch 8070/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 63.6123 - val_loss: 11.8140\n",
      "Epoch 8071/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 61.6015 - val_loss: 11.7231\n",
      "Epoch 8072/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 75.7384 - val_loss: 11.4748\n",
      "Epoch 8073/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 75.3383 - val_loss: 11.4085\n",
      "Epoch 8074/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 67.9526 - val_loss: 11.1726\n",
      "Epoch 8075/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 82.5191 - val_loss: 11.1815\n",
      "Epoch 8076/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 70.3013 - val_loss: 11.2051\n",
      "Epoch 8077/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 70.0460 - val_loss: 11.3625\n",
      "Epoch 8078/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 59.2481 - val_loss: 11.3341\n",
      "Epoch 8079/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 78.8446 - val_loss: 11.2907\n",
      "Epoch 8080/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 68.3385 - val_loss: 11.2622\n",
      "Epoch 8081/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 63.0195 - val_loss: 11.2508\n",
      "Epoch 8082/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 74.2585 - val_loss: 11.2524\n",
      "Epoch 8083/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 62.4206 - val_loss: 11.3330\n",
      "Epoch 8084/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 71.2421 - val_loss: 11.1320\n",
      "Epoch 8085/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 50.8066 - val_loss: 11.0845\n",
      "Epoch 8086/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 72.5354 - val_loss: 11.1241\n",
      "Epoch 8087/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 59.0131 - val_loss: 11.0470\n",
      "Epoch 8088/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 53.6090 - val_loss: 11.2939\n",
      "Epoch 8089/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 52.0393 - val_loss: 11.4129\n",
      "Epoch 8090/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 65.0780 - val_loss: 11.2769\n",
      "Epoch 8091/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 70.1998 - val_loss: 11.2786\n",
      "Epoch 8092/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 73.7248 - val_loss: 11.2985\n",
      "Epoch 8093/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 67.0037 - val_loss: 11.3217\n",
      "Epoch 8094/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 62.9812 - val_loss: 11.3452\n",
      "Epoch 8095/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 88.4843 - val_loss: 11.3822\n",
      "Epoch 8096/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 60.2306 - val_loss: 11.4095\n",
      "Epoch 8097/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 79.0098 - val_loss: 11.4308\n",
      "Epoch 8098/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 58.0327 - val_loss: 11.4705\n",
      "Epoch 8099/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 63.8642 - val_loss: 11.4854\n",
      "Epoch 8100/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 65.5613 - val_loss: 11.4751\n",
      "\n",
      "Epoch 08100: loss did not improve from 56.74038\n",
      "Epoch 8101/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 66.9284 - val_loss: 11.5783\n",
      "Epoch 8102/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 70.3970 - val_loss: 11.5516\n",
      "Epoch 8103/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 70.1761 - val_loss: 11.5649\n",
      "Epoch 8104/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 61.3370 - val_loss: 11.5793\n",
      "Epoch 8105/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 50.1486 - val_loss: 11.5582\n",
      "Epoch 8106/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 73.1300 - val_loss: 11.5526\n",
      "Epoch 8107/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 489us/step - loss: 68.6572 - val_loss: 11.5468\n",
      "Epoch 8108/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 77.8079 - val_loss: 11.5428\n",
      "Epoch 8109/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 70.1658 - val_loss: 11.5362\n",
      "Epoch 8110/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 60.2039 - val_loss: 11.5345\n",
      "Epoch 8111/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 56.4021 - val_loss: 11.5389\n",
      "Epoch 8112/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 62.8692 - val_loss: 11.5416\n",
      "Epoch 8113/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 91.8324 - val_loss: 11.5360\n",
      "Epoch 8114/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 87.4269 - val_loss: 11.5166\n",
      "Epoch 8115/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 57.2093 - val_loss: 11.3222\n",
      "Epoch 8116/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 62.7975 - val_loss: 11.2784\n",
      "Epoch 8117/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 78.4891 - val_loss: 11.2065\n",
      "Epoch 8118/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 94.0978 - val_loss: 11.0349\n",
      "Epoch 8119/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 56.7194 - val_loss: 10.9427\n",
      "Epoch 8120/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 65.7283 - val_loss: 10.8579\n",
      "Epoch 8121/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 70.2305 - val_loss: 10.9264\n",
      "Epoch 8122/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 66.1675 - val_loss: 10.9811\n",
      "Epoch 8123/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 54.9325 - val_loss: 10.9635\n",
      "Epoch 8124/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 71.2941 - val_loss: 10.9485\n",
      "Epoch 8125/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 75.7028 - val_loss: 10.9627\n",
      "Epoch 8126/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 66.9440 - val_loss: 10.8527\n",
      "Epoch 8127/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 62.7705 - val_loss: 10.8723\n",
      "Epoch 8128/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 66.1237 - val_loss: 10.9213\n",
      "Epoch 8129/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 74.3803 - val_loss: 11.2493\n",
      "Epoch 8130/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 75.0029 - val_loss: 11.1003\n",
      "Epoch 8131/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 57.4850 - val_loss: 11.2840\n",
      "Epoch 8132/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 58.8972 - val_loss: 10.9516\n",
      "Epoch 8133/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 60.8943 - val_loss: 11.0064\n",
      "Epoch 8134/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 56.7661 - val_loss: 11.0823\n",
      "Epoch 8135/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 77.6705 - val_loss: 11.2767\n",
      "Epoch 8136/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 66.8546 - val_loss: 11.2445\n",
      "Epoch 8137/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 58.3029 - val_loss: 11.2593\n",
      "Epoch 8138/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 50.1249 - val_loss: 11.2559\n",
      "Epoch 8139/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 66.6968 - val_loss: 11.2126\n",
      "Epoch 8140/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 67.3404 - val_loss: 11.1346\n",
      "Epoch 8141/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 79.1412 - val_loss: 11.1496\n",
      "Epoch 8142/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 57.5461 - val_loss: 11.1602\n",
      "Epoch 8143/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 69.4419 - val_loss: 11.1677\n",
      "Epoch 8144/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 55.3271 - val_loss: 11.1762\n",
      "Epoch 8145/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 69.2516 - val_loss: 11.1739\n",
      "Epoch 8146/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 59.5162 - val_loss: 11.1748\n",
      "Epoch 8147/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 56.5381 - val_loss: 11.1768\n",
      "Epoch 8148/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 58.0787 - val_loss: 11.1786\n",
      "Epoch 8149/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 67.2352 - val_loss: 11.1833\n",
      "Epoch 8150/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 62.3208 - val_loss: 11.1825\n",
      "Epoch 8151/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 54.2496 - val_loss: 11.1824\n",
      "Epoch 8152/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 71.1967 - val_loss: 11.1862\n",
      "Epoch 8153/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 80.2925 - val_loss: 11.1858\n",
      "Epoch 8154/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 61.9038 - val_loss: 11.1849\n",
      "Epoch 8155/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 64.6282 - val_loss: 11.1538\n",
      "Epoch 8156/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 64.2489 - val_loss: 11.1878\n",
      "Epoch 8157/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 63.1582 - val_loss: 11.1977\n",
      "Epoch 8158/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 47.6828 - val_loss: 11.2031\n",
      "Epoch 8159/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 76.8832 - val_loss: 11.1887\n",
      "Epoch 8160/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 68.6167 - val_loss: 11.1746\n",
      "Epoch 8161/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 76.1345 - val_loss: 11.1679\n",
      "Epoch 8162/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 75.1146 - val_loss: 11.1614\n",
      "Epoch 8163/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 54.7560 - val_loss: 11.1578\n",
      "Epoch 8164/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 48.0095 - val_loss: 11.1553\n",
      "Epoch 8165/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 64.2004 - val_loss: 11.1543\n",
      "Epoch 8166/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 72.8499 - val_loss: 11.1502\n",
      "Epoch 8167/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 62.4293 - val_loss: 11.1452\n",
      "Epoch 8168/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 58.2768 - val_loss: 11.1394\n",
      "Epoch 8169/10000\n",
      "184/184 [==============================] - 0s 908us/step - loss: 67.8112 - val_loss: 11.1324\n",
      "Epoch 8170/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 63.8265 - val_loss: 11.1231\n",
      "Epoch 8171/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 62.4323 - val_loss: 11.1112\n",
      "Epoch 8172/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 72.9808 - val_loss: 11.1028\n",
      "Epoch 8173/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 59.0796 - val_loss: 11.0911\n",
      "Epoch 8174/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 68.5089 - val_loss: 11.1112\n",
      "Epoch 8175/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 57.3212 - val_loss: 11.1119\n",
      "Epoch 8176/10000\n",
      "184/184 [==============================] - 0s 642us/step - loss: 73.1023 - val_loss: 11.1095\n",
      "Epoch 8177/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 66.0268 - val_loss: 11.1138\n",
      "Epoch 8178/10000\n",
      "184/184 [==============================] - 0s 755us/step - loss: 66.1586 - val_loss: 11.1338\n",
      "Epoch 8179/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 62.8733 - val_loss: 11.0937\n",
      "Epoch 8180/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 63.0811 - val_loss: 11.0393\n",
      "Epoch 8181/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 620us/step - loss: 52.8543 - val_loss: 11.0131\n",
      "Epoch 8182/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 65.2564 - val_loss: 10.9978\n",
      "Epoch 8183/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 50.3420 - val_loss: 10.9864\n",
      "Epoch 8184/10000\n",
      "184/184 [==============================] - 0s 815us/step - loss: 82.5399 - val_loss: 10.9800\n",
      "Epoch 8185/10000\n",
      "184/184 [==============================] - 0s 793us/step - loss: 72.9075 - val_loss: 10.9679\n",
      "Epoch 8186/10000\n",
      "184/184 [==============================] - 0s 853us/step - loss: 77.9815 - val_loss: 11.0326\n",
      "Epoch 8187/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 71.9223 - val_loss: 11.0674\n",
      "Epoch 8188/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 63.3412 - val_loss: 11.0751\n",
      "Epoch 8189/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 70.4715 - val_loss: 11.1464\n",
      "Epoch 8190/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 52.4350 - val_loss: 11.1734\n",
      "Epoch 8191/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 61.8505 - val_loss: 11.1533\n",
      "Epoch 8192/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 55.0859 - val_loss: 10.9503\n",
      "Epoch 8193/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 82.2696 - val_loss: 11.1174\n",
      "Epoch 8194/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 56.3441 - val_loss: 11.1077\n",
      "Epoch 8195/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 61.4216 - val_loss: 10.9951\n",
      "Epoch 8196/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 60.2438 - val_loss: 11.0324\n",
      "Epoch 8197/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 49.3748 - val_loss: 11.0408\n",
      "Epoch 8198/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 86.1314 - val_loss: 11.0335\n",
      "Epoch 8199/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 57.3310 - val_loss: 10.9895\n",
      "Epoch 8200/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 61.8646 - val_loss: 10.9599\n",
      "\n",
      "Epoch 08200: loss did not improve from 56.74038\n",
      "Epoch 8201/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 65.2138 - val_loss: 10.9937\n",
      "Epoch 8202/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 65.4523 - val_loss: 11.0032\n",
      "Epoch 8203/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 63.8497 - val_loss: 10.9984\n",
      "Epoch 8204/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 49.4416 - val_loss: 10.9934\n",
      "Epoch 8205/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 65.4273 - val_loss: 10.9868\n",
      "Epoch 8206/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 65.1291 - val_loss: 10.9737\n",
      "Epoch 8207/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 64.7688 - val_loss: 10.9573\n",
      "Epoch 8208/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 76.7709 - val_loss: 10.9519\n",
      "Epoch 8209/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 61.8688 - val_loss: 10.9400\n",
      "Epoch 8210/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 75.4493 - val_loss: 10.9235\n",
      "Epoch 8211/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 68.1190 - val_loss: 10.9077\n",
      "Epoch 8212/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 88.6899 - val_loss: 10.9087\n",
      "Epoch 8213/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 57.7809 - val_loss: 10.8796\n",
      "Epoch 8214/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 69.7554 - val_loss: 10.8654\n",
      "Epoch 8215/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 81.9068 - val_loss: 10.8302\n",
      "Epoch 8216/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 63.1478 - val_loss: 10.8901\n",
      "Epoch 8217/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 81.8739 - val_loss: 10.9354\n",
      "Epoch 8218/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 72.1904 - val_loss: 10.8325\n",
      "Epoch 8219/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 69.1464 - val_loss: 10.7669\n",
      "Epoch 8220/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 63.3532 - val_loss: 10.7743\n",
      "Epoch 8221/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 73.8094 - val_loss: 10.7601\n",
      "Epoch 8222/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 55.9357 - val_loss: 10.7196\n",
      "Epoch 8223/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 48.8316 - val_loss: 10.7097\n",
      "Epoch 8224/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 65.7288 - val_loss: 10.7075\n",
      "Epoch 8225/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 63.7845 - val_loss: 10.7041\n",
      "Epoch 8226/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 81.1999 - val_loss: 10.6923\n",
      "Epoch 8227/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 71.2048 - val_loss: 10.7560\n",
      "Epoch 8228/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 68.6764 - val_loss: 10.8855\n",
      "Epoch 8229/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 58.8741 - val_loss: 10.9260\n",
      "Epoch 8230/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 89.3989 - val_loss: 11.2024\n",
      "Epoch 8231/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 66.5931 - val_loss: 10.7891\n",
      "Epoch 8232/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 54.8572 - val_loss: 10.8683\n",
      "Epoch 8233/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 60.3215 - val_loss: 10.8646\n",
      "Epoch 8234/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 71.2398 - val_loss: 10.8661\n",
      "Epoch 8235/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 68.9962 - val_loss: 10.8540\n",
      "Epoch 8236/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 65.8954 - val_loss: 10.8991\n",
      "Epoch 8237/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 79.3893 - val_loss: 10.6996\n",
      "Epoch 8238/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 60.8595 - val_loss: 10.5883\n",
      "Epoch 8239/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 52.1651 - val_loss: 10.5525\n",
      "Epoch 8240/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 56.4943 - val_loss: 10.5900\n",
      "Epoch 8241/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 64.2662 - val_loss: 10.6038\n",
      "Epoch 8242/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 72.3776 - val_loss: 10.6001\n",
      "Epoch 8243/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 56.2392 - val_loss: 10.5865\n",
      "Epoch 8244/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 66.4213 - val_loss: 10.5771\n",
      "Epoch 8245/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 80.0850 - val_loss: 10.5689\n",
      "Epoch 8246/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 57.0108 - val_loss: 10.5633\n",
      "Epoch 8247/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 60.3237 - val_loss: 10.6412\n",
      "Epoch 8248/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 62.2872 - val_loss: 10.6739\n",
      "Epoch 8249/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 73.3355 - val_loss: 10.7109\n",
      "Epoch 8250/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 62.0513 - val_loss: 10.7459\n",
      "Epoch 8251/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 90.8955 - val_loss: 10.7917\n",
      "Epoch 8252/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 74.9940 - val_loss: 10.7874\n",
      "Epoch 8253/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 75.1425 - val_loss: 10.7786\n",
      "Epoch 8254/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 53.2104 - val_loss: 10.7540\n",
      "Epoch 8255/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 511us/step - loss: 61.9326 - val_loss: 10.7148\n",
      "Epoch 8256/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 53.8887 - val_loss: 10.6824\n",
      "Epoch 8257/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 64.0752 - val_loss: 10.6679\n",
      "Epoch 8258/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 68.4596 - val_loss: 10.6543\n",
      "Epoch 8259/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 53.9250 - val_loss: 10.6225\n",
      "Epoch 8260/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 49.3611 - val_loss: 10.5982\n",
      "Epoch 8261/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 59.7989 - val_loss: 10.5812\n",
      "Epoch 8262/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 58.0840 - val_loss: 10.5735\n",
      "Epoch 8263/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 66.8957 - val_loss: 10.5896\n",
      "Epoch 8264/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 48.5541 - val_loss: 10.6031\n",
      "Epoch 8265/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 53.2490 - val_loss: 10.6131\n",
      "Epoch 8266/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 72.2150 - val_loss: 10.6141\n",
      "Epoch 8267/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 64.5681 - val_loss: 10.6116\n",
      "Epoch 8268/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 80.5836 - val_loss: 10.6078\n",
      "Epoch 8269/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 73.9640 - val_loss: 10.6083\n",
      "Epoch 8270/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 64.3696 - val_loss: 10.5962\n",
      "Epoch 8271/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 62.7173 - val_loss: 10.5800\n",
      "Epoch 8272/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 57.6333 - val_loss: 10.5620\n",
      "Epoch 8273/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 61.5412 - val_loss: 10.5490\n",
      "Epoch 8274/10000\n",
      "184/184 [==============================] - 0s 563us/step - loss: 49.1071 - val_loss: 10.5374\n",
      "Epoch 8275/10000\n",
      "184/184 [==============================] - 0s 541us/step - loss: 59.1653 - val_loss: 10.5283\n",
      "Epoch 8276/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 71.2936 - val_loss: 10.5167\n",
      "Epoch 8277/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 60.3131 - val_loss: 10.5052\n",
      "Epoch 8278/10000\n",
      "184/184 [==============================] - 0s 541us/step - loss: 83.1773 - val_loss: 10.4902\n",
      "Epoch 8279/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 62.5476 - val_loss: 10.4582\n",
      "Epoch 8280/10000\n",
      "184/184 [==============================] - 0s 524us/step - loss: 61.7197 - val_loss: 10.4429\n",
      "Epoch 8281/10000\n",
      "184/184 [==============================] - 0s 563us/step - loss: 52.6726 - val_loss: 10.4408\n",
      "Epoch 8282/10000\n",
      "184/184 [==============================] - 0s 601us/step - loss: 71.6660 - val_loss: 10.4282\n",
      "Epoch 8283/10000\n",
      "184/184 [==============================] - 0s 514us/step - loss: 58.7368 - val_loss: 10.4184\n",
      "Epoch 8284/10000\n",
      "184/184 [==============================] - 0s 546us/step - loss: 59.7409 - val_loss: 10.4091\n",
      "Epoch 8285/10000\n",
      "184/184 [==============================] - 0s 497us/step - loss: 62.0583 - val_loss: 10.4025\n",
      "Epoch 8286/10000\n",
      "184/184 [==============================] - 0s 519us/step - loss: 64.6569 - val_loss: 10.3948\n",
      "Epoch 8287/10000\n",
      "184/184 [==============================] - 0s 682us/step - loss: 55.6182 - val_loss: 10.3965\n",
      "Epoch 8288/10000\n",
      "184/184 [==============================] - 0s 756us/step - loss: 52.0435 - val_loss: 10.4010\n",
      "Epoch 8289/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 66.9579 - val_loss: 10.4067\n",
      "Epoch 8290/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 49.3504 - val_loss: 10.4110\n",
      "Epoch 8291/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 57.2462 - val_loss: 10.4134\n",
      "Epoch 8292/10000\n",
      "184/184 [==============================] - 0s 918us/step - loss: 51.2690 - val_loss: 10.4118\n",
      "Epoch 8293/10000\n",
      "184/184 [==============================] - 0s 967us/step - loss: 83.8611 - val_loss: 10.4048\n",
      "Epoch 8294/10000\n",
      "184/184 [==============================] - 0s 864us/step - loss: 63.0788 - val_loss: 10.4011\n",
      "Epoch 8295/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 55.7214 - val_loss: 10.3984\n",
      "Epoch 8296/10000\n",
      "184/184 [==============================] - 0s 967us/step - loss: 71.9121 - val_loss: 10.4021\n",
      "Epoch 8297/10000\n",
      "184/184 [==============================] - 0s 957us/step - loss: 56.2081 - val_loss: 10.3877\n",
      "Epoch 8298/10000\n",
      "184/184 [==============================] - 0s 908us/step - loss: 52.9514 - val_loss: 10.3736\n",
      "Epoch 8299/10000\n",
      "184/184 [==============================] - 0s 761us/step - loss: 63.9251 - val_loss: 10.3590\n",
      "Epoch 8300/10000\n",
      "184/184 [==============================] - 0s 706us/step - loss: 64.8488 - val_loss: 10.3499\n",
      "\n",
      "Epoch 08300: loss did not improve from 56.74038\n",
      "Epoch 8301/10000\n",
      "184/184 [==============================] - 0s 984us/step - loss: 61.9345 - val_loss: 10.3428\n",
      "Epoch 8302/10000\n",
      "184/184 [==============================] - 0s 793us/step - loss: 66.5064 - val_loss: 10.3366\n",
      "Epoch 8303/10000\n",
      "184/184 [==============================] - 0s 769us/step - loss: 69.9859 - val_loss: 10.3455\n",
      "Epoch 8304/10000\n",
      "184/184 [==============================] - 0s 742us/step - loss: 50.5161 - val_loss: 10.3785\n",
      "Epoch 8305/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 63.9579 - val_loss: 10.4023\n",
      "Epoch 8306/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 50.7287 - val_loss: 10.4145\n",
      "Epoch 8307/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 57.3399 - val_loss: 10.4169\n",
      "Epoch 8308/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 75.4554 - val_loss: 10.4250\n",
      "Epoch 8309/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 70.2948 - val_loss: 10.4340\n",
      "Epoch 8310/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 69.6210 - val_loss: 10.4783\n",
      "Epoch 8311/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 54.8354 - val_loss: 10.4742\n",
      "Epoch 8312/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 61.2857 - val_loss: 10.4446\n",
      "Epoch 8313/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 51.5572 - val_loss: 10.5044\n",
      "Epoch 8314/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 50.9791 - val_loss: 10.6127\n",
      "Epoch 8315/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 58.5880 - val_loss: 10.8798\n",
      "Epoch 8316/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 52.6353 - val_loss: 10.9507\n",
      "Epoch 8317/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 68.3742 - val_loss: 11.0102\n",
      "Epoch 8318/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 66.0729 - val_loss: 11.0772\n",
      "Epoch 8319/10000\n",
      "184/184 [==============================] - 0s 940us/step - loss: 46.7835 - val_loss: 11.1176\n",
      "Epoch 8320/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 59.6278 - val_loss: 11.1117\n",
      "Epoch 8321/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 73.7340 - val_loss: 11.1101\n",
      "Epoch 8322/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 61.9071 - val_loss: 11.1160\n",
      "Epoch 8323/10000\n",
      "184/184 [==============================] - 0s 918us/step - loss: 74.1591 - val_loss: 11.1040\n",
      "Epoch 8324/10000\n",
      "184/184 [==============================] - 0s 853us/step - loss: 56.4559 - val_loss: 11.0720\n",
      "Epoch 8325/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 66.5299 - val_loss: 11.0327\n",
      "Epoch 8326/10000\n",
      "184/184 [==============================] - 0s 946us/step - loss: 55.6705 - val_loss: 11.0335\n",
      "Epoch 8327/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 59.0691 - val_loss: 11.0086\n",
      "Epoch 8328/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 51.0738 - val_loss: 11.0183\n",
      "Epoch 8329/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 1ms/step - loss: 63.7724 - val_loss: 11.0164\n",
      "Epoch 8330/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 46.7400 - val_loss: 11.0118\n",
      "Epoch 8331/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 66.5690 - val_loss: 11.0093\n",
      "Epoch 8332/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 59.0770 - val_loss: 11.0088\n",
      "Epoch 8333/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 53.8493 - val_loss: 11.0056\n",
      "Epoch 8334/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 62.2777 - val_loss: 11.0084\n",
      "Epoch 8335/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 74.3003 - val_loss: 10.9995\n",
      "Epoch 8336/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 46.5459 - val_loss: 11.0176\n",
      "Epoch 8337/10000\n",
      "184/184 [==============================] - 0s 946us/step - loss: 69.2998 - val_loss: 11.0035\n",
      "Epoch 8338/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 59.9267 - val_loss: 10.9959\n",
      "Epoch 8339/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 62.4199 - val_loss: 10.9904\n",
      "Epoch 8340/10000\n",
      "184/184 [==============================] - 0s 908us/step - loss: 58.1885 - val_loss: 10.9849\n",
      "Epoch 8341/10000\n",
      "184/184 [==============================] - 0s 788us/step - loss: 45.3310 - val_loss: 10.9779\n",
      "Epoch 8342/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 61.4267 - val_loss: 10.9717\n",
      "Epoch 8343/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 53.8258 - val_loss: 10.9656\n",
      "Epoch 8344/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 54.4304 - val_loss: 10.9591\n",
      "Epoch 8345/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 64.8902 - val_loss: 10.9548\n",
      "Epoch 8346/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 58.8680 - val_loss: 10.9499\n",
      "Epoch 8347/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 47.8473 - val_loss: 10.9459\n",
      "Epoch 8348/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 71.9174 - val_loss: 10.9443\n",
      "Epoch 8349/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 51.2225 - val_loss: 10.9429\n",
      "Epoch 8350/10000\n",
      "184/184 [==============================] - 0s 924us/step - loss: 81.6957 - val_loss: 10.9452\n",
      "Epoch 8351/10000\n",
      "184/184 [==============================] - 0s 913us/step - loss: 75.1486 - val_loss: 10.9462\n",
      "Epoch 8352/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 66.7489 - val_loss: 10.9457\n",
      "Epoch 8353/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 63.7461 - val_loss: 10.9445\n",
      "Epoch 8354/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 59.4980 - val_loss: 10.9437\n",
      "Epoch 8355/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 73.5536 - val_loss: 10.9433\n",
      "Epoch 8356/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 55.4368 - val_loss: 10.9431\n",
      "Epoch 8357/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 72.5872 - val_loss: 10.9406\n",
      "Epoch 8358/10000\n",
      "184/184 [==============================] - 0s 842us/step - loss: 61.2788 - val_loss: 10.9389\n",
      "Epoch 8359/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 79.1264 - val_loss: 10.9364\n",
      "Epoch 8360/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 59.1211 - val_loss: 10.9343\n",
      "Epoch 8361/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 63.6845 - val_loss: 10.9287\n",
      "Epoch 8362/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 58.9011 - val_loss: 10.9222\n",
      "Epoch 8363/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 73.9205 - val_loss: 10.9173\n",
      "Epoch 8364/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 73.7425 - val_loss: 10.9136\n",
      "Epoch 8365/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 62.8650 - val_loss: 10.9079\n",
      "Epoch 8366/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 51.9297 - val_loss: 10.9009\n",
      "Epoch 8367/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 71.2573 - val_loss: 10.8948\n",
      "Epoch 8368/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 78.6941 - val_loss: 10.8913\n",
      "Epoch 8369/10000\n",
      "184/184 [==============================] - 0s 750us/step - loss: 50.4147 - val_loss: 10.8877\n",
      "Epoch 8370/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 62.8190 - val_loss: 10.8841\n",
      "Epoch 8371/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 82.8028 - val_loss: 10.8793\n",
      "Epoch 8372/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 49.9655 - val_loss: 10.8705\n",
      "Epoch 8373/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 66.5724 - val_loss: 10.8617\n",
      "Epoch 8374/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 62.3765 - val_loss: 10.8529\n",
      "Epoch 8375/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 70.1144 - val_loss: 10.8376\n",
      "Epoch 8376/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 73.5763 - val_loss: 10.8124\n",
      "Epoch 8377/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 77.0165 - val_loss: 10.7459\n",
      "Epoch 8378/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 56.5386 - val_loss: 10.7957\n",
      "Epoch 8379/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 75.4497 - val_loss: 10.7892\n",
      "Epoch 8380/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 68.8945 - val_loss: 10.7900\n",
      "Epoch 8381/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 55.4701 - val_loss: 10.7604\n",
      "Epoch 8382/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 49.8374 - val_loss: 10.6578\n",
      "Epoch 8383/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 60.9266 - val_loss: 10.6448\n",
      "Epoch 8384/10000\n",
      "184/184 [==============================] - 0s 783us/step - loss: 58.2245 - val_loss: 10.6427\n",
      "Epoch 8385/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 75.0356 - val_loss: 10.6657\n",
      "Epoch 8386/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 53.7206 - val_loss: 10.6554\n",
      "Epoch 8387/10000\n",
      "184/184 [==============================] - 0s 924us/step - loss: 60.1678 - val_loss: 10.6443\n",
      "Epoch 8388/10000\n",
      "184/184 [==============================] - 0s 810us/step - loss: 51.3540 - val_loss: 10.6376\n",
      "Epoch 8389/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 65.5628 - val_loss: 10.6398\n",
      "Epoch 8390/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 75.7388 - val_loss: 10.6416\n",
      "Epoch 8391/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 58.6510 - val_loss: 10.6428\n",
      "Epoch 8392/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 74.9559 - val_loss: 10.6412\n",
      "Epoch 8393/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 53.1682 - val_loss: 10.6399\n",
      "Epoch 8394/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 51.0727 - val_loss: 10.6360\n",
      "Epoch 8395/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 61.1783 - val_loss: 10.6315\n",
      "Epoch 8396/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 58.3099 - val_loss: 10.6232\n",
      "Epoch 8397/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 49.6998 - val_loss: 10.6100\n",
      "Epoch 8398/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 58.6201 - val_loss: 10.6058\n",
      "Epoch 8399/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 64.6701 - val_loss: 10.6016\n",
      "Epoch 8400/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 69.65 - 0s 908us/step - loss: 67.0533 - val_loss: 10.5976\n",
      "\n",
      "Epoch 08400: loss did not improve from 56.74038\n",
      "Epoch 8401/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 58.0492 - val_loss: 10.5941\n",
      "Epoch 8402/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 59.1246 - val_loss: 10.5832\n",
      "Epoch 8403/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 614us/step - loss: 56.0420 - val_loss: 10.5958\n",
      "Epoch 8404/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 64.8694 - val_loss: 10.5523\n",
      "Epoch 8405/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 61.4297 - val_loss: 10.5474\n",
      "Epoch 8406/10000\n",
      "184/184 [==============================] - 0s 870us/step - loss: 60.4928 - val_loss: 10.5478\n",
      "Epoch 8407/10000\n",
      "184/184 [==============================] - 0s 919us/step - loss: 76.5536 - val_loss: 10.5488\n",
      "Epoch 8408/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 69.2265 - val_loss: 10.5473\n",
      "Epoch 8409/10000\n",
      "184/184 [==============================] - 0s 750us/step - loss: 56.5524 - val_loss: 10.5448\n",
      "Epoch 8410/10000\n",
      "184/184 [==============================] - 0s 815us/step - loss: 47.9829 - val_loss: 10.5390\n",
      "Epoch 8411/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 62.1821 - val_loss: 10.5343\n",
      "Epoch 8412/10000\n",
      "184/184 [==============================] - 0s 742us/step - loss: 54.8072 - val_loss: 10.5308\n",
      "Epoch 8413/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 57.2739 - val_loss: 10.5282\n",
      "Epoch 8414/10000\n",
      "184/184 [==============================] - 0s 595us/step - loss: 53.7737 - val_loss: 10.5260\n",
      "Epoch 8415/10000\n",
      "184/184 [==============================] - 0s 606us/step - loss: 74.2958 - val_loss: 10.5285\n",
      "Epoch 8416/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 56.2321 - val_loss: 10.5302\n",
      "Epoch 8417/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 52.2560 - val_loss: 10.5325\n",
      "Epoch 8418/10000\n",
      "184/184 [==============================] - 0s 810us/step - loss: 49.6265 - val_loss: 10.5320\n",
      "Epoch 8419/10000\n",
      "184/184 [==============================] - 0s 967us/step - loss: 58.4426 - val_loss: 10.5287\n",
      "Epoch 8420/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 67.4589 - val_loss: 10.5151\n",
      "Epoch 8421/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 60.5688 - val_loss: 10.5056\n",
      "Epoch 8422/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 55.3585 - val_loss: 10.5013\n",
      "Epoch 8423/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 65.0579 - val_loss: 10.4960\n",
      "Epoch 8424/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 78.2758 - val_loss: 10.4882\n",
      "Epoch 8425/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 49.9679 - val_loss: 10.4811\n",
      "Epoch 8426/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 63.7844 - val_loss: 10.4745\n",
      "Epoch 8427/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 62.4395 - val_loss: 10.4677\n",
      "Epoch 8428/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 63.3928 - val_loss: 10.4779\n",
      "Epoch 8429/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 55.2179 - val_loss: 10.4899\n",
      "Epoch 8430/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 49.4130 - val_loss: 10.4959\n",
      "Epoch 8431/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 66.0318 - val_loss: 10.5163\n",
      "Epoch 8432/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 90.1660 - val_loss: 10.5344\n",
      "Epoch 8433/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 54.2952 - val_loss: 10.5462\n",
      "Epoch 8434/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 54.0887 - val_loss: 10.5314\n",
      "Epoch 8435/10000\n",
      "184/184 [==============================] - 0s 799us/step - loss: 59.9836 - val_loss: 10.5805\n",
      "Epoch 8436/10000\n",
      "184/184 [==============================] - 0s 891us/step - loss: 55.9431 - val_loss: 10.5291\n",
      "Epoch 8437/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 56.9696 - val_loss: 10.5608\n",
      "Epoch 8438/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 65.1646 - val_loss: 10.5346\n",
      "Epoch 8439/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 53.0851 - val_loss: 10.5238\n",
      "Epoch 8440/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 67.7724 - val_loss: 10.5204\n",
      "Epoch 8441/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 57.6974 - val_loss: 10.5201\n",
      "Epoch 8442/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 58.7693 - val_loss: 10.5217\n",
      "Epoch 8443/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 59.8338 - val_loss: 10.5161\n",
      "Epoch 8444/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 62.1503 - val_loss: 10.5144\n",
      "Epoch 8445/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 62.5059 - val_loss: 10.5085\n",
      "Epoch 8446/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 61.2553 - val_loss: 10.4982\n",
      "Epoch 8447/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 47.6461 - val_loss: 10.4698\n",
      "Epoch 8448/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 65.8772 - val_loss: 10.4700\n",
      "Epoch 8449/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 62.3694 - val_loss: 10.4686\n",
      "Epoch 8450/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 67.8659 - val_loss: 10.4612\n",
      "Epoch 8451/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 71.3306 - val_loss: 10.4561\n",
      "Epoch 8452/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 52.1693 - val_loss: 10.4662\n",
      "Epoch 8453/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 77.7710 - val_loss: 10.4778\n",
      "Epoch 8454/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 80.8153 - val_loss: 10.4901\n",
      "Epoch 8455/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 71.3451 - val_loss: 10.4949\n",
      "Epoch 8456/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 46.9132 - val_loss: 10.4826\n",
      "Epoch 8457/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 54.1662 - val_loss: 10.4229\n",
      "Epoch 8458/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 61.0970 - val_loss: 10.4930\n",
      "Epoch 8459/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 61.2527 - val_loss: 10.4259\n",
      "Epoch 8460/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 60.8316 - val_loss: 10.4704\n",
      "Epoch 8461/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 53.0748 - val_loss: 10.4555\n",
      "Epoch 8462/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 71.7364 - val_loss: 10.4681\n",
      "Epoch 8463/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 62.6036 - val_loss: 10.4909\n",
      "Epoch 8464/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 62.0018 - val_loss: 10.5333\n",
      "Epoch 8465/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 80.0874 - val_loss: 10.5544\n",
      "Epoch 8466/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 69.5906 - val_loss: 10.5705\n",
      "Epoch 8467/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 62.7640 - val_loss: 10.5873\n",
      "Epoch 8468/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 61.7137 - val_loss: 10.6359\n",
      "Epoch 8469/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 68.8880 - val_loss: 10.4645\n",
      "Epoch 8470/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 51.4291 - val_loss: 10.2655\n",
      "Epoch 8471/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 66.5732 - val_loss: 10.2343\n",
      "Epoch 8472/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 65.4686 - val_loss: 10.2117\n",
      "Epoch 8473/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 58.5048 - val_loss: 10.2134\n",
      "Epoch 8474/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 62.2067 - val_loss: 10.1940\n",
      "Epoch 8475/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 53.8766 - val_loss: 10.2875\n",
      "Epoch 8476/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 50.1444 - val_loss: 10.3044\n",
      "Epoch 8477/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 647us/step - loss: 62.6686 - val_loss: 10.3219\n",
      "Epoch 8478/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 76.0876 - val_loss: 10.3348\n",
      "Epoch 8479/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 66.3154 - val_loss: 10.2343\n",
      "Epoch 8480/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 74.3798 - val_loss: 9.9773\n",
      "Epoch 8481/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 52.3181 - val_loss: 9.8938\n",
      "Epoch 8482/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 67.2304 - val_loss: 9.8049\n",
      "Epoch 8483/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 49.5117 - val_loss: 9.7672\n",
      "Epoch 8484/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 48.6455 - val_loss: 9.7466\n",
      "Epoch 8485/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 63.1095 - val_loss: 9.7301\n",
      "Epoch 8486/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 52.1916 - val_loss: 9.7169\n",
      "Epoch 8487/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 57.9532 - val_loss: 9.7050\n",
      "Epoch 8488/10000\n",
      "184/184 [==============================] - 0s 788us/step - loss: 57.1300 - val_loss: 9.6928\n",
      "Epoch 8489/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 83.1401 - val_loss: 9.6769\n",
      "Epoch 8490/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 60.7995 - val_loss: 9.6572\n",
      "Epoch 8491/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 71.6564 - val_loss: 9.6356\n",
      "Epoch 8492/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 58.7306 - val_loss: 9.6178\n",
      "Epoch 8493/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 55.6852 - val_loss: 9.6061\n",
      "Epoch 8494/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 52.3406 - val_loss: 9.5975\n",
      "Epoch 8495/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 58.4805 - val_loss: 9.5888\n",
      "Epoch 8496/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 77.3592 - val_loss: 9.5795\n",
      "Epoch 8497/10000\n",
      "184/184 [==============================] - 0s 750us/step - loss: 72.9380 - val_loss: 9.5712\n",
      "Epoch 8498/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 57.7629 - val_loss: 9.5746\n",
      "Epoch 8499/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 64.3617 - val_loss: 10.1425\n",
      "Epoch 8500/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 64.4239 - val_loss: 10.2226\n",
      "\n",
      "Epoch 08500: loss did not improve from 56.74038\n",
      "Epoch 8501/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 76.4610 - val_loss: 9.9450\n",
      "Epoch 8502/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 66.4661 - val_loss: 10.0487\n",
      "Epoch 8503/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 63.3574 - val_loss: 10.0385\n",
      "Epoch 8504/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 68.4804 - val_loss: 10.0656\n",
      "Epoch 8505/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 50.5844 - val_loss: 10.0951\n",
      "Epoch 8506/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 59.6515 - val_loss: 10.0881\n",
      "Epoch 8507/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 69.2343 - val_loss: 10.1296\n",
      "Epoch 8508/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 80.5506 - val_loss: 10.1608\n",
      "Epoch 8509/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 64.0671 - val_loss: 10.1863\n",
      "Epoch 8510/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 62.6642 - val_loss: 10.1937\n",
      "Epoch 8511/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 53.6159 - val_loss: 10.2061\n",
      "Epoch 8512/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 64.7666 - val_loss: 10.2258\n",
      "Epoch 8513/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 80.0556 - val_loss: 10.2395\n",
      "Epoch 8514/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 53.5514 - val_loss: 10.2504\n",
      "Epoch 8515/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 55.8217 - val_loss: 10.2644\n",
      "Epoch 8516/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 60.0367 - val_loss: 10.2810\n",
      "Epoch 8517/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 52.8018 - val_loss: 10.2954\n",
      "Epoch 8518/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 59.2477 - val_loss: 10.3162\n",
      "Epoch 8519/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 60.3310 - val_loss: 10.3234\n",
      "Epoch 8520/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 60.3755 - val_loss: 10.3144\n",
      "Epoch 8521/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 60.5352 - val_loss: 10.3066\n",
      "Epoch 8522/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 46.9707 - val_loss: 10.3014\n",
      "Epoch 8523/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 59.4445 - val_loss: 10.2992\n",
      "Epoch 8524/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 58.3529 - val_loss: 10.2925\n",
      "Epoch 8525/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 57.7440 - val_loss: 10.2867\n",
      "Epoch 8526/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 72.1079 - val_loss: 10.2826\n",
      "Epoch 8527/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 53.4102 - val_loss: 10.2763\n",
      "Epoch 8528/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 48.5255 - val_loss: 10.2727\n",
      "Epoch 8529/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 56.8069 - val_loss: 10.2681\n",
      "Epoch 8530/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 60.8644 - val_loss: 10.2612\n",
      "Epoch 8531/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 56.2282 - val_loss: 10.2498\n",
      "Epoch 8532/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 56.9635 - val_loss: 10.2427\n",
      "Epoch 8533/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 72.0689 - val_loss: 10.2369\n",
      "Epoch 8534/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 63.2337 - val_loss: 10.2211\n",
      "Epoch 8535/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 63.5988 - val_loss: 10.2193\n",
      "Epoch 8536/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 57.3935 - val_loss: 10.2241\n",
      "Epoch 8537/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 60.2237 - val_loss: 10.2250\n",
      "Epoch 8538/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 64.8613 - val_loss: 10.2292\n",
      "Epoch 8539/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 51.5170 - val_loss: 10.2339\n",
      "Epoch 8540/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 63.0678 - val_loss: 10.2364\n",
      "Epoch 8541/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 51.5089 - val_loss: 10.2371\n",
      "Epoch 8542/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 62.9536 - val_loss: 10.2361\n",
      "Epoch 8543/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 61.7151 - val_loss: 10.2328\n",
      "Epoch 8544/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 59.0706 - val_loss: 10.2284\n",
      "Epoch 8545/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 54.0650 - val_loss: 10.2237\n",
      "Epoch 8546/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 58.2075 - val_loss: 10.2102\n",
      "Epoch 8547/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 51.8067 - val_loss: 10.1927\n",
      "Epoch 8548/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 68.7804 - val_loss: 10.1789\n",
      "Epoch 8549/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 60.3927 - val_loss: 10.1512\n",
      "Epoch 8550/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 54.9112 - val_loss: 10.1119\n",
      "Epoch 8551/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 598us/step - loss: 48.0997 - val_loss: 10.0816\n",
      "Epoch 8552/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 53.1484 - val_loss: 10.0520\n",
      "Epoch 8553/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 65.5003 - val_loss: 10.0114\n",
      "Epoch 8554/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 57.7200 - val_loss: 9.9723\n",
      "Epoch 8555/10000\n",
      "184/184 [==============================] - 0s 804us/step - loss: 65.3694 - val_loss: 9.9359\n",
      "Epoch 8556/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 63.0087 - val_loss: 9.9042\n",
      "Epoch 8557/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 44.5524 - val_loss: 9.8758\n",
      "Epoch 8558/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 54.1837 - val_loss: 9.8529\n",
      "Epoch 8559/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 45.3843 - val_loss: 9.8378\n",
      "Epoch 8560/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 65.6107 - val_loss: 9.8272\n",
      "Epoch 8561/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 76.8902 - val_loss: 9.8163\n",
      "Epoch 8562/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 59.3292 - val_loss: 9.8061\n",
      "Epoch 8563/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 58.1228 - val_loss: 9.7953\n",
      "Epoch 8564/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 66.1318 - val_loss: 9.7854\n",
      "Epoch 8565/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 59.6595 - val_loss: 9.7793\n",
      "Epoch 8566/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 63.1402 - val_loss: 9.7692\n",
      "Epoch 8567/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 54.4835 - val_loss: 9.7568\n",
      "Epoch 8568/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 52.9192 - val_loss: 9.7511\n",
      "Epoch 8569/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 66.6078 - val_loss: 9.7562\n",
      "Epoch 8570/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 63.4066 - val_loss: 9.7643\n",
      "Epoch 8571/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 66.1708 - val_loss: 9.7691\n",
      "Epoch 8572/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 76.6331 - val_loss: 9.7746\n",
      "Epoch 8573/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 48.9079 - val_loss: 9.7793\n",
      "Epoch 8574/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 47.0068 - val_loss: 9.7895\n",
      "Epoch 8575/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 54.2642 - val_loss: 9.7992\n",
      "Epoch 8576/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 60.9061 - val_loss: 9.8123\n",
      "Epoch 8577/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 71.3101 - val_loss: 9.8229\n",
      "Epoch 8578/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 58.0635 - val_loss: 9.8300\n",
      "Epoch 8579/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 54.6754 - val_loss: 9.8464\n",
      "Epoch 8580/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 59.0095 - val_loss: 9.8230\n",
      "Epoch 8581/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 49.5711 - val_loss: 9.8117\n",
      "Epoch 8582/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 52.3794 - val_loss: 9.8032\n",
      "Epoch 8583/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 58.7262 - val_loss: 9.7908\n",
      "Epoch 8584/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 65.9234 - val_loss: 9.7816\n",
      "Epoch 8585/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 70.9735 - val_loss: 9.7740\n",
      "Epoch 8586/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 53.1646 - val_loss: 9.7663\n",
      "Epoch 8587/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 61.9565 - val_loss: 9.7517\n",
      "Epoch 8588/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 64.0058 - val_loss: 9.7439\n",
      "Epoch 8589/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 58.9108 - val_loss: 9.7528\n",
      "Epoch 8590/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 48.4128 - val_loss: 9.7545\n",
      "Epoch 8591/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 70.5075 - val_loss: 9.7634\n",
      "Epoch 8592/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 54.3051 - val_loss: 9.7715\n",
      "Epoch 8593/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 61.21 - 0s 652us/step - loss: 66.9511 - val_loss: 9.7803\n",
      "Epoch 8594/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 75.3318 - val_loss: 9.7857\n",
      "Epoch 8595/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 50.8562 - val_loss: 9.7808\n",
      "Epoch 8596/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 57.0033 - val_loss: 9.7763\n",
      "Epoch 8597/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 54.7565 - val_loss: 9.7834\n",
      "Epoch 8598/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 68.9566 - val_loss: 9.7908\n",
      "Epoch 8599/10000\n",
      "184/184 [==============================] - 0s 734us/step - loss: 50.7279 - val_loss: 9.7955\n",
      "Epoch 8600/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 60.0783 - val_loss: 9.7963\n",
      "\n",
      "Epoch 08600: loss did not improve from 56.74038\n",
      "Epoch 8601/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 61.7184 - val_loss: 9.7943\n",
      "Epoch 8602/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 60.7814 - val_loss: 9.7984\n",
      "Epoch 8603/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 54.0654 - val_loss: 9.7889\n",
      "Epoch 8604/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 60.0003 - val_loss: 9.7654\n",
      "Epoch 8605/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 58.2477 - val_loss: 9.7412\n",
      "Epoch 8606/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 48.9364 - val_loss: 9.7249\n",
      "Epoch 8607/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 57.9102 - val_loss: 9.7171\n",
      "Epoch 8608/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 48.6726 - val_loss: 9.7067\n",
      "Epoch 8609/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 52.5583 - val_loss: 9.6957\n",
      "Epoch 8610/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 51.0903 - val_loss: 9.6846\n",
      "Epoch 8611/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 43.6792 - val_loss: 9.6771\n",
      "Epoch 8612/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 59.0545 - val_loss: 9.6723\n",
      "Epoch 8613/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 81.6117 - val_loss: 9.6733\n",
      "Epoch 8614/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 50.8034 - val_loss: 9.6720\n",
      "Epoch 8615/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 54.0386 - val_loss: 9.6746\n",
      "Epoch 8616/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 74.6312 - val_loss: 9.6773\n",
      "Epoch 8617/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 52.7352 - val_loss: 9.6797\n",
      "Epoch 8618/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 66.7946 - val_loss: 9.6808\n",
      "Epoch 8619/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 60.9844 - val_loss: 9.6757\n",
      "Epoch 8620/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 62.7745 - val_loss: 9.6798\n",
      "Epoch 8621/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 52.4005 - val_loss: 9.6812\n",
      "Epoch 8622/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 46.6096 - val_loss: 9.6871\n",
      "Epoch 8623/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 59.6509 - val_loss: 9.6941\n",
      "Epoch 8624/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 56.3270 - val_loss: 9.7044\n",
      "Epoch 8625/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 554us/step - loss: 63.2546 - val_loss: 9.7028\n",
      "Epoch 8626/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 47.6098 - val_loss: 9.7018\n",
      "Epoch 8627/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 48.7820 - val_loss: 9.7004\n",
      "Epoch 8628/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 60.2019 - val_loss: 9.6976\n",
      "Epoch 8629/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 64.5839 - val_loss: 9.6883\n",
      "Epoch 8630/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 62.1053 - val_loss: 9.6759\n",
      "Epoch 8631/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 64.7844 - val_loss: 9.6650\n",
      "Epoch 8632/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 71.3896 - val_loss: 9.6550\n",
      "Epoch 8633/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 76.1181 - val_loss: 9.7869\n",
      "Epoch 8634/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 64.5619 - val_loss: 9.9054\n",
      "Epoch 8635/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 75.9377 - val_loss: 10.0221\n",
      "Epoch 8636/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 48.8105 - val_loss: 10.1370\n",
      "Epoch 8637/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 47.9361 - val_loss: 10.0490\n",
      "Epoch 8638/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 52.5969 - val_loss: 9.8099\n",
      "Epoch 8639/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 48.1753 - val_loss: 9.5852\n",
      "Epoch 8640/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 52.5466 - val_loss: 9.7860\n",
      "Epoch 8641/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 50.4552 - val_loss: 9.5987\n",
      "Epoch 8642/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 49.7679 - val_loss: 9.3530\n",
      "Epoch 8643/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 44.2976 - val_loss: 9.2652\n",
      "Epoch 8644/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 49.2397 - val_loss: 8.7607\n",
      "Epoch 8645/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 60.99 - 0s 630us/step - loss: 61.9686 - val_loss: 8.5763\n",
      "Epoch 8646/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 56.1953 - val_loss: 8.5229\n",
      "Epoch 8647/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 49.2056 - val_loss: 8.4681\n",
      "Epoch 8648/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 66.8911 - val_loss: 8.4633\n",
      "Epoch 8649/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 67.9549 - val_loss: 8.4473\n",
      "Epoch 8650/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 48.7780 - val_loss: 8.9446\n",
      "Epoch 8651/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 63.5468 - val_loss: 9.2959\n",
      "Epoch 8652/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 57.1325 - val_loss: 9.6653\n",
      "Epoch 8653/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 68.2584 - val_loss: 9.1921\n",
      "Epoch 8654/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 60.1603 - val_loss: 9.6294\n",
      "Epoch 8655/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 45.2491 - val_loss: 9.8100\n",
      "Epoch 8656/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 58.5942 - val_loss: 9.1130\n",
      "Epoch 8657/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 58.0009 - val_loss: 9.1259\n",
      "Epoch 8658/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 45.7368 - val_loss: 9.7781\n",
      "Epoch 8659/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 53.7515 - val_loss: 10.3501\n",
      "Epoch 8660/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 59.1283 - val_loss: 9.4499\n",
      "Epoch 8661/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 57.4929 - val_loss: 9.2877\n",
      "Epoch 8662/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 43.7557 - val_loss: 8.9965\n",
      "Epoch 8663/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 63.5116 - val_loss: 8.9566\n",
      "Epoch 8664/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 50.3750 - val_loss: 8.8385\n",
      "Epoch 8665/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 49.5983 - val_loss: 9.1848\n",
      "Epoch 8666/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 58.8426 - val_loss: 9.1655\n",
      "Epoch 8667/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 65.8875 - val_loss: 8.8367\n",
      "Epoch 8668/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 52.6749 - val_loss: 8.7007\n",
      "Epoch 8669/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 58.4955 - val_loss: 8.6384\n",
      "Epoch 8670/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 63.4504 - val_loss: 8.6106\n",
      "Epoch 8671/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 57.1251 - val_loss: 9.0377\n",
      "Epoch 8672/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 66.6325 - val_loss: 10.5688\n",
      "Epoch 8673/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 62.0115 - val_loss: 10.1520\n",
      "Epoch 8674/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 53.6136 - val_loss: 9.6789\n",
      "Epoch 8675/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 56.8312 - val_loss: 9.6001\n",
      "Epoch 8676/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 75.3214 - val_loss: 9.3413\n",
      "Epoch 8677/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 49.9385 - val_loss: 9.6955\n",
      "Epoch 8678/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 55.5825 - val_loss: 9.9019\n",
      "Epoch 8679/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 54.7450 - val_loss: 9.6826\n",
      "Epoch 8680/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 51.2325 - val_loss: 9.6706\n",
      "Epoch 8681/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 54.3205 - val_loss: 10.3432\n",
      "Epoch 8682/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 68.5865 - val_loss: 9.7168\n",
      "Epoch 8683/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 61.6719 - val_loss: 9.5484\n",
      "Epoch 8684/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 60.6738 - val_loss: 9.6942\n",
      "Epoch 8685/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 58.0616 - val_loss: 9.6969\n",
      "Epoch 8686/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 59.8990 - val_loss: 9.8421\n",
      "Epoch 8687/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 60.0143 - val_loss: 10.9337\n",
      "Epoch 8688/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 53.7738 - val_loss: 10.9723\n",
      "Epoch 8689/10000\n",
      "184/184 [==============================] - 0s 745us/step - loss: 59.1634 - val_loss: 9.6086\n",
      "Epoch 8690/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 52.9256 - val_loss: 9.5172\n",
      "Epoch 8691/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 55.1297 - val_loss: 9.8402\n",
      "Epoch 8692/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 62.9298 - val_loss: 9.4218\n",
      "Epoch 8693/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 60.1869 - val_loss: 10.6872\n",
      "Epoch 8694/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 67.2231 - val_loss: 10.4177\n",
      "Epoch 8695/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 47.5366 - val_loss: 12.3738\n",
      "Epoch 8696/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 64.4753 - val_loss: 9.6996\n",
      "Epoch 8697/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 64.6753 - val_loss: 9.4334\n",
      "Epoch 8698/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 69.6674 - val_loss: 10.2510\n",
      "Epoch 8699/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 57.9595 - val_loss: 9.8159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8700/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 54.1068 - val_loss: 9.4252\n",
      "\n",
      "Epoch 08700: loss improved from 56.74038 to 54.10677, saving model to C6007C.hdf5\n",
      "Epoch 8701/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 71.9780 - val_loss: 9.5826\n",
      "Epoch 8702/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 64.6857 - val_loss: 9.6694\n",
      "Epoch 8703/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 63.3582 - val_loss: 10.8269\n",
      "Epoch 8704/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 59.3440 - val_loss: 10.0323\n",
      "Epoch 8705/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 53.5143 - val_loss: 10.3334\n",
      "Epoch 8706/10000\n",
      "184/184 [==============================] - 0s 783us/step - loss: 55.6938 - val_loss: 10.1826\n",
      "Epoch 8707/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 63.0448 - val_loss: 10.0163\n",
      "Epoch 8708/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 59.4950 - val_loss: 9.4064\n",
      "Epoch 8709/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 48.1094 - val_loss: 9.2187\n",
      "Epoch 8710/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 54.7987 - val_loss: 9.1839\n",
      "Epoch 8711/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 51.0524 - val_loss: 9.1382\n",
      "Epoch 8712/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 63.4585 - val_loss: 9.1724\n",
      "Epoch 8713/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 49.8569 - val_loss: 9.3193\n",
      "Epoch 8714/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 59.1736 - val_loss: 9.7762\n",
      "Epoch 8715/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 60.7375 - val_loss: 9.1077\n",
      "Epoch 8716/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 58.8549 - val_loss: 8.9543\n",
      "Epoch 8717/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 61.3157 - val_loss: 9.0490\n",
      "Epoch 8718/10000\n",
      "184/184 [==============================] - 0s 707us/step - loss: 44.4062 - val_loss: 8.8907\n",
      "Epoch 8719/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 59.8551 - val_loss: 9.0897\n",
      "Epoch 8720/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 57.7360 - val_loss: 8.4100\n",
      "Epoch 8721/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 58.5018 - val_loss: 9.8854\n",
      "Epoch 8722/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 59.2420 - val_loss: 9.3875\n",
      "Epoch 8723/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 58.9216 - val_loss: 9.3231\n",
      "Epoch 8724/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 60.6407 - val_loss: 9.1929\n",
      "Epoch 8725/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 66.6858 - val_loss: 9.2075\n",
      "Epoch 8726/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 53.4413 - val_loss: 8.7107\n",
      "Epoch 8727/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 64.6257 - val_loss: 8.6497\n",
      "Epoch 8728/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 59.2242 - val_loss: 8.5571\n",
      "Epoch 8729/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 49.5495 - val_loss: 8.7298\n",
      "Epoch 8730/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 61.0824 - val_loss: 8.5619\n",
      "Epoch 8731/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 67.4243 - val_loss: 8.6031\n",
      "Epoch 8732/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 56.1235 - val_loss: 8.6399\n",
      "Epoch 8733/10000\n",
      "184/184 [==============================] - 0s 739us/step - loss: 44.8628 - val_loss: 8.7755\n",
      "Epoch 8734/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 46.0694 - val_loss: 8.8830\n",
      "Epoch 8735/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 53.1198 - val_loss: 8.9528\n",
      "Epoch 8736/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 54.5017 - val_loss: 9.1315\n",
      "Epoch 8737/10000\n",
      "184/184 [==============================] - 0s 853us/step - loss: 57.2195 - val_loss: 9.1362\n",
      "Epoch 8738/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 46.8212 - val_loss: 9.1047\n",
      "Epoch 8739/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 50.5689 - val_loss: 9.1384\n",
      "Epoch 8740/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 59.9912 - val_loss: 9.1587\n",
      "Epoch 8741/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 41.7819 - val_loss: 9.1703\n",
      "Epoch 8742/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 57.2097 - val_loss: 9.1858\n",
      "Epoch 8743/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 55.2205 - val_loss: 9.2028\n",
      "Epoch 8744/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 56.3043 - val_loss: 9.2207\n",
      "Epoch 8745/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 53.9665 - val_loss: 9.2512\n",
      "Epoch 8746/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 56.9306 - val_loss: 9.2413\n",
      "Epoch 8747/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 54.8990 - val_loss: 9.1761\n",
      "Epoch 8748/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 50.0959 - val_loss: 9.1557\n",
      "Epoch 8749/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 71.2540 - val_loss: 9.1502\n",
      "Epoch 8750/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 65.3106 - val_loss: 9.1416\n",
      "Epoch 8751/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 50.4654 - val_loss: 9.1343\n",
      "Epoch 8752/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 55.8414 - val_loss: 9.0663\n",
      "Epoch 8753/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 59.8010 - val_loss: 9.0806\n",
      "Epoch 8754/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 58.0593 - val_loss: 9.0144\n",
      "Epoch 8755/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 60.0900 - val_loss: 8.8303\n",
      "Epoch 8756/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 66.1767 - val_loss: 8.7625\n",
      "Epoch 8757/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 77.1638 - val_loss: 8.7503\n",
      "Epoch 8758/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 67.6924 - val_loss: 8.7005\n",
      "Epoch 8759/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 59.8711 - val_loss: 8.6881\n",
      "Epoch 8760/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 48.1891 - val_loss: 8.6237\n",
      "Epoch 8761/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 64.4032 - val_loss: 8.6055\n",
      "Epoch 8762/10000\n",
      "184/184 [==============================] - 0s 810us/step - loss: 51.8768 - val_loss: 8.5972\n",
      "Epoch 8763/10000\n",
      "184/184 [==============================] - 0s 804us/step - loss: 46.4633 - val_loss: 8.5941\n",
      "Epoch 8764/10000\n",
      "184/184 [==============================] - 0s 723us/step - loss: 66.4250 - val_loss: 8.5927\n",
      "Epoch 8765/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 57.4326 - val_loss: 8.5896\n",
      "Epoch 8766/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 57.3530 - val_loss: 8.5846\n",
      "Epoch 8767/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 68.4119 - val_loss: 8.5898\n",
      "Epoch 8768/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 70.5253 - val_loss: 8.6035\n",
      "Epoch 8769/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 69.7530 - val_loss: 8.6101\n",
      "Epoch 8770/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 75.9986 - val_loss: 8.6097\n",
      "Epoch 8771/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 51.5347 - val_loss: 8.6056\n",
      "Epoch 8772/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 58.7317 - val_loss: 8.5999\n",
      "Epoch 8773/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 59.6507 - val_loss: 8.5950\n",
      "Epoch 8774/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 603us/step - loss: 59.8768 - val_loss: 8.5904\n",
      "Epoch 8775/10000\n",
      "184/184 [==============================] - 0s 799us/step - loss: 48.3857 - val_loss: 8.5874\n",
      "Epoch 8776/10000\n",
      "184/184 [==============================] - 0s 908us/step - loss: 76.4518 - val_loss: 8.5874\n",
      "Epoch 8777/10000\n",
      "184/184 [==============================] - 0s 766us/step - loss: 53.9352 - val_loss: 8.5875\n",
      "Epoch 8778/10000\n",
      "184/184 [==============================] - 0s 793us/step - loss: 61.6353 - val_loss: 8.5856\n",
      "Epoch 8779/10000\n",
      "184/184 [==============================] - 0s 750us/step - loss: 58.5249 - val_loss: 8.5828\n",
      "Epoch 8780/10000\n",
      "184/184 [==============================] - 0s 728us/step - loss: 65.8184 - val_loss: 8.5798\n",
      "Epoch 8781/10000\n",
      "184/184 [==============================] - 0s 690us/step - loss: 49.3643 - val_loss: 8.5780\n",
      "Epoch 8782/10000\n",
      "184/184 [==============================] - 0s 704us/step - loss: 70.4647 - val_loss: 8.5758\n",
      "Epoch 8783/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 50.8349 - val_loss: 8.5737\n",
      "Epoch 8784/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 35.03 - 0s 598us/step - loss: 38.8121 - val_loss: 8.5738\n",
      "Epoch 8785/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 54.7076 - val_loss: 8.5696\n",
      "Epoch 8786/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 53.9425 - val_loss: 8.5604\n",
      "Epoch 8787/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 45.4083 - val_loss: 8.5732\n",
      "Epoch 8788/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 51.7864 - val_loss: 8.5738\n",
      "Epoch 8789/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 46.9742 - val_loss: 8.5347\n",
      "Epoch 8790/10000\n",
      "184/184 [==============================] - 0s 769us/step - loss: 66.0456 - val_loss: 8.5302\n",
      "Epoch 8791/10000\n",
      "184/184 [==============================] - 0s 846us/step - loss: 50.8159 - val_loss: 8.5196\n",
      "Epoch 8792/10000\n",
      "184/184 [==============================] - 0s 875us/step - loss: 71.8445 - val_loss: 8.5156\n",
      "Epoch 8793/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 71.5679 - val_loss: 8.5164\n",
      "Epoch 8794/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 53.7516 - val_loss: 8.5828\n",
      "Epoch 8795/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 61.7237 - val_loss: 8.6559\n",
      "Epoch 8796/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 57.0423 - val_loss: 8.7323\n",
      "Epoch 8797/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 47.4624 - val_loss: 8.5312\n",
      "Epoch 8798/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 56.2497 - val_loss: 8.5200\n",
      "Epoch 8799/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 63.9246 - val_loss: 8.4730\n",
      "Epoch 8800/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 46.3258 - val_loss: 8.4294\n",
      "\n",
      "Epoch 08800: loss improved from 54.10677 to 46.32582, saving model to C6007C.hdf5\n",
      "Epoch 8801/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 55.5836 - val_loss: 8.4071\n",
      "Epoch 8802/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 50.1086 - val_loss: 8.3881\n",
      "Epoch 8803/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 53.2015 - val_loss: 8.3752\n",
      "Epoch 8804/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 69.1581 - val_loss: 8.3542\n",
      "Epoch 8805/10000\n",
      "184/184 [==============================] - 0s 593us/step - loss: 52.5282 - val_loss: 8.3941\n",
      "Epoch 8806/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 66.5906 - val_loss: 8.3979\n",
      "Epoch 8807/10000\n",
      "184/184 [==============================] - 0s 606us/step - loss: 58.9123 - val_loss: 8.3588\n",
      "Epoch 8808/10000\n",
      "184/184 [==============================] - 0s 832us/step - loss: 54.3833 - val_loss: 8.4104\n",
      "Epoch 8809/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 54.1801 - val_loss: 8.3835\n",
      "Epoch 8810/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 65.4168 - val_loss: 8.6331\n",
      "Epoch 8811/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 53.5899 - val_loss: 8.6330\n",
      "Epoch 8812/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 53.7407 - val_loss: 8.5791\n",
      "Epoch 8813/10000\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 59.1390 - val_loss: 8.4807\n",
      "Epoch 8814/10000\n",
      "184/184 [==============================] - 0s 978us/step - loss: 56.5300 - val_loss: 8.4297\n",
      "Epoch 8815/10000\n",
      "184/184 [==============================] - 0s 696us/step - loss: 59.3724 - val_loss: 8.4857\n",
      "Epoch 8816/10000\n",
      "184/184 [==============================] - 0s 864us/step - loss: 43.0766 - val_loss: 8.5491\n",
      "Epoch 8817/10000\n",
      "184/184 [==============================] - 0s 717us/step - loss: 56.8562 - val_loss: 8.5717\n",
      "Epoch 8818/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 46.8084 - val_loss: 8.5895\n",
      "Epoch 8819/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 57.6774 - val_loss: 8.6458\n",
      "Epoch 8820/10000\n",
      "184/184 [==============================] - 0s 590us/step - loss: 50.7147 - val_loss: 8.6561\n",
      "Epoch 8821/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 56.2926 - val_loss: 8.6335\n",
      "Epoch 8822/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 63.1302 - val_loss: 8.5754\n",
      "Epoch 8823/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 75.1281 - val_loss: 8.5517\n",
      "Epoch 8824/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 56.0135 - val_loss: 8.6310\n",
      "Epoch 8825/10000\n",
      "184/184 [==============================] - 0s 736us/step - loss: 63.7417 - val_loss: 8.6427\n",
      "Epoch 8826/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 57.3838 - val_loss: 8.6400\n",
      "Epoch 8827/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 54.5560 - val_loss: 8.6342\n",
      "Epoch 8828/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 67.7728 - val_loss: 8.6294\n",
      "Epoch 8829/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 54.7630 - val_loss: 8.6369\n",
      "Epoch 8830/10000\n",
      "184/184 [==============================] - 0s 815us/step - loss: 42.3417 - val_loss: 8.6368\n",
      "Epoch 8831/10000\n",
      "184/184 [==============================] - 0s 848us/step - loss: 55.0574 - val_loss: 8.6468\n",
      "Epoch 8832/10000\n",
      "184/184 [==============================] - 0s 837us/step - loss: 53.9134 - val_loss: 8.6554\n",
      "Epoch 8833/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 52.6702 - val_loss: 8.5935\n",
      "Epoch 8834/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 53.9295 - val_loss: 8.5590\n",
      "Epoch 8835/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 69.5398 - val_loss: 8.5762\n",
      "Epoch 8836/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 41.48 - 0s 511us/step - loss: 48.3596 - val_loss: 8.5763\n",
      "Epoch 8837/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 56.3723 - val_loss: 8.5550\n",
      "Epoch 8838/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 55.4350 - val_loss: 8.5171\n",
      "Epoch 8839/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 60.1097 - val_loss: 8.4834\n",
      "Epoch 8840/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 55.4754 - val_loss: 8.4734\n",
      "Epoch 8841/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 43.5487 - val_loss: 8.4596\n",
      "Epoch 8842/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 61.3399 - val_loss: 8.4399\n",
      "Epoch 8843/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 57.6313 - val_loss: 8.4217\n",
      "Epoch 8844/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 61.2568 - val_loss: 8.4109\n",
      "Epoch 8845/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 68.7524 - val_loss: 8.3975\n",
      "Epoch 8846/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 72.9231 - val_loss: 8.3737\n",
      "Epoch 8847/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 65.0907 - val_loss: 8.2878\n",
      "Epoch 8848/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 549us/step - loss: 59.1510 - val_loss: 8.3101\n",
      "Epoch 8849/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 56.7526 - val_loss: 8.1693\n",
      "Epoch 8850/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 42.0297 - val_loss: 8.1458\n",
      "Epoch 8851/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 62.3699 - val_loss: 8.1877\n",
      "Epoch 8852/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 54.52 - 0s 495us/step - loss: 55.6324 - val_loss: 8.1941\n",
      "Epoch 8853/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 69.1086 - val_loss: 8.1949\n",
      "Epoch 8854/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 62.9409 - val_loss: 8.1923\n",
      "Epoch 8855/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 56.5886 - val_loss: 8.1914\n",
      "Epoch 8856/10000\n",
      "184/184 [==============================] - 0s 544us/step - loss: 60.7601 - val_loss: 8.2581\n",
      "Epoch 8857/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 61.6722 - val_loss: 8.1882\n",
      "Epoch 8858/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 60.5937 - val_loss: 7.9913\n",
      "Epoch 8859/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 57.8805 - val_loss: 7.8067\n",
      "Epoch 8860/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 48.6359 - val_loss: 7.7462\n",
      "Epoch 8861/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 57.6836 - val_loss: 7.6115\n",
      "Epoch 8862/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 51.8266 - val_loss: 7.5393\n",
      "Epoch 8863/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 51.4784 - val_loss: 7.5537\n",
      "Epoch 8864/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 54.9558 - val_loss: 7.5048\n",
      "Epoch 8865/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 45.9432 - val_loss: 7.4777\n",
      "Epoch 8866/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 54.8145 - val_loss: 7.5445\n",
      "Epoch 8867/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 68.2166 - val_loss: 7.7041\n",
      "Epoch 8868/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 61.9352 - val_loss: 7.7362\n",
      "Epoch 8869/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 60.9196 - val_loss: 7.7128\n",
      "Epoch 8870/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 57.7732 - val_loss: 7.6818\n",
      "Epoch 8871/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 83.5832 - val_loss: 7.6292\n",
      "Epoch 8872/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 45.4978 - val_loss: 7.5966\n",
      "Epoch 8873/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 57.3298 - val_loss: 7.5803\n",
      "Epoch 8874/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 60.3970 - val_loss: 7.5526\n",
      "Epoch 8875/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 50.7179 - val_loss: 7.5250\n",
      "Epoch 8876/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 55.5678 - val_loss: 7.5061\n",
      "Epoch 8877/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 56.2694 - val_loss: 7.4896\n",
      "Epoch 8878/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 49.4785 - val_loss: 7.4788\n",
      "Epoch 8879/10000\n",
      "184/184 [==============================] - 0s 636us/step - loss: 44.3168 - val_loss: 7.4707\n",
      "Epoch 8880/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 49.6397 - val_loss: 7.4639\n",
      "Epoch 8881/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 47.2222 - val_loss: 7.4585\n",
      "Epoch 8882/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 60.3382 - val_loss: 7.4543\n",
      "Epoch 8883/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 61.8933 - val_loss: 7.4512\n",
      "Epoch 8884/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 57.3357 - val_loss: 7.4488\n",
      "Epoch 8885/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 53.1985 - val_loss: 7.4468\n",
      "Epoch 8886/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 62.7806 - val_loss: 7.4446\n",
      "Epoch 8887/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 55.7829 - val_loss: 7.4433\n",
      "Epoch 8888/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 51.9073 - val_loss: 7.4410\n",
      "Epoch 8889/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 54.1639 - val_loss: 7.4389\n",
      "Epoch 8890/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 59.4757 - val_loss: 7.4366\n",
      "Epoch 8891/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 47.7095 - val_loss: 7.4345\n",
      "Epoch 8892/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 55.7380 - val_loss: 7.4322\n",
      "Epoch 8893/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 67.0699 - val_loss: 7.4291\n",
      "Epoch 8894/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 50.6055 - val_loss: 7.4279\n",
      "Epoch 8895/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 59.2075 - val_loss: 7.4284\n",
      "Epoch 8896/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 55.4517 - val_loss: 7.4260\n",
      "Epoch 8897/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 55.3212 - val_loss: 7.4175\n",
      "Epoch 8898/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 47.9443 - val_loss: 7.4090\n",
      "Epoch 8899/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 55.8045 - val_loss: 7.4019\n",
      "Epoch 8900/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 60.6490 - val_loss: 7.3979\n",
      "\n",
      "Epoch 08900: loss did not improve from 46.32582\n",
      "Epoch 8901/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 56.0584 - val_loss: 7.3982\n",
      "Epoch 8902/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 60.5938 - val_loss: 7.3972\n",
      "Epoch 8903/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 56.8404 - val_loss: 7.3960\n",
      "Epoch 8904/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 47.4811 - val_loss: 7.3959\n",
      "Epoch 8905/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 68.4423 - val_loss: 7.3941\n",
      "Epoch 8906/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 54.3851 - val_loss: 7.3939\n",
      "Epoch 8907/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 46.5305 - val_loss: 7.3950\n",
      "Epoch 8908/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 48.0364 - val_loss: 7.4012\n",
      "Epoch 8909/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 50.7428 - val_loss: 7.4044\n",
      "Epoch 8910/10000\n",
      "184/184 [==============================] - 0s 544us/step - loss: 63.6977 - val_loss: 7.4067\n",
      "Epoch 8911/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 43.8482 - val_loss: 7.3770\n",
      "Epoch 8912/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 55.8497 - val_loss: 7.2886\n",
      "Epoch 8913/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 62.9596 - val_loss: 7.2478\n",
      "Epoch 8914/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 50.7710 - val_loss: 7.2340\n",
      "Epoch 8915/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 75.1175 - val_loss: 7.2320\n",
      "Epoch 8916/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 44.7500 - val_loss: 7.2302\n",
      "Epoch 8917/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 56.3341 - val_loss: 7.2435\n",
      "Epoch 8918/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 49.1085 - val_loss: 7.2549\n",
      "Epoch 8919/10000\n",
      "184/184 [==============================] - 0s 679us/step - loss: 60.9922 - val_loss: 7.2734\n",
      "Epoch 8920/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 50.91 - 0s 593us/step - loss: 54.0698 - val_loss: 7.2836\n",
      "Epoch 8921/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 59.7425 - val_loss: 7.2929\n",
      "Epoch 8922/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 527us/step - loss: 58.5317 - val_loss: 7.3001\n",
      "Epoch 8923/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 67.2551 - val_loss: 7.3024\n",
      "Epoch 8924/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 53.2024 - val_loss: 7.3008\n",
      "Epoch 8925/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 51.53 - 0s 457us/step - loss: 53.5673 - val_loss: 7.3052\n",
      "Epoch 8926/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 58.6829 - val_loss: 7.3018\n",
      "Epoch 8927/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 54.4189 - val_loss: 7.2912\n",
      "Epoch 8928/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 48.7241 - val_loss: 7.2927\n",
      "Epoch 8929/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 56.6028 - val_loss: 7.2978\n",
      "Epoch 8930/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 41.9730 - val_loss: 7.2946\n",
      "Epoch 8931/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 45.4390 - val_loss: 7.2984\n",
      "Epoch 8932/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 71.7759 - val_loss: 7.2946\n",
      "Epoch 8933/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 57.4033 - val_loss: 7.2912\n",
      "Epoch 8934/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 57.3359 - val_loss: 7.2881\n",
      "Epoch 8935/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 45.4962 - val_loss: 7.2855\n",
      "Epoch 8936/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 58.4845 - val_loss: 7.5167\n",
      "Epoch 8937/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 77.2343 - val_loss: 7.7576\n",
      "Epoch 8938/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 63.8593 - val_loss: 8.2429\n",
      "Epoch 8939/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 48.5529 - val_loss: 8.5721\n",
      "Epoch 8940/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 62.5342 - val_loss: 8.8794\n",
      "Epoch 8941/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 70.7430 - val_loss: 8.7004\n",
      "Epoch 8942/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 57.1720 - val_loss: 8.0786\n",
      "Epoch 8943/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 59.5216 - val_loss: 7.6368\n",
      "Epoch 8944/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 64.5731 - val_loss: 7.4249\n",
      "Epoch 8945/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 40.1400 - val_loss: 7.3327\n",
      "Epoch 8946/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 64.5508 - val_loss: 7.2763\n",
      "Epoch 8947/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 44.5152 - val_loss: 7.2502\n",
      "Epoch 8948/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 52.9172 - val_loss: 7.2423\n",
      "Epoch 8949/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 51.1657 - val_loss: 7.2348\n",
      "Epoch 8950/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 58.8087 - val_loss: 7.2281\n",
      "Epoch 8951/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 49.0841 - val_loss: 7.2218\n",
      "Epoch 8952/10000\n",
      "184/184 [==============================] - 0s 573us/step - loss: 48.5172 - val_loss: 7.2130\n",
      "Epoch 8953/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 56.5817 - val_loss: 7.2083\n",
      "Epoch 8954/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 46.7439 - val_loss: 7.2212\n",
      "Epoch 8955/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 55.1107 - val_loss: 7.2263\n",
      "Epoch 8956/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 50.9302 - val_loss: 7.2409\n",
      "Epoch 8957/10000\n",
      "184/184 [==============================] - 0s 568us/step - loss: 65.2719 - val_loss: 7.2631\n",
      "Epoch 8958/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 52.5724 - val_loss: 7.2804\n",
      "Epoch 8959/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 50.0173 - val_loss: 7.2944\n",
      "Epoch 8960/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 45.3783 - val_loss: 7.3066\n",
      "Epoch 8961/10000\n",
      "184/184 [==============================] - 0s 435us/step - loss: 43.2409 - val_loss: 7.3196\n",
      "Epoch 8962/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 66.0507 - val_loss: 7.3301\n",
      "Epoch 8963/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 47.1074 - val_loss: 7.3370\n",
      "Epoch 8964/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 52.8446 - val_loss: 7.3384\n",
      "Epoch 8965/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 54.1856 - val_loss: 7.3411\n",
      "Epoch 8966/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 46.0565 - val_loss: 7.3441\n",
      "Epoch 8967/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 55.9208 - val_loss: 7.3449\n",
      "Epoch 8968/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 57.8866 - val_loss: 7.3553\n",
      "Epoch 8969/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 49.8576 - val_loss: 7.3627\n",
      "Epoch 8970/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 59.7089 - val_loss: 7.4463\n",
      "Epoch 8971/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 52.0840 - val_loss: 7.7610\n",
      "Epoch 8972/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 52.1199 - val_loss: 8.1789\n",
      "Epoch 8973/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 50.6192 - val_loss: 8.5111\n",
      "Epoch 8974/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 57.9896 - val_loss: 8.6881\n",
      "Epoch 8975/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 61.5141 - val_loss: 8.7909\n",
      "Epoch 8976/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 48.9139 - val_loss: 8.8421\n",
      "Epoch 8977/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 37.9036 - val_loss: 8.8584\n",
      "Epoch 8978/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 45.8792 - val_loss: 8.2153\n",
      "Epoch 8979/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 56.8883 - val_loss: 7.4966\n",
      "Epoch 8980/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 52.4642 - val_loss: 7.1954\n",
      "Epoch 8981/10000\n",
      "184/184 [==============================] - 0s 541us/step - loss: 47.5076 - val_loss: 7.1138\n",
      "Epoch 8982/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 68.8620 - val_loss: 7.0885\n",
      "Epoch 8983/10000\n",
      "184/184 [==============================] - 0s 573us/step - loss: 47.0190 - val_loss: 7.0891\n",
      "Epoch 8984/10000\n",
      "184/184 [==============================] - 0s 568us/step - loss: 50.0989 - val_loss: 7.0771\n",
      "Epoch 8985/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 56.8225 - val_loss: 7.0654\n",
      "Epoch 8986/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 47.5732 - val_loss: 7.0599\n",
      "Epoch 8987/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 59.5395 - val_loss: 7.0520\n",
      "Epoch 8988/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 47.9426 - val_loss: 7.0447\n",
      "Epoch 8989/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 51.4674 - val_loss: 6.8923\n",
      "Epoch 8990/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 55.1023 - val_loss: 6.8662\n",
      "Epoch 8991/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 63.5694 - val_loss: 6.8636\n",
      "Epoch 8992/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 57.7655 - val_loss: 6.8744\n",
      "Epoch 8993/10000\n",
      "184/184 [==============================] - 0s 593us/step - loss: 50.7594 - val_loss: 6.8360\n",
      "Epoch 8994/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 61.8123 - val_loss: 6.8550\n",
      "Epoch 8995/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 60.0742 - val_loss: 6.8437\n",
      "Epoch 8996/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 51.7421 - val_loss: 6.7895\n",
      "Epoch 8997/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 560us/step - loss: 56.7076 - val_loss: 6.9775\n",
      "Epoch 8998/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 53.7815 - val_loss: 7.5448\n",
      "Epoch 8999/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 63.8862 - val_loss: 9.0105\n",
      "Epoch 9000/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 56.0177 - val_loss: 9.6695\n",
      "\n",
      "Epoch 09000: loss did not improve from 46.32582\n",
      "Epoch 9001/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 56.3028 - val_loss: 9.7927\n",
      "Epoch 9002/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 45.6980 - val_loss: 9.7968\n",
      "Epoch 9003/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 56.7166 - val_loss: 9.7616\n",
      "Epoch 9004/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 58.7791 - val_loss: 9.7251\n",
      "Epoch 9005/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 55.5406 - val_loss: 9.7819\n",
      "Epoch 9006/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 57.9263 - val_loss: 9.9105\n",
      "Epoch 9007/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 52.2078 - val_loss: 9.9957\n",
      "Epoch 9008/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 57.2390 - val_loss: 10.0643\n",
      "Epoch 9009/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 55.8122 - val_loss: 10.1173\n",
      "Epoch 9010/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 56.8818 - val_loss: 10.1563\n",
      "Epoch 9011/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 61.5618 - val_loss: 10.1856\n",
      "Epoch 9012/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 56.2297 - val_loss: 10.2052\n",
      "Epoch 9013/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 50.3667 - val_loss: 10.2227\n",
      "Epoch 9014/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 46.3284 - val_loss: 10.2443\n",
      "Epoch 9015/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 50.9168 - val_loss: 10.2618\n",
      "Epoch 9016/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 49.4659 - val_loss: 10.2782\n",
      "Epoch 9017/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 46.9634 - val_loss: 10.2914\n",
      "Epoch 9018/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 52.1895 - val_loss: 10.2966\n",
      "Epoch 9019/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 72.6764 - val_loss: 10.2943\n",
      "Epoch 9020/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 50.2851 - val_loss: 10.2918\n",
      "Epoch 9021/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 47.3850 - val_loss: 10.2917\n",
      "Epoch 9022/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 64.0834 - val_loss: 10.2879\n",
      "Epoch 9023/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 51.9060 - val_loss: 10.2813\n",
      "Epoch 9024/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 53.8757 - val_loss: 10.2771\n",
      "Epoch 9025/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 57.6384 - val_loss: 10.2762\n",
      "Epoch 9026/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 56.6013 - val_loss: 10.2675\n",
      "Epoch 9027/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 48.2790 - val_loss: 10.2528\n",
      "Epoch 9028/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 49.7648 - val_loss: 10.2374\n",
      "Epoch 9029/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 53.6279 - val_loss: 10.2242\n",
      "Epoch 9030/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 60.2697 - val_loss: 10.2199\n",
      "Epoch 9031/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 48.2667 - val_loss: 10.2196\n",
      "Epoch 9032/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 57.0788 - val_loss: 10.2162\n",
      "Epoch 9033/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 56.6019 - val_loss: 10.1955\n",
      "Epoch 9034/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 54.9357 - val_loss: 10.1741\n",
      "Epoch 9035/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 56.7225 - val_loss: 10.1570\n",
      "Epoch 9036/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 68.9771 - val_loss: 10.1422\n",
      "Epoch 9037/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 58.0176 - val_loss: 10.1090\n",
      "Epoch 9038/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 51.6373 - val_loss: 10.0549\n",
      "Epoch 9039/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 62.1408 - val_loss: 10.0093\n",
      "Epoch 9040/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 53.0032 - val_loss: 9.9761\n",
      "Epoch 9041/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 50.4358 - val_loss: 9.9439\n",
      "Epoch 9042/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 45.7179 - val_loss: 9.9171\n",
      "Epoch 9043/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 49.9822 - val_loss: 9.8950\n",
      "Epoch 9044/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 39.3116 - val_loss: 9.8717\n",
      "Epoch 9045/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 41.1308 - val_loss: 9.8443\n",
      "Epoch 9046/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 52.6578 - val_loss: 9.8231\n",
      "Epoch 9047/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 45.5887 - val_loss: 9.8107\n",
      "Epoch 9048/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 51.0102 - val_loss: 9.7772\n",
      "Epoch 9049/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 59.9912 - val_loss: 9.7214\n",
      "Epoch 9050/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 51.3503 - val_loss: 9.6797\n",
      "Epoch 9051/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 62.2119 - val_loss: 9.6493\n",
      "Epoch 9052/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 52.1978 - val_loss: 9.6275\n",
      "Epoch 9053/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 52.4219 - val_loss: 9.6092\n",
      "Epoch 9054/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 56.2436 - val_loss: 9.5971\n",
      "Epoch 9055/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 45.0535 - val_loss: 9.5652\n",
      "Epoch 9056/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 51.3975 - val_loss: 9.5555\n",
      "Epoch 9057/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 57.4301 - val_loss: 9.5548\n",
      "Epoch 9058/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 50.2804 - val_loss: 9.5682\n",
      "Epoch 9059/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 54.4240 - val_loss: 9.5942\n",
      "Epoch 9060/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 47.2755 - val_loss: 9.6024\n",
      "Epoch 9061/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 52.1118 - val_loss: 9.6111\n",
      "Epoch 9062/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 52.83 - 0s 527us/step - loss: 48.0947 - val_loss: 9.5916\n",
      "Epoch 9063/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 52.2888 - val_loss: 9.5593\n",
      "Epoch 9064/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 61.6572 - val_loss: 9.4963\n",
      "Epoch 9065/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 52.3680 - val_loss: 9.4341\n",
      "Epoch 9066/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 52.0698 - val_loss: 9.3793\n",
      "Epoch 9067/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 62.4851 - val_loss: 9.3407\n",
      "Epoch 9068/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 37.0226 - val_loss: 9.3335\n",
      "Epoch 9069/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 56.9372 - val_loss: 9.3742\n",
      "Epoch 9070/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 57.8783 - val_loss: 9.2924\n",
      "Epoch 9071/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 603us/step - loss: 51.8081 - val_loss: 9.1913\n",
      "Epoch 9072/10000\n",
      "184/184 [==============================] - 0s 435us/step - loss: 40.3862 - val_loss: 9.1040\n",
      "Epoch 9073/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 45.4630 - val_loss: 9.0017\n",
      "Epoch 9074/10000\n",
      "184/184 [==============================] - 0s 456us/step - loss: 55.1370 - val_loss: 8.9060\n",
      "Epoch 9075/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 61.2426 - val_loss: 8.8514\n",
      "Epoch 9076/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 58.4193 - val_loss: 8.7893\n",
      "Epoch 9077/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 43.3508 - val_loss: 8.7438\n",
      "Epoch 9078/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 43.4755 - val_loss: 8.6748\n",
      "Epoch 9079/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 60.2655 - val_loss: 8.6611\n",
      "Epoch 9080/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 53.0728 - val_loss: 8.6338\n",
      "Epoch 9081/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 56.6068 - val_loss: 8.6213\n",
      "Epoch 9082/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 58.1005 - val_loss: 8.5951\n",
      "Epoch 9083/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 46.7606 - val_loss: 8.5744\n",
      "Epoch 9084/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 53.0578 - val_loss: 8.5624\n",
      "Epoch 9085/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 50.4084 - val_loss: 8.5660\n",
      "Epoch 9086/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 61.0983 - val_loss: 8.5731\n",
      "Epoch 9087/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 42.6705 - val_loss: 8.5787\n",
      "Epoch 9088/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 44.0223 - val_loss: 8.5665\n",
      "Epoch 9089/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 90.4012 - val_loss: 8.5752\n",
      "Epoch 9090/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 57.7815 - val_loss: 8.5806\n",
      "Epoch 9091/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 49.4846 - val_loss: 8.5565\n",
      "Epoch 9092/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 56.2435 - val_loss: 8.5119\n",
      "Epoch 9093/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 53.9150 - val_loss: 8.4946\n",
      "Epoch 9094/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 61.4847 - val_loss: 8.4865\n",
      "Epoch 9095/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 52.2798 - val_loss: 8.4332\n",
      "Epoch 9096/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 48.1307 - val_loss: 8.3998\n",
      "Epoch 9097/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 58.5400 - val_loss: 8.3822\n",
      "Epoch 9098/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 59.2256 - val_loss: 8.3666\n",
      "Epoch 9099/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 62.7979 - val_loss: 8.3570\n",
      "Epoch 9100/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 47.50 - 0s 457us/step - loss: 53.0798 - val_loss: 8.3538\n",
      "\n",
      "Epoch 09100: loss did not improve from 46.32582\n",
      "Epoch 9101/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 54.1360 - val_loss: 8.3235\n",
      "Epoch 9102/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 57.9374 - val_loss: 8.2981\n",
      "Epoch 9103/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 44.3588 - val_loss: 8.3419\n",
      "Epoch 9104/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 53.8056 - val_loss: 8.3561\n",
      "Epoch 9105/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 46.2987 - val_loss: 8.3803\n",
      "Epoch 9106/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 45.0736 - val_loss: 7.7086\n",
      "Epoch 9107/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 52.9316 - val_loss: 6.9984\n",
      "Epoch 9108/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 53.9853 - val_loss: 6.8128\n",
      "Epoch 9109/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 49.9628 - val_loss: 6.8517\n",
      "Epoch 9110/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 54.8404 - val_loss: 7.0685\n",
      "Epoch 9111/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 47.7423 - val_loss: 7.2304\n",
      "Epoch 9112/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 48.8620 - val_loss: 7.4268\n",
      "Epoch 9113/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 49.1758 - val_loss: 7.5467\n",
      "Epoch 9114/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 39.9547 - val_loss: 7.4898\n",
      "Epoch 9115/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 51.0167 - val_loss: 7.4787\n",
      "Epoch 9116/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 45.8971 - val_loss: 7.4234\n",
      "Epoch 9117/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 55.5057 - val_loss: 7.2777\n",
      "Epoch 9118/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 48.5738 - val_loss: 7.2115\n",
      "Epoch 9119/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 50.4246 - val_loss: 7.2416\n",
      "Epoch 9120/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 46.4865 - val_loss: 7.2331\n",
      "Epoch 9121/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 47.9058 - val_loss: 7.2099\n",
      "Epoch 9122/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 52.2169 - val_loss: 7.1976\n",
      "Epoch 9123/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 53.6302 - val_loss: 7.1998\n",
      "Epoch 9124/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 54.6224 - val_loss: 7.2059\n",
      "Epoch 9125/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 63.4571 - val_loss: 7.2033\n",
      "Epoch 9126/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 44.3949 - val_loss: 7.2062\n",
      "Epoch 9127/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 76.5259 - val_loss: 7.2141\n",
      "Epoch 9128/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 52.0814 - val_loss: 7.2207\n",
      "Epoch 9129/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 57.4948 - val_loss: 7.2244\n",
      "Epoch 9130/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 53.2967 - val_loss: 7.2256\n",
      "Epoch 9131/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 59.3010 - val_loss: 7.2205\n",
      "Epoch 9132/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 41.9521 - val_loss: 7.1014\n",
      "Epoch 9133/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 44.3772 - val_loss: 7.1908\n",
      "Epoch 9134/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 61.6423 - val_loss: 7.2893\n",
      "Epoch 9135/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 50.9201 - val_loss: 7.3635\n",
      "Epoch 9136/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 58.3860 - val_loss: 7.4490\n",
      "Epoch 9137/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 52.7874 - val_loss: 7.5627\n",
      "Epoch 9138/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 46.1764 - val_loss: 7.5642\n",
      "Epoch 9139/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 38.3886 - val_loss: 7.6022\n",
      "Epoch 9140/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 52.2496 - val_loss: 7.6364\n",
      "Epoch 9141/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 36.7282 - val_loss: 7.6554\n",
      "Epoch 9142/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 52.4589 - val_loss: 7.6721\n",
      "Epoch 9143/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 46.6811 - val_loss: 7.7039\n",
      "Epoch 9144/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 52.1025 - val_loss: 7.7284\n",
      "Epoch 9145/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 533us/step - loss: 47.9184 - val_loss: 7.7489\n",
      "Epoch 9146/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 51.0471 - val_loss: 7.7641\n",
      "Epoch 9147/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 50.4888 - val_loss: 7.7743\n",
      "Epoch 9148/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 42.2529 - val_loss: 7.7822\n",
      "Epoch 9149/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 51.5930 - val_loss: 7.7942\n",
      "Epoch 9150/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 40.9109 - val_loss: 7.8285\n",
      "Epoch 9151/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 50.8165 - val_loss: 7.8226\n",
      "Epoch 9152/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 44.4605 - val_loss: 7.4796\n",
      "Epoch 9153/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 66.2479 - val_loss: 7.4242\n",
      "Epoch 9154/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 48.4332 - val_loss: 7.4733\n",
      "Epoch 9155/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 51.3038 - val_loss: 7.8568\n",
      "Epoch 9156/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 70.9885 - val_loss: 7.8793\n",
      "Epoch 9157/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 43.6018 - val_loss: 7.7764\n",
      "Epoch 9158/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 50.6419 - val_loss: 7.6910\n",
      "Epoch 9159/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 39.7754 - val_loss: 7.6401\n",
      "Epoch 9160/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 62.1132 - val_loss: 7.6006\n",
      "Epoch 9161/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 56.4050 - val_loss: 7.5797\n",
      "Epoch 9162/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 48.5242 - val_loss: 7.5844\n",
      "Epoch 9163/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 74.7320 - val_loss: 7.6181\n",
      "Epoch 9164/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 60.7562 - val_loss: 7.6014\n",
      "Epoch 9165/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 52.9826 - val_loss: 7.6228\n",
      "Epoch 9166/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 40.7875 - val_loss: 7.6482\n",
      "Epoch 9167/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 66.5936 - val_loss: 7.6661\n",
      "Epoch 9168/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 66.1772 - val_loss: 7.6865\n",
      "Epoch 9169/10000\n",
      "184/184 [==============================] - 0s 777us/step - loss: 56.5952 - val_loss: 7.7220\n",
      "Epoch 9170/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 47.3498 - val_loss: 7.7747\n",
      "Epoch 9171/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 58.3919 - val_loss: 7.8095\n",
      "Epoch 9172/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 55.6910 - val_loss: 7.8369\n",
      "Epoch 9173/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 48.8744 - val_loss: 7.8517\n",
      "Epoch 9174/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 58.9276 - val_loss: 7.8562\n",
      "Epoch 9175/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 44.9175 - val_loss: 7.8465\n",
      "Epoch 9176/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 57.4670 - val_loss: 7.8380\n",
      "Epoch 9177/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 52.1223 - val_loss: 7.8283\n",
      "Epoch 9178/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 53.6198 - val_loss: 7.8218\n",
      "Epoch 9179/10000\n",
      "184/184 [==============================] - 0s 435us/step - loss: 47.9557 - val_loss: 7.8194\n",
      "Epoch 9180/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 49.7987 - val_loss: 7.8225\n",
      "Epoch 9181/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 49.9551 - val_loss: 7.8204\n",
      "Epoch 9182/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 46.0789 - val_loss: 7.8186\n",
      "Epoch 9183/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 53.6112 - val_loss: 7.8215\n",
      "Epoch 9184/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 58.9199 - val_loss: 7.8245\n",
      "Epoch 9185/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 58.6918 - val_loss: 7.8265\n",
      "Epoch 9186/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 57.3261 - val_loss: 7.8299\n",
      "Epoch 9187/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 42.0633 - val_loss: 7.8303\n",
      "Epoch 9188/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 55.1211 - val_loss: 7.8294\n",
      "Epoch 9189/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 49.9929 - val_loss: 7.8275\n",
      "Epoch 9190/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 73.7355 - val_loss: 7.8251\n",
      "Epoch 9191/10000\n",
      "184/184 [==============================] - 0s 581us/step - loss: 41.8220 - val_loss: 7.8237\n",
      "Epoch 9192/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 45.5961 - val_loss: 7.8227\n",
      "Epoch 9193/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 50.2460 - val_loss: 7.8204\n",
      "Epoch 9194/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 46.4701 - val_loss: 7.8176\n",
      "Epoch 9195/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 59.5691 - val_loss: 7.8148\n",
      "Epoch 9196/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 52.2326 - val_loss: 7.8158\n",
      "Epoch 9197/10000\n",
      "184/184 [==============================] - 0s 544us/step - loss: 47.4165 - val_loss: 7.8162\n",
      "Epoch 9198/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 56.1021 - val_loss: 7.8118\n",
      "Epoch 9199/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 40.3651 - val_loss: 7.8058\n",
      "Epoch 9200/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 51.5918 - val_loss: 7.7551\n",
      "\n",
      "Epoch 09200: loss did not improve from 46.32582\n",
      "Epoch 9201/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 53.8187 - val_loss: 7.6784\n",
      "Epoch 9202/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 49.8871 - val_loss: 7.6144\n",
      "Epoch 9203/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 60.3045 - val_loss: 7.5419\n",
      "Epoch 9204/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 48.0974 - val_loss: 7.4869\n",
      "Epoch 9205/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 50.5481 - val_loss: 7.3712\n",
      "Epoch 9206/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 47.2097 - val_loss: 7.3210\n",
      "Epoch 9207/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 52.6081 - val_loss: 7.2779\n",
      "Epoch 9208/10000\n",
      "184/184 [==============================] - 0s 490us/step - loss: 55.7969 - val_loss: 7.1484\n",
      "Epoch 9209/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 50.0605 - val_loss: 7.1864\n",
      "Epoch 9210/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 65.5757 - val_loss: 7.1768\n",
      "Epoch 9211/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 58.3694 - val_loss: 7.0895\n",
      "Epoch 9212/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 58.9425 - val_loss: 7.0072\n",
      "Epoch 9213/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 49.8545 - val_loss: 6.9497\n",
      "Epoch 9214/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 45.8776 - val_loss: 6.8991\n",
      "Epoch 9215/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 48.6031 - val_loss: 6.8563\n",
      "Epoch 9216/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 60.5521 - val_loss: 6.8351\n",
      "Epoch 9217/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 49.5605 - val_loss: 6.8298\n",
      "Epoch 9218/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 55.9672 - val_loss: 6.8197\n",
      "Epoch 9219/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 55.1650 - val_loss: 6.8120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9220/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 51.0055 - val_loss: 6.8070\n",
      "Epoch 9221/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 44.8211 - val_loss: 6.8029\n",
      "Epoch 9222/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 50.9235 - val_loss: 6.8009\n",
      "Epoch 9223/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 51.0120 - val_loss: 6.8140\n",
      "Epoch 9224/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 58.3764 - val_loss: 6.8272\n",
      "Epoch 9225/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 50.8251 - val_loss: 6.8332\n",
      "Epoch 9226/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 54.8162 - val_loss: 6.8371\n",
      "Epoch 9227/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 51.2467 - val_loss: 6.8316\n",
      "Epoch 9228/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 46.3585 - val_loss: 6.8113\n",
      "Epoch 9229/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 46.0940 - val_loss: 6.7737\n",
      "Epoch 9230/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 63.5062 - val_loss: 6.7459\n",
      "Epoch 9231/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 46.1040 - val_loss: 6.7285\n",
      "Epoch 9232/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 46.3806 - val_loss: 6.7183\n",
      "Epoch 9233/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 38.5878 - val_loss: 6.7103\n",
      "Epoch 9234/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 60.2498 - val_loss: 6.7027\n",
      "Epoch 9235/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 41.6525 - val_loss: 6.6997\n",
      "Epoch 9236/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 46.7307 - val_loss: 6.6982\n",
      "Epoch 9237/10000\n",
      "184/184 [==============================] - 0s 701us/step - loss: 42.1326 - val_loss: 6.6960\n",
      "Epoch 9238/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 49.0340 - val_loss: 6.6974\n",
      "Epoch 9239/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 65.0937 - val_loss: 6.6983\n",
      "Epoch 9240/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 42.0715 - val_loss: 6.6990\n",
      "Epoch 9241/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 55.8266 - val_loss: 6.6991\n",
      "Epoch 9242/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 51.1584 - val_loss: 6.6943\n",
      "Epoch 9243/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 50.4830 - val_loss: 6.6924\n",
      "Epoch 9244/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 48.3116 - val_loss: 6.6954\n",
      "Epoch 9245/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 53.5409 - val_loss: 6.6979\n",
      "Epoch 9246/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 49.3265 - val_loss: 6.6969\n",
      "Epoch 9247/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 44.3491 - val_loss: 6.6962\n",
      "Epoch 9248/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 56.3864 - val_loss: 6.7029\n",
      "Epoch 9249/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 56.3762 - val_loss: 6.7112\n",
      "Epoch 9250/10000\n",
      "184/184 [==============================] - 0s 663us/step - loss: 48.8502 - val_loss: 6.7184\n",
      "Epoch 9251/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 44.0832 - val_loss: 6.7195\n",
      "Epoch 9252/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 63.9486 - val_loss: 6.7152\n",
      "Epoch 9253/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 45.4618 - val_loss: 6.7139\n",
      "Epoch 9254/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 38.3825 - val_loss: 6.7136\n",
      "Epoch 9255/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 46.7688 - val_loss: 6.7127\n",
      "Epoch 9256/10000\n",
      "184/184 [==============================] - 0s 601us/step - loss: 52.1937 - val_loss: 6.7107\n",
      "Epoch 9257/10000\n",
      "184/184 [==============================] - 0s 486us/step - loss: 54.1035 - val_loss: 6.7055\n",
      "Epoch 9258/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 69.9011 - val_loss: 6.6944\n",
      "Epoch 9259/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 40.3961 - val_loss: 6.6827\n",
      "Epoch 9260/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 52.9615 - val_loss: 6.6741\n",
      "Epoch 9261/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 63.8097 - val_loss: 6.6643\n",
      "Epoch 9262/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 49.3666 - val_loss: 6.6563\n",
      "Epoch 9263/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 53.2197 - val_loss: 6.6469\n",
      "Epoch 9264/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 41.9999 - val_loss: 6.6393\n",
      "Epoch 9265/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 59.0245 - val_loss: 6.6352\n",
      "Epoch 9266/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 60.3459 - val_loss: 6.6325\n",
      "Epoch 9267/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 59.7533 - val_loss: 6.6321\n",
      "Epoch 9268/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 46.4125 - val_loss: 6.6355\n",
      "Epoch 9269/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 67.15 - 0s 505us/step - loss: 60.5356 - val_loss: 6.6500\n",
      "Epoch 9270/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 51.8028 - val_loss: 6.6649\n",
      "Epoch 9271/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 48.0680 - val_loss: 6.6809\n",
      "Epoch 9272/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 46.4561 - val_loss: 6.6881\n",
      "Epoch 9273/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 50.6074 - val_loss: 6.6957\n",
      "Epoch 9274/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 55.9471 - val_loss: 6.7057\n",
      "Epoch 9275/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 47.3713 - val_loss: 6.7139\n",
      "Epoch 9276/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 53.0489 - val_loss: 6.7196\n",
      "Epoch 9277/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 56.9858 - val_loss: 6.7242\n",
      "Epoch 9278/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 41.7085 - val_loss: 6.7248\n",
      "Epoch 9279/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 58.8464 - val_loss: 6.7227\n",
      "Epoch 9280/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 51.4424 - val_loss: 6.7210\n",
      "Epoch 9281/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 64.0790 - val_loss: 6.7280\n",
      "Epoch 9282/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 53.5253 - val_loss: 6.7329\n",
      "Epoch 9283/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 52.3231 - val_loss: 6.7260\n",
      "Epoch 9284/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 48.6717 - val_loss: 6.7147\n",
      "Epoch 9285/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 57.8386 - val_loss: 6.6945\n",
      "Epoch 9286/10000\n",
      "184/184 [==============================] - 0s 424us/step - loss: 43.3469 - val_loss: 6.6676\n",
      "Epoch 9287/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 43.5490 - val_loss: 6.6443\n",
      "Epoch 9288/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 60.7663 - val_loss: 6.5972\n",
      "Epoch 9289/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 48.5452 - val_loss: 6.5380\n",
      "Epoch 9290/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 56.8582 - val_loss: 6.5222\n",
      "Epoch 9291/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 41.1626 - val_loss: 6.5182\n",
      "Epoch 9292/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 51.2955 - val_loss: 6.5201\n",
      "Epoch 9293/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 64.6176 - val_loss: 6.5242\n",
      "Epoch 9294/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 44.5403 - val_loss: 6.5258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9295/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 57.0124 - val_loss: 6.5272\n",
      "Epoch 9296/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 49.7345 - val_loss: 6.5293\n",
      "Epoch 9297/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 49.9440 - val_loss: 6.5287\n",
      "Epoch 9298/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 54.7512 - val_loss: 6.5251\n",
      "Epoch 9299/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 45.9078 - val_loss: 6.5228\n",
      "Epoch 9300/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 58.8310 - val_loss: 6.5194\n",
      "\n",
      "Epoch 09300: loss did not improve from 46.32582\n",
      "Epoch 9301/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 64.4933 - val_loss: 6.5134\n",
      "Epoch 9302/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 45.2311 - val_loss: 6.5089\n",
      "Epoch 9303/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 45.0234 - val_loss: 6.5037\n",
      "Epoch 9304/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 54.4108 - val_loss: 6.4990\n",
      "Epoch 9305/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 53.7119 - val_loss: 6.4955\n",
      "Epoch 9306/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 45.7566 - val_loss: 6.4938\n",
      "Epoch 9307/10000\n",
      "184/184 [==============================] - 0s 606us/step - loss: 47.0482 - val_loss: 6.4918\n",
      "Epoch 9308/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 51.3493 - val_loss: 6.4906\n",
      "Epoch 9309/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 39.9177 - val_loss: 6.4898\n",
      "Epoch 9310/10000\n",
      "184/184 [==============================] - 0s 579us/step - loss: 45.8140 - val_loss: 6.4893\n",
      "Epoch 9311/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 41.1301 - val_loss: 6.4878\n",
      "Epoch 9312/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 55.9609 - val_loss: 6.4810\n",
      "Epoch 9313/10000\n",
      "184/184 [==============================] - 0s 647us/step - loss: 50.3209 - val_loss: 6.4760\n",
      "Epoch 9314/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 48.1182 - val_loss: 6.4705\n",
      "Epoch 9315/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 61.2802 - val_loss: 6.4650\n",
      "Epoch 9316/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 60.9254 - val_loss: 6.4606\n",
      "Epoch 9317/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 54.8502 - val_loss: 6.4564\n",
      "Epoch 9318/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 47.1376 - val_loss: 6.4509\n",
      "Epoch 9319/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 55.1946 - val_loss: 6.4457\n",
      "Epoch 9320/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 52.3783 - val_loss: 6.4423\n",
      "Epoch 9321/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 41.7255 - val_loss: 6.4418\n",
      "Epoch 9322/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 42.4549 - val_loss: 6.4403\n",
      "Epoch 9323/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 54.8731 - val_loss: 6.4388\n",
      "Epoch 9324/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 56.0691 - val_loss: 6.4360\n",
      "Epoch 9325/10000\n",
      "184/184 [==============================] - 0s 429us/step - loss: 52.4389 - val_loss: 6.4279\n",
      "Epoch 9326/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 48.2245 - val_loss: 6.4260\n",
      "Epoch 9327/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 36.8912 - val_loss: 6.4262\n",
      "Epoch 9328/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 45.4064 - val_loss: 6.4310\n",
      "Epoch 9329/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 45.4181 - val_loss: 6.4352\n",
      "Epoch 9330/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 56.6913 - val_loss: 6.4385\n",
      "Epoch 9331/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 58.0064 - val_loss: 6.4285\n",
      "Epoch 9332/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 55.2930 - val_loss: 6.4237\n",
      "Epoch 9333/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 46.8361 - val_loss: 6.4192\n",
      "Epoch 9334/10000\n",
      "184/184 [==============================] - 0s 456us/step - loss: 49.6631 - val_loss: 6.4153\n",
      "Epoch 9335/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 45.9808 - val_loss: 6.4129\n",
      "Epoch 9336/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 61.7609 - val_loss: 6.4098\n",
      "Epoch 9337/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 59.0930 - val_loss: 6.4090\n",
      "Epoch 9338/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 52.7120 - val_loss: 6.4087\n",
      "Epoch 9339/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 41.3762 - val_loss: 6.4105\n",
      "Epoch 9340/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 50.0398 - val_loss: 6.4110\n",
      "Epoch 9341/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 57.2980 - val_loss: 6.4128\n",
      "Epoch 9342/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 43.5816 - val_loss: 6.4160\n",
      "Epoch 9343/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 44.4604 - val_loss: 6.4934\n",
      "Epoch 9344/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 51.9002 - val_loss: 6.6396\n",
      "Epoch 9345/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 49.7566 - val_loss: 6.7920\n",
      "Epoch 9346/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 40.5325 - val_loss: 6.9332\n",
      "Epoch 9347/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 53.0458 - val_loss: 7.0694\n",
      "Epoch 9348/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 51.7482 - val_loss: 7.1674\n",
      "Epoch 9349/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 44.8224 - val_loss: 7.2543\n",
      "Epoch 9350/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 70.1459 - val_loss: 7.3081\n",
      "Epoch 9351/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 43.6433 - val_loss: 7.3309\n",
      "Epoch 9352/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 59.6509 - val_loss: 7.3327\n",
      "Epoch 9353/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 42.0614 - val_loss: 7.3226\n",
      "Epoch 9354/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 49.7858 - val_loss: 7.3020\n",
      "Epoch 9355/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 60.0252 - val_loss: 7.2838\n",
      "Epoch 9356/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 48.8806 - val_loss: 7.2579\n",
      "Epoch 9357/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 42.4531 - val_loss: 7.2335\n",
      "Epoch 9358/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 51.0687 - val_loss: 7.2189\n",
      "Epoch 9359/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 45.0362 - val_loss: 7.2088\n",
      "Epoch 9360/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 60.8016 - val_loss: 7.2234\n",
      "Epoch 9361/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 48.0437 - val_loss: 7.2328\n",
      "Epoch 9362/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 48.1295 - val_loss: 7.2303\n",
      "Epoch 9363/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 44.3156 - val_loss: 7.2191\n",
      "Epoch 9364/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 30.3158 - val_loss: 6.9078\n",
      "Epoch 9365/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 58.4643 - val_loss: 6.4520\n",
      "Epoch 9366/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 55.4985 - val_loss: 6.0799\n",
      "Epoch 9367/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 47.8672 - val_loss: 5.8115\n",
      "Epoch 9368/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 54.3219 - val_loss: 5.6427\n",
      "Epoch 9369/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 489us/step - loss: 43.8319 - val_loss: 5.5587\n",
      "Epoch 9370/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 52.9783 - val_loss: 5.5040\n",
      "Epoch 9371/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 52.0011 - val_loss: 5.4619\n",
      "Epoch 9372/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 53.5268 - val_loss: 5.4293\n",
      "Epoch 9373/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 48.3964 - val_loss: 5.4078\n",
      "Epoch 9374/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 55.5841 - val_loss: 5.4201\n",
      "Epoch 9375/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 42.7467 - val_loss: 5.3499\n",
      "Epoch 9376/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 60.5879 - val_loss: 5.3493\n",
      "Epoch 9377/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 46.9505 - val_loss: 5.3778\n",
      "Epoch 9378/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 56.6817 - val_loss: 5.3982\n",
      "Epoch 9379/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 43.7758 - val_loss: 5.3758\n",
      "Epoch 9380/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 58.4882 - val_loss: 5.3684\n",
      "Epoch 9381/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 51.9551 - val_loss: 5.3845\n",
      "Epoch 9382/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 46.8060 - val_loss: 5.4228\n",
      "Epoch 9383/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 58.1002 - val_loss: 5.4492\n",
      "Epoch 9384/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 50.0441 - val_loss: 5.4634\n",
      "Epoch 9385/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 55.1854 - val_loss: 5.4759\n",
      "Epoch 9386/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 46.9524 - val_loss: 5.4856\n",
      "Epoch 9387/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 49.3265 - val_loss: 5.4930\n",
      "Epoch 9388/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 52.4626 - val_loss: 5.5001\n",
      "Epoch 9389/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 45.0729 - val_loss: 5.5085\n",
      "Epoch 9390/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 56.6862 - val_loss: 5.5205\n",
      "Epoch 9391/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 39.6306 - val_loss: 5.5321\n",
      "Epoch 9392/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 46.7802 - val_loss: 5.5459\n",
      "Epoch 9393/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 57.3233 - val_loss: 5.5584\n",
      "Epoch 9394/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 44.9620 - val_loss: 5.5778\n",
      "Epoch 9395/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 41.5353 - val_loss: 5.6282\n",
      "Epoch 9396/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 54.4237 - val_loss: 5.6555\n",
      "Epoch 9397/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 52.4244 - val_loss: 5.6330\n",
      "Epoch 9398/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 47.0980 - val_loss: 5.6522\n",
      "Epoch 9399/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 41.0286 - val_loss: 5.7055\n",
      "Epoch 9400/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 54.2270 - val_loss: 5.7112\n",
      "\n",
      "Epoch 09400: loss did not improve from 46.32582\n",
      "Epoch 9401/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 67.0668 - val_loss: 5.7070\n",
      "Epoch 9402/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 49.1452 - val_loss: 5.7125\n",
      "Epoch 9403/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 55.2507 - val_loss: 5.7173\n",
      "Epoch 9404/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 59.3769 - val_loss: 5.7133\n",
      "Epoch 9405/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 45.8339 - val_loss: 5.7154\n",
      "Epoch 9406/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 43.0886 - val_loss: 5.7483\n",
      "Epoch 9407/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 51.5912 - val_loss: 5.7333\n",
      "Epoch 9408/10000\n",
      "184/184 [==============================] - 0s 712us/step - loss: 53.6175 - val_loss: 5.6937\n",
      "Epoch 9409/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 36.4613 - val_loss: 5.8234\n",
      "Epoch 9410/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 66.8338 - val_loss: 7.5524\n",
      "Epoch 9411/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 47.1216 - val_loss: 7.2128\n",
      "Epoch 9412/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 41.2411 - val_loss: 6.5020\n",
      "Epoch 9413/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 55.1424 - val_loss: 6.3312\n",
      "Epoch 9414/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 47.9597 - val_loss: 6.3385\n",
      "Epoch 9415/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 43.6964 - val_loss: 6.3416\n",
      "Epoch 9416/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 49.6204 - val_loss: 6.3666\n",
      "Epoch 9417/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 61.0794 - val_loss: 6.3577\n",
      "Epoch 9418/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 57.2175 - val_loss: 6.3732\n",
      "Epoch 9419/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 50.3095 - val_loss: 6.3928\n",
      "Epoch 9420/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 58.5947 - val_loss: 6.4262\n",
      "Epoch 9421/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 50.4409 - val_loss: 6.4613\n",
      "Epoch 9422/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 49.0171 - val_loss: 6.4783\n",
      "Epoch 9423/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 38.2671 - val_loss: 6.4939\n",
      "Epoch 9424/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 48.3368 - val_loss: 6.5084\n",
      "Epoch 9425/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 42.4605 - val_loss: 6.5190\n",
      "Epoch 9426/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 51.4914 - val_loss: 6.5255\n",
      "Epoch 9427/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 40.7077 - val_loss: 6.5329\n",
      "Epoch 9428/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 39.9298 - val_loss: 6.5411\n",
      "Epoch 9429/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 44.3546 - val_loss: 6.5481\n",
      "Epoch 9430/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 55.1207 - val_loss: 6.5616\n",
      "Epoch 9431/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 65.1733 - val_loss: 6.5691\n",
      "Epoch 9432/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 48.5796 - val_loss: 6.5740\n",
      "Epoch 9433/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 47.8929 - val_loss: 6.5791\n",
      "Epoch 9434/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 37.7014 - val_loss: 6.5731\n",
      "Epoch 9435/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 45.1828 - val_loss: 6.5612\n",
      "Epoch 9436/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 52.7443 - val_loss: 6.5511\n",
      "Epoch 9437/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 44.8820 - val_loss: 6.5487\n",
      "Epoch 9438/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 51.8696 - val_loss: 6.5258\n",
      "Epoch 9439/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 48.0356 - val_loss: 6.4959\n",
      "Epoch 9440/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 54.7817 - val_loss: 6.4792\n",
      "Epoch 9441/10000\n",
      "184/184 [==============================] - 0s 435us/step - loss: 50.4685 - val_loss: 6.4685\n",
      "Epoch 9442/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 57.4934 - val_loss: 6.4568\n",
      "Epoch 9443/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 45.0546 - val_loss: 6.4473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9444/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 39.6532 - val_loss: 6.4363\n",
      "Epoch 9445/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 45.0277 - val_loss: 6.4271\n",
      "Epoch 9446/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 55.7361 - val_loss: 6.4189\n",
      "Epoch 9447/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 50.5234 - val_loss: 6.4276\n",
      "Epoch 9448/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 46.5615 - val_loss: 6.4367\n",
      "Epoch 9449/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 49.5588 - val_loss: 6.4468\n",
      "Epoch 9450/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 55.63 - 0s 582us/step - loss: 54.0670 - val_loss: 6.4526\n",
      "Epoch 9451/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 55.6928 - val_loss: 6.4613\n",
      "Epoch 9452/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 65.4791 - val_loss: 6.4705\n",
      "Epoch 9453/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 46.6066 - val_loss: 6.4643\n",
      "Epoch 9454/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 52.0287 - val_loss: 6.4565\n",
      "Epoch 9455/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 45.0088 - val_loss: 6.4530\n",
      "Epoch 9456/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 42.6537 - val_loss: 6.4515\n",
      "Epoch 9457/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 71.3840 - val_loss: 6.4551\n",
      "Epoch 9458/10000\n",
      "184/184 [==============================] - 0s 669us/step - loss: 56.0393 - val_loss: 6.4604\n",
      "Epoch 9459/10000\n",
      "184/184 [==============================] - 0s 685us/step - loss: 56.4918 - val_loss: 6.4615\n",
      "Epoch 9460/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 43.9770 - val_loss: 6.4581\n",
      "Epoch 9461/10000\n",
      "184/184 [==============================] - 0s 674us/step - loss: 63.0346 - val_loss: 6.3745\n",
      "Epoch 9462/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 52.6281 - val_loss: 6.3386\n",
      "Epoch 9463/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 60.8116 - val_loss: 6.3041\n",
      "Epoch 9464/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 44.6467 - val_loss: 6.2435\n",
      "Epoch 9465/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 44.4445 - val_loss: 6.1981\n",
      "Epoch 9466/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 38.1691 - val_loss: 6.1605\n",
      "Epoch 9467/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 55.0222 - val_loss: 6.1248\n",
      "Epoch 9468/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 44.0796 - val_loss: 6.0937\n",
      "Epoch 9469/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 59.6970 - val_loss: 6.0701\n",
      "Epoch 9470/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 52.3341 - val_loss: 6.0525\n",
      "Epoch 9471/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 47.9851 - val_loss: 6.0371\n",
      "Epoch 9472/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 35.4929 - val_loss: 6.0324\n",
      "Epoch 9473/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 62.2210 - val_loss: 6.0300\n",
      "Epoch 9474/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 46.6884 - val_loss: 6.0244\n",
      "Epoch 9475/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 51.8814 - val_loss: 6.0199\n",
      "Epoch 9476/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 61.2991 - val_loss: 6.0129\n",
      "Epoch 9477/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 46.8805 - val_loss: 6.0057\n",
      "Epoch 9478/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 52.5864 - val_loss: 6.0080\n",
      "Epoch 9479/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 40.7138 - val_loss: 6.0093\n",
      "Epoch 9480/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 45.9687 - val_loss: 6.0138\n",
      "Epoch 9481/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 43.4775 - val_loss: 6.0151\n",
      "Epoch 9482/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 47.9032 - val_loss: 6.0146\n",
      "Epoch 9483/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 49.5061 - val_loss: 6.0125\n",
      "Epoch 9484/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 43.1022 - val_loss: 6.0097\n",
      "Epoch 9485/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 61.2552 - val_loss: 6.0066\n",
      "Epoch 9486/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 49.5663 - val_loss: 6.0033\n",
      "Epoch 9487/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 50.4048 - val_loss: 6.0004\n",
      "Epoch 9488/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 54.4709 - val_loss: 5.9972\n",
      "Epoch 9489/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 55.3638 - val_loss: 5.9923\n",
      "Epoch 9490/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 54.8643 - val_loss: 5.9909\n",
      "Epoch 9491/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 47.1397 - val_loss: 5.9896\n",
      "Epoch 9492/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 42.4085 - val_loss: 5.9888\n",
      "Epoch 9493/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 46.4227 - val_loss: 5.9886\n",
      "Epoch 9494/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 47.7640 - val_loss: 5.9849\n",
      "Epoch 9495/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 46.7005 - val_loss: 5.9797\n",
      "Epoch 9496/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 40.8396 - val_loss: 5.9741\n",
      "Epoch 9497/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 45.8047 - val_loss: 5.9694\n",
      "Epoch 9498/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 50.4847 - val_loss: 5.9644\n",
      "Epoch 9499/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 54.2074 - val_loss: 5.9595\n",
      "Epoch 9500/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 46.2573 - val_loss: 5.9546\n",
      "\n",
      "Epoch 09500: loss improved from 46.32582 to 46.25728, saving model to C6007C.hdf5\n",
      "Epoch 9501/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 43.0257 - val_loss: 5.9503\n",
      "Epoch 9502/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 52.2613 - val_loss: 5.9463\n",
      "Epoch 9503/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 41.9945 - val_loss: 5.9415\n",
      "Epoch 9504/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 55.9670 - val_loss: 5.9377\n",
      "Epoch 9505/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 49.6077 - val_loss: 5.9342\n",
      "Epoch 9506/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 48.7435 - val_loss: 5.9254\n",
      "Epoch 9507/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 48.1395 - val_loss: 5.9189\n",
      "Epoch 9508/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 56.7935 - val_loss: 5.9126\n",
      "Epoch 9509/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 52.2091 - val_loss: 5.9078\n",
      "Epoch 9510/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 59.2973 - val_loss: 5.9034\n",
      "Epoch 9511/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 52.3822 - val_loss: 5.8996\n",
      "Epoch 9512/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 63.05 - 0s 457us/step - loss: 62.7034 - val_loss: 5.8950\n",
      "Epoch 9513/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 40.5857 - val_loss: 5.8944\n",
      "Epoch 9514/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 49.5291 - val_loss: 5.8931\n",
      "Epoch 9515/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 35.9698 - val_loss: 5.8912\n",
      "Epoch 9516/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 45.1869 - val_loss: 5.8888\n",
      "Epoch 9517/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 41.9928 - val_loss: 5.8883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9518/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 47.5873 - val_loss: 5.8899\n",
      "Epoch 9519/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 44.8716 - val_loss: 5.8916\n",
      "Epoch 9520/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 39.2575 - val_loss: 5.8933\n",
      "Epoch 9521/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 43.2472 - val_loss: 5.8941\n",
      "Epoch 9522/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 42.5902 - val_loss: 5.8939\n",
      "Epoch 9523/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 47.0687 - val_loss: 5.8925\n",
      "Epoch 9524/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 47.5481 - val_loss: 5.8898\n",
      "Epoch 9525/10000\n",
      "184/184 [==============================] - 0s 435us/step - loss: 44.2200 - val_loss: 5.8863\n",
      "Epoch 9526/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 43.61 - 0s 527us/step - loss: 51.0067 - val_loss: 5.8829\n",
      "Epoch 9527/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 50.6192 - val_loss: 5.8794\n",
      "Epoch 9528/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 39.7914 - val_loss: 5.8764\n",
      "Epoch 9529/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 50.9422 - val_loss: 5.8465\n",
      "Epoch 9530/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 45.2454 - val_loss: 5.8193\n",
      "Epoch 9531/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 44.7520 - val_loss: 5.8317\n",
      "Epoch 9532/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 44.3418 - val_loss: 5.8346\n",
      "Epoch 9533/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 49.0893 - val_loss: 5.8789\n",
      "Epoch 9534/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 39.0339 - val_loss: 5.8797\n",
      "Epoch 9535/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 42.5127 - val_loss: 5.8623\n",
      "Epoch 9536/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 53.8814 - val_loss: 5.8486\n",
      "Epoch 9537/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 41.8299 - val_loss: 5.8407\n",
      "Epoch 9538/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 45.1300 - val_loss: 5.8356\n",
      "Epoch 9539/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 50.1962 - val_loss: 5.8327\n",
      "Epoch 9540/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 51.1557 - val_loss: 5.8322\n",
      "Epoch 9541/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 50.2025 - val_loss: 5.8340\n",
      "Epoch 9542/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 49.9870 - val_loss: 5.8350\n",
      "Epoch 9543/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 39.5809 - val_loss: 5.8341\n",
      "Epoch 9544/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 54.7243 - val_loss: 5.8333\n",
      "Epoch 9545/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 57.9182 - val_loss: 5.8325\n",
      "Epoch 9546/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 46.4921 - val_loss: 5.8321\n",
      "Epoch 9547/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 63.4577 - val_loss: 5.8316\n",
      "Epoch 9548/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 55.6218 - val_loss: 5.8313\n",
      "Epoch 9549/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 44.1196 - val_loss: 5.8304\n",
      "Epoch 9550/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 54.6794 - val_loss: 5.8301\n",
      "Epoch 9551/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 48.8872 - val_loss: 5.8295\n",
      "Epoch 9552/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 45.69 - 0s 495us/step - loss: 45.5725 - val_loss: 5.8241\n",
      "Epoch 9553/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 49.7243 - val_loss: 5.8319\n",
      "Epoch 9554/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 41.3958 - val_loss: 5.8405\n",
      "Epoch 9555/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 32.2728 - val_loss: 5.8483\n",
      "Epoch 9556/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 49.2918 - val_loss: 5.8530\n",
      "Epoch 9557/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 43.0231 - val_loss: 5.8574\n",
      "Epoch 9558/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 54.7067 - val_loss: 5.8620\n",
      "Epoch 9559/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 42.2688 - val_loss: 5.8656\n",
      "Epoch 9560/10000\n",
      "184/184 [==============================] - 0s 668us/step - loss: 43.6343 - val_loss: 5.8687\n",
      "Epoch 9561/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 39.4283 - val_loss: 5.8709\n",
      "Epoch 9562/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 45.9938 - val_loss: 5.9523\n",
      "Epoch 9563/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 35.6400 - val_loss: 5.9444\n",
      "Epoch 9564/10000\n",
      "184/184 [==============================] - 0s 755us/step - loss: 44.4340 - val_loss: 5.9743\n",
      "Epoch 9565/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 48.0741 - val_loss: 6.0250\n",
      "Epoch 9566/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 44.5519 - val_loss: 6.1383\n",
      "Epoch 9567/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 48.6518 - val_loss: 6.0022\n",
      "Epoch 9568/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 45.7560 - val_loss: 6.0823\n",
      "Epoch 9569/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 62.7590 - val_loss: 6.0092\n",
      "Epoch 9570/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 40.7398 - val_loss: 5.9877\n",
      "Epoch 9571/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 66.6640 - val_loss: 5.9612\n",
      "Epoch 9572/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 42.5644 - val_loss: 5.9427\n",
      "Epoch 9573/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 47.8767 - val_loss: 5.9554\n",
      "Epoch 9574/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 45.1988 - val_loss: 5.9661\n",
      "Epoch 9575/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 40.4739 - val_loss: 5.9704\n",
      "Epoch 9576/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 46.4991 - val_loss: 5.9712\n",
      "Epoch 9577/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 44.7630 - val_loss: 5.9702\n",
      "Epoch 9578/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 40.6629 - val_loss: 5.9681\n",
      "Epoch 9579/10000\n",
      "184/184 [==============================] - 0s 641us/step - loss: 44.1777 - val_loss: 5.9653\n",
      "Epoch 9580/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 48.4661 - val_loss: 5.9624\n",
      "Epoch 9581/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 53.8967 - val_loss: 5.9619\n",
      "Epoch 9582/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 27.1711 - val_loss: 5.9628\n",
      "Epoch 9583/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 47.4268 - val_loss: 5.9620\n",
      "Epoch 9584/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 44.8849 - val_loss: 5.9608\n",
      "Epoch 9585/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 53.1498 - val_loss: 5.9517\n",
      "Epoch 9586/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 38.4505 - val_loss: 5.9443\n",
      "Epoch 9587/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 56.4566 - val_loss: 5.9422\n",
      "Epoch 9588/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 59.3905 - val_loss: 5.9410\n",
      "Epoch 9589/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 46.2990 - val_loss: 5.9394\n",
      "Epoch 9590/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 43.1999 - val_loss: 5.9377\n",
      "Epoch 9591/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 41.4107 - val_loss: 5.9363\n",
      "Epoch 9592/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 500us/step - loss: 48.2014 - val_loss: 5.9349\n",
      "Epoch 9593/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 66.0332 - val_loss: 5.9243\n",
      "Epoch 9594/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 41.3531 - val_loss: 5.9095\n",
      "Epoch 9595/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 49.3969 - val_loss: 5.8988\n",
      "Epoch 9596/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 62.4208 - val_loss: 5.8886\n",
      "Epoch 9597/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 40.1508 - val_loss: 5.8799\n",
      "Epoch 9598/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 42.9054 - val_loss: 5.8727\n",
      "Epoch 9599/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 46.4449 - val_loss: 5.8716\n",
      "Epoch 9600/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 53.0942 - val_loss: 5.8766\n",
      "\n",
      "Epoch 09600: loss did not improve from 46.25728\n",
      "Epoch 9601/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 48.4812 - val_loss: 5.8932\n",
      "Epoch 9602/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 41.4543 - val_loss: 5.9188\n",
      "Epoch 9603/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 47.4147 - val_loss: 5.9373\n",
      "Epoch 9604/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 48.6488 - val_loss: 5.9550\n",
      "Epoch 9605/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 45.5589 - val_loss: 5.9687\n",
      "Epoch 9606/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 46.5271 - val_loss: 5.9788\n",
      "Epoch 9607/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 47.7461 - val_loss: 5.9877\n",
      "Epoch 9608/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 44.8024 - val_loss: 5.9946\n",
      "Epoch 9609/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 53.5308 - val_loss: 5.9989\n",
      "Epoch 9610/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 57.1896 - val_loss: 6.0012\n",
      "Epoch 9611/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 38.8810 - val_loss: 6.0060\n",
      "Epoch 9612/10000\n",
      "184/184 [==============================] - 0s 761us/step - loss: 39.5968 - val_loss: 6.0157\n",
      "Epoch 9613/10000\n",
      "184/184 [==============================] - 0s 821us/step - loss: 43.9921 - val_loss: 6.0232\n",
      "Epoch 9614/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 70.8193 - val_loss: 6.0360\n",
      "Epoch 9615/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 46.0762 - val_loss: 6.0512\n",
      "Epoch 9616/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 51.4680 - val_loss: 6.0615\n",
      "Epoch 9617/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 59.0843 - val_loss: 6.0666\n",
      "Epoch 9618/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 42.6654 - val_loss: 6.0687\n",
      "Epoch 9619/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 40.6613 - val_loss: 6.0686\n",
      "Epoch 9620/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 45.1541 - val_loss: 6.0697\n",
      "Epoch 9621/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 47.6707 - val_loss: 6.0711\n",
      "Epoch 9622/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 55.8101 - val_loss: 6.0722\n",
      "Epoch 9623/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 45.9310 - val_loss: 6.0722\n",
      "Epoch 9624/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 44.3041 - val_loss: 6.0767\n",
      "Epoch 9625/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 51.5324 - val_loss: 6.0860\n",
      "Epoch 9626/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 47.9130 - val_loss: 6.0944\n",
      "Epoch 9627/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 41.5399 - val_loss: 6.1010\n",
      "Epoch 9628/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 39.0592 - val_loss: 6.1064\n",
      "Epoch 9629/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 63.1086 - val_loss: 6.1100\n",
      "Epoch 9630/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 52.4276 - val_loss: 6.1020\n",
      "Epoch 9631/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 43.7351 - val_loss: 6.0944\n",
      "Epoch 9632/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 48.7393 - val_loss: 6.0882\n",
      "Epoch 9633/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 49.4249 - val_loss: 6.0793\n",
      "Epoch 9634/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 47.5289 - val_loss: 6.0731\n",
      "Epoch 9635/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 40.5174 - val_loss: 6.0669\n",
      "Epoch 9636/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 43.4428 - val_loss: 6.0612\n",
      "Epoch 9637/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 53.7059 - val_loss: 6.0561\n",
      "Epoch 9638/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 38.4064 - val_loss: 6.0521\n",
      "Epoch 9639/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 51.4914 - val_loss: 6.0495\n",
      "Epoch 9640/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 57.7112 - val_loss: 6.0436\n",
      "Epoch 9641/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 52.3816 - val_loss: 6.0378\n",
      "Epoch 9642/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 46.3443 - val_loss: 6.0320\n",
      "Epoch 9643/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 51.5172 - val_loss: 6.0275\n",
      "Epoch 9644/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 44.4811 - val_loss: 6.0247\n",
      "Epoch 9645/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 49.9807 - val_loss: 6.0214\n",
      "Epoch 9646/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 44.2313 - val_loss: 6.0184\n",
      "Epoch 9647/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 46.0435 - val_loss: 6.0136\n",
      "Epoch 9648/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 60.3740 - val_loss: 6.0090\n",
      "Epoch 9649/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 40.3424 - val_loss: 6.0050\n",
      "Epoch 9650/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 44.6638 - val_loss: 6.0016\n",
      "Epoch 9651/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 50.3295 - val_loss: 5.9984\n",
      "Epoch 9652/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 47.3585 - val_loss: 5.9951\n",
      "Epoch 9653/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 42.5266 - val_loss: 5.9896\n",
      "Epoch 9654/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 37.2692 - val_loss: 5.9835\n",
      "Epoch 9655/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 56.5384 - val_loss: 5.9791\n",
      "Epoch 9656/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 48.2600 - val_loss: 5.9745\n",
      "Epoch 9657/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 45.6183 - val_loss: 5.9708\n",
      "Epoch 9658/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 57.8779 - val_loss: 5.9676\n",
      "Epoch 9659/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 46.4575 - val_loss: 5.9645\n",
      "Epoch 9660/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 42.3149 - val_loss: 5.9613\n",
      "Epoch 9661/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 44.9014 - val_loss: 5.9587\n",
      "Epoch 9662/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 45.7532 - val_loss: 5.9564\n",
      "Epoch 9663/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 41.4178 - val_loss: 5.9538\n",
      "Epoch 9664/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 40.5407 - val_loss: 5.9519\n",
      "Epoch 9665/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 45.1780 - val_loss: 5.9484\n",
      "Epoch 9666/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 38.3825 - val_loss: 5.9459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9667/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 49.9554 - val_loss: 5.9446\n",
      "Epoch 9668/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 63.0365 - val_loss: 5.9437\n",
      "Epoch 9669/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 41.4384 - val_loss: 5.9423\n",
      "Epoch 9670/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 45.9926 - val_loss: 5.9410\n",
      "Epoch 9671/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 41.3511 - val_loss: 5.9390\n",
      "Epoch 9672/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 43.1671 - val_loss: 5.9373\n",
      "Epoch 9673/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 55.7578 - val_loss: 5.9353\n",
      "Epoch 9674/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 40.4361 - val_loss: 5.9334\n",
      "Epoch 9675/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 48.6928 - val_loss: 5.9248\n",
      "Epoch 9676/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 48.7060 - val_loss: 5.9163\n",
      "Epoch 9677/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 38.0401 - val_loss: 5.9087\n",
      "Epoch 9678/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 46.7504 - val_loss: 5.9036\n",
      "Epoch 9679/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 41.5354 - val_loss: 5.8991\n",
      "Epoch 9680/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 38.3205 - val_loss: 5.8937\n",
      "Epoch 9681/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 53.2194 - val_loss: 5.8886\n",
      "Epoch 9682/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 51.0592 - val_loss: 5.8840\n",
      "Epoch 9683/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 51.1687 - val_loss: 5.8806\n",
      "Epoch 9684/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 46.6047 - val_loss: 5.8826\n",
      "Epoch 9685/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 45.7917 - val_loss: 5.8894\n",
      "Epoch 9686/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 50.0374 - val_loss: 5.8945\n",
      "Epoch 9687/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 41.4877 - val_loss: 5.8988\n",
      "Epoch 9688/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 58.5485 - val_loss: 5.9013\n",
      "Epoch 9689/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 50.4621 - val_loss: 5.9022\n",
      "Epoch 9690/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 53.0827 - val_loss: 5.9013\n",
      "Epoch 9691/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 46.0383 - val_loss: 5.9000\n",
      "Epoch 9692/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 60.9641 - val_loss: 5.8993\n",
      "Epoch 9693/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 44.1703 - val_loss: 5.8992\n",
      "Epoch 9694/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 50.97 - 0s 505us/step - loss: 58.5560 - val_loss: 5.9015\n",
      "Epoch 9695/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 40.7339 - val_loss: 5.9056\n",
      "Epoch 9696/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 76.4139 - val_loss: 5.9083\n",
      "Epoch 9697/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 44.3899 - val_loss: 5.9074\n",
      "Epoch 9698/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 44.8576 - val_loss: 5.9066\n",
      "Epoch 9699/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 52.4403 - val_loss: 5.9055\n",
      "Epoch 9700/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 42.17 - 0s 500us/step - loss: 44.1030 - val_loss: 5.8697\n",
      "\n",
      "Epoch 09700: loss improved from 46.25728 to 44.10298, saving model to C6007C.hdf5\n",
      "Epoch 9701/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 44.2350 - val_loss: 5.8391\n",
      "Epoch 9702/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 53.4103 - val_loss: 5.8141\n",
      "Epoch 9703/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 40.5190 - val_loss: 5.7928\n",
      "Epoch 9704/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 38.9334 - val_loss: 5.7753\n",
      "Epoch 9705/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 44.5302 - val_loss: 5.7616\n",
      "Epoch 9706/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 36.4277 - val_loss: 5.7511\n",
      "Epoch 9707/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 42.6127 - val_loss: 5.7434\n",
      "Epoch 9708/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 38.0149 - val_loss: 5.7362\n",
      "Epoch 9709/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 52.7725 - val_loss: 5.7270\n",
      "Epoch 9710/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 48.9168 - val_loss: 5.7159\n",
      "Epoch 9711/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 57.7940 - val_loss: 5.7013\n",
      "Epoch 9712/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 47.1355 - val_loss: 5.6854\n",
      "Epoch 9713/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 45.1507 - val_loss: 5.6724\n",
      "Epoch 9714/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 44.3581 - val_loss: 5.6604\n",
      "Epoch 9715/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 41.7988 - val_loss: 5.6515\n",
      "Epoch 9716/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 46.9089 - val_loss: 5.6458\n",
      "Epoch 9717/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 36.3524 - val_loss: 5.6334\n",
      "Epoch 9718/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 36.9023 - val_loss: 5.6143\n",
      "Epoch 9719/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 41.7860 - val_loss: 5.5989\n",
      "Epoch 9720/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 59.4339 - val_loss: 5.5870\n",
      "Epoch 9721/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 52.1671 - val_loss: 5.5806\n",
      "Epoch 9722/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 51.9823 - val_loss: 5.5818\n",
      "Epoch 9723/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 42.9362 - val_loss: 5.5887\n",
      "Epoch 9724/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 45.0839 - val_loss: 5.5951\n",
      "Epoch 9725/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 46.7791 - val_loss: 5.6012\n",
      "Epoch 9726/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 40.3608 - val_loss: 5.6064\n",
      "Epoch 9727/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 40.3023 - val_loss: 5.6105\n",
      "Epoch 9728/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 48.3983 - val_loss: 5.6134\n",
      "Epoch 9729/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 48.2198 - val_loss: 5.6154\n",
      "Epoch 9730/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 45.2207 - val_loss: 5.6161\n",
      "Epoch 9731/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 46.6619 - val_loss: 5.6154\n",
      "Epoch 9732/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 45.1025 - val_loss: 5.6129\n",
      "Epoch 9733/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 49.8510 - val_loss: 5.6092\n",
      "Epoch 9734/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 37.1675 - val_loss: 5.6040\n",
      "Epoch 9735/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 42.1430 - val_loss: 5.6014\n",
      "Epoch 9736/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 54.6219 - val_loss: 5.5986\n",
      "Epoch 9737/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 45.1869 - val_loss: 5.5969\n",
      "Epoch 9738/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 58.7969 - val_loss: 5.5971\n",
      "Epoch 9739/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 49.9257 - val_loss: 5.5965\n",
      "Epoch 9740/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 50.2733 - val_loss: 5.5960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9741/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 34.3593 - val_loss: 5.5960\n",
      "Epoch 9742/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 54.7621 - val_loss: 5.5939\n",
      "Epoch 9743/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 40.0698 - val_loss: 5.5866\n",
      "Epoch 9744/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 44.1185 - val_loss: 5.5788\n",
      "Epoch 9745/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 47.2696 - val_loss: 5.5827\n",
      "Epoch 9746/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 51.3775 - val_loss: 5.5865\n",
      "Epoch 9747/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 44.0561 - val_loss: 5.5811\n",
      "Epoch 9748/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 47.5249 - val_loss: 5.5757\n",
      "Epoch 9749/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 44.8761 - val_loss: 5.5694\n",
      "Epoch 9750/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 51.9641 - val_loss: 5.5632\n",
      "Epoch 9751/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 46.2089 - val_loss: 5.5583\n",
      "Epoch 9752/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 47.3149 - val_loss: 5.5541\n",
      "Epoch 9753/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 38.9264 - val_loss: 5.5519\n",
      "Epoch 9754/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 53.9383 - val_loss: 5.5484\n",
      "Epoch 9755/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 41.7654 - val_loss: 5.5461\n",
      "Epoch 9756/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 43.9251 - val_loss: 5.5382\n",
      "Epoch 9757/10000\n",
      "184/184 [==============================] - 0s 494us/step - loss: 47.3308 - val_loss: 5.5387\n",
      "Epoch 9758/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 54.7578 - val_loss: 5.5390\n",
      "Epoch 9759/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 49.8509 - val_loss: 5.5349\n",
      "Epoch 9760/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 64.0411 - val_loss: 5.5274\n",
      "Epoch 9761/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 35.61 - 0s 500us/step - loss: 41.1172 - val_loss: 5.5185\n",
      "Epoch 9762/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 44.0308 - val_loss: 5.5054\n",
      "Epoch 9763/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 38.8891 - val_loss: 5.4896\n",
      "Epoch 9764/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 45.9345 - val_loss: 5.4898\n",
      "Epoch 9765/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 54.9422 - val_loss: 5.5238\n",
      "Epoch 9766/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 51.3372 - val_loss: 5.5153\n",
      "Epoch 9767/10000\n",
      "184/184 [==============================] - 0s 587us/step - loss: 45.0162 - val_loss: 5.5082\n",
      "Epoch 9768/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 59.1596 - val_loss: 5.4639\n",
      "Epoch 9769/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 41.7699 - val_loss: 5.4540\n",
      "Epoch 9770/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 43.5098 - val_loss: 5.4469\n",
      "Epoch 9771/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 49.3074 - val_loss: 5.5012\n",
      "Epoch 9772/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 45.3762 - val_loss: 5.5940\n",
      "Epoch 9773/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 41.7997 - val_loss: 5.5728\n",
      "Epoch 9774/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 44.1612 - val_loss: 5.5449\n",
      "Epoch 9775/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 55.0221 - val_loss: 5.5302\n",
      "Epoch 9776/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 39.6901 - val_loss: 5.5203\n",
      "Epoch 9777/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 38.4658 - val_loss: 5.5070\n",
      "Epoch 9778/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 44.1091 - val_loss: 5.4949\n",
      "Epoch 9779/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 40.3701 - val_loss: 5.4847\n",
      "Epoch 9780/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 53.6379 - val_loss: 5.4839\n",
      "Epoch 9781/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 40.6312 - val_loss: 5.4984\n",
      "Epoch 9782/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 46.2386 - val_loss: 5.5160\n",
      "Epoch 9783/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 58.2551 - val_loss: 5.5302\n",
      "Epoch 9784/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 54.1973 - val_loss: 5.5421\n",
      "Epoch 9785/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 40.9153 - val_loss: 5.4855\n",
      "Epoch 9786/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 46.6229 - val_loss: 5.4169\n",
      "Epoch 9787/10000\n",
      "184/184 [==============================] - 0s 603us/step - loss: 40.4102 - val_loss: 5.3870\n",
      "Epoch 9788/10000\n",
      "184/184 [==============================] - 0s 652us/step - loss: 40.3402 - val_loss: 5.3694\n",
      "Epoch 9789/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 41.5302 - val_loss: 5.3715\n",
      "Epoch 9790/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 54.2051 - val_loss: 5.3702\n",
      "Epoch 9791/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 52.0710 - val_loss: 5.3700\n",
      "Epoch 9792/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 43.2718 - val_loss: 5.3693\n",
      "Epoch 9793/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 41.3820 - val_loss: 5.3675\n",
      "Epoch 9794/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 51.5902 - val_loss: 5.3616\n",
      "Epoch 9795/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 46.0140 - val_loss: 5.3579\n",
      "Epoch 9796/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 40.0513 - val_loss: 5.3558\n",
      "Epoch 9797/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 43.3143 - val_loss: 5.3409\n",
      "Epoch 9798/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 36.4780 - val_loss: 5.3931\n",
      "Epoch 9799/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 50.71 - 0s 484us/step - loss: 47.4545 - val_loss: 5.3907\n",
      "Epoch 9800/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 51.6898 - val_loss: 5.3514\n",
      "\n",
      "Epoch 09800: loss did not improve from 44.10298\n",
      "Epoch 9801/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 56.7962 - val_loss: 5.4049\n",
      "Epoch 9802/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 37.0100 - val_loss: 5.4756\n",
      "Epoch 9803/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 33.8002 - val_loss: 5.4064\n",
      "Epoch 9804/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 45.3803 - val_loss: 5.3753\n",
      "Epoch 9805/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 38.5646 - val_loss: 5.3596\n",
      "Epoch 9806/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 57.0465 - val_loss: 5.3505\n",
      "Epoch 9807/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 39.8887 - val_loss: 5.3423\n",
      "Epoch 9808/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 39.7066 - val_loss: 5.3368\n",
      "Epoch 9809/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 47.9784 - val_loss: 5.3342\n",
      "Epoch 9810/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 37.3007 - val_loss: 5.3318\n",
      "Epoch 9811/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 46.3920 - val_loss: 5.3298\n",
      "Epoch 9812/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 50.3290 - val_loss: 5.3280\n",
      "Epoch 9813/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 46.5456 - val_loss: 5.3304\n",
      "Epoch 9814/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 43.7099 - val_loss: 5.3333\n",
      "Epoch 9815/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 533us/step - loss: 61.0524 - val_loss: 5.3360\n",
      "Epoch 9816/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 39.3398 - val_loss: 5.3346\n",
      "Epoch 9817/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 49.8601 - val_loss: 5.3294\n",
      "Epoch 9818/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 43.6854 - val_loss: 5.3274\n",
      "Epoch 9819/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 46.1312 - val_loss: 5.3291\n",
      "Epoch 9820/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 58.0041 - val_loss: 5.3264\n",
      "Epoch 9821/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 42.1331 - val_loss: 5.3190\n",
      "Epoch 9822/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 51.4991 - val_loss: 5.3084\n",
      "Epoch 9823/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 36.8191 - val_loss: 5.2998\n",
      "Epoch 9824/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 57.2805 - val_loss: 5.2938\n",
      "Epoch 9825/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 45.6131 - val_loss: 5.2901\n",
      "Epoch 9826/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 41.5401 - val_loss: 5.2873\n",
      "Epoch 9827/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 46.5343 - val_loss: 5.2848\n",
      "Epoch 9828/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 53.7149 - val_loss: 5.2827\n",
      "Epoch 9829/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 42.0896 - val_loss: 5.2807\n",
      "Epoch 9830/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 43.9033 - val_loss: 5.2760\n",
      "Epoch 9831/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 41.4289 - val_loss: 5.2733\n",
      "Epoch 9832/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 44.7194 - val_loss: 5.2732\n",
      "Epoch 9833/10000\n",
      "184/184 [==============================] - 0s 772us/step - loss: 48.2706 - val_loss: 5.2740\n",
      "Epoch 9834/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 33.9135 - val_loss: 5.2742\n",
      "Epoch 9835/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 52.7836 - val_loss: 5.2713\n",
      "Epoch 9836/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 54.5279 - val_loss: 5.2637\n",
      "Epoch 9837/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 41.5486 - val_loss: 5.3922\n",
      "Epoch 9838/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 47.1070 - val_loss: 6.3415\n",
      "Epoch 9839/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 44.6713 - val_loss: 6.4751\n",
      "Epoch 9840/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 54.4218 - val_loss: 6.5332\n",
      "Epoch 9841/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 53.3989 - val_loss: 5.3569\n",
      "Epoch 9842/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 44.5752 - val_loss: 5.1085\n",
      "Epoch 9843/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 41.8118 - val_loss: 5.1074\n",
      "Epoch 9844/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 47.8494 - val_loss: 5.0950\n",
      "Epoch 9845/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 55.2022 - val_loss: 5.0787\n",
      "Epoch 9846/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 46.3066 - val_loss: 5.0623\n",
      "Epoch 9847/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 39.9166 - val_loss: 5.0679\n",
      "Epoch 9848/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 45.8682 - val_loss: 5.0690\n",
      "Epoch 9849/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 49.8219 - val_loss: 5.0673\n",
      "Epoch 9850/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 45.0585 - val_loss: 5.0591\n",
      "Epoch 9851/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 45.3265 - val_loss: 5.0586\n",
      "Epoch 9852/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 44.7048 - val_loss: 5.0574\n",
      "Epoch 9853/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 42.5004 - val_loss: 5.0471\n",
      "Epoch 9854/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 51.6097 - val_loss: 5.0394\n",
      "Epoch 9855/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 42.4362 - val_loss: 5.0369\n",
      "Epoch 9856/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 42.8157 - val_loss: 5.0248\n",
      "Epoch 9857/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 53.3941 - val_loss: 5.0126\n",
      "Epoch 9858/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 44.2951 - val_loss: 5.0090\n",
      "Epoch 9859/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 39.7802 - val_loss: 5.0063\n",
      "Epoch 9860/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 59.9703 - val_loss: 5.0011\n",
      "Epoch 9861/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 32.9277 - val_loss: 4.9950\n",
      "Epoch 9862/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 42.3920 - val_loss: 4.9905\n",
      "Epoch 9863/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 40.2926 - val_loss: 4.9841\n",
      "Epoch 9864/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 51.5090 - val_loss: 4.9786\n",
      "Epoch 9865/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 36.9142 - val_loss: 4.9746\n",
      "Epoch 9866/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 52.0288 - val_loss: 4.9715\n",
      "Epoch 9867/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 50.3118 - val_loss: 4.9680\n",
      "Epoch 9868/10000\n",
      "184/184 [==============================] - ETA: 0s - loss: 49.34 - 0s 511us/step - loss: 45.4925 - val_loss: 4.9651\n",
      "Epoch 9869/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 41.2009 - val_loss: 4.9622\n",
      "Epoch 9870/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 42.7497 - val_loss: 4.9615\n",
      "Epoch 9871/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 48.0222 - val_loss: 4.9607\n",
      "Epoch 9872/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 53.2402 - val_loss: 4.9643\n",
      "Epoch 9873/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 41.8635 - val_loss: 4.9684\n",
      "Epoch 9874/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 51.0672 - val_loss: 4.9726\n",
      "Epoch 9875/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 46.1376 - val_loss: 4.9746\n",
      "Epoch 9876/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 47.0278 - val_loss: 4.9754\n",
      "Epoch 9877/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 43.4895 - val_loss: 4.9750\n",
      "Epoch 9878/10000\n",
      "184/184 [==============================] - 0s 592us/step - loss: 48.1968 - val_loss: 4.9738\n",
      "Epoch 9879/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 41.2316 - val_loss: 4.9725\n",
      "Epoch 9880/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 36.8993 - val_loss: 4.9650\n",
      "Epoch 9881/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 44.6105 - val_loss: 4.9737\n",
      "Epoch 9882/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 54.9680 - val_loss: 4.9749\n",
      "Epoch 9883/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 35.7420 - val_loss: 4.9720\n",
      "Epoch 9884/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 42.8144 - val_loss: 4.9670\n",
      "Epoch 9885/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 51.8314 - val_loss: 4.9604\n",
      "Epoch 9886/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 42.4843 - val_loss: 4.9555\n",
      "Epoch 9887/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 50.0944 - val_loss: 4.9467\n",
      "Epoch 9888/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 46.1227 - val_loss: 4.9320\n",
      "Epoch 9889/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 44.3288 - val_loss: 4.9160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9890/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 40.7413 - val_loss: 4.9047\n",
      "Epoch 9891/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 45.8745 - val_loss: 4.8998\n",
      "Epoch 9892/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 51.7339 - val_loss: 4.8973\n",
      "Epoch 9893/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 48.0659 - val_loss: 4.8904\n",
      "Epoch 9894/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 42.4410 - val_loss: 4.8831\n",
      "Epoch 9895/10000\n",
      "184/184 [==============================] - 0s 630us/step - loss: 44.7391 - val_loss: 4.8741\n",
      "Epoch 9896/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 44.2300 - val_loss: 4.8684\n",
      "Epoch 9897/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 38.1853 - val_loss: 4.8662\n",
      "Epoch 9898/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 44.4067 - val_loss: 4.8627\n",
      "Epoch 9899/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 44.6981 - val_loss: 4.8586\n",
      "Epoch 9900/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 32.9526 - val_loss: 4.8540\n",
      "\n",
      "Epoch 09900: loss improved from 44.10298 to 32.95264, saving model to C6007C.hdf5\n",
      "Epoch 9901/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 44.1635 - val_loss: 4.8507\n",
      "Epoch 9902/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 46.1768 - val_loss: 4.8475\n",
      "Epoch 9903/10000\n",
      "184/184 [==============================] - 0s 582us/step - loss: 48.7873 - val_loss: 4.8441\n",
      "Epoch 9904/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 42.2275 - val_loss: 4.8392\n",
      "Epoch 9905/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 42.4817 - val_loss: 4.8324\n",
      "Epoch 9906/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 43.6487 - val_loss: 4.8278\n",
      "Epoch 9907/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 54.7307 - val_loss: 4.8238\n",
      "Epoch 9908/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 37.5286 - val_loss: 4.8203\n",
      "Epoch 9909/10000\n",
      "184/184 [==============================] - 0s 446us/step - loss: 60.0942 - val_loss: 4.8168\n",
      "Epoch 9910/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 38.6122 - val_loss: 4.8188\n",
      "Epoch 9911/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 42.9010 - val_loss: 4.8167\n",
      "Epoch 9912/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 48.2455 - val_loss: 4.8201\n",
      "Epoch 9913/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 34.0098 - val_loss: 4.8348\n",
      "Epoch 9914/10000\n",
      "184/184 [==============================] - 0s 554us/step - loss: 46.8578 - val_loss: 4.8451\n",
      "Epoch 9915/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 45.1867 - val_loss: 4.8483\n",
      "Epoch 9916/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 40.6545 - val_loss: 4.8485\n",
      "Epoch 9917/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 37.8852 - val_loss: 4.8485\n",
      "Epoch 9918/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 38.9336 - val_loss: 4.8475\n",
      "Epoch 9919/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 48.9904 - val_loss: 4.8482\n",
      "Epoch 9920/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 30.7570 - val_loss: 4.8513\n",
      "Epoch 9921/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 36.2280 - val_loss: 4.8537\n",
      "Epoch 9922/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 42.9677 - val_loss: 4.8554\n",
      "Epoch 9923/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 40.7565 - val_loss: 4.8561\n",
      "Epoch 9924/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 43.5551 - val_loss: 4.8553\n",
      "Epoch 9925/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 47.4502 - val_loss: 4.8550\n",
      "Epoch 9926/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 41.7064 - val_loss: 4.8537\n",
      "Epoch 9927/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 57.8790 - val_loss: 4.8504\n",
      "Epoch 9928/10000\n",
      "184/184 [==============================] - 0s 565us/step - loss: 44.8275 - val_loss: 4.8456\n",
      "Epoch 9929/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 35.7856 - val_loss: 4.8425\n",
      "Epoch 9930/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 46.7437 - val_loss: 4.8382\n",
      "Epoch 9931/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 38.2810 - val_loss: 4.8288\n",
      "Epoch 9932/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 44.6643 - val_loss: 4.8244\n",
      "Epoch 9933/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 47.2444 - val_loss: 4.8254\n",
      "Epoch 9934/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 40.0361 - val_loss: 4.8261\n",
      "Epoch 9935/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 46.4079 - val_loss: 4.8253\n",
      "Epoch 9936/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 37.9991 - val_loss: 4.8239\n",
      "Epoch 9937/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 42.1870 - val_loss: 4.8232\n",
      "Epoch 9938/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 42.7305 - val_loss: 4.8239\n",
      "Epoch 9939/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 39.3049 - val_loss: 4.8246\n",
      "Epoch 9940/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 49.9552 - val_loss: 4.8230\n",
      "Epoch 9941/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 45.1825 - val_loss: 4.8225\n",
      "Epoch 9942/10000\n",
      "184/184 [==============================] - 0s 609us/step - loss: 47.7411 - val_loss: 4.8238\n",
      "Epoch 9943/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 46.1383 - val_loss: 4.8145\n",
      "Epoch 9944/10000\n",
      "184/184 [==============================] - 0s 658us/step - loss: 44.8971 - val_loss: 4.8047\n",
      "Epoch 9945/10000\n",
      "184/184 [==============================] - 0s 614us/step - loss: 52.1075 - val_loss: 4.7970\n",
      "Epoch 9946/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 40.8440 - val_loss: 4.7892\n",
      "Epoch 9947/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 55.0143 - val_loss: 4.7938\n",
      "Epoch 9948/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 44.6734 - val_loss: 4.7939\n",
      "Epoch 9949/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 45.4828 - val_loss: 4.7983\n",
      "Epoch 9950/10000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 36.9179 - val_loss: 4.7990\n",
      "Epoch 9951/10000\n",
      "184/184 [==============================] - 0s 456us/step - loss: 51.0606 - val_loss: 4.7965\n",
      "Epoch 9952/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 50.1192 - val_loss: 4.7931\n",
      "Epoch 9953/10000\n",
      "184/184 [==============================] - 0s 435us/step - loss: 42.2308 - val_loss: 4.7905\n",
      "Epoch 9954/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 48.0997 - val_loss: 4.7868\n",
      "Epoch 9955/10000\n",
      "184/184 [==============================] - 0s 576us/step - loss: 42.0115 - val_loss: 4.7806\n",
      "Epoch 9956/10000\n",
      "184/184 [==============================] - 0s 549us/step - loss: 40.9158 - val_loss: 4.7725\n",
      "Epoch 9957/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 45.7667 - val_loss: 4.7646\n",
      "Epoch 9958/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 40.9173 - val_loss: 4.7575\n",
      "Epoch 9959/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 44.7316 - val_loss: 4.7502\n",
      "Epoch 9960/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 37.3081 - val_loss: 4.7434\n",
      "Epoch 9961/10000\n",
      "184/184 [==============================] - 0s 527us/step - loss: 56.2958 - val_loss: 4.7368\n",
      "Epoch 9962/10000\n",
      "184/184 [==============================] - 0s 598us/step - loss: 37.7114 - val_loss: 4.7315\n",
      "Epoch 9963/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 65.5768 - val_loss: 4.7286\n",
      "Epoch 9964/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 500us/step - loss: 42.2599 - val_loss: 4.7255\n",
      "Epoch 9965/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 48.2370 - val_loss: 4.7216\n",
      "Epoch 9966/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 54.0677 - val_loss: 4.7181\n",
      "Epoch 9967/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 44.7992 - val_loss: 4.7150\n",
      "Epoch 9968/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 51.7596 - val_loss: 4.7121\n",
      "Epoch 9969/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 48.0466 - val_loss: 4.7083\n",
      "Epoch 9970/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 36.2672 - val_loss: 4.7050\n",
      "Epoch 9971/10000\n",
      "184/184 [==============================] - 0s 571us/step - loss: 40.1749 - val_loss: 4.7030\n",
      "Epoch 9972/10000\n",
      "184/184 [==============================] - 0s 500us/step - loss: 39.2052 - val_loss: 4.7007\n",
      "Epoch 9973/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 51.0104 - val_loss: 4.6999\n",
      "Epoch 9974/10000\n",
      "184/184 [==============================] - 0s 625us/step - loss: 39.1084 - val_loss: 4.7088\n",
      "Epoch 9975/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 50.5934 - val_loss: 4.7269\n",
      "Epoch 9976/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 51.6580 - val_loss: 4.7277\n",
      "Epoch 9977/10000\n",
      "184/184 [==============================] - 0s 451us/step - loss: 44.2601 - val_loss: 4.7190\n",
      "Epoch 9978/10000\n",
      "184/184 [==============================] - 0s 473us/step - loss: 36.3841 - val_loss: 4.7112\n",
      "Epoch 9979/10000\n",
      "184/184 [==============================] - 0s 440us/step - loss: 37.4930 - val_loss: 4.7149\n",
      "Epoch 9980/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 43.9357 - val_loss: 4.7182\n",
      "Epoch 9981/10000\n",
      "184/184 [==============================] - 0s 484us/step - loss: 46.4496 - val_loss: 4.7122\n",
      "Epoch 9982/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 55.6875 - val_loss: 4.7037\n",
      "Epoch 9983/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 41.0319 - val_loss: 4.6983\n",
      "Epoch 9984/10000\n",
      "184/184 [==============================] - 0s 511us/step - loss: 53.3136 - val_loss: 4.6943\n",
      "Epoch 9985/10000\n",
      "184/184 [==============================] - 0s 516us/step - loss: 54.2351 - val_loss: 4.6943\n",
      "Epoch 9986/10000\n",
      "184/184 [==============================] - 0s 560us/step - loss: 44.9707 - val_loss: 4.6947\n",
      "Epoch 9987/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 41.6964 - val_loss: 4.6956\n",
      "Epoch 9988/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 46.6724 - val_loss: 4.6963\n",
      "Epoch 9989/10000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 39.7326 - val_loss: 4.6970\n",
      "Epoch 9990/10000\n",
      "184/184 [==============================] - 0s 478us/step - loss: 53.4170 - val_loss: 4.6947\n",
      "Epoch 9991/10000\n",
      "184/184 [==============================] - 0s 543us/step - loss: 42.8447 - val_loss: 4.6923\n",
      "Epoch 9992/10000\n",
      "184/184 [==============================] - 0s 429us/step - loss: 34.9314 - val_loss: 4.6880\n",
      "Epoch 9993/10000\n",
      "184/184 [==============================] - 0s 505us/step - loss: 42.2164 - val_loss: 4.6837\n",
      "Epoch 9994/10000\n",
      "184/184 [==============================] - 0s 457us/step - loss: 41.3397 - val_loss: 4.6683\n",
      "Epoch 9995/10000\n",
      "184/184 [==============================] - 0s 462us/step - loss: 41.9245 - val_loss: 4.6500\n",
      "Epoch 9996/10000\n",
      "184/184 [==============================] - 0s 495us/step - loss: 39.4435 - val_loss: 4.6505\n",
      "Epoch 9997/10000\n",
      "184/184 [==============================] - 0s 489us/step - loss: 39.7270 - val_loss: 4.6642\n",
      "Epoch 9998/10000\n",
      "184/184 [==============================] - 0s 620us/step - loss: 47.2537 - val_loss: 4.6979\n",
      "Epoch 9999/10000\n",
      "184/184 [==============================] - 0s 522us/step - loss: 37.7947 - val_loss: 4.6768\n",
      "Epoch 10000/10000\n",
      "184/184 [==============================] - 0s 533us/step - loss: 44.4512 - val_loss: 4.6285\n",
      "\n",
      "Epoch 10000: loss did not improve from 32.95264\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    # throw error if n_input is too big\n",
    "    assert n_input+n_forecasts < len(val), \"n_input + n_forecasts ({}) is larger than the amount of validation samples ({}) \".format(n_input+n_forecasts, len(val))\n",
    "    \n",
    "    \n",
    "    data = [train, val]\n",
    "    params = [epochs, batch_size, verbose, learning_rate, n_checkpoint, model_location, resume_training, activation_function]\n",
    "    model = build_model(data, n_input, params)\n",
    "else:\n",
    "    model = load_model(model_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting & Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\envs\\ztdl-updated\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\moham\\anaconda3\\envs\\ztdl-updated\\lib\\site-packages\\ipykernel_launcher.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\moham\\anaconda3\\envs\\ztdl-updated\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\moham\\anaconda3\\envs\\ztdl-updated\\lib\\site-packages\\pandas\\plotting\\_converter.py:129: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
      "\n",
      "To register the converters:\n",
      "\t>>> from pandas.plotting import register_matplotlib_converters\n",
      "\t>>> register_matplotlib_converters()\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Actueel verbruik  Month  Week  Day  Hour  Prediction\n",
      "Timestamp                                                                \n",
      "2020-12-22 09:00:00          0.058439     12    52   22     1   -0.273277\n",
      "2020-12-22 10:00:00          0.044885     12    52   22     2   -0.683215\n",
      "2020-12-22 11:00:00          0.059195     12    52   22     3   -1.018941\n",
      "2020-12-22 12:00:00          0.049249     12    52   22     4   -0.469158\n",
      "2020-12-22 13:00:00          0.053161     12    52   22     5   -0.901778\n",
      "2020-12-22 14:00:00          0.227471     12    52   22     6   -2.394627\n",
      "2020-12-22 15:00:00          0.102370     12    52   22     7    2.402416\n",
      "2020-12-22 16:00:00          0.079355     12    52   22     8    3.774457\n"
     ]
    }
   ],
   "source": [
    "if use_scaled:\n",
    "    pred = forecast(model, df_pred_scaled, n_input)\n",
    "    future = forecast(model, df_future_scaled, n_input)\n",
    "    \n",
    "    _ = np.zeros([len(pred), len(df_pred.columns)])\n",
    "    \n",
    "    _[:,0] = np.squeeze(pred)\n",
    "    pred = scaler.inverse_transform(_)\n",
    "    \n",
    "    _[:,0] = np.squeeze(future)\n",
    "    future_pred = scaler.inverse_transform(_)\n",
    "\n",
    "    visualize_forecast(df, df_pred, df_future, pred[:,0], future_pred[:,0], n_input, n_forecasts, history_length)\n",
    "else:\n",
    "    pred = forecast(model, df_pred, n_input)\n",
    "    future_pred = forecast(model, df_future, n_input)\n",
    "    \n",
    "    # Prepare dataframes for plotting\n",
    "    visualize_forecast(df, df_pred, df_future, pred, future_pred, n_input, n_forecasts, history_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
