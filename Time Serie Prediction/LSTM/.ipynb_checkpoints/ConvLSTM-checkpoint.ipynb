{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM\n",
    "\n",
    "## Requirements\n",
    "- python 3.7\n",
    "- keras\n",
    "- tensorflow\n",
    "- scikit-learn\n",
    "- matplotlib\n",
    "- seaborn\n",
    "- pandas\n",
    "- numpy\n",
    "- wandb\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Keras version 2.2.4 is not fully supported. Required keras >= 2.4.0\n",
      "wandb: Currently logged in as: tyromijn (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">misunderstood-bush-36</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/tyromijn/convlstm\" target=\"_blank\">https://wandb.ai/tyromijn/convlstm</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/tyromijn/convlstm/runs/7qp05f1z\" target=\"_blank\">https://wandb.ai/tyromijn/convlstm/runs/7qp05f1z</a><br/>\n",
       "                Run data is saved locally in <code>F:\\dev\\Minor\\SmartGrid\\Time Serie Prediction\\LSTM\\wandb\\run-20201218_144121-7qp05f1z</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(7qp05f1z)</h1><p></p><iframe src=\"https://wandb.ai/tyromijn/convlstm/runs/7qp05f1z\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x283551a5cc8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# PlaidML Imports - disable if you make use of cudnn\n",
    "amd = True\n",
    "\n",
    "if amd:\n",
    "    import plaidml.keras\n",
    "    plaidml.keras.install_backend()\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "    os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#     os.environ['PLAIDML_USE_STRIPE']='1'\n",
    "#     os.environ['PLAIDML_VERBOSE']='1'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, ConvLSTM2D, LSTM, Dropout, Flatten, TimeDistributed, RepeatVector\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "wandb.init(project=\"convlstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_supervised(train, n_input, n_output=8):\n",
    "    X, y = list(),list()\n",
    "    \n",
    "    X_start = 0\n",
    "    \n",
    "    # iterate over train dataset\n",
    "    for _ in range(len(train)):\n",
    "        \n",
    "        # set the ranges for input + output\n",
    "        X_end = X_start + n_input\n",
    "        y_end = X_end + n_output\n",
    "        \n",
    "        # check if data contains enough samples for sequence\n",
    "        if y_end <= len(train):\n",
    "            X.append(train[X_start:X_end, :])\n",
    "            y.append(train[X_end:y_end, 0])    \n",
    "        X_start += 1\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def build_model(data, n_steps, n_length, n_input, params):\n",
    "    \n",
    "    # ConvLSTM2D expected input: [samples, timesteps, rows, cols, channels]\n",
    "    # In our case, this will be [n_input, 7, 1, 24, 1]\n",
    "    \n",
    "    # data preperation\n",
    "    train, val = data\n",
    "    X_train, y_train = to_supervised(train, n_input)\n",
    "    X_val, y_val = to_supervised(val, n_input)\n",
    "    \n",
    "    # meta / parameters\n",
    "    epochs, batch_size, verbose, learning_rate, n_checkpoint, activation_function = params\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "    \n",
    "    X_train = X_train.reshape((X_train.shape[0], n_steps, 1, n_length, n_features))\n",
    "    X_val = X_val.reshape((X_val.shape[0], n_steps, 1, n_length, n_features))\n",
    "    \n",
    "    # reshape output\n",
    "    y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], 1))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], 1))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(ConvLSTM2D(filters=32, kernel_size=(1,3), activation=activation_function, input_shape=(n_steps, 1, n_length, n_features), return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    model.add(LSTM(128, activation=activation_function, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(128, activation=activation_function)))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=opt)\n",
    "    checkpoint = ModelCheckpoint(\"convmodelcheckpoint.hdf5\", monitor='loss', verbose=1,\n",
    "    save_best_only=True, mode='auto', period=n_checkpoint)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data=(X_val, y_val), callbacks=[WandbCallback(), checkpoint], shuffle=False)\n",
    "    \n",
    "    model.save(os.path.join(wandb.run.dir, \"model.h5\"))\n",
    "    \n",
    "    # plot the model\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def forecast(model, history, n_steps, n_length, n_input, n_features):\n",
    "    data = np.array(history)\n",
    "    X = data[-n_input:, 0]\n",
    "    X = X.reshape((1, n_steps, 1, n_length, n_features))\n",
    "    yhat = model.predict(X, verbose=0)\n",
    "    yhat = yhat[0]\n",
    "    return yhat\n",
    "\n",
    "\n",
    "def visualize_forecast(history, validation, future, pred, future_pred, n_input, n_forecasts):\n",
    "    if n_input > 48:\n",
    "        past = history[-48:-n_forecasts+1]\n",
    "    else:   \n",
    "        past = history[-n_input:-n_forecasts+1]\n",
    "    \n",
    "    future = future[-n_forecasts:]\n",
    "    validation = validation[-n_forecasts:]\n",
    "\n",
    "#     validation.index = validation.index + pd.Timedelta(n_forecasts, unit='h')\n",
    "    future.index = future.index + pd.Timedelta(n_forecasts, unit='h')\n",
    "\n",
    "    future['Prediction'] = future_pred\n",
    "    validation['Prediction'] = pred\n",
    "    validation['Actual'] = history[-8:]['Global_active_power']\n",
    "\n",
    "    \n",
    "    sns.set(rc={'figure.figsize':(14,5)})\n",
    "    sns.lineplot(data=past, x=past.index, y=\"Global_active_power\")\n",
    "    sns.lineplot(data=validation, x=validation.index, y=\"Actual\", color=\"lime\")\n",
    "    sns.lineplot(data=validation, x=validation.index, y=\"Prediction\", color=\"red\")\n",
    "    sns.lineplot(data=future, x=future.index, y=\"Prediction\", color=\"darkred\")\n",
    "    plt.legend(['Active Power (Past)','Active Power (Actual)','Active Power (Prediction)', 'Active Power (Future Prediction)'])\n",
    "\n",
    "    plt.title('Predictions of Global Active Power')\n",
    "    plt.xlabel('Timeline')\n",
    "    plt.ylabel('Global Active Power')\n",
    "    plt.grid(which='major', color=\"#ffffff\", alpha=.5)\n",
    "    plt.axvline(x=past.index[-1], color=\"green\", linestyle=\"--\")\n",
    "    plt.axvline(x=validation.index[-1], color=\"green\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis / Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:00:00</th>\n",
       "      <td>4.222889</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 18:00:00</th>\n",
       "      <td>3.632200</td>\n",
       "      <td>0.080033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>1012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 19:00:00</th>\n",
       "      <td>3.400233</td>\n",
       "      <td>0.085233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 20:00:00</th>\n",
       "      <td>3.268567</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 21:00:00</th>\n",
       "      <td>3.056467</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1033.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power  \\\n",
       "dt                                                                \n",
       "2006-12-16 17:00:00             4.222889               0.229000   \n",
       "2006-12-16 18:00:00             3.632200               0.080033   \n",
       "2006-12-16 19:00:00             3.400233               0.085233   \n",
       "2006-12-16 20:00:00             3.268567               0.075100   \n",
       "2006-12-16 21:00:00             3.056467               0.076667   \n",
       "\n",
       "                     Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
       "dt                                                                   \n",
       "2006-12-16 17:00:00             0.0            19.0           607.0  \n",
       "2006-12-16 18:00:00             0.0           403.0          1012.0  \n",
       "2006-12-16 19:00:00             0.0            86.0          1001.0  \n",
       "2006-12-16 20:00:00             0.0             0.0          1007.0  \n",
       "2006-12-16 21:00:00             0.0            25.0          1033.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/household_power_consumption.txt', sep=';', \n",
    "                 parse_dates={'dt' : ['Date', 'Time']}, infer_datetime_format=True, \n",
    "                 low_memory=False, na_values=['nan','?'], index_col='dt')\n",
    "\n",
    "df_resample = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# global_active_power: household global minute-averaged active power (in kilowatt)\n",
    "# global_reactive_power: household global minute-averaged reactive power (in kilowatt)\n",
    "# voltage: minute-averaged voltage (in volt)\n",
    "# global_intensity: household global minute-averaged current intensity (in ampere)\n",
    "\n",
    "# df_resample['Global_active_power'] = np.cumsum(df['Global_active_power'].resample('h').mean())\n",
    "# df_resample['Global_reactive_power'] = np.cumsum(df['Global_reactive_power'].resample('h').mean())\n",
    "df_resample['Global_active_power'] = df['Global_active_power'].resample('h').mean()\n",
    "df_resample['Global_reactive_power'] = df['Global_reactive_power'].resample('h').mean()\n",
    "df_resample['Voltage'] = df['Voltage'].resample('h').mean()\n",
    "df_resample['Global_intensity'] = df['Global_intensity'].resample('h').mean()\n",
    "\n",
    "# sub_metering_#: energy sub-metering No. # (in watt-hour of active energy).\n",
    "df_resample['Sub_metering_1'] = df['Sub_metering_1'].resample('h').sum()\n",
    "df_resample['Sub_metering_2'] = df['Sub_metering_2'].resample('h').sum()\n",
    "df_resample['Sub_metering_3'] = df['Sub_metering_3'].resample('h').sum()\n",
    "\n",
    "# columns = [x for x in df_resample.columns if x not in ['Voltage', 'Global_intensity', 'Global_reactive_power']] \n",
    "columns = [x for x in df_resample.columns if x not in ['Voltage', 'Global_intensity']] \n",
    "\n",
    "df_resample = df_resample[columns]\n",
    "\n",
    "df = df_resample\n",
    "\n",
    "df_resample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN's with column's mean value\n",
    "for j in range(0,len(df_resample.columns)):        \n",
    "        df_resample.iloc[:,j]=df_resample.iloc[:,j].fillna(df_resample.iloc[:,j].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:00:00</th>\n",
       "      <td>4.222889</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 18:00:00</th>\n",
       "      <td>3.632200</td>\n",
       "      <td>0.080033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>1012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 19:00:00</th>\n",
       "      <td>3.400233</td>\n",
       "      <td>0.085233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 20:00:00</th>\n",
       "      <td>3.268567</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 21:00:00</th>\n",
       "      <td>3.056467</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1033.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 17:00:00</th>\n",
       "      <td>1.725900</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 18:00:00</th>\n",
       "      <td>1.573467</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 19:00:00</th>\n",
       "      <td>1.659333</td>\n",
       "      <td>0.060033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:00:00</th>\n",
       "      <td>1.163700</td>\n",
       "      <td>0.061167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 21:00:00</th>\n",
       "      <td>0.934667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34589 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power  \\\n",
       "dt                                                                \n",
       "2006-12-16 17:00:00             4.222889               0.229000   \n",
       "2006-12-16 18:00:00             3.632200               0.080033   \n",
       "2006-12-16 19:00:00             3.400233               0.085233   \n",
       "2006-12-16 20:00:00             3.268567               0.075100   \n",
       "2006-12-16 21:00:00             3.056467               0.076667   \n",
       "...                                  ...                    ...   \n",
       "2010-11-26 17:00:00             1.725900               0.061400   \n",
       "2010-11-26 18:00:00             1.573467               0.053700   \n",
       "2010-11-26 19:00:00             1.659333               0.060033   \n",
       "2010-11-26 20:00:00             1.163700               0.061167   \n",
       "2010-11-26 21:00:00             0.934667               0.000000   \n",
       "\n",
       "                     Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
       "dt                                                                   \n",
       "2006-12-16 17:00:00             0.0            19.0           607.0  \n",
       "2006-12-16 18:00:00             0.0           403.0          1012.0  \n",
       "2006-12-16 19:00:00             0.0            86.0          1001.0  \n",
       "2006-12-16 20:00:00             0.0             0.0          1007.0  \n",
       "2006-12-16 21:00:00             0.0            25.0          1033.0  \n",
       "...                             ...             ...             ...  \n",
       "2010-11-26 17:00:00             0.0             0.0           772.0  \n",
       "2010-11-26 18:00:00             0.0             0.0             0.0  \n",
       "2010-11-26 19:00:00             0.0             4.0             0.0  \n",
       "2010-11-26 20:00:00             0.0            64.0             0.0  \n",
       "2010-11-26 21:00:00             0.0             0.0             0.0  \n",
       "\n",
       "[34589 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. hours to forecast\n",
    "n_forecasts = 8\n",
    "\n",
    "# Amount of sequences that the data will be split into\n",
    "n_steps = 21\n",
    "\n",
    "# Amount of hours per sequence\n",
    "n_length = 24\n",
    "\n",
    "# Amount of features in dataset\n",
    "n_features = len(df_resample.columns)\n",
    "\n",
    "# determines how much data is used to forecast (currently using a week of data per row)\n",
    "n_input = n_steps * n_length\n",
    "\n",
    "# determines whether we're going to train or evaluate an existing model\n",
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a few hours of time, validate if model isn't inaccurate due to an anomaly in the data\n",
    "# df_resample = df_resample[:-8]\n",
    "\n",
    "df_future = df_resample[-n_forecasts:]\n",
    "df_pred = df_resample[-n_input*n_features:]\n",
    "df_resample = df_resample[:-n_forecasts]\n",
    "\n",
    "train, test = train_test_split(df_resample.values, test_size=.2, shuffle=False, stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_ellesmere.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1 samples, validate on 1 samples\n",
      "Epoch 1/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 661 of 3026 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 2288 of 3026 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 601 of 1286 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 22s 22s/step - loss: 1.1939 - val_loss: 3.1218\n",
      "Epoch 2/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0589 - val_loss: 3.1113\n",
      "Epoch 3/750\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.7408 - val_loss: 2.7543\n",
      "Epoch 4/750\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3024 - val_loss: 2.2754\n",
      "Epoch 5/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.8078 - val_loss: 1.7498\n",
      "Epoch 6/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2799 - val_loss: 1.2013\n",
      "Epoch 7/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7643 - val_loss: 0.6847\n",
      "Epoch 8/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3523 - val_loss: 0.2719\n",
      "Epoch 9/750\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4083 - val_loss: 0.3250\n",
      "Epoch 10/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7971 - val_loss: 0.5565\n",
      "Epoch 11/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0288 - val_loss: 0.6468\n",
      "Epoch 12/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1193 - val_loss: 0.6290\n",
      "Epoch 13/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1014 - val_loss: 0.5266\n",
      "Epoch 14/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9989 - val_loss: 0.3568\n",
      "Epoch 15/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8290 - val_loss: 0.1422\n",
      "Epoch 16/750\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6047 - val_loss: 0.3027\n",
      "Epoch 17/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3875 - val_loss: 0.5075\n",
      "Epoch 18/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2595 - val_loss: 0.7040\n",
      "Epoch 19/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3717 - val_loss: 0.8526\n",
      "Epoch 20/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5050 - val_loss: 0.9576\n",
      "Epoch 21/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5834 - val_loss: 0.9986\n",
      "Epoch 22/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6141 - val_loss: 0.9836\n",
      "Epoch 23/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6029 - val_loss: 0.9195\n",
      "Epoch 24/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5552 - val_loss: 0.8122\n",
      "Epoch 25/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4752 - val_loss: 0.6990\n",
      "\n",
      "Epoch 00025: loss improved from inf to 0.47516, saving model to convmodelcheckpoint.hdf5\n",
      "Epoch 26/750\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3667 - val_loss: 0.5655\n",
      "Epoch 27/750\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2566 - val_loss: 0.4438\n",
      "Epoch 28/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2939 - val_loss: 0.3586\n",
      "Epoch 29/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3499 - val_loss: 0.3063\n",
      "Epoch 30/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3843 - val_loss: 0.2836\n",
      "Epoch 31/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3992 - val_loss: 0.2877\n",
      "Epoch 32/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3965 - val_loss: 0.3158\n",
      "Epoch 33/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3779 - val_loss: 0.3658\n",
      "Epoch 34/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3450 - val_loss: 0.4354\n",
      "Epoch 35/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2991 - val_loss: 0.5228\n",
      "Epoch 36/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2548 - val_loss: 0.6013\n",
      "Epoch 37/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2689 - val_loss: 0.6342\n",
      "Epoch 38/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3017 - val_loss: 0.6262\n",
      "Epoch 39/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2937 - val_loss: 0.5818\n",
      "Epoch 40/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2618 - val_loss: 0.5296\n",
      "Epoch 41/750\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2545 - val_loss: 0.4815\n",
      "Epoch 42/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2685 - val_loss: 0.4630\n",
      "Epoch 43/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2806 - val_loss: 0.4715\n",
      "Epoch 44/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2750 - val_loss: 0.5043\n",
      "Epoch 45/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2589 - val_loss: 0.5464\n",
      "Epoch 46/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2543 - val_loss: 0.5840\n",
      "Epoch 47/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2629 - val_loss: 0.6055\n",
      "Epoch 48/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2729 - val_loss: 0.5858\n",
      "Epoch 49/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2637 - val_loss: 0.5555\n",
      "Epoch 50/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2542 - val_loss: 0.5272\n",
      "\n",
      "Epoch 00050: loss improved from 0.47516 to 0.25422, saving model to convmodelcheckpoint.hdf5\n",
      "Epoch 51/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2536 - val_loss: 0.5008\n",
      "Epoch 52/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2597 - val_loss: 0.4898\n",
      "Epoch 53/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2632 - val_loss: 0.4929\n",
      "Epoch 54/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2622 - val_loss: 0.5089\n",
      "Epoch 55/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2570 - val_loss: 0.5367\n",
      "Epoch 56/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2533 - val_loss: 0.5611\n",
      "Epoch 57/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2563 - val_loss: 0.5699\n",
      "Epoch 58/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2592 - val_loss: 0.5646\n",
      "Epoch 59/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2576 - val_loss: 0.5463\n",
      "Epoch 60/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2532 - val_loss: 0.5289\n",
      "Epoch 61/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2529 - val_loss: 0.5123\n",
      "Epoch 62/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2556 - val_loss: 0.5112\n",
      "Epoch 63/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2560 - val_loss: 0.5243\n",
      "Epoch 64/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2525 - val_loss: 0.5352\n",
      "Epoch 65/750\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2527 - val_loss: 0.5444\n",
      "Epoch 66/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2527 - val_loss: 0.5518\n",
      "Epoch 67/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2540 - val_loss: 0.5443\n",
      "Epoch 68/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2525 - val_loss: 0.5367\n",
      "Epoch 69/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2522 - val_loss: 0.5289\n",
      "Epoch 70/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2520 - val_loss: 0.5209\n",
      "Epoch 71/750\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2524 - val_loss: 0.5286\n",
      "Epoch 72/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2517 - val_loss: 0.5346\n",
      "Epoch 73/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2516 - val_loss: 0.5392\n",
      "Epoch 74/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2516 - val_loss: 0.5425\n",
      "Epoch 75/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2519 - val_loss: 0.5304\n",
      "\n",
      "Epoch 00075: loss improved from 0.25422 to 0.25190, saving model to convmodelcheckpoint.hdf5\n",
      "Epoch 76/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2511 - val_loss: 0.5186\n",
      "Epoch 77/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2527 - val_loss: 0.5233\n",
      "Epoch 78/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2511 - val_loss: 0.5431\n",
      "Epoch 79/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2525 - val_loss: 0.5456\n",
      "Epoch 80/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2534 - val_loss: 0.5325\n",
      "Epoch 81/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2505 - val_loss: 0.5196\n",
      "Epoch 82/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2520 - val_loss: 0.5238\n",
      "Epoch 83/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2506 - val_loss: 0.5436\n",
      "Epoch 84/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2531 - val_loss: 0.5457\n",
      "Epoch 85/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2538 - val_loss: 0.5317\n",
      "Epoch 86/750\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2500 - val_loss: 0.5181\n",
      "Epoch 87/750\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2523 - val_loss: 0.5221\n",
      "Epoch 88/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2510 - val_loss: 0.5420\n",
      "Epoch 89/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2529 - val_loss: 0.5438\n",
      "Epoch 90/750\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2535 - val_loss: 0.5292\n",
      "Epoch 91/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2497 - val_loss: 0.5150\n",
      "Epoch 92/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2532 - val_loss: 0.5189\n",
      "Epoch 93/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2519 - val_loss: 0.5391\n",
      "Epoch 94/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2521 - val_loss: 0.5407\n",
      "Epoch 95/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2527 - val_loss: 0.5256\n",
      "Epoch 96/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2497 - val_loss: 0.5289\n",
      "Epoch 97/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2494 - val_loss: 0.5309\n",
      "Epoch 98/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2497 - val_loss: 0.5158\n",
      "Epoch 99/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2528 - val_loss: 0.5194\n",
      "Epoch 100/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2516 - val_loss: 0.5399\n",
      "\n",
      "Epoch 00100: loss improved from 0.25190 to 0.25162, saving model to convmodelcheckpoint.hdf5\n",
      "Epoch 101/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2526 - val_loss: 0.5413\n",
      "Epoch 102/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2531 - val_loss: 0.5254\n",
      "Epoch 103/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2496 - val_loss: 0.5285\n",
      "Epoch 104/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2492 - val_loss: 0.5303\n",
      "Epoch 105/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2496 - val_loss: 0.5146\n",
      "Epoch 106/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2531 - val_loss: 0.5180\n",
      "Epoch 107/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2520 - val_loss: 0.5389\n",
      "Epoch 108/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2524 - val_loss: 0.5402\n",
      "Epoch 109/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2528 - val_loss: 0.5238\n",
      "Epoch 110/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2501 - val_loss: 0.5269\n",
      "Epoch 111/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2491 - val_loss: 0.5477\n",
      "Epoch 112/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2552 - val_loss: 0.5486\n",
      "Epoch 113/750\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2555 - val_loss: 0.5316\n",
      "Epoch 114/750\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2501 - val_loss: 0.4983\n",
      "Epoch 115/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2584 - val_loss: 0.4865\n",
      "Epoch 116/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2635 - val_loss: 0.5131\n",
      "Epoch 117/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2536 - val_loss: 0.5556\n",
      "Epoch 118/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2576 - val_loss: 0.5758\n",
      "Epoch 119/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2640 - val_loss: 0.5758\n",
      "Epoch 120/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2640 - val_loss: 0.5576\n",
      "Epoch 121/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2581 - val_loss: 0.5228\n",
      "Epoch 122/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2506 - val_loss: 0.5100\n",
      "Epoch 123/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2547 - val_loss: 0.5172\n",
      "Epoch 124/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2524 - val_loss: 0.5424\n",
      "Epoch 125/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2531 - val_loss: 0.5466\n",
      "\n",
      "Epoch 00125: loss did not improve from 0.25162\n",
      "Epoch 126/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2545 - val_loss: 0.5318\n",
      "Epoch 127/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2497 - val_loss: 0.4998\n",
      "Epoch 128/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2581 - val_loss: 0.4899\n",
      "Epoch 129/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2614 - val_loss: 0.5198\n",
      "Epoch 130/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2518 - val_loss: 0.5658\n",
      "Epoch 131/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2603 - val_loss: 0.5885\n",
      "Epoch 132/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2675 - val_loss: 0.5901\n",
      "Epoch 133/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2680 - val_loss: 0.5725\n",
      "Epoch 134/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2623 - val_loss: 0.5378\n",
      "Epoch 135/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2512 - val_loss: 0.4873\n",
      "Epoch 136/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2632 - val_loss: 0.4814\n",
      "Epoch 137/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2672 - val_loss: 0.5154\n",
      "Epoch 138/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2534 - val_loss: 0.5655\n",
      "Epoch 139/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2598 - val_loss: 0.5915\n",
      "Epoch 140/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2680 - val_loss: 0.5959\n",
      "Epoch 141/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2693 - val_loss: 0.5806\n",
      "Epoch 142/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2644 - val_loss: 0.5475\n",
      "Epoch 143/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2537 - val_loss: 0.4983\n",
      "Epoch 144/750\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2592 - val_loss: 0.4736\n",
      "Epoch 145/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2725 - val_loss: 0.4915\n",
      "Epoch 146/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2615 - val_loss: 0.5272\n",
      "Epoch 147/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2512 - val_loss: 0.5584\n",
      "Epoch 148/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2569 - val_loss: 0.5670\n",
      "Epoch 149/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2596 - val_loss: 0.5552\n",
      "Epoch 150/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2558 - val_loss: 0.5250\n",
      "\n",
      "Epoch 00150: loss did not improve from 0.25162\n",
      "Epoch 151/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2514 - val_loss: 0.4965\n",
      "Epoch 152/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2601 - val_loss: 0.4908\n",
      "Epoch 153/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2619 - val_loss: 0.5057\n",
      "Epoch 154/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2571 - val_loss: 0.5392\n",
      "Epoch 155/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2517 - val_loss: 0.5683\n",
      "Epoch 156/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2599 - val_loss: 0.5747\n",
      "Epoch 157/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2619 - val_loss: 0.5604\n",
      "Epoch 158/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2574 - val_loss: 0.5276\n",
      "Epoch 159/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2515 - val_loss: 0.4968\n",
      "Epoch 160/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2600 - val_loss: 0.4894\n",
      "Epoch 161/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2623 - val_loss: 0.5032\n",
      "Epoch 162/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2579 - val_loss: 0.5360\n",
      "Epoch 163/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2516 - val_loss: 0.5645\n",
      "Epoch 164/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2588 - val_loss: 0.5699\n",
      "Epoch 165/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2605 - val_loss: 0.5544\n",
      "Epoch 166/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2556 - val_loss: 0.5201\n",
      "Epoch 167/750\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2523 - val_loss: 0.5099\n",
      "Epoch 168/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2556 - val_loss: 0.5214\n",
      "Epoch 169/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2519 - val_loss: 0.5525\n",
      "Epoch 170/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2551 - val_loss: 0.5601\n",
      "Epoch 171/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2575 - val_loss: 0.5464\n",
      "Epoch 172/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2531 - val_loss: 0.5134\n",
      "Epoch 173/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2545 - val_loss: 0.5046\n",
      "Epoch 174/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2574 - val_loss: 0.5176\n",
      "Epoch 175/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2532 - val_loss: 0.5504\n",
      "\n",
      "Epoch 00175: loss did not improve from 0.25162\n",
      "Epoch 176/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2543 - val_loss: 0.5592\n",
      "Epoch 177/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2571 - val_loss: 0.5463\n",
      "Epoch 178/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2530 - val_loss: 0.5138\n",
      "Epoch 179/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2544 - val_loss: 0.5057\n",
      "Epoch 180/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2571 - val_loss: 0.5197\n",
      "Epoch 181/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2526 - val_loss: 0.5535\n",
      "Epoch 182/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2552 - val_loss: 0.5630\n",
      "Epoch 183/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2582 - val_loss: 0.5506\n",
      "Epoch 184/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2542 - val_loss: 0.5182\n",
      "Epoch 185/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2531 - val_loss: 0.5105\n",
      "Epoch 186/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2556 - val_loss: 0.5250\n",
      "Epoch 187/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2517 - val_loss: 0.5368\n",
      "Epoch 188/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2519 - val_loss: 0.5463\n",
      "Epoch 189/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2527 - val_loss: 0.5334\n",
      "Epoch 190/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2518 - val_loss: 0.5206\n",
      "Epoch 191/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2523 - val_loss: 0.5308\n",
      "Epoch 192/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2516 - val_loss: 0.5387\n",
      "Epoch 193/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2517 - val_loss: 0.5445\n",
      "Epoch 194/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2524 - val_loss: 0.5282\n",
      "Epoch 195/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2513 - val_loss: 0.5123\n",
      "Epoch 196/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2548 - val_loss: 0.5199\n",
      "Epoch 197/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2523 - val_loss: 0.5487\n",
      "Epoch 198/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2541 - val_loss: 0.5529\n",
      "Epoch 199/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2555 - val_loss: 0.5350\n",
      "Epoch 200/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2509 - val_loss: 0.5176\n",
      "\n",
      "Epoch 00200: loss improved from 0.25162 to 0.25091, saving model to convmodelcheckpoint.hdf5\n",
      "Epoch 201/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2528 - val_loss: 0.5240\n",
      "Epoch 202/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2507 - val_loss: 0.5520\n",
      "Epoch 203/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2555 - val_loss: 0.5553\n",
      "Epoch 204/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2566 - val_loss: 0.5363\n",
      "Epoch 205/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2506 - val_loss: 0.5179\n",
      "Epoch 206/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2526 - val_loss: 0.5237\n",
      "Epoch 207/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2507 - val_loss: 0.5513\n",
      "Epoch 208/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2555 - val_loss: 0.5540\n",
      "Epoch 209/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2564 - val_loss: 0.5343\n",
      "Epoch 210/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2503 - val_loss: 0.5153\n",
      "Epoch 211/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2533 - val_loss: 0.5207\n",
      "Epoch 212/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2515 - val_loss: 0.5481\n",
      "Epoch 213/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2547 - val_loss: 0.5505\n",
      "Epoch 214/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2555 - val_loss: 0.5304\n",
      "Epoch 215/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2499 - val_loss: 0.5109\n",
      "Epoch 216/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2546 - val_loss: 0.5160\n",
      "Epoch 217/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2529 - val_loss: 0.5435\n",
      "Epoch 218/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2534 - val_loss: 0.5457\n",
      "Epoch 219/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2541 - val_loss: 0.5252\n",
      "Epoch 220/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2499 - val_loss: 0.5296\n",
      "Epoch 221/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2497 - val_loss: 0.5323\n",
      "Epoch 222/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2499 - val_loss: 0.5120\n",
      "Epoch 223/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2541 - val_loss: 0.5167\n",
      "Epoch 224/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2525 - val_loss: 0.5440\n",
      "Epoch 225/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2537 - val_loss: 0.5459\n",
      "\n",
      "Epoch 00225: loss did not improve from 0.25091\n",
      "Epoch 226/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2543 - val_loss: 0.5248\n",
      "Epoch 227/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2499 - val_loss: 0.5289\n",
      "Epoch 228/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2495 - val_loss: 0.5313\n",
      "Epoch 229/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2497 - val_loss: 0.5105\n",
      "Epoch 230/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2545 - val_loss: 0.5150\n",
      "Epoch 231/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2530 - val_loss: 0.5424\n",
      "Epoch 232/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2533 - val_loss: 0.5441\n",
      "Epoch 233/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2539 - val_loss: 0.5226\n",
      "Epoch 234/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2505 - val_loss: 0.5266\n",
      "Epoch 235/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2493 - val_loss: 0.5288\n",
      "Epoch 236/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2493 - val_loss: 0.5295\n",
      "Epoch 237/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2493 - val_loss: 0.5069\n",
      "Epoch 238/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2555 - val_loss: 0.5101\n",
      "Epoch 239/750\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2545 - val_loss: 0.5366\n",
      "Epoch 240/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2517 - val_loss: 0.5371\n",
      "Epoch 241/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2519 - val_loss: 0.5143\n",
      "Epoch 242/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2531 - val_loss: 0.5174\n",
      "Epoch 243/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2520 - val_loss: 0.5440\n",
      "Epoch 244/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2541 - val_loss: 0.5445\n",
      "Epoch 245/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2543 - val_loss: 0.5215\n",
      "Epoch 246/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2507 - val_loss: 0.5246\n",
      "Epoch 247/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2497 - val_loss: 0.5512\n",
      "Epoch 248/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2564 - val_loss: 0.5516\n",
      "Epoch 249/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2565 - val_loss: 0.5285\n",
      "Epoch 250/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2491 - val_loss: 0.5062\n",
      "\n",
      "Epoch 00250: loss improved from 0.25091 to 0.24911, saving model to convmodelcheckpoint.hdf5\n",
      "Epoch 251/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2557 - val_loss: 0.5101\n",
      "Epoch 252/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2544 - val_loss: 0.5376\n",
      "Epoch 253/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2520 - val_loss: 0.5387\n",
      "Epoch 254/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2524 - val_loss: 0.5160\n",
      "Epoch 255/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2525 - val_loss: 0.5196\n",
      "Epoch 256/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2514 - val_loss: 0.5470\n",
      "Epoch 257/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2550 - val_loss: 0.5478\n",
      "Epoch 258/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2552 - val_loss: 0.5248\n",
      "Epoch 259/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2497 - val_loss: 0.5282\n",
      "Epoch 260/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2492 - val_loss: 0.5299\n",
      "Epoch 261/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2495 - val_loss: 0.5074\n",
      "Epoch 262/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2553 - val_loss: 0.5115\n",
      "Epoch 263/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2540 - val_loss: 0.5396\n",
      "Epoch 264/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2526 - val_loss: 0.5408\n",
      "Epoch 265/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2530 - val_loss: 0.5178\n",
      "Epoch 266/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2520 - val_loss: 0.5216\n",
      "Epoch 267/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2508 - val_loss: 0.5494\n",
      "Epoch 268/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2557 - val_loss: 0.5504\n",
      "Epoch 269/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2560 - val_loss: 0.5270\n",
      "Epoch 270/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2493 - val_loss: 0.5046\n",
      "Epoch 271/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2563 - val_loss: 0.5089\n",
      "Epoch 272/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2549 - val_loss: 0.5375\n",
      "Epoch 273/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2518 - val_loss: 0.5389\n",
      "Epoch 274/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2523 - val_loss: 0.5158\n",
      "Epoch 275/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2527 - val_loss: 0.5198\n",
      "\n",
      "Epoch 00275: loss did not improve from 0.24911\n",
      "Epoch 276/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2514 - val_loss: 0.5480\n",
      "Epoch 277/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2552 - val_loss: 0.5491\n",
      "Epoch 278/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2555 - val_loss: 0.5256\n",
      "Epoch 279/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2495 - val_loss: 0.5293\n",
      "Epoch 280/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2494 - val_loss: 0.5311\n",
      "Epoch 281/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2497 - val_loss: 0.5083\n",
      "Epoch 282/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2551 - val_loss: 0.5126\n",
      "Epoch 283/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2538 - val_loss: 0.5414\n",
      "Epoch 284/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2530 - val_loss: 0.5427\n",
      "Epoch 285/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2534 - val_loss: 0.5193\n",
      "Epoch 286/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2516 - val_loss: 0.5233\n",
      "Epoch 287/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2503 - val_loss: 0.5518\n",
      "Epoch 288/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2563 - val_loss: 0.5528\n",
      "Epoch 289/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2566 - val_loss: 0.5290\n",
      "Epoch 290/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2495 - val_loss: 0.5061\n",
      "Epoch 291/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2559 - val_loss: 0.5106\n",
      "Epoch 292/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2544 - val_loss: 0.5398\n",
      "Epoch 293/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2524 - val_loss: 0.5413\n",
      "Epoch 294/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2529 - val_loss: 0.5178\n",
      "Epoch 295/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2521 - val_loss: 0.5218\n",
      "Epoch 296/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2508 - val_loss: 0.5507\n",
      "Epoch 297/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2558 - val_loss: 0.5518\n",
      "Epoch 298/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2562 - val_loss: 0.5279\n",
      "Epoch 299/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2496 - val_loss: 0.5048\n",
      "Epoch 300/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2564 - val_loss: 0.5094\n",
      "\n",
      "Epoch 00300: loss did not improve from 0.24911\n",
      "Epoch 301/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2549 - val_loss: 0.5389\n",
      "Epoch 302/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2521 - val_loss: 0.5405\n",
      "Epoch 303/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2526 - val_loss: 0.5168\n",
      "Epoch 304/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2525 - val_loss: 0.5209\n",
      "Epoch 305/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2512 - val_loss: 0.5501\n",
      "Epoch 306/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2556 - val_loss: 0.5512\n",
      "Epoch 307/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2559 - val_loss: 0.5271\n",
      "Epoch 308/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2497 - val_loss: 0.5039\n",
      "Epoch 309/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2567 - val_loss: 0.5085\n",
      "Epoch 310/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2552 - val_loss: 0.5383\n",
      "Epoch 311/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2518 - val_loss: 0.5399\n",
      "Epoch 312/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2523 - val_loss: 0.5160\n",
      "Epoch 313/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2528 - val_loss: 0.5202\n",
      "Epoch 314/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2514 - val_loss: 0.5496\n",
      "Epoch 315/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2554 - val_loss: 0.5508\n",
      "Epoch 316/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2558 - val_loss: 0.5265\n",
      "Epoch 317/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2497 - val_loss: 0.5031\n",
      "Epoch 318/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2570 - val_loss: 0.5078\n",
      "Epoch 319/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2554 - val_loss: 0.5378\n",
      "Epoch 320/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2516 - val_loss: 0.5394\n",
      "Epoch 321/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2521 - val_loss: 0.5153\n",
      "Epoch 322/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2530 - val_loss: 0.5195\n",
      "Epoch 323/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2516 - val_loss: 0.5492\n",
      "Epoch 324/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2552 - val_loss: 0.5504\n",
      "Epoch 325/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2556 - val_loss: 0.5259\n",
      "\n",
      "Epoch 00325: loss did not improve from 0.24911\n",
      "Epoch 326/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2498 - val_loss: 0.5023\n",
      "Epoch 327/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2572 - val_loss: 0.5070\n",
      "Epoch 328/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2557 - val_loss: 0.5373\n",
      "Epoch 329/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2514 - val_loss: 0.5390\n",
      "Epoch 330/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2519 - val_loss: 0.5147\n",
      "Epoch 331/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2532 - val_loss: 0.5189\n",
      "Epoch 332/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2519 - val_loss: 0.5489\n",
      "Epoch 333/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2551 - val_loss: 0.5500\n",
      "Epoch 334/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2554 - val_loss: 0.5253\n",
      "Epoch 335/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2498 - val_loss: 0.5293\n",
      "Epoch 336/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2499 - val_loss: 0.5313\n",
      "Epoch 337/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2499 - val_loss: 0.5316\n",
      "Epoch 338/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2499 - val_loss: 0.5303\n",
      "Epoch 339/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2498 - val_loss: 0.5277\n",
      "Epoch 340/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2496 - val_loss: 0.5238\n",
      "Epoch 341/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2501 - val_loss: 0.5467\n",
      "Epoch 342/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2548 - val_loss: 0.5413\n",
      "Epoch 343/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2532 - val_loss: 0.5103\n",
      "Epoch 344/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2543 - val_loss: 0.5089\n",
      "Epoch 345/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2547 - val_loss: 0.5341\n",
      "Epoch 346/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2511 - val_loss: 0.5306\n",
      "Epoch 347/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2501 - val_loss: 0.5014\n",
      "Epoch 348/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2570 - val_loss: 0.5016\n",
      "Epoch 349/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2569 - val_loss: 0.5283\n",
      "Epoch 350/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2494 - val_loss: 0.5262\n",
      "\n",
      "Epoch 00350: loss did not improve from 0.24911\n",
      "Epoch 351/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2491 - val_loss: 0.5261\n",
      "Epoch 352/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2490 - val_loss: 0.5280\n",
      "Epoch 353/750\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2492 - val_loss: 0.5034\n",
      "Epoch 354/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2564 - val_loss: 0.5080\n",
      "Epoch 355/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2550 - val_loss: 0.5387\n",
      "Epoch 356/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2524 - val_loss: 0.5401\n",
      "Epoch 357/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2528 - val_loss: 0.5150\n",
      "Epoch 358/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2529 - val_loss: 0.5191\n",
      "Epoch 359/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2516 - val_loss: 0.5496\n",
      "Epoch 360/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2556 - val_loss: 0.5506\n",
      "Epoch 361/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2559 - val_loss: 0.5251\n",
      "Epoch 362/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2497 - val_loss: 0.5289\n",
      "Epoch 363/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2497 - val_loss: 0.5309\n",
      "Epoch 364/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2497 - val_loss: 0.5311\n",
      "Epoch 365/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2497 - val_loss: 0.5297\n",
      "Epoch 366/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2496 - val_loss: 0.5269\n",
      "Epoch 367/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2495 - val_loss: 0.5229\n",
      "Epoch 368/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2503 - val_loss: 0.5462\n",
      "Epoch 369/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2547 - val_loss: 0.5406\n",
      "Epoch 370/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2530 - val_loss: 0.5088\n",
      "Epoch 371/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2547 - val_loss: 0.5073\n",
      "Epoch 372/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2552 - val_loss: 0.5331\n",
      "Epoch 373/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2508 - val_loss: 0.5295\n",
      "Epoch 374/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2497 - val_loss: 0.4995\n",
      "Epoch 375/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2576 - val_loss: 0.4997\n",
      "\n",
      "Epoch 00375: loss did not improve from 0.24911\n",
      "Epoch 376/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2576 - val_loss: 0.5270\n",
      "Epoch 377/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2489 - val_loss: 0.5248\n",
      "Epoch 378/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2494 - val_loss: 0.5500\n",
      "Epoch 379/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2563 - val_loss: 0.5458\n",
      "Epoch 380/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2550 - val_loss: 0.5152\n",
      "Epoch 381/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2525 - val_loss: 0.5149\n",
      "Epoch 382/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2526 - val_loss: 0.5419\n",
      "Epoch 383/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2537 - val_loss: 0.5394\n",
      "Epoch 384/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2528 - val_loss: 0.5101\n",
      "Epoch 385/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2542 - val_loss: 0.5111\n",
      "Epoch 386/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2539 - val_loss: 0.5393\n",
      "Epoch 387/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2527 - val_loss: 0.5377\n",
      "Epoch 388/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2522 - val_loss: 0.5093\n",
      "Epoch 389/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2546 - val_loss: 0.5111\n",
      "Epoch 390/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2540 - val_loss: 0.5401\n",
      "Epoch 391/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2528 - val_loss: 0.5392\n",
      "Epoch 392/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2525 - val_loss: 0.5114\n",
      "Epoch 393/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2540 - val_loss: 0.5137\n",
      "Epoch 394/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2532 - val_loss: 0.5433\n",
      "Epoch 395/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2537 - val_loss: 0.5428\n",
      "Epoch 396/750\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2535 - val_loss: 0.5153\n",
      "Epoch 397/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2528 - val_loss: 0.5180\n",
      "Epoch 398/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2520 - val_loss: 0.5480\n",
      "Epoch 399/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2550 - val_loss: 0.5478\n",
      "Epoch 400/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2549 - val_loss: 0.5205\n",
      "\n",
      "Epoch 00400: loss did not improve from 0.24911\n",
      "Epoch 401/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2512 - val_loss: 0.5235\n",
      "Epoch 402/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2503 - val_loss: 0.5537\n",
      "Epoch 403/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2566 - val_loss: 0.5537\n",
      "Epoch 404/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2566 - val_loss: 0.5265\n",
      "Epoch 405/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2499 - val_loss: 0.5005\n",
      "Epoch 406/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2579 - val_loss: 0.5046\n",
      "Epoch 407/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2565 - val_loss: 0.5360\n",
      "Epoch 408/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2509 - val_loss: 0.5370\n",
      "Epoch 409/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2511 - val_loss: 0.5106\n",
      "Epoch 410/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2546 - val_loss: 0.5145\n",
      "Epoch 411/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2534 - val_loss: 0.5457\n",
      "Epoch 412/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2539 - val_loss: 0.5465\n",
      "Epoch 413/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2541 - val_loss: 0.5198\n",
      "Epoch 414/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2517 - val_loss: 0.5236\n",
      "Epoch 415/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2505 - val_loss: 0.5547\n",
      "Epoch 416/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2566 - val_loss: 0.5554\n",
      "Epoch 417/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2568 - val_loss: 0.5285\n",
      "Epoch 418/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2504 - val_loss: 0.5028\n",
      "Epoch 419/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2573 - val_loss: 0.5074\n",
      "Epoch 420/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2558 - val_loss: 0.5394\n",
      "Epoch 421/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2516 - val_loss: 0.5408\n",
      "Epoch 422/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2521 - val_loss: 0.5145\n",
      "Epoch 423/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2535 - val_loss: 0.5188\n",
      "Epoch 424/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2522 - val_loss: 0.5505\n",
      "Epoch 425/750\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2551 - val_loss: 0.5515\n",
      "\n",
      "Epoch 00425: loss did not improve from 0.24911\n",
      "Epoch 426/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2554 - val_loss: 0.5249\n",
      "Epoch 427/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2505 - val_loss: 0.4993\n",
      "Epoch 428/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2585 - val_loss: 0.5043\n",
      "Epoch 429/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2569 - val_loss: 0.5367\n",
      "Epoch 430/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2507 - val_loss: 0.5643\n",
      "Epoch 431/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2595 - val_loss: 0.5615\n",
      "Epoch 432/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2586 - val_loss: 0.5314\n",
      "Epoch 433/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2505 - val_loss: 0.5027\n",
      "Epoch 434/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2573 - val_loss: 0.5049\n",
      "Epoch 435/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2566 - val_loss: 0.5349\n",
      "Epoch 436/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2504 - val_loss: 0.5603\n",
      "Epoch 437/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2585 - val_loss: 0.5555\n",
      "Epoch 438/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2570 - val_loss: 0.5235\n",
      "Epoch 439/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2504 - val_loss: 0.5227\n",
      "Epoch 440/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2506 - val_loss: 0.5502\n",
      "Epoch 441/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2554 - val_loss: 0.5472\n",
      "Epoch 442/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2545 - val_loss: 0.5167\n",
      "Epoch 443/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2525 - val_loss: 0.5174\n",
      "Epoch 444/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2523 - val_loss: 0.5462\n",
      "Epoch 445/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2542 - val_loss: 0.5444\n",
      "Epoch 446/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2536 - val_loss: 0.5149\n",
      "Epoch 447/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2531 - val_loss: 0.5166\n",
      "Epoch 448/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2526 - val_loss: 0.5463\n",
      "Epoch 449/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2542 - val_loss: 0.5452\n",
      "Epoch 450/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2538 - val_loss: 0.5164\n",
      "\n",
      "Epoch 00450: loss did not improve from 0.24911\n",
      "Epoch 451/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2527 - val_loss: 0.5186\n",
      "Epoch 452/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2520 - val_loss: 0.5490\n",
      "Epoch 453/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2549 - val_loss: 0.5484\n",
      "Epoch 454/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2547 - val_loss: 0.5200\n",
      "Epoch 455/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2516 - val_loss: 0.5227\n",
      "Epoch 456/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2508 - val_loss: 0.5534\n",
      "Epoch 457/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2562 - val_loss: 0.5532\n",
      "Epoch 458/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2561 - val_loss: 0.5250\n",
      "Epoch 459/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2504 - val_loss: 0.4980\n",
      "Epoch 460/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2588 - val_loss: 0.5021\n",
      "Epoch 461/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2575 - val_loss: 0.5341\n",
      "Epoch 462/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2505 - val_loss: 0.5614\n",
      "Epoch 463/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2587 - val_loss: 0.5579\n",
      "Epoch 464/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2576 - val_loss: 0.5267\n",
      "Epoch 465/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2503 - val_loss: 0.4970\n",
      "Epoch 466/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2591 - val_loss: 0.4987\n",
      "Epoch 467/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2585 - val_loss: 0.5287\n",
      "Epoch 468/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2502 - val_loss: 0.5541\n",
      "Epoch 469/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2566 - val_loss: 0.5489\n",
      "Epoch 470/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2550 - val_loss: 0.5161\n",
      "Epoch 471/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2527 - val_loss: 0.5151\n",
      "Epoch 472/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2530 - val_loss: 0.5426\n",
      "Epoch 473/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2531 - val_loss: 0.5393\n",
      "Epoch 474/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2521 - val_loss: 0.5082\n",
      "Epoch 475/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2552 - val_loss: 0.5088\n",
      "\n",
      "Epoch 00475: loss did not improve from 0.24911\n",
      "Epoch 476/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2550 - val_loss: 0.5378\n",
      "Epoch 477/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2516 - val_loss: 0.5357\n",
      "Epoch 478/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2509 - val_loss: 0.5057\n",
      "Epoch 479/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2560 - val_loss: 0.5073\n",
      "Epoch 480/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2555 - val_loss: 0.5373\n",
      "Epoch 481/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2514 - val_loss: 0.5360\n",
      "Epoch 482/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2509 - val_loss: 0.5067\n",
      "Epoch 483/750\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2558 - val_loss: 0.5090\n",
      "Epoch 484/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2551 - val_loss: 0.5396\n",
      "Epoch 485/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2520 - val_loss: 0.5389\n",
      "Epoch 486/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2517 - val_loss: 0.5101\n",
      "Epoch 487/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2548 - val_loss: 0.5128\n",
      "Epoch 488/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2539 - val_loss: 0.5438\n",
      "Epoch 489/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2532 - val_loss: 0.5435\n",
      "Epoch 490/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2531 - val_loss: 0.5150\n",
      "Epoch 491/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2533 - val_loss: 0.5179\n",
      "Epoch 492/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2523 - val_loss: 0.5493\n",
      "Epoch 493/750\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2548 - val_loss: 0.5492\n",
      "Epoch 494/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2547 - val_loss: 0.5208\n",
      "Epoch 495/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2515 - val_loss: 0.5240\n",
      "Epoch 496/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2506 - val_loss: 0.5252\n",
      "Epoch 497/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2506 - val_loss: 0.5247\n",
      "Epoch 498/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2506 - val_loss: 0.5226\n",
      "Epoch 499/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2509 - val_loss: 0.5495\n",
      "Epoch 500/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2549 - val_loss: 0.5454\n",
      "\n",
      "Epoch 00500: loss did not improve from 0.24911\n",
      "Epoch 501/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2536 - val_loss: 0.5131\n",
      "Epoch 502/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2538 - val_loss: 0.5130\n",
      "Epoch 503/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2539 - val_loss: 0.5417\n",
      "Epoch 504/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2525 - val_loss: 0.5391\n",
      "Epoch 505/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2517 - val_loss: 0.5082\n",
      "Epoch 506/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2554 - val_loss: 0.5093\n",
      "Epoch 507/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2550 - val_loss: 0.5392\n",
      "Epoch 508/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2517 - val_loss: 0.5376\n",
      "Epoch 509/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2512 - val_loss: 0.5077\n",
      "Epoch 510/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2556 - val_loss: 0.5096\n",
      "Epoch 511/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2550 - val_loss: 0.5403\n",
      "Epoch 512/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2520 - val_loss: 0.5394\n",
      "Epoch 513/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2517 - val_loss: 0.5100\n",
      "Epoch 514/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2549 - val_loss: 0.5125\n",
      "Epoch 515/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2541 - val_loss: 0.5437\n",
      "Epoch 516/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2530 - val_loss: 0.5433\n",
      "Epoch 517/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2528 - val_loss: 0.5143\n",
      "Epoch 518/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2536 - val_loss: 0.5171\n",
      "Epoch 519/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2527 - val_loss: 0.5487\n",
      "Epoch 520/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2544 - val_loss: 0.5485\n",
      "Epoch 521/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2543 - val_loss: 0.5197\n",
      "Epoch 522/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2519 - val_loss: 0.5228\n",
      "Epoch 523/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2510 - val_loss: 0.5546\n",
      "Epoch 524/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2561 - val_loss: 0.5546\n",
      "Epoch 525/750\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2561 - val_loss: 0.5260\n",
      "\n",
      "Epoch 00525: loss did not improve from 0.24911\n",
      "Epoch 526/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2511 - val_loss: 0.4986\n",
      "Epoch 527/750\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2589 - val_loss: 0.5030\n",
      "Epoch 528/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2575 - val_loss: 0.5360\n",
      "Epoch 529/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2513 - val_loss: 0.5641\n",
      "Epoch 530/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2590 - val_loss: 0.5607\n",
      "Epoch 531/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2580 - val_loss: 0.5289\n",
      "Epoch 532/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2511 - val_loss: 0.4986\n",
      "Epoch 533/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2588 - val_loss: 0.5005\n",
      "Epoch 534/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2582 - val_loss: 0.5313\n",
      "Epoch 535/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2509 - val_loss: 0.5575\n",
      "Epoch 536/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2572 - val_loss: 0.5522\n",
      "Epoch 537/750\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2555 - val_loss: 0.5187\n",
      "Epoch 538/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2522 - val_loss: 0.5177\n",
      "Epoch 539/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2524 - val_loss: 0.5460\n",
      "Epoch 540/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2537 - val_loss: 0.5427\n",
      "Epoch 541/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2526 - val_loss: 0.5109\n",
      "Epoch 542/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2546 - val_loss: 0.5115\n",
      "Epoch 543/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2544 - val_loss: 0.5413\n",
      "Epoch 544/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2522 - val_loss: 0.5392\n",
      "Epoch 545/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2515 - val_loss: 0.5085\n",
      "Epoch 546/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2554 - val_loss: 0.5102\n",
      "Epoch 547/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2549 - val_loss: 0.5408\n",
      "Epoch 548/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2520 - val_loss: 0.5396\n",
      "Epoch 549/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2516 - val_loss: 0.5097\n",
      "Epoch 550/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2551 - val_loss: 0.5120\n",
      "\n",
      "Epoch 00550: loss did not improve from 0.24911\n",
      "Epoch 551/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2544 - val_loss: 0.5432\n",
      "Epoch 552/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2526 - val_loss: 0.5426\n",
      "Epoch 553/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2524 - val_loss: 0.5131\n",
      "Epoch 554/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2541 - val_loss: 0.5158\n",
      "Epoch 555/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2532 - val_loss: 0.5476\n",
      "Epoch 556/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2539 - val_loss: 0.5472\n",
      "Epoch 557/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2537 - val_loss: 0.5181\n",
      "Epoch 558/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2526 - val_loss: 0.5211\n",
      "Epoch 559/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2516 - val_loss: 0.5531\n",
      "Epoch 560/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2555 - val_loss: 0.5530\n",
      "Epoch 561/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2554 - val_loss: 0.5240\n",
      "Epoch 562/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2513 - val_loss: 0.4963\n",
      "Epoch 563/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2597 - val_loss: 0.5006\n",
      "Epoch 564/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2583 - val_loss: 0.5339\n",
      "Epoch 565/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2515 - val_loss: 0.5622\n",
      "Epoch 566/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2583 - val_loss: 0.5587\n",
      "Epoch 567/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2572 - val_loss: 0.5266\n",
      "Epoch 568/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2513 - val_loss: 0.4960\n",
      "Epoch 569/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2597 - val_loss: 0.4979\n",
      "Epoch 570/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2591 - val_loss: 0.5290\n",
      "Epoch 571/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2511 - val_loss: 0.5554\n",
      "Epoch 572/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2563 - val_loss: 0.5501\n",
      "Epoch 573/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2547 - val_loss: 0.5163\n",
      "Epoch 574/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2530 - val_loss: 0.5153\n",
      "Epoch 575/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2533 - val_loss: 0.5438\n",
      "\n",
      "Epoch 00575: loss did not improve from 0.24911\n",
      "Epoch 576/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2528 - val_loss: 0.5405\n",
      "Epoch 577/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2518 - val_loss: 0.5084\n",
      "Epoch 578/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2555 - val_loss: 0.5090\n",
      "Epoch 579/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2553 - val_loss: 0.5389\n",
      "Epoch 580/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2513 - val_loss: 0.5369\n",
      "Epoch 581/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2509 - val_loss: 0.5333\n",
      "Epoch 582/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2508 - val_loss: 0.5285\n",
      "Epoch 583/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2507 - val_loss: 0.5226\n",
      "Epoch 584/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2508 - val_loss: 0.5467\n",
      "Epoch 585/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2541 - val_loss: 0.5393\n",
      "Epoch 586/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2518 - val_loss: 0.5035\n",
      "Epoch 587/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2568 - val_loss: 0.5008\n",
      "Epoch 588/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2577 - val_loss: 0.5279\n",
      "Epoch 589/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2501 - val_loss: 0.5507\n",
      "Epoch 590/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2556 - val_loss: 0.5420\n",
      "Epoch 591/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2529 - val_loss: 0.5050\n",
      "Epoch 592/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2561 - val_loss: 0.5013\n",
      "Epoch 593/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2573 - val_loss: 0.5275\n",
      "Epoch 594/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2497 - val_loss: 0.5495\n",
      "Epoch 595/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2555 - val_loss: 0.5401\n",
      "Epoch 596/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2526 - val_loss: 0.5024\n",
      "Epoch 597/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2568 - val_loss: 0.4981\n",
      "Epoch 598/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2582 - val_loss: 0.5238\n",
      "Epoch 599/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2499 - val_loss: 0.5765\n",
      "Epoch 600/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2643 - val_loss: 0.5948\n",
      "\n",
      "Epoch 00600: loss did not improve from 0.24911\n",
      "Epoch 601/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2702 - val_loss: 0.5820\n",
      "Epoch 602/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2661 - val_loss: 0.5413\n",
      "Epoch 603/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2531 - val_loss: 0.4754\n",
      "Epoch 604/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2703 - val_loss: 0.4765\n",
      "Epoch 605/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2696 - val_loss: 0.5376\n",
      "Epoch 606/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2518 - val_loss: 0.5635\n",
      "Epoch 607/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2600 - val_loss: 0.5578\n",
      "Epoch 608/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2581 - val_loss: 0.5235\n",
      "Epoch 609/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2502 - val_loss: 0.5222\n",
      "Epoch 610/750\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2506 - val_loss: 0.5504\n",
      "Epoch 611/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2555 - val_loss: 0.5467\n",
      "Epoch 612/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2542 - val_loss: 0.5144\n",
      "Epoch 613/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2533 - val_loss: 0.5147\n",
      "Epoch 614/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2532 - val_loss: 0.5444\n",
      "Epoch 615/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2533 - val_loss: 0.5422\n",
      "Epoch 616/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2525 - val_loss: 0.5111\n",
      "Epoch 617/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2545 - val_loss: 0.5125\n",
      "Epoch 618/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2541 - val_loss: 0.5432\n",
      "Epoch 619/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2527 - val_loss: 0.5418\n",
      "Epoch 620/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2522 - val_loss: 0.5116\n",
      "Epoch 621/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2545 - val_loss: 0.5137\n",
      "Epoch 622/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2539 - val_loss: 0.5451\n",
      "Epoch 623/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2530 - val_loss: 0.5443\n",
      "Epoch 624/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2527 - val_loss: 0.5146\n",
      "Epoch 625/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2537 - val_loss: 0.5172\n",
      "\n",
      "Epoch 00625: loss did not improve from 0.24911\n",
      "Epoch 626/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2529 - val_loss: 0.5490\n",
      "Epoch 627/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2540 - val_loss: 0.5486\n",
      "Epoch 628/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2538 - val_loss: 0.5192\n",
      "Epoch 629/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2524 - val_loss: 0.5222\n",
      "Epoch 630/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2516 - val_loss: 0.5232\n",
      "Epoch 631/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2516 - val_loss: 0.5225\n",
      "Epoch 632/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2516 - val_loss: 0.5203\n",
      "Epoch 633/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2520 - val_loss: 0.5478\n",
      "Epoch 634/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2536 - val_loss: 0.5434\n",
      "Epoch 635/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2522 - val_loss: 0.5103\n",
      "Epoch 636/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2551 - val_loss: 0.5101\n",
      "Epoch 637/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2552 - val_loss: 0.5394\n",
      "Epoch 638/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2515 - val_loss: 0.5642\n",
      "Epoch 639/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2590 - val_loss: 0.5573\n",
      "Epoch 640/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2569 - val_loss: 0.5220\n",
      "Epoch 641/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2512 - val_loss: 0.5197\n",
      "Epoch 642/750\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2519 - val_loss: 0.5472\n",
      "Epoch 643/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2537 - val_loss: 0.5428\n",
      "Epoch 644/750\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2523 - val_loss: 0.5097\n",
      "Epoch 645/750\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2552 - val_loss: 0.5094\n",
      "Epoch 646/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2552 - val_loss: 0.5388\n",
      "Epoch 647/750\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2513 - val_loss: 0.5636\n",
      "Epoch 648/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2590 - val_loss: 0.5567\n",
      "Epoch 649/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2568 - val_loss: 0.5213\n",
      "Epoch 650/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2514 - val_loss: 0.5190\n",
      "\n",
      "Epoch 00650: loss did not improve from 0.24911\n",
      "Epoch 651/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2521 - val_loss: 0.5466\n",
      "Epoch 652/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2536 - val_loss: 0.5422\n",
      "Epoch 653/750\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2522 - val_loss: 0.5090\n",
      "Epoch 654/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2553 - val_loss: 0.5087\n",
      "Epoch 655/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2554 - val_loss: 0.5381\n",
      "Epoch 656/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2512 - val_loss: 0.5629\n",
      "Epoch 657/750\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2588 - val_loss: 0.5560\n",
      "Epoch 658/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2566 - val_loss: 0.5206\n",
      "Epoch 659/750\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2516 - val_loss: 0.5183\n",
      "Epoch 660/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2523 - val_loss: 0.5459\n",
      "Epoch 661/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2534 - val_loss: 0.5414\n",
      "Epoch 662/750\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2520 - val_loss: 0.5082\n",
      "Epoch 663/750\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2556 - val_loss: 0.5080\n",
      "Epoch 664/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2557 - val_loss: 0.5374\n",
      "Epoch 665/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2512 - val_loss: 0.5622\n",
      "Epoch 666/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2586 - val_loss: 0.5553\n",
      "Epoch 667/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2564 - val_loss: 0.5198\n",
      "Epoch 668/750\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2518 - val_loss: 0.5175\n",
      "Epoch 669/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2526 - val_loss: 0.5451\n",
      "Epoch 670/750\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2532 - val_loss: 0.5407\n",
      "Epoch 671/750\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2517 - val_loss: 0.5075\n",
      "Epoch 672/750\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2558 - val_loss: 0.5072\n",
      "Epoch 673/750\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2559 - val_loss: 0.5366\n",
      "Epoch 674/750\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2512 - val_loss: 0.5615\n",
      "Epoch 675/750\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2583 - val_loss: 0.5546\n",
      "\n",
      "Epoch 00675: loss did not improve from 0.24911\n",
      "Epoch 676/750\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2561 - val_loss: 0.5191\n",
      "Epoch 677/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2521 - val_loss: 0.5168\n",
      "Epoch 678/750\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2528 - val_loss: 0.5444\n",
      "Epoch 679/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2529 - val_loss: 0.5400\n",
      "Epoch 680/750\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2515 - val_loss: 0.5067\n",
      "Epoch 681/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2561 - val_loss: 0.5064\n",
      "Epoch 682/750\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2562 - val_loss: 0.5359\n",
      "Epoch 683/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2513 - val_loss: 0.5608\n",
      "Epoch 684/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2581 - val_loss: 0.5539\n",
      "Epoch 685/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2559 - val_loss: 0.5183\n",
      "Epoch 686/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2523 - val_loss: 0.5160\n",
      "Epoch 687/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2531 - val_loss: 0.5437\n",
      "Epoch 688/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2526 - val_loss: 0.5393\n",
      "Epoch 689/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2513 - val_loss: 0.5336\n",
      "Epoch 690/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2512 - val_loss: 0.5270\n",
      "Epoch 691/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2510 - val_loss: 0.5193\n",
      "Epoch 692/750\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2519 - val_loss: 0.5422\n",
      "Epoch 693/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2524 - val_loss: 0.5334\n",
      "Epoch 694/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2507 - val_loss: 0.5239\n",
      "Epoch 695/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2504 - val_loss: 0.5137\n",
      "Epoch 696/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2534 - val_loss: 0.5343\n",
      "Epoch 697/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2504 - val_loss: 0.5235\n",
      "Epoch 698/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2501 - val_loss: 0.5435\n",
      "Epoch 699/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2535 - val_loss: 0.5321\n",
      "Epoch 700/750\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2499 - val_loss: 0.4924\n",
      "\n",
      "Epoch 00700: loss did not improve from 0.24911\n",
      "Epoch 701/750\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2601 - val_loss: 0.4865\n",
      "Epoch 702/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2629 - val_loss: 0.5419\n",
      "Epoch 703/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2532 - val_loss: 0.5623\n",
      "Epoch 704/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2597 - val_loss: 0.5514\n",
      "Epoch 705/750\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2562 - val_loss: 0.5121\n",
      "Epoch 706/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2536 - val_loss: 0.5066\n",
      "Epoch 707/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2554 - val_loss: 0.5313\n",
      "Epoch 708/750\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2498 - val_loss: 0.5520\n",
      "Epoch 709/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2564 - val_loss: 0.5412\n",
      "Epoch 710/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2529 - val_loss: 0.5021\n",
      "Epoch 711/750\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2569 - val_loss: 0.4967\n",
      "Epoch 712/750\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2586 - val_loss: 0.5216\n",
      "Epoch 713/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2506 - val_loss: 0.5738\n",
      "Epoch 714/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2633 - val_loss: 0.5914\n",
      "Epoch 715/750\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2690 - val_loss: 0.5778\n",
      "Epoch 716/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2646 - val_loss: 0.5362\n",
      "Epoch 717/750\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2512 - val_loss: 0.4694\n",
      "Epoch 718/750\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2742 - val_loss: 0.4700\n",
      "Epoch 719/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2739 - val_loss: 0.5308\n",
      "Epoch 720/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2501 - val_loss: 0.5840\n",
      "Epoch 721/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2663 - val_loss: 0.6026\n",
      "Epoch 722/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2722 - val_loss: 0.5902\n",
      "Epoch 723/750\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2682 - val_loss: 0.5498\n",
      "Epoch 724/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2552 - val_loss: 0.4842\n",
      "Epoch 725/750\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2646 - val_loss: 0.4855\n",
      "\n",
      "Epoch 00725: loss did not improve from 0.24911\n",
      "Epoch 726/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2638 - val_loss: 0.5466\n",
      "Epoch 727/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2539 - val_loss: 0.5726\n",
      "Epoch 728/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2621 - val_loss: 0.5669\n",
      "Epoch 729/750\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2602 - val_loss: 0.5329\n",
      "Epoch 730/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2511 - val_loss: 0.5006\n",
      "Epoch 731/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2580 - val_loss: 0.5010\n",
      "Epoch 732/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2579 - val_loss: 0.5306\n",
      "Epoch 733/750\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2513 - val_loss: 0.5557\n",
      "Epoch 734/750\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2564 - val_loss: 0.5493\n",
      "Epoch 735/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2544 - val_loss: 0.5147\n",
      "Epoch 736/750\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2535 - val_loss: 0.5128\n",
      "Epoch 737/750\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2542 - val_loss: 0.5404\n",
      "Epoch 738/750\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2515 - val_loss: 0.5637\n",
      "Epoch 739/750\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2589 - val_loss: 0.5557\n",
      "Epoch 740/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2564 - val_loss: 0.5196\n",
      "Epoch 741/750\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2519 - val_loss: 0.5164\n",
      "Epoch 742/750\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2530 - val_loss: 0.5428\n",
      "Epoch 743/750\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2522 - val_loss: 0.5376\n",
      "Epoch 744/750\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2514 - val_loss: 0.5314\n",
      "Epoch 745/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2513 - val_loss: 0.5243\n",
      "Epoch 746/750\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2511 - val_loss: 0.5163\n",
      "Epoch 747/750\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2529 - val_loss: 0.5384\n",
      "Epoch 748/750\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2511 - val_loss: 0.5293\n",
      "Epoch 749/750\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2508 - val_loss: 0.5196\n",
      "Epoch 750/750\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2516 - val_loss: 0.5402\n",
      "\n",
      "Epoch 00750: loss did not improve from 0.24911\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    data = [train, test]\n",
    "\n",
    "    # params = [epochs, batch_size, verbose, learning_rate, n_checkpoint, activation_function]\n",
    "    params = [750, 512, 1, 0.001, 25, 'tanh']\n",
    "\n",
    "    model = build_model(data, n_steps, n_length, n_input, params)\n",
    "\n",
    "else:\n",
    "    model = load_model('convmodelcheckpoint.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting & Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 486 of 1272 operations complete\n",
      "F:\\Dev-Tools\\envs\\amdlstm\\lib\\site-packages\\ipykernel_launcher.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "F:\\Dev-Tools\\envs\\amdlstm\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "F:\\Dev-Tools\\envs\\amdlstm\\lib\\site-packages\\ipykernel_launcher.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = np.array([x for x in train])\n",
    "\n",
    "# Forecast\n",
    "pred = forecast(model, history, n_steps, n_length, n_input*n_features, n_features)\n",
    "future_pred = forecast(model, df_pred, n_steps, n_length, n_input*n_features, n_features)\n",
    "\n",
    "# Visualize\n",
    "visualize_forecast(df, df_pred, df_future, pred, future_pred, n_input, n_forecasts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
