{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM\n",
    "\n",
    "## Requirements\n",
    "- python 3.7\n",
    "- keras\n",
    "- tensorflow\n",
    "- scikit-learn\n",
    "- matplotlib\n",
    "- seaborn\n",
    "- pandas\n",
    "- numpy\n",
    "- wandb\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "wandb: WARNING Keras version 2.3.1 is not fully supported. Required keras >= 2.4.0\n",
      "wandb: Currently logged in as: insaine (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.12 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.11<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">sunny-salad-32</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/insaine/convlstm\" target=\"_blank\">https://wandb.ai/insaine/convlstm</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/insaine/convlstm/runs/3h7drndw\" target=\"_blank\">https://wandb.ai/insaine/convlstm/runs/3h7drndw</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\moham\\JupyterProjects\\SmartGridAI\\Time Serie Prediction\\LSTM\\wandb\\run-20201211_161654-3h7drndw</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(3h7drndw)</h1><p></p><iframe src=\"https://wandb.ai/insaine/convlstm/runs/3h7drndw\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x24f3f5ef448>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, ConvLSTM2D, LSTM, Dropout, Flatten, TimeDistributed, RepeatVector\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "wandb.init(project=\"convlstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_supervised(train, n_input, n_output=8):\n",
    "    X, y = list(),list()\n",
    "    \n",
    "    X_start = 0\n",
    "    \n",
    "    # iterate over train dataset\n",
    "    for _ in range(len(train)):\n",
    "        \n",
    "        # set the ranges for input + output\n",
    "        X_end = X_start + n_input\n",
    "        y_end = X_end + n_output\n",
    "        \n",
    "        n_columns = len(train[0])\n",
    "        \n",
    "        # check if data contains enough samples for sequence\n",
    "        if y_end <= len(train):\n",
    "            if X_start == 0:\n",
    "                print(y_end)\n",
    "                print(train[y_end])\n",
    "            X.append(train[X_start:X_end, :])\n",
    "            y.append(train[X_end:y_end, n_columns-1])    \n",
    "        X_start += 1\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def build_model(data, n_steps, n_length, n_input, params):\n",
    "    \n",
    "    # ConvLSTM2D expected input: [samples, timesteps, rows, cols, channels]\n",
    "    # In our case, this will be [n_input, 7, 1, 24, 1]\n",
    "    \n",
    "    # data preperation\n",
    "    train, val = data\n",
    "    X_train, y_train = to_supervised(train, n_input)\n",
    "    print(len(X_train))\n",
    "    X_val, y_val = to_supervised(val, n_input)\n",
    "    \n",
    "    # meta / parameters\n",
    "    epochs, batch_size, verbose, learning_rate = params\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "    \n",
    "    X_train = X_train.reshape((X_train.shape[0], n_steps, 1, n_length, n_features))\n",
    "    X_val = X_val.reshape((X_val.shape[0], n_steps, 1, n_length, n_features))\n",
    "    \n",
    "    # reshape output\n",
    "    y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], 1))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], 1))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(ConvLSTM2D(filters=64, kernel_size=(1,8), activation='relu', input_shape=(n_steps, 1, n_length, n_features), return_sequences=True))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(ConvLSTM2D(filters=24, kernel_size=(1,8), activation='relu', return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "#     model.add(Dropout(0.1))\n",
    "#     model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "#     model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    opt = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=opt)\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data=(X_val, y_val), callbacks=[WandbCallback()], shuffle=False)\n",
    "    \n",
    "    model.save(os.path.join(wandb.run.dir, \"model.h5\"))\n",
    "    \n",
    "    # plot the model\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def forecast(model, history, n_steps, n_length, n_input, n_features):\n",
    "    data = np.array(history)\n",
    "    X = data[-n_input:, 0]\n",
    "    X = X.reshape((1, n_steps, 1, n_length, n_features))\n",
    "    yhat = model.predict(X, verbose=0)\n",
    "    yhat = yhat[0]\n",
    "    return yhat\n",
    "\n",
    "\n",
    "def visualize_forecast(history, validation, future, pred, future_pred, n_input, n_forecasts):\n",
    "    past = history[-n_forecasts*6:-n_forecasts+1]\n",
    "    \n",
    "    future = future[-n_forecasts:]\n",
    "    validation = validation[-n_forecasts:]\n",
    "\n",
    "#     validation.index = validation.index + pd.Timedelta(n_forecasts, unit='h')\n",
    "    future.index = future.index + pd.Timedelta(n_forecasts, unit='h')\n",
    "\n",
    "    future['Prediction'] = future_pred\n",
    "    validation['Prediction'] = pred\n",
    "    validation['Actual'] = history[-8:]['Increment']\n",
    "\n",
    "    \n",
    "    sns.set(rc={'figure.figsize':(14,5)})\n",
    "    sns.lineplot(data=past, x=past.index, y=\"Increment\")\n",
    "    sns.lineplot(data=validation, x=validation.index, y=\"Actual\", color=\"lime\")\n",
    "    sns.lineplot(data=validation, x=validation.index, y=\"Prediction\", color=\"red\")\n",
    "    sns.lineplot(data=future, x=future.index, y=\"Prediction\", color=\"darkred\")\n",
    "    plt.legend(['Active Power (Past)','Active Power (Actual)','Active Power (Prediction)', 'Active Power (Future Prediction)'])\n",
    "\n",
    "    plt.title('Predictions of Global Active Power')\n",
    "    plt.xlabel('Timeline')\n",
    "    plt.ylabel('Global Active Power')\n",
    "    plt.grid(which='major', color=\"#ffffff\", alpha=.5)\n",
    "    plt.axvline(x=past.index[-1], color=\"green\", linestyle=\"--\")\n",
    "    plt.axvline(x=validation.index[-1], color=\"green\", linestyle=\"--\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis / Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/household_power_consumption.txt', sep=';', \n",
    "                 parse_dates={'dt' : ['Date', 'Time']}, infer_datetime_format=True, \n",
    "                 low_memory=False, na_values=['nan','?'], index_col='dt')\n",
    "\n",
    "df_resample = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# global_active_power: household global minute-averaged active power (in kilowatt)\n",
    "# global_reactive_power: household global minute-averaged reactive power (in kilowatt)\n",
    "# voltage: minute-averaged voltage (in volt)\n",
    "# global_intensity: household global minute-averaged current intensity (in ampere)\n",
    "\n",
    "\n",
    "\n",
    "df_resample['Global_active_power'] = np.cumsum(df['Global_active_power'].resample('h').mean())*1000\n",
    "df_resample['Global_reactive_power'] = np.cumsum(df['Global_reactive_power'].resample('h').mean())*1000\n",
    "\n",
    "df_resample['Increment'] = df_resample['Global_active_power'].diff(periods=1)\n",
    "df_resample['Increment'] = df_resample['Increment'].fillna(0)\n",
    "\n",
    "# df_resample['Global_active_power'] = df['Global_active_power'].resample('h').mean()*1000\n",
    "# df_resample['Global_reactive_power'] = df['Global_reactive_power'].resample('h').mean()*1000\n",
    "\n",
    "\n",
    "df_resample['Voltage'] = df['Voltage'].resample('h').mean()\n",
    "df_resample['Global_intensity'] = df['Global_intensity'].resample('h').mean()\n",
    "\n",
    "# sub_metering_#: energy sub-metering No. # (in watt-hour of active energy).\n",
    "df_resample['Sub_metering_1'] = df['Sub_metering_1'].resample('h').sum()\n",
    "df_resample['Sub_metering_2'] = df['Sub_metering_2'].resample('h').sum()\n",
    "df_resample['Sub_metering_3'] = df['Sub_metering_3'].resample('h').sum()\n",
    "\n",
    "# columns = [x for x in df_resample.columns if x not in ['Voltage', 'Global_intensity', 'Global_reactive_power']] \n",
    "columns = [x for x in df_resample.columns if x not in ['Voltage', 'Global_intensity']] \n",
    "\n",
    "df_resample = df_resample[columns]\n",
    "\n",
    "df = df_resample\n",
    "\n",
    "df_resample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN's with column's mean value\n",
    "for j in range(0,len(df_resample.columns)):        \n",
    "        df_resample.iloc[:,j]=df_resample.iloc[:,j].fillna(df_resample.iloc[:,j].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(df_resample)\n",
    "# df_scaled = scaler.transform(df_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. hours to forecast\n",
    "n_forecasts = 8\n",
    "\n",
    "# Amount of sequences that the data will be split into\n",
    "n_steps = 7\n",
    "\n",
    "# Amount of hours per sequence\n",
    "n_length = 24\n",
    "\n",
    "# Amount of features in dataset\n",
    "n_features = len(df_resample.columns)\n",
    "\n",
    "# determines how much data is used to forecast (currently using a week of data per row)\n",
    "n_input = n_steps * n_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a few hours of time, validate if model isn't inaccurate due to an anomaly in the data\n",
    "# df_resample = df_resample[:-8]\n",
    "\n",
    "df_future = df_resample[-n_forecasts:]\n",
    "df_pred = df_resample[-n_input*n_features:]\n",
    "df_resample = df_resample[:-n_forecasts]\n",
    "\n",
    "train, test = train_test_split(df_resample.values, test_size=.2, shuffle=False, stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train, test]\n",
    "\n",
    "# params = [epochs, batch_size, verbose, learning_rate]\n",
    "params = [500, 512, 1, 0.001]\n",
    "\n",
    "model = build_model(data, n_steps, n_length, n_input, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(history.shape)\n",
    "\n",
    "# pred = forecast(model, history, n_steps, n_length, n_input*n_features, n_features)\n",
    "# future_pred = forecast(model, df_pred, n_steps, n_length, n_input*n_features, n_features)\n",
    "\n",
    "# df_future['Prediction'] = future_pred\n",
    "\n",
    "# df_pred = df_resample[-n_forecasts:]\n",
    "# df_pred['Prediction'] = pred\n",
    "\n",
    "# # df_pred.index = df_pred.index + pd.Timedelta(n_forecasts, unit='h')\n",
    "# # df_future.index = df_future.index + pd.Timedelta(n_forecasts, unit='h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = np.array([x for x in train])\n",
    "\n",
    "# Forecast\n",
    "pred = forecast(model, history, n_steps, n_length, n_input*n_features, n_features)\n",
    "future_pred = forecast(model, df_pred, n_steps, n_length, n_input*n_features, n_features)\n",
    "\n",
    "# Visualize\n",
    "visualize_forecast(df, df_pred, df_future, pred, future_pred, n_input, n_forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# past = df_resample[-48:-n_forecasts+1]\n",
    "\n",
    "# sns.set(rc={'figure.figsize':(14,5)})\n",
    "# sns.lineplot(data=past, x=past.index, y=\"Global_active_power\")\n",
    "# sns.lineplot(data=df_pred, x=df_pred.index, y=\"Global_active_power\", color=\"lime\")\n",
    "# sns.lineplot(data=df_pred, x=df_pred.index, y=\"Prediction\", color=\"red\")\n",
    "# sns.lineplot(data=df_future, x=df_future.index, y=\"Prediction\", color=\"darkred\")\n",
    "# plt.legend(['Active Power (Past)','Active Power (Actual)','Active Power (Prediction)', 'Active Power (Future Prediction)'])\n",
    "\n",
    "# plt.title('Predictions of Global Active Power')\n",
    "# plt.xlabel('Timeline')\n",
    "# plt.ylabel('Global Active Power')\n",
    "# plt.grid(which='major', color=\"#ffffff\", alpha=.5)\n",
    "# plt.axvline(x=past.index[-1], color=\"green\", linestyle=\"--\")\n",
    "# plt.axvline(x=df_pred.index[-1], color=\"green\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
