{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM\n",
    "\n",
    "## Requirements\n",
    "- python 3.7\n",
    "- keras\n",
    "- tensorflow\n",
    "- scikit-learn\n",
    "- matplotlib\n",
    "- seaborn\n",
    "- pandas\n",
    "- numpy\n",
    "- wandb\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Keras version 2.2.4 is not fully supported. Required keras >= 2.4.0\n",
      "wandb: Currently logged in as: tyromijn (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">light-gorge-37</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/tyromijn/convlstm\" target=\"_blank\">https://wandb.ai/tyromijn/convlstm</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/tyromijn/convlstm/runs/2urjugyc\" target=\"_blank\">https://wandb.ai/tyromijn/convlstm/runs/2urjugyc</a><br/>\n",
       "                Run data is saved locally in <code>F:\\dev\\Minor\\SmartGrid\\Time Serie Prediction\\LSTM\\wandb\\run-20201218_144330-2urjugyc</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(2urjugyc)</h1><p></p><iframe src=\"https://wandb.ai/tyromijn/convlstm/runs/2urjugyc\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x252f067db48>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# PlaidML Imports - disable if you make use of cudnn\n",
    "amd = True\n",
    "\n",
    "if amd:\n",
    "    import plaidml.keras\n",
    "    plaidml.keras.install_backend()\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "    os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#     os.environ['PLAIDML_USE_STRIPE']='1'\n",
    "#     os.environ['PLAIDML_VERBOSE']='1'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, ConvLSTM2D, LSTM, Dropout, Flatten, TimeDistributed, RepeatVector\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "wandb.init(project=\"convlstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_supervised(train, n_input, n_output=8):\n",
    "    X, y = list(),list()\n",
    "    \n",
    "    X_start = 0\n",
    "    \n",
    "    # iterate over train dataset\n",
    "    for _ in range(len(train)):\n",
    "        \n",
    "        # set the ranges for input + output\n",
    "        X_end = X_start + n_input\n",
    "        y_end = X_end + n_output\n",
    "        \n",
    "        # check if data contains enough samples for sequence\n",
    "        if y_end <= len(train):\n",
    "            X.append(train[X_start:X_end, :])\n",
    "            y.append(train[X_end:y_end, 0])    \n",
    "        X_start += 1\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def build_model(data, n_steps, n_length, n_input, params):\n",
    "    \n",
    "    # ConvLSTM2D expected input: [samples, timesteps, rows, cols, channels]\n",
    "    # In our case, this will be [n_input, 7, 1, 24, 1]\n",
    "    \n",
    "    # data preperation\n",
    "    train, val = data\n",
    "    X_train, y_train = to_supervised(train, n_input)\n",
    "    X_val, y_val = to_supervised(val, n_input)\n",
    "    \n",
    "    # meta / parameters\n",
    "    epochs, batch_size, verbose, learning_rate, n_checkpoint, activation_function = params\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "    \n",
    "    X_train = X_train.reshape((X_train.shape[0], n_steps, 1, n_length, n_features))\n",
    "    X_val = X_val.reshape((X_val.shape[0], n_steps, 1, n_length, n_features))\n",
    "    \n",
    "    # reshape output\n",
    "    y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], 1))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], 1))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(ConvLSTM2D(filters=8, kernel_size=(5,5), activation=activation_function, input_shape=(n_steps, 1, n_length, n_features), return_sequences=True))\n",
    "    model.add(ConvLSTM2D(filters=8, kernel_size=(5,5), activation=activation_function, return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    model.add(LSTM(128, activation=activation_function, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(128, activation=activation_function)))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=opt)\n",
    "    checkpoint = ModelCheckpoint(\"convmodelcheckpoint.hdf5\", monitor='loss', verbose=1,\n",
    "    save_best_only=True, mode='auto', period=n_checkpoint)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data=(X_val, y_val), callbacks=[WandbCallback(), checkpoint], shuffle=False)\n",
    "    \n",
    "    model.save(os.path.join(wandb.run.dir, \"model.h5\"))\n",
    "    \n",
    "    # plot the model\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def forecast(model, history, n_steps, n_length, n_input, n_features):\n",
    "    data = np.array(history)\n",
    "    X = data[-n_input:, 0]\n",
    "    X = X.reshape((1, n_steps, 1, n_length, n_features))\n",
    "    yhat = model.predict(X, verbose=0)\n",
    "    yhat = yhat[0]\n",
    "    return yhat\n",
    "\n",
    "\n",
    "def visualize_forecast(history, validation, future, pred, future_pred, n_input, n_forecasts):\n",
    "    if n_input > 48:\n",
    "        past = history[-48:-n_forecasts+1]\n",
    "    else:   \n",
    "        past = history[-n_input:-n_forecasts+1]\n",
    "    \n",
    "    future = future[-n_forecasts:]\n",
    "    validation = validation[-n_forecasts:]\n",
    "\n",
    "#     validation.index = validation.index + pd.Timedelta(n_forecasts, unit='h')\n",
    "    future.index = future.index + pd.Timedelta(n_forecasts, unit='h')\n",
    "\n",
    "    future['Prediction'] = future_pred\n",
    "    validation['Prediction'] = pred\n",
    "    validation['Actual'] = history[-8:]['Global_active_power']\n",
    "\n",
    "    \n",
    "    sns.set(rc={'figure.figsize':(14,5)})\n",
    "    sns.lineplot(data=past, x=past.index, y=\"Global_active_power\")\n",
    "    sns.lineplot(data=validation, x=validation.index, y=\"Actual\", color=\"lime\")\n",
    "    sns.lineplot(data=validation, x=validation.index, y=\"Prediction\", color=\"red\")\n",
    "    sns.lineplot(data=future, x=future.index, y=\"Prediction\", color=\"darkred\")\n",
    "    plt.legend(['Active Power (Past)','Active Power (Actual)','Active Power (Prediction)', 'Active Power (Future Prediction)'])\n",
    "\n",
    "    plt.title('Predictions of Global Active Power')\n",
    "    plt.xlabel('Timeline')\n",
    "    plt.ylabel('Global Active Power')\n",
    "    plt.grid(which='major', color=\"#ffffff\", alpha=.5)\n",
    "    plt.axvline(x=past.index[-1], color=\"green\", linestyle=\"--\")\n",
    "    plt.axvline(x=validation.index[-1], color=\"green\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis / Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:00:00</th>\n",
       "      <td>4.222889</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 18:00:00</th>\n",
       "      <td>3.632200</td>\n",
       "      <td>0.080033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>1012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 19:00:00</th>\n",
       "      <td>3.400233</td>\n",
       "      <td>0.085233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 20:00:00</th>\n",
       "      <td>3.268567</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 21:00:00</th>\n",
       "      <td>3.056467</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1033.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power  \\\n",
       "dt                                                                \n",
       "2006-12-16 17:00:00             4.222889               0.229000   \n",
       "2006-12-16 18:00:00             3.632200               0.080033   \n",
       "2006-12-16 19:00:00             3.400233               0.085233   \n",
       "2006-12-16 20:00:00             3.268567               0.075100   \n",
       "2006-12-16 21:00:00             3.056467               0.076667   \n",
       "\n",
       "                     Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
       "dt                                                                   \n",
       "2006-12-16 17:00:00             0.0            19.0           607.0  \n",
       "2006-12-16 18:00:00             0.0           403.0          1012.0  \n",
       "2006-12-16 19:00:00             0.0            86.0          1001.0  \n",
       "2006-12-16 20:00:00             0.0             0.0          1007.0  \n",
       "2006-12-16 21:00:00             0.0            25.0          1033.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/household_power_consumption.txt', sep=';', \n",
    "                 parse_dates={'dt' : ['Date', 'Time']}, infer_datetime_format=True, \n",
    "                 low_memory=False, na_values=['nan','?'], index_col='dt')\n",
    "\n",
    "df_resample = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# global_active_power: household global minute-averaged active power (in kilowatt)\n",
    "# global_reactive_power: household global minute-averaged reactive power (in kilowatt)\n",
    "# voltage: minute-averaged voltage (in volt)\n",
    "# global_intensity: household global minute-averaged current intensity (in ampere)\n",
    "\n",
    "# df_resample['Global_active_power'] = np.cumsum(df['Global_active_power'].resample('h').mean())\n",
    "# df_resample['Global_reactive_power'] = np.cumsum(df['Global_reactive_power'].resample('h').mean())\n",
    "df_resample['Global_active_power'] = df['Global_active_power'].resample('h').mean()\n",
    "df_resample['Global_reactive_power'] = df['Global_reactive_power'].resample('h').mean()\n",
    "df_resample['Voltage'] = df['Voltage'].resample('h').mean()\n",
    "df_resample['Global_intensity'] = df['Global_intensity'].resample('h').mean()\n",
    "\n",
    "# sub_metering_#: energy sub-metering No. # (in watt-hour of active energy).\n",
    "df_resample['Sub_metering_1'] = df['Sub_metering_1'].resample('h').sum()\n",
    "df_resample['Sub_metering_2'] = df['Sub_metering_2'].resample('h').sum()\n",
    "df_resample['Sub_metering_3'] = df['Sub_metering_3'].resample('h').sum()\n",
    "\n",
    "# columns = [x for x in df_resample.columns if x not in ['Voltage', 'Global_intensity', 'Global_reactive_power']] \n",
    "columns = [x for x in df_resample.columns if x not in ['Voltage', 'Global_intensity']] \n",
    "\n",
    "df_resample = df_resample[columns]\n",
    "\n",
    "df = df_resample\n",
    "\n",
    "df_resample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN's with column's mean value\n",
    "for j in range(0,len(df_resample.columns)):        \n",
    "        df_resample.iloc[:,j]=df_resample.iloc[:,j].fillna(df_resample.iloc[:,j].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:00:00</th>\n",
       "      <td>4.222889</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 18:00:00</th>\n",
       "      <td>3.632200</td>\n",
       "      <td>0.080033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>1012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 19:00:00</th>\n",
       "      <td>3.400233</td>\n",
       "      <td>0.085233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 20:00:00</th>\n",
       "      <td>3.268567</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 21:00:00</th>\n",
       "      <td>3.056467</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1033.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 17:00:00</th>\n",
       "      <td>1.725900</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 18:00:00</th>\n",
       "      <td>1.573467</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 19:00:00</th>\n",
       "      <td>1.659333</td>\n",
       "      <td>0.060033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:00:00</th>\n",
       "      <td>1.163700</td>\n",
       "      <td>0.061167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 21:00:00</th>\n",
       "      <td>0.934667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34589 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power  \\\n",
       "dt                                                                \n",
       "2006-12-16 17:00:00             4.222889               0.229000   \n",
       "2006-12-16 18:00:00             3.632200               0.080033   \n",
       "2006-12-16 19:00:00             3.400233               0.085233   \n",
       "2006-12-16 20:00:00             3.268567               0.075100   \n",
       "2006-12-16 21:00:00             3.056467               0.076667   \n",
       "...                                  ...                    ...   \n",
       "2010-11-26 17:00:00             1.725900               0.061400   \n",
       "2010-11-26 18:00:00             1.573467               0.053700   \n",
       "2010-11-26 19:00:00             1.659333               0.060033   \n",
       "2010-11-26 20:00:00             1.163700               0.061167   \n",
       "2010-11-26 21:00:00             0.934667               0.000000   \n",
       "\n",
       "                     Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
       "dt                                                                   \n",
       "2006-12-16 17:00:00             0.0            19.0           607.0  \n",
       "2006-12-16 18:00:00             0.0           403.0          1012.0  \n",
       "2006-12-16 19:00:00             0.0            86.0          1001.0  \n",
       "2006-12-16 20:00:00             0.0             0.0          1007.0  \n",
       "2006-12-16 21:00:00             0.0            25.0          1033.0  \n",
       "...                             ...             ...             ...  \n",
       "2010-11-26 17:00:00             0.0             0.0           772.0  \n",
       "2010-11-26 18:00:00             0.0             0.0             0.0  \n",
       "2010-11-26 19:00:00             0.0             4.0             0.0  \n",
       "2010-11-26 20:00:00             0.0            64.0             0.0  \n",
       "2010-11-26 21:00:00             0.0             0.0             0.0  \n",
       "\n",
       "[34589 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. hours to forecast\n",
    "n_forecasts = 8\n",
    "\n",
    "# Amount of sequences that the data will be split into\n",
    "n_steps = 21\n",
    "\n",
    "# Amount of hours per sequence\n",
    "n_length = 24\n",
    "\n",
    "# Amount of features in dataset\n",
    "n_features = len(df_resample.columns)\n",
    "\n",
    "# determines how much data is used to forecast (currently using a week of data per row)\n",
    "n_input = n_steps * n_length\n",
    "\n",
    "# determines whether we're going to train or evaluate an existing model\n",
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a few hours of time, validate if model isn't inaccurate due to an anomaly in the data\n",
    "# df_resample = df_resample[:-8]\n",
    "\n",
    "df_future = df_resample[-n_forecasts:]\n",
    "df_pred = df_resample[-n_input*n_features:]\n",
    "df_resample = df_resample[:-n_forecasts]\n",
    "\n",
    "train, test = train_test_split(df_resample.values, test_size=.2, shuffle=False, stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_ellesmere.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27153 samples, validate on 6406 samples\n",
      "Epoch 1/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 729 of 3024 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 2314 of 3024 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27136/27153 [============================>.] - ETA: 0s - loss: 1.2805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 615 of 3024 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 2245 of 3024 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 684 of 1285 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 768 of 1285 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27153/27153 [==============================] - 80s 3ms/step - loss: 1.2800 - val_loss: 0.5787\n",
      "Epoch 2/750\n",
      "27153/27153 [==============================] - 16s 597us/step - loss: 0.9423 - val_loss: 0.6311\n",
      "Epoch 3/750\n",
      "27153/27153 [==============================] - 17s 610us/step - loss: 0.9484 - val_loss: 0.6493\n",
      "Epoch 4/750\n",
      "27153/27153 [==============================] - 17s 634us/step - loss: 0.9360 - val_loss: 0.5063\n",
      "Epoch 5/750\n",
      "27153/27153 [==============================] - 17s 638us/step - loss: 0.8648 - val_loss: 0.5356\n",
      "Epoch 6/750\n",
      "27153/27153 [==============================] - 17s 640us/step - loss: 0.8375 - val_loss: 0.5185\n",
      "Epoch 7/750\n",
      "27153/27153 [==============================] - 16s 596us/step - loss: 0.8044 - val_loss: 0.5018\n",
      "Epoch 8/750\n",
      "27153/27153 [==============================] - 16s 593us/step - loss: 0.7721 - val_loss: 0.5048\n",
      "Epoch 9/750\n",
      "27153/27153 [==============================] - 16s 592us/step - loss: 0.7359 - val_loss: 0.5122\n",
      "Epoch 10/750\n",
      "27153/27153 [==============================] - 16s 591us/step - loss: 0.7021 - val_loss: 0.5206\n",
      "Epoch 11/750\n",
      "27153/27153 [==============================] - 16s 598us/step - loss: 0.6736 - val_loss: 0.5228\n",
      "Epoch 12/750\n",
      "27153/27153 [==============================] - 16s 595us/step - loss: 0.6682 - val_loss: 0.5034\n",
      "Epoch 13/750\n",
      "27153/27153 [==============================] - 16s 595us/step - loss: 0.6635 - val_loss: 0.4730\n",
      "Epoch 14/750\n",
      "27153/27153 [==============================] - 16s 593us/step - loss: 0.6300 - val_loss: 0.4880\n",
      "Epoch 15/750\n",
      "27153/27153 [==============================] - 16s 592us/step - loss: 0.6021 - val_loss: 0.4897\n",
      "Epoch 16/750\n",
      "27153/27153 [==============================] - 16s 593us/step - loss: 0.5807 - val_loss: 0.5281\n",
      "Epoch 17/750\n",
      "27153/27153 [==============================] - 16s 599us/step - loss: 0.6199 - val_loss: 0.5324\n",
      "Epoch 18/750\n",
      "27153/27153 [==============================] - 16s 597us/step - loss: 0.6612 - val_loss: 0.4773\n",
      "Epoch 19/750\n",
      "27153/27153 [==============================] - 16s 596us/step - loss: 0.5867 - val_loss: 0.4571\n",
      "Epoch 20/750\n",
      "27153/27153 [==============================] - 16s 599us/step - loss: 0.5696 - val_loss: 0.4902\n",
      "Epoch 21/750\n",
      "27153/27153 [==============================] - 16s 599us/step - loss: 0.5328 - val_loss: 0.4477\n",
      "Epoch 22/750\n",
      "27153/27153 [==============================] - 16s 603us/step - loss: 0.5114 - val_loss: 0.4673\n",
      "Epoch 23/750\n",
      "27153/27153 [==============================] - 16s 596us/step - loss: 0.5229 - val_loss: 0.5192\n",
      "Epoch 24/750\n",
      "27153/27153 [==============================] - 16s 603us/step - loss: 0.5306 - val_loss: 0.4556\n",
      "Epoch 25/750\n",
      "27153/27153 [==============================] - 16s 597us/step - loss: 0.4718 - val_loss: 0.5504\n",
      "\n",
      "Epoch 00025: loss improved from inf to 0.47177, saving model to convmodelcheckpoint.hdf5\n",
      "Epoch 26/750\n",
      "27153/27153 [==============================] - 16s 596us/step - loss: 0.5207 - val_loss: 0.5688\n",
      "Epoch 27/750\n",
      "27153/27153 [==============================] - 16s 606us/step - loss: 0.5445 - val_loss: 0.4474\n",
      "Epoch 28/750\n",
      "27153/27153 [==============================] - 16s 595us/step - loss: 0.4558 - val_loss: 0.4739\n",
      "Epoch 29/750\n",
      "27153/27153 [==============================] - 16s 591us/step - loss: 0.4397 - val_loss: 0.6891\n",
      "Epoch 30/750\n",
      "27153/27153 [==============================] - 16s 591us/step - loss: 0.4317 - val_loss: 0.5907\n",
      "Epoch 31/750\n",
      "27153/27153 [==============================] - 16s 591us/step - loss: 0.4060 - val_loss: 0.7132\n",
      "Epoch 32/750\n",
      "27153/27153 [==============================] - 16s 591us/step - loss: 0.4062 - val_loss: 0.6253\n",
      "Epoch 33/750\n",
      "27153/27153 [==============================] - 16s 596us/step - loss: 0.4227 - val_loss: 0.5615\n",
      "Epoch 34/750\n",
      "27153/27153 [==============================] - 16s 599us/step - loss: 0.4872 - val_loss: 0.4945\n",
      "Epoch 35/750\n",
      "27153/27153 [==============================] - 16s 604us/step - loss: 0.5120 - val_loss: 0.4446\n",
      "Epoch 36/750\n",
      "27153/27153 [==============================] - 16s 602us/step - loss: 0.3992 - val_loss: 0.4334\n",
      "Epoch 37/750\n",
      "27153/27153 [==============================] - 16s 594us/step - loss: 0.3947 - val_loss: 0.5055\n",
      "Epoch 38/750\n",
      "27153/27153 [==============================] - 16s 598us/step - loss: 0.3994 - val_loss: 0.4884\n",
      "Epoch 39/750\n",
      "27153/27153 [==============================] - 16s 595us/step - loss: 0.4293 - val_loss: 0.5938\n",
      "Epoch 40/750\n",
      "27153/27153 [==============================] - 16s 598us/step - loss: 0.4215 - val_loss: 0.5555\n",
      "Epoch 41/750\n",
      "27153/27153 [==============================] - 16s 597us/step - loss: 0.3629 - val_loss: 0.5096\n",
      "Epoch 42/750\n",
      "27153/27153 [==============================] - 16s 597us/step - loss: 0.3622 - val_loss: 0.4664\n",
      "Epoch 43/750\n",
      "27153/27153 [==============================] - 16s 602us/step - loss: 0.3801 - val_loss: 0.4438\n",
      "Epoch 44/750\n",
      "27153/27153 [==============================] - 16s 598us/step - loss: 0.3725 - val_loss: 0.4506\n",
      "Epoch 45/750\n",
      "27153/27153 [==============================] - 16s 592us/step - loss: 0.3457 - val_loss: 0.4524\n",
      "Epoch 46/750\n",
      "27153/27153 [==============================] - 16s 596us/step - loss: 0.3498 - val_loss: 0.5643\n",
      "Epoch 47/750\n",
      "27153/27153 [==============================] - 16s 595us/step - loss: 0.3574 - val_loss: 0.5448\n",
      "Epoch 48/750\n",
      "27153/27153 [==============================] - 16s 597us/step - loss: 0.3611 - val_loss: 0.4584\n",
      "Epoch 49/750\n",
      "27153/27153 [==============================] - 16s 597us/step - loss: 0.3880 - val_loss: 0.5128\n",
      "Epoch 50/750\n",
      "27153/27153 [==============================] - 16s 597us/step - loss: 0.3878 - val_loss: 0.4632\n",
      "\n",
      "Epoch 00050: loss improved from 0.47177 to 0.38780, saving model to convmodelcheckpoint.hdf5\n",
      "Epoch 51/750\n",
      "27153/27153 [==============================] - 16s 593us/step - loss: 0.3477 - val_loss: 0.4410\n",
      "Epoch 52/750\n",
      "27153/27153 [==============================] - 16s 593us/step - loss: 0.3903 - val_loss: 0.5153\n",
      "Epoch 53/750\n",
      "27153/27153 [==============================] - 16s 597us/step - loss: 0.3505 - val_loss: 0.4396\n",
      "Epoch 54/750\n",
      "27153/27153 [==============================] - 16s 599us/step - loss: 0.3160 - val_loss: 0.4448\n",
      "Epoch 55/750\n",
      "27153/27153 [==============================] - 16s 597us/step - loss: 0.3041 - val_loss: 0.5092\n",
      "Epoch 56/750\n",
      "27153/27153 [==============================] - 16s 593us/step - loss: 0.2989 - val_loss: 0.4819\n",
      "Epoch 57/750\n",
      "27153/27153 [==============================] - 16s 592us/step - loss: 0.3193 - val_loss: 0.4753\n",
      "Epoch 58/750\n",
      "27153/27153 [==============================] - 16s 595us/step - loss: 0.3073 - val_loss: 0.4990\n",
      "Epoch 59/750\n",
      "27153/27153 [==============================] - 16s 598us/step - loss: 0.3166 - val_loss: 0.6273\n",
      "Epoch 60/750\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6ecc67b530b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m750\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tanh'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-26156a4a22f4>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(data, n_steps, n_length, n_input, params)\u001b[0m\n\u001b[0;32m     51\u001b[0m     save_best_only=True, mode='auto', period=n_checkpoint)\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWandbCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Dev-Tools\\envs\\amdlstm\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mF:\\Dev-Tools\\envs\\amdlstm\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Dev-Tools\\envs\\amdlstm\\lib\\site-packages\\plaidml\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invoker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Dev-Tools\\envs\\amdlstm\\lib\\site-packages\\plaidml\\keras\\backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invoker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Dev-Tools\\envs\\amdlstm\\lib\\site-packages\\plaidml\\__init__.py\u001b[0m in \u001b[0;36mas_ndarray\u001b[1;34m(self, ctx)\u001b[0m\n\u001b[0;32m   1279\u001b[0m             self._ndarray = np.ndarray(tuple(dim.size for dim in self.shape.dimensions),\n\u001b[0;32m   1280\u001b[0m                                        dtype=_NP_TYPES[self.shape.dtype])\n\u001b[1;32m-> 1281\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmmap_current\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1282\u001b[0m             \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_to_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Dev-Tools\\envs\\amdlstm\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Dev-Tools\\envs\\amdlstm\\lib\\site-packages\\plaidml\\__init__.py\u001b[0m in \u001b[0;36mmmap_current\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmmap_current\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         mapping = _lib().plaidml_map_buffer_current(self.buffer,\n\u001b[1;32m-> 1265\u001b[1;33m                                                     ctypes.cast(None, _MAP_BUFFER_FUNCTYPE), None)\n\u001b[0m\u001b[0;32m   1266\u001b[0m         yield _View(self.buffer._ctx, mapping, self.shape.dtype, self.shape.ctype,\n\u001b[0;32m   1267\u001b[0m                     _lib().plaidml_get_shape_element_count(self.shape), self.shape, None)\n",
      "\u001b[1;32mF:\\Dev-Tools\\envs\\amdlstm\\lib\\site-packages\\plaidml\\__init__.py\u001b[0m in \u001b[0;36m_check_err\u001b[1;34m(self, result, func, args)\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaidml_compute_grad_wrt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 770\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_err\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    771\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if training:\n",
    "    data = [train, test]\n",
    "\n",
    "    # params = [epochs, batch_size, verbose, learning_rate, n_checkpoint, activation_function]\n",
    "    params = [750, 512, 1, 0.001, 25, 'tanh']\n",
    "\n",
    "    model = build_model(data, n_steps, n_length, n_input, params)\n",
    "\n",
    "else:\n",
    "    model = load_model('convmodelcheckpoint.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting & Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1b43b57ea725>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Forecast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfuture_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = np.array([x for x in train])\n",
    "\n",
    "# Forecast\n",
    "pred = forecast(model, history, n_steps, n_length, n_input*n_features, n_features)\n",
    "future_pred = forecast(model, df_pred, n_steps, n_length, n_input*n_features, n_features)\n",
    "\n",
    "# Visualize\n",
    "visualize_forecast(df, df_pred, df_future, pred, future_pred, n_input, n_forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
